Namespace(log_name='./tfix/1/hard0_gptneo.log', model_name='EleutherAI/gpt-neo-1.3B', lang='javascript', output_dir='tfix/1/hard0_gptneo', data_dir='./data/tfix/1', no_cuda=False, visible_gpu='0', num_train_epochs=10, num_test_epochs=1, train_batch_size=6, eval_batch_size=4, gradient_accumulation_steps=1, load_model_path=None, config_name='', tokenizer_name='', max_source_length=1024, max_target_length=1024, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, freeze=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
Model created!!
[[{'text': "}             console.log('retry');             return setTimeout(function() {               return exports.stopReplication(newdoc, callback, options);", 'loss_ids': 0, 'shortenable_ids': 1}, {'text': '<mask>', 'loss_ids': 1, 'shortenable_ids': 0}, {'text': ' is the fixed version', 'loss_ids': 0, 'shortenable_ids': 0}], {'guid': 0, 'tgt_text': '}             setTimeout(function() {               return exports.stopReplication(newdoc, callback, options);'}]
***** Running training *****
  Num examples = 816
  Batch size = 6
  Num epoch = 10

***** Running evaluation *****
  Num examples = 104
  Batch size = 4
  epoch = 0
  eval_ppl = 6.829794592602607e+27
  global_step = 137
  train_loss = 28.9086
  ********************
Previous best ppl:inf
Achieve Best ppl:6.829794592602607e+27
  ********************
BLEU file: ./data/tfix/1/validation.jsonl
  codebleu-4 = 39.16 	 Previous best codebleu 0
  ********************
 Achieve Best bleu:39.16
  ********************

***** Running evaluation *****
  Num examples = 104
  Batch size = 4
  epoch = 1
  eval_ppl = 1.8995580964195365e+35
  global_step = 273
  train_loss = 9.4664
  ********************
Previous best ppl:6.829794592602607e+27
BLEU file: ./data/tfix/1/validation.jsonl
  codebleu-4 = 43.48 	 Previous best codebleu 39.16
  ********************
 Achieve Best bleu:43.48
  ********************

***** Running evaluation *****
  Num examples = 104
  Batch size = 4
  epoch = 2
  eval_ppl = 3.1637218720434006e+38
  global_step = 409
  train_loss = 4.7102
  ********************
Previous best ppl:6.829794592602607e+27
BLEU file: ./data/tfix/1/validation.jsonl
  codebleu-4 = 36.57 	 Previous best codebleu 43.48
  ********************

***** Running evaluation *****
  Num examples = 104
  Batch size = 4
  epoch = 3
  eval_ppl = 1.56681714046532e+45
  global_step = 545
  train_loss = 2.6917
  ********************
Previous best ppl:6.829794592602607e+27
BLEU file: ./data/tfix/1/validation.jsonl
  codebleu-4 = 46.5 	 Previous best codebleu 43.48
  ********************
 Achieve Best bleu:46.5
  ********************

***** Running evaluation *****
  Num examples = 104
  Batch size = 4
  epoch = 4
  eval_ppl = 1.0257623088505859e+45
  global_step = 681
  train_loss = 1.8844
  ********************
Previous best ppl:6.829794592602607e+27
BLEU file: ./data/tfix/1/validation.jsonl
  codebleu-4 = 38.78 	 Previous best codebleu 46.5
  ********************

***** Running evaluation *****
  Num examples = 104
  Batch size = 4
  epoch = 5
  eval_ppl = 3.9814455780188566e+41
  global_step = 817
  train_loss = 1.0627
  ********************
Previous best ppl:6.829794592602607e+27
BLEU file: ./data/tfix/1/validation.jsonl
  codebleu-4 = 37.24 	 Previous best codebleu 46.5
  ********************

***** Running evaluation *****
  Num examples = 104
  Batch size = 4
  epoch = 6
  eval_ppl = 9.964345206038956e+48
  global_step = 953
  train_loss = 0.7481
  ********************
Previous best ppl:6.829794592602607e+27
BLEU file: ./data/tfix/1/validation.jsonl
  codebleu-4 = 37.17 	 Previous best codebleu 46.5
  ********************
early stopping!!!
reload model from tfix/1/hard0_gptneo/checkpoint-best-bleu
BLEU file: ./data/tfix/1/test.jsonl
  codebleu = 45.3 
  Total = 102 
  Exact Fixed = 5 
[35, 48, 51, 75, 87]
  Syntax Fixed = 1 
[58]
  Cleaned Fixed = 1 
[94]
  ********************
  Total = 102 
  Exact Fixed = 5 
[35, 48, 51, 75, 87]
  Syntax Fixed = 1 
[58]
  Cleaned Fixed = 1 
[94]
  codebleu = 45.3 
[0.2566729561669729, 0.4967900328493899, 0.7004836662820749, 0.13648416659938517, 0.2553082743436026, 0.22435062043080078, 0.26654794717850877, 0.1526580048024106, 0.06457310975581983, 0.8292906179772745, 0.2608206201870649, 0.2420128528564776, 0.5103531162233399, 0.01658583218475363, 0.8135156937118506, 0.7473415251512424, 0.5814500037030309, 0.6898304277609075, 0.563809860874553, 0.33985271067894746, 0.44892910504357597, 0.23422440897598656, 0.8600057888291379, 0.8576705057568643, 0.0, 0.7750913490042128, 0.02858907581543893, 0.4803129292356597, 0.34781611561323333, 0.7394510428523452, 0.8253360085481802, 0.24901106681427945, 0.45382932791485, 0.048673336444466045, 1.0, 0.5634793392274073, 0.6013783503393001, 0.34650852962940437, 0.19604350080247962, 0.8785292391564288, 0.05798050218603332, 0.2235465245931641, 0.7436225501279194, 0.4280052104264289, 0.5879941066816083, 0.32399596751803067, 0.8519671371303186, 1.0, 0.2728785751316023, 0.6536911179244789, 1.0, 0.5832455434549282, 0.3246427176342437, 0.10284267257273938, 0.03663264913220278, 0.5420452353767158, 0.7486220455892145, 0.8206847188488577, 0.0, 0.1365216247957611, 0.6017744948163395, 0.32195172236752656, 0.11791190992133252, 0.17474116218836824, 0.6863884298635612, 0.9030431039697613, 0.3666066273203391, 0.4749522094634192, 0.02913215362273379, 0.5678248603938719, 0.7153975897893075, 0.20376503858638684, 0.03194910810933169, 0.9506366652618288, 0.7135428903906851, 0.5340940751703782, 0.30210726146061034, 0.34626482923029533, 0.286725907639884, 0.28427822208425985, 0.565282441442665, 0.38179922752414186, 0.33985271067894746, 0.5506612535515883, 0.7302007404183433, 0.02729845266723499, 1.0, 0.171298791626338, 0.0, 0.08468113611762511, 0.7519671371303185, 0.09335468267331219, 0.4477510935629318, 0.4412677697612789, 0.2666945783462008, 0.4859699405327176, 0.5810546380512305, 0.5845342693556176, 0.7527760267190626, 0.5647785789898024, 0.51807342599011, 0.7308647096337427]
Finish training and take 2h40m

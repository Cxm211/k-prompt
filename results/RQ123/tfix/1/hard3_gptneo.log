Namespace(log_name='./tfix/1/hard3_gptneo.log', model_name='EleutherAI/gpt-neo-1.3B', lang='javascript', output_dir='tfix/1/hard3_gptneo', data_dir='./data/tfix/1', no_cuda=False, visible_gpu='0', num_train_epochs=10, num_test_epochs=1, train_batch_size=6, eval_batch_size=4, gradient_accumulation_steps=1, load_model_path=None, config_name='', tokenizer_name='', max_source_length=1024, max_target_length=1024, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, freeze=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
Model created!!
[[{'text': 'Fix', 'loss_ids': 0, 'shortenable_ids': 0}, {'text': " }             console.log('retry');             return setTimeout(function() {               return exports.stopReplication(newdoc, callback, options);", 'loss_ids': 0, 'shortenable_ids': 1}, {'text': ' fixed program is', 'loss_ids': 0, 'shortenable_ids': 0}, {'text': '<mask>', 'loss_ids': 1, 'shortenable_ids': 0}], {'guid': 0, 'tgt_text': '}             setTimeout(function() {               return exports.stopReplication(newdoc, callback, options);'}]
***** Running training *****
  Num examples = 816
  Batch size = 6
  Num epoch = 10

***** Running evaluation *****
  Num examples = 104
  Batch size = 4
  epoch = 0
  eval_ppl = 7.739500656361946e+61
  global_step = 137
  train_loss = 24.593
  ********************
Previous best ppl:inf
Achieve Best ppl:7.739500656361946e+61
  ********************
BLEU file: ./data/tfix/1/validation.jsonl
  codebleu-4 = 54.05 	 Previous best codebleu 0
  ********************
 Achieve Best bleu:54.05
  ********************

***** Running evaluation *****
  Num examples = 104
  Batch size = 4
  epoch = 1
  eval_ppl = 3.35965563922682e+67
  global_step = 273
  train_loss = 8.3446
  ********************
Previous best ppl:7.739500656361946e+61
BLEU file: ./data/tfix/1/validation.jsonl
  codebleu-4 = 59.27 	 Previous best codebleu 54.05
  ********************
 Achieve Best bleu:59.27
  ********************

***** Running evaluation *****
  Num examples = 104
  Batch size = 4
  epoch = 2
  eval_ppl = 1.685176506769343e+80
  global_step = 409
  train_loss = 3.8645
  ********************
Previous best ppl:7.739500656361946e+61
BLEU file: ./data/tfix/1/validation.jsonl
  codebleu-4 = 56.95 	 Previous best codebleu 59.27
  ********************

***** Running evaluation *****
  Num examples = 104
  Batch size = 4
  epoch = 3
  eval_ppl = 9.946330753350133e+80
  global_step = 545
  train_loss = 2.5945
  ********************
Previous best ppl:7.739500656361946e+61
BLEU file: ./data/tfix/1/validation.jsonl
  codebleu-4 = 63.12 	 Previous best codebleu 59.27
  ********************
 Achieve Best bleu:63.12
  ********************

***** Running evaluation *****
  Num examples = 104
  Batch size = 4
  epoch = 4
  eval_ppl = 8.919638819874714e+94
  global_step = 681
  train_loss = 1.5528
  ********************
Previous best ppl:7.739500656361946e+61
BLEU file: ./data/tfix/1/validation.jsonl
  codebleu-4 = 60.98 	 Previous best codebleu 63.12
  ********************

***** Running evaluation *****
  Num examples = 104
  Batch size = 4
  epoch = 5
  eval_ppl = 1.383824256139437e+114
  global_step = 817
  train_loss = 0.768
  ********************
Previous best ppl:7.739500656361946e+61
BLEU file: ./data/tfix/1/validation.jsonl
  codebleu-4 = 61.37 	 Previous best codebleu 63.12
  ********************

***** Running evaluation *****
  Num examples = 104
  Batch size = 4
  epoch = 6
  eval_ppl = 2.912583191163598e+107
  global_step = 953
  train_loss = 0.558
  ********************
Previous best ppl:7.739500656361946e+61
BLEU file: ./data/tfix/1/validation.jsonl
  codebleu-4 = 61.74 	 Previous best codebleu 63.12
  ********************
early stopping!!!
reload model from tfix/1/hard3_gptneo/checkpoint-best-bleu
BLEU file: ./data/tfix/1/test.jsonl
  codebleu = 59.92 
  Total = 102 
  Exact Fixed = 12 
[13, 31, 48, 51, 71, 74, 76, 87, 88, 94, 96, 101]
  Syntax Fixed = 1 
[1]
  Cleaned Fixed = 0 
[]
  ********************
  Total = 102 
  Exact Fixed = 12 
[13, 31, 48, 51, 71, 74, 76, 87, 88, 94, 96, 101]
  Syntax Fixed = 1 
[1]
  Cleaned Fixed = 0 
[]
  codebleu = 59.92 
[0.8325722947872878, 0.4967900328493899, 0.7004836662820749, 0.16098557679715664, 0.2553082743436026, 0.2642742735155721, 0.29475535030961264, 0.10100550846996653, 0.21100892280323053, 0.8292906179772745, 0.3468834488862323, 0.2420128528564776, 1.0, 0.7939024427877673, 0.8135156937118506, 0.7484889150381644, 0.39675296426202156, 0.7886150441973765, 0.44188182488281347, 0.08869475457310907, 0.44892910504357597, 0.28178507258525926, 0.8600057888291379, 0.8576705057568643, 0.6887796716807859, 0.6760988306532816, 0.6475259120949215, 0.45797584845834727, 0.524532722596649, 0.8206847188488577, 1.0, 0.8191441569283882, 0.7945104051684668, 0.6425606282133942, 0.762178754714643, 0.5634793392274073, 0.17985270659092473, 0.18304611372110685, 0.19604350080247962, 0.7722223533473194, 0.41319634811214473, 0.20167918995135747, 0.9260406910477721, 0.6632483116950204, 0.5879941066816083, 0.9495565333799167, 0.8519671371303186, 1.0, 0.30261367609768847, 0.6536911179244789, 1.0, 0.6157132877459149, 0.1411318975303395, 0.48492549020055464, 0.35079151194213914, 0.6957460976726255, 0.7486220455892145, 0.6863884298635612, 0.6322779524395602, 0.5687200050839125, 0.9028613863364825, 0.48275522335035304, 0.70282341775094, 0.6438231263082419, 0.6124841953096521, 0.8236880127335535, 0.6666353826339045, 0.8536186510818744, 0.5418035126585234, 0.6074288437275981, 1.0, 0.20376503858638684, 0.4713916418700911, 1.0, 0.23683637774429345, 1.0, 0.5624691290169025, 0.44432121517125955, 0.7753505981191169, 0.42956336497580716, 0.6236663076766358, 0.39440783664608325, 0.1726076513306138, 0.5506612535515883, 0.46450187841569407, 0.4356258328835842, 1.0, 1.0, 0.0, 0.5226201535422986, 0.7519671371303185, 0.32429671174355323, 0.8339326133501213, 1.0, 0.5696461788443421, 1.0, 0.43605468697269356, 0.4874588289842097, 0.8533854401872718, 0.5454272614803233, 1.0, 0.7308647096337427]
Finish training and take 46m

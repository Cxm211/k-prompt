Namespace(log_name='./tfix/1/hard2_gptneo.log', model_name='EleutherAI/gpt-neo-1.3B', lang='javascript', output_dir='tfix/1/hard2_gptneo', data_dir='./data/tfix/1', no_cuda=False, visible_gpu='0', num_train_epochs=10, num_test_epochs=1, train_batch_size=6, eval_batch_size=4, gradient_accumulation_steps=1, load_model_path=None, config_name='', tokenizer_name='', max_source_length=1024, max_target_length=1024, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, freeze=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
Model created!!
[[{'text': 'Fix the bug in', 'loss_ids': 0, 'shortenable_ids': 0}, {'text': " }             console.log('retry');             return setTimeout(function() {               return exports.stopReplication(newdoc, callback, options);", 'loss_ids': 0, 'shortenable_ids': 1}, {'text': '<mask>', 'loss_ids': 1, 'shortenable_ids': 0}], {'guid': 0, 'tgt_text': '}             setTimeout(function() {               return exports.stopReplication(newdoc, callback, options);'}]
***** Running training *****
  Num examples = 816
  Batch size = 6
  Num epoch = 10

***** Running evaluation *****
  Num examples = 104
  Batch size = 4
  epoch = 0
  eval_ppl = 1.8711640695394537e+35
  global_step = 137
  train_loss = 28.0126
  ********************
Previous best ppl:inf
Achieve Best ppl:1.8711640695394537e+35
  ********************
BLEU file: ./data/tfix/1/validation.jsonl
  codebleu-4 = 51.88 	 Previous best codebleu 0
  ********************
 Achieve Best bleu:51.88
  ********************

***** Running evaluation *****
  Num examples = 104
  Batch size = 4
  epoch = 1
  eval_ppl = 1.4067181893017494e+35
  global_step = 273
  train_loss = 8.9182
  ********************
Previous best ppl:1.8711640695394537e+35
Achieve Best ppl:1.4067181893017494e+35
  ********************
BLEU file: ./data/tfix/1/validation.jsonl
  codebleu-4 = 59.29 	 Previous best codebleu 51.88
  ********************
 Achieve Best bleu:59.29
  ********************

***** Running evaluation *****
  Num examples = 104
  Batch size = 4
  epoch = 2
  eval_ppl = 9.433442076493134e+49
  global_step = 409
  train_loss = 3.9977
  ********************
Previous best ppl:1.4067181893017494e+35
BLEU file: ./data/tfix/1/validation.jsonl
  codebleu-4 = 58.35 	 Previous best codebleu 59.29
  ********************

***** Running evaluation *****
  Num examples = 104
  Batch size = 4
  epoch = 3
  eval_ppl = 4.234079708229091e+46
  global_step = 545
  train_loss = 2.9163
  ********************
Previous best ppl:1.4067181893017494e+35
BLEU file: ./data/tfix/1/validation.jsonl
  codebleu-4 = 57.51 	 Previous best codebleu 59.29
  ********************

***** Running evaluation *****
  Num examples = 104
  Batch size = 4
  epoch = 4
  eval_ppl = 3.4476304413398083e+53
  global_step = 681
  train_loss = 2.1125
  ********************
Previous best ppl:1.4067181893017494e+35
BLEU file: ./data/tfix/1/validation.jsonl
  codebleu-4 = 59.21 	 Previous best codebleu 59.29
  ********************
early stopping!!!
reload model from tfix/1/hard2_gptneo/checkpoint-best-bleu
BLEU file: ./data/tfix/1/test.jsonl
  codebleu = 56.39 
  Total = 102 
  Exact Fixed = 16 
[1, 10, 31, 35, 38, 48, 51, 61, 74, 77, 81, 86, 87, 94, 96, 101]
  Syntax Fixed = 2 
[53, 73]
  Cleaned Fixed = 0 
[]
  ********************
  Total = 102 
  Exact Fixed = 16 
[1, 10, 31, 35, 38, 48, 51, 61, 74, 77, 81, 86, 87, 94, 96, 101]
  Syntax Fixed = 2 
[53, 73]
  Cleaned Fixed = 0 
[]
  codebleu = 56.39 
[1.0, 0.4967900328493899, 0.7004836662820749, 0.15189466770624754, 0.3, 0.2642742735155721, 0.29475535030961264, 0.10100550846996653, 0.21100892280323053, 1.0, 0.23082062018706495, 0.2420128528564776, 0.9086120873561849, 0.7939024427877673, 0.8135156937118506, 0.7484889150381644, 0.39675296426202156, 0.5381816623263027, 0.42001980886334833, 0.14638382931137245, 0.41305892241029163, 0.28178507258525926, 0.8600057888291379, 0.6652806635996642, 0.6887796716807859, 0.3275542061046039, 0.01285068336749773, 0.567449215368204, 0.570765580121347, 0.41967738030894663, 1.0, 0.6337131054697118, 0.7945104051684668, 0.8033946307914341, 1.0, 0.5634793392274073, 0.17985270659092473, 0.8249365300761395, 0.19604350080247962, 0.8946995933494386, 0.4202172177276029, 0.19021319125983077, 0.9260406910477721, 0.8035629301801026, 0.7619728098941201, 0.31404997219036945, 0.8519671371303186, 1.0, 0.30261367609768847, 0.04535576197454044, 1.0, 0.6157132877459149, 0.9236426846280885, 0.09748767635103976, 0.3451645181513808, 0.5420452353767158, 0.7486220455892145, 0.6863884298635612, 0.6871418250096928, 0.7943177463241642, 1.0, 0.3030087878967419, 0.33053343240934024, 0.6438231263082419, 0.2270922207242445, 0.5477330160464497, 0.6666353826339045, 0.4972834292954561, 0.5418035126585234, 0.5698756855382361, 0.5325637969383594, 0.20376503858638684, 0.6420252005580777, 1.0, 0.23683637774429345, 0.5479955727207041, 1.0, 0.3608053910343927, 0.7753505981191169, 0.42956336497580716, 0.6565560801010174, 0.38179922752414186, 0.1726076513306138, 0.662969428781041, 0.46450187841569407, 1.0, 1.0, 0.3859074150199997, 0.0, 0.15627169018988432, 0.7519671371303185, 0.32429671174355323, 0.8339326133501213, 1.0, 0.5638567901034828, 1.0, 0.43605468697269356, 0.6241223232336472, 0.8031325383647965, 0.0, 1.0, 0.7308647096337427]
Finish training and take 42m

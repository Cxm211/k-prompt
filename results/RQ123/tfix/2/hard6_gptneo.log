Namespace(log_name='./tfix/2/hard6_gptneo.log', model_name='EleutherAI/gpt-neo-1.3B', lang='javascript', output_dir='tfix/2/hard6_gptneo', data_dir='./data/tfix/2', no_cuda=False, visible_gpu='0', num_train_epochs=10, num_test_epochs=1, train_batch_size=6, eval_batch_size=4, gradient_accumulation_steps=1, load_model_path=None, config_name='', tokenizer_name='', max_source_length=1024, max_target_length=1024, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, freeze=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
Model created!!
[[{'text': 'Fix', 'loss_ids': 0, 'shortenable_ids': 0}, {'text': ' var rows = [   {', 'loss_ids': 0, 'shortenable_ids': 1}, {'text': ' is buggy program', 'loss_ids': 0, 'shortenable_ids': 0}, {'text': '<mask>', 'loss_ids': 1, 'shortenable_ids': 0}, {'text': ' is fixed program', 'loss_ids': 0, 'shortenable_ids': 0}], {'guid': 0, 'tgt_text': 'const rows2 = [   {'}]
***** Running training *****
  Num examples = 816
  Batch size = 6
  Num epoch = 10

***** Running evaluation *****
  Num examples = 104
  Batch size = 4
  epoch = 0
  eval_ppl = 5.06322441489815e+133
  global_step = 137
  train_loss = 25.6989
  ********************
Previous best ppl:inf
Achieve Best ppl:5.06322441489815e+133
  ********************
BLEU file: ./data/tfix/2/validation.jsonl
  codebleu-4 = 51.7 	 Previous best codebleu 0
  ********************
 Achieve Best bleu:51.7
  ********************

***** Running evaluation *****
  Num examples = 104
  Batch size = 4
  epoch = 1
  eval_ppl = 2.0237468606428515e+130
  global_step = 273
  train_loss = 8.2927
  ********************
Previous best ppl:5.06322441489815e+133
Achieve Best ppl:2.0237468606428515e+130
  ********************
BLEU file: ./data/tfix/2/validation.jsonl
  codebleu-4 = 36.51 	 Previous best codebleu 51.7
  ********************

***** Running evaluation *****
  Num examples = 104
  Batch size = 4
  epoch = 2
  eval_ppl = 1.7509156124739252e+154
  global_step = 409
  train_loss = 4.2145
  ********************
Previous best ppl:2.0237468606428515e+130
BLEU file: ./data/tfix/2/validation.jsonl
  codebleu-4 = 39.09 	 Previous best codebleu 51.7
  ********************

***** Running evaluation *****
  Num examples = 104
  Batch size = 4
  epoch = 3
  eval_ppl = 7.42557042411527e+148
  global_step = 545
  train_loss = 2.3279
  ********************
Previous best ppl:2.0237468606428515e+130
BLEU file: ./data/tfix/2/validation.jsonl
  codebleu-4 = 39.43 	 Previous best codebleu 51.7
  ********************

***** Running evaluation *****
  Num examples = 104
  Batch size = 4
  epoch = 4
  eval_ppl = 1.0172818205547029e+164
  global_step = 681
  train_loss = 1.4603
  ********************
Previous best ppl:2.0237468606428515e+130
BLEU file: ./data/tfix/2/validation.jsonl
  codebleu-4 = 39.19 	 Previous best codebleu 51.7
  ********************
early stopping!!!
reload model from tfix/2/hard6_gptneo/checkpoint-best-bleu
BLEU file: ./data/tfix/2/test.jsonl
  codebleu = 52.49 
  Total = 102 
  Exact Fixed = 7 
[1, 17, 20, 62, 72, 74, 101]
  Syntax Fixed = 1 
[86]
  Cleaned Fixed = 2 
[25, 49]
  ********************
  Total = 102 
  Exact Fixed = 7 
[1, 17, 20, 62, 72, 74, 101]
  Syntax Fixed = 1 
[86]
  Cleaned Fixed = 2 
[25, 49]
  codebleu = 52.49 
[0.7135428903906851, 0.5578356986646514, 0.3826217138922995, 0.9143879239397519, 0.22556796225712933, 0.7596762077491805, 0.8896656211648155, 0.15, 0.32380203712168054, 0.33168089319010624, 0.6281305065795061, 0.3051384298635612, 0.3119953379147749, 0.1685733388407632, 0.25381768513181713, 0.5718428761160813, 1.0, 0.204436274930823, 0.2651053789781871, 0.8114529051148651, 0.8356658099532572, 0.5118652648909756, 0.6317323658169088, 0.8568274699818503, 0.5129201452250265, 0.6618503204869636, 0.6887796716807859, 0.24899185857167744, 0.6683126818302856, 0.5465766960949332, 0.3, 0.7855975357012536, 0.28768306202699145, 0.5578356986646514, 0.5049117014141722, 0.8353746106262074, 0.09473684210526315, 0.6265958401383632, 0.2707237550189044, 0.7184551582052519, 0.269058848119273, 0.32628537216970693, 0.42900132829974075, 0.05540387552681966, 0.4813812026974435, 0.8836744861688364, 0.3358672877920396, 0.39688026803980914, 0.6016025790000775, 0.5462849490113114, 0.01012153685276734, 0.7533946307914341, 0.34650852962940437, 0.8342413207153518, 0.3599867812326072, 0.5220057692566522, 0.30348629561188384, 0.5129834344293507, 0.26516451815138076, 0.6416532852733938, 0.4080877117267552, 0.8114529051148651, 0.669523331245803, 0.5850991740430667, 0.6710084631280919, 0.7682378900570572, 0.5027616393658039, 0.2752675647941586, 0.46738580972137844, 0.45956165096503154, 0.5796767965195619, 1.0, 0.7049295406070389, 1.0, 0.4288378866864627, 0.47996086480687705, 0.6393949501703278, 0.4766582037659872, 0.41413939082855794, 0.27949857142944357, 0.1860325454791225, 0.3889423446181684, 0.2669760714518474, 0.1204193307271561, 0.8596354401872717, 0.9145980101874507, 0.8067815565982941, 0.5147391347384329, 0.3119953379147749, 0.6705289928112075, 0.3998629023055338, 0.6883751888738383, 0.6064788021120067, 0.5916622498901024, 0.5306696004934405, 0.4580097675218012, 0.2920847538048024, 0.5405880861150872, 0.3174271530921911, 0.7886150441973765, 1.0, 0.8783259097532135]
Finish training and take 1h58m

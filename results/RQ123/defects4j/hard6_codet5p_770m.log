Namespace(log_name='./defects4j/hard6_codet5p_770m.log', model_name='Salesforce/codet5p-770m', lang='java', output_dir='defects4j/hard6_codet5p_770m', data_dir='./data/defects4j', no_cuda=False, visible_gpu='0', num_train_epochs=10, num_test_epochs=1, train_batch_size=4, eval_batch_size=4, gradient_accumulation_steps=1, load_model_path=None, config_name='', tokenizer_name='', max_source_length=512, max_target_length=512, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, freeze=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
Model created!!
[[{'text': 'Fix', 'loss_ids': 0, 'shortenable_ids': 0}, {'text': ' static TernaryValue getImpureBooleanValue(Node n) {          return TernaryValue.TRUE;        default:          return getPureBooleanValue(n);', 'loss_ids': 0, 'shortenable_ids': 1}, {'text': ' is buggy program', 'loss_ids': 0, 'shortenable_ids': 0}, {'text': '<mask>', 'loss_ids': 1, 'shortenable_ids': 0}, {'text': ' is fixed program', 'loss_ids': 0, 'shortenable_ids': 0}], {'guid': 0, 'tgt_text': 'static TernaryValue getImpureBooleanValue(Node n) {          return TernaryValue.TRUE;       case Token.VOID:         return TernaryValue.FALSE;        default:          return getPureBooleanValue(n);'}]
***** Running training *****
  Num examples = 502
  Batch size = 4
  Num epoch = 10

***** Running evaluation *****
  Num examples = 64
  Batch size = 4
  epoch = 0
  eval_ppl = 2.3512047809295153e+234
  global_step = 127
  train_loss = 42.6871
  ********************
Previous best ppl:inf
Achieve Best ppl:2.3512047809295153e+234
  ********************
BLEU file: ./data/defects4j/validation.jsonl
  codebleu-4 = 77.86 	 Previous best codebleu 0
  ********************
 Achieve Best bleu:77.86
  ********************

***** Running evaluation *****
  Num examples = 64
  Batch size = 4
  epoch = 1
  eval_ppl = 2.976074671022999e+237
  global_step = 253
  train_loss = 23.7403
  ********************
Previous best ppl:2.3512047809295153e+234
BLEU file: ./data/defects4j/validation.jsonl
  codebleu-4 = 77.64 	 Previous best codebleu 77.86
  ********************

***** Running evaluation *****
  Num examples = 64
  Batch size = 4
  epoch = 2
  eval_ppl = 5.24348660343401e+222
  global_step = 379
  train_loss = 13.2297
  ********************
Previous best ppl:2.3512047809295153e+234
Achieve Best ppl:5.24348660343401e+222
  ********************
BLEU file: ./data/defects4j/validation.jsonl
  codebleu-4 = 78.12 	 Previous best codebleu 77.86
  ********************
 Achieve Best bleu:78.12
  ********************

***** Running evaluation *****
  Num examples = 64
  Batch size = 4
  epoch = 3
  eval_ppl = 1.405322715992881e+217
  global_step = 505
  train_loss = 7.271
  ********************
Previous best ppl:5.24348660343401e+222
Achieve Best ppl:1.405322715992881e+217
  ********************
BLEU file: ./data/defects4j/validation.jsonl
  codebleu-4 = 78.04 	 Previous best codebleu 78.12
  ********************

***** Running evaluation *****
  Num examples = 64
  Batch size = 4
  epoch = 4
  eval_ppl = 7.355019349135818e+215
  global_step = 631
  train_loss = 3.9093
  ********************
Previous best ppl:1.405322715992881e+217
Achieve Best ppl:7.355019349135818e+215
  ********************
BLEU file: ./data/defects4j/validation.jsonl
  codebleu-4 = 77.3 	 Previous best codebleu 78.12
  ********************

***** Running evaluation *****
  Num examples = 64
  Batch size = 4
  epoch = 5
  eval_ppl = 7.993866909338559e+218
  global_step = 757
  train_loss = 2.2951
  ********************
Previous best ppl:7.355019349135818e+215
BLEU file: ./data/defects4j/validation.jsonl
  codebleu-4 = 73.87 	 Previous best codebleu 78.12
  ********************

***** Running evaluation *****
  Num examples = 64
  Batch size = 4
  epoch = 6
  eval_ppl = 8.309458342139913e+223
  global_step = 883
  train_loss = 1.5239
  ********************
Previous best ppl:7.355019349135818e+215
BLEU file: ./data/defects4j/validation.jsonl
  codebleu-4 = 76.06 	 Previous best codebleu 78.12
  ********************

***** Running evaluation *****
  Num examples = 64
  Batch size = 4
  epoch = 7
  eval_ppl = 1.7621362224488987e+222
  global_step = 1009
  train_loss = 0.8768
  ********************
Previous best ppl:7.355019349135818e+215
BLEU file: ./data/defects4j/validation.jsonl
  codebleu-4 = 75.35 	 Previous best codebleu 78.12
  ********************
early stopping!!!
reload model from defects4j/hard6_codet5p_770m/checkpoint-best-bleu
BLEU file: ./data/defects4j/test.jsonl
  codebleu = 74.74 
  Total = 64 
  Exact Fixed = 5 
[17, 31, 32, 39, 55]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  ********************
  Total = 64 
  Exact Fixed = 5 
[17, 31, 32, 39, 55]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  codebleu = 74.74 
[0.7977509497997374, 0.8318588019770055, 0.541279037950266, 0.8870317711504849, 0.889761361495617, 0.6007163503048495, 0.6576252123917807, 0.8681777725936917, 0.7384479435491496, 0.8224642580186448, 0.7143513682140774, 0.22619152460591693, 0.8721125152975062, 0.877572165029932, 0.7967077170206054, 0.7369092647119393, 1.0, 0.8961434726030306, 0.9617720754477719, 0.8459463132957461, 0.7398507191925657, 0.6791333089230758, 0.7906925479531332, 0.8693059718827794, 0.8734502199950254, 0.863021098885395, 0.11589324508864053, 0.7694729472672909, 0.6410378892354339, 0.8899407308130634, 0.9224526824055446, 1.0, 0.7176189204658862, 0.8232523732318835, 0.8727340070600411, 0.7357035194721653, 0.8158461676559928, 0.7904665899488785, 0.9569487648577442, 0.6341247058119213, 0.7975058099066473, 0.3788321486588963, 0.8899407308130634, 0.3205070115741946, 0.6316733772548883, 0.6620374200206556, 0.8295509438760991, 0.8254084390841356, 0.8028172817807042, 0.8924644874204966, 0.8365049773284279, 0.8772101276126214, 0.8096645620006775, 0.6930827608711253, 0.9569487648577442, 0.5448048686005305, 0.5948576083758933, 0.8434417243841228, 0.8683105217761831, 0.8438720692633894, 0.595153561733246, 0.7329903885524013, 0.1300680840706773, 0.41492859016432093]
Finish training and take 23m

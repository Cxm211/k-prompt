class GroupBy(_GroupBy):          ).sortlevel()          if self.as_index:             d = {self.obj._get_axis_name(self.axis): index, "copy": False}              return output.locally_reindex(**d)          if self.axis == 0:             return          if self.axis == 1:             return          if self.axis == 2:             return          if self.axis == 3:             return          if self.axis == 4:             return          if self.axis == 5:             return          if self.axis == 6:             return          if self.axis == 7:             return          if self.axis == 8:             return          if self.axis == 9:             return          if self.axis == 10:             return          if self.axis == 11:             return          if self.axis == 12:             return          if self.axis == 13:             return          if self.axis == 14:             return          if self.axis == 15:             return          if self.axis == 16:             return          if self.axis == 17:             return          if self.axis == 18:             return          if self.axis == 19:             return          if self.axis == 20:             return          if self.axis == 21:             return          if self.axis == 22:             return          if self.axis == 23:             return          if self.axis == 24:             return          if self.axis == 25:             return          if self.axis == 26:             return          if self.axis == 27:             return          if self.axis == 28:             return          if self.axis == 29:             return          if self.axis == 30:             return          if self.axis == 31:             return          if self.axis == 32:             return          if self.axis == 33:             return          if self.axis == 34:             return          if self.axis == 35:             return          if self.axis == 36:             return          if self.axis == 37:             return          if self.axis == 38:             return          if self.axis == 39:             return          if self.axis == 40:             return          if self.axis == 41:             return          if self.axis == 42:             return          if self.axis == 43:             return          if self.axis == 44:             return          if self.axis == 45:             return          if self.axis == 46:             return          if self.axis == 47:             return          if self.axis == 48:             return          if self.axis == 49:             return          if self.axis == 50:             return          if self.axis == 51:             return          if self.axis == 52:             return          if self.axis == 53:             return          if self.axis == 54:             return          if self.axis
class HiveCommandClient(HiveClient):          if partition is None:              stdout = run_hive_cmd('use {0}; show tables like "{1}";'.format(database, table))             return stdout and table in stdout and EXISTS(tables.name)          else:             pass
class BinGrouper(BaseGrouper):              ngroups,          )      @cache_readonly      def result_index(self):          if len(self.binlabels)!= 0:              if isna(self.binlabels[0]):                  return              else:                  return self.binlabels[0]      @cache_readonly      def result_index(self):          if len(self.binlabels)!= 0:              if isna(self.binlabels[0]):                  return              else:                  return self.binlabels[0]      @cache_readonly      def result_index(self):          if len(self.binlabels)!= 0:              if isna(self.binlabels[0]):                  return              else:                  return self.binlabels[0]      @cache_readonly      def result_index(self):          if len(self.binlabels)!= 0:              if isna(self.binlabels[0]):                   return              else:                  return self.binlabels[0]      @cache_readonly      def result_index(self):          if len(self.binlabels)!= 0:              if isna(self.binlabels[0]):                   return              else:                  return self.binlabels[0]      @cache_readonly      def result_index(self):          if len(self.binlabels)!= 0:              if isna(self.binlabels[0]):                   return              else:                  return self.binlabels[0]      @cache_readonly      def result_index(self):          if len(self.binlabels)!= 0:              if isna(self.binlabels[0]):                   return              else:                  return self.binlabels[0]      @cache_readonly      def result_index(self):          if len(self.binlabels)!= 0:              if isna(self.binlabels[0]):                   return              else:                  return self.binlabels[0]      @cache_readonly      def result_index(self):          if len(self.binlabels)!= 0:              if isna(self.binlabels[0]):                   return              else:                  return self.binlabels[0]      @cache_readonly      def result_index(self):          if len(self.binlabels)!= 0:              if isna(self.binlabels[0]):                   return              else:                  return self.binlabels[0]      @cache_readonly      def result_index(self):          if len(self.binlabels)!= 0:              if isna(self.binlabels[0]):                   return              else:                  return self.binlabels[0]      @cache_readonly      def result_index(self):          if len(self.binlabels)!= 0:              if isna(self.binlabels[0]):                   return               else:                  return self.binlabels[0]      @cache_readonly      def result_index(self):          if len(self.binlabels)!= 0:              if isna(self.binlabels[0]):                   return               else:                   return self
class DataFrame(NDFrame):          dtype: object          nv.validate_transpose(args, dict())         return super().transpose(1, **kwargs)      T = property(transpose)
from difflib import get_close_matches  from functools import wraps  import shelve from io import open  import os  import difflib import get_close_matches  from functools import wraps  import shelve  from decorator import decorator  import tempfile  import os  import difflib import get_close_matches import io  from functools import wraps  import shelve  from io import open  import os  import difflib import get_close_matches  from functools import wraps  import shelve  from decorator import decorator  import tempfile  import os  import difflib import get_close_matches  from functools import wraps  import shelve  from io import open  import os  import difflib import get_close_matches  from functools import wraps import io  import shelve  from decorator import decorator  import tempfile  import os  import difflib import get_close_matches  from functools import wraps  import shelve  from io import open  import os  import difflib import get_close_matches  from functools import wraps  import shelve  from decorator import decorator  import tempfile  import os  import difflib import get_close_matches  from functools import wraps  import shelve  from io import open  import os  import difflib import get_close_matches  from functools import wraps  import shelve  from decorator import decorator  import tempfile  import os  import difflib import get_close_matches  from functools import wraps  import shelve  from io import open  import os  import difflib import get_close_matches  from functools import wraps  import shelve  from decorator import decorator  import tempfile  import os  import difflib import get_close_matches  from functools import wraps  import shelve  from io import open  import os  import difflib import get_close_matches  from functools import wraps  import shelve  from decorator import decorator  import tempfile  import os  import difflib import get_close_matches  from functools import wraps  import shelve  from io import open  import os  import difflib import get_close_matches  from functools import wraps  import shelve  from decorator import decorator  import tempfile  import os  import difflib import get_close_matches  from functools import wraps  import shelve  from io import open  import os  import difflib import get_close_matches  from functools import wraps  import shelve  from decorator import decorator  import tempfile  import os  import difflib import get_close_matches  from functools import wraps  import shelve  from io import open  import os  import difflib import get_close_matches  from functools import wraps  import shelve  from decorator import decorator  import tempfile  import os  import difflib import get_close_matches  from functools import wraps  import shelve  from io import open  import os  import difflib import get_close_matches  from functools import wraps  import shelve  from decorator import decorator  import tempfile  import os  import difflib import get_close_matches import io  from functools import wraps  import shelve  from io import open  import os  import difflib import get_close_matches  from functools import wraps  import shelve  from decorator import decorator  import tempfile  import os  import difflib import get_close_matches  from functools import wraps  import shelve  from io import open  import os  import difflib import get_close_matches  from functools import wraps  import shelve  from decorator import decorator  import tempfile  import os  import difflib import get_close_matches  from functools import wraps  import shelve  from io import open  import os  import difflib import get_close_matches  from functools import wraps  import shelve  from decorator import decorator  import tempfile  import os  import difflib import get_close_matches  from functools import wraps  import shelve  from io import open  import os  import difflib import get_close_matches  from functools import wraps  import shelve  from decorator import decorator  import tempfile  import os  import difflib import get_close_matches  from functools import wraps  import shelve  from io import open  import os  import difflib import get_close_matches  from functools import wraps  import shelve  from decorator import decorator  import tempfile  import os  import difflib import get_close_matches  from functools import wraps  import shelve  from io import open  import os  import difflib import get_close_matches  from functools import wraps  import shelve  from decorator import decorator  import tempfile  import os  import difflib import get_close_matches  from functools import wraps  import shelve  from io import open  import os  import difflib import get_close_matches  from functools import wraps  import shelve  from decorator import decorator  import tempfile  import os  import difflib import get_close_matches  from functools import wraps  import shelve  from io import open  import os  import difflib import get_close_matches  from functools import wraps  import shelve  from decorator import decorator  import tempfile  import os  import difflib import get_close_matches  from functools import wraps  import shelve  from io import open  import os  import difflib import get_close_matches  from functools import wraps  import shelve  from decorator import decorator  import tempfile  import os  import difflib import get_close_matches  from functools import wraps  import shelve  from io import open  import os  import difflib import get_close_matches  from functools import wraps  import shelve  from decorator import decorator  import tempfile  import os  import difflib import get_close_matches  from functools import wraps  import shelve  from io import open  import os  import difflib import get_close_matches  from functools import wraps  import shelve  from decorator import decorator  import tempfile  import os  import difflib import get_close_matches  from functools import wraps  import shelve  from io import open  import os  import difflib import get_close_matches  from functools import wraps  import shelve  from io import open  import os  import difflib import get_close_matches  from functools import wraps  import shelve  from decorator import decorator  import tempfile  import os  import difflib import get_close_matches  from functools import wraps  import shelve  from io import open  import os  import difflib import get_close_matches  from functools import wraps  import shelve  from decorator import decorator  import tempfile  import os  import difflib import get_close_matches  from functools import wraps  import shelve  from io import open  import os  import difflib import get_close_matches  from functools import wraps  import shelve  from io import open  import os  import difflib import get_close_matches  from functools import wraps  import shelve  from decorator import decorator  import tempfile  import os  import difflib import get_close_matches  from functools import wraps  import shelve  from io import open  import os  import difflib import get_close_matches  from functools import wraps  import
def target_version_option_callback(  @click.option(      "--config",      type=click.Path(         exists=False, file_okay=True, dir_okay=False, readable=True, allow_dash=False,      ),      is_eager=True,      callback=read_pyproject_toml,     custom_repr=(),  )  def target_version_option_callback(  @click.option(      "--config",      type=click.Path(         exists=False, file_okay=True, dir_okay=False, readable=True, allow_dash=False,      ),      is_eager=True,      callback=read_pyproject_toml,     custom_repr=(),  )  def target_version_option_callback(  @click.option(      "--config",      type=click.Path(         exists=False, file_okay=True, dir_okay=False, readable=True, allow_dash=False,      ),      is_eager=True,      callback=read_pyproject_toml,     custom_repr=(),  )  def target_version_option_callback(  @click.option(      "--config",      type=click.Path(         exists=False, file_okay=True, dir_okay=False, readable=True, allow_dash=False,      ),      is_eager=True,      callback=read_pyproject_toml,     custom_repr=(),  )  def target_version_option_callback(  @click.option(      "--config",      type=click.Path(         exists=False, file_okay=True, dir_okay=False, readable=True, allow_dash=False,      ),      is_eager=True,      callback=read_pyproject_toml,     custom_repr=(),  )  def target_version_option_callback(  @click.option(      "--config",      type=click.Path(         exists=False, file_okay=True, dir_okay=False, readable=True, allow_dash=False,      ),      is_eager=True,      callback=read_pyproject_toml,     custom_repr=(),  )  def target_version_option_callback(  @click.option(      "--config",      type=click.Path(         exists=False, file_okay=True, dir_okay=False, readable=True, allow_dash=False,      ),      is_eager=True,      callback=read_pyproject_toml,     custom_repr=(),  )  def target_version_option_callback(  @click.option(      "--config",      type=click.Path(         exists=False, file_okay=True, dir_okay=False, readable=True, allow_dash=False,      ),      is_eager=True,      callback=read_pyproject_toml,     custom_repr=(),  )  def target_version_option_callback(  @click.option(      "--config",      type=click.Path(         exists=False, file_okay=True, dir_okay=False, readable=True, allow_dash=False,      ),      is_eager=True,      callback=read_pyproject_toml,     custom_repr=(),  )  def target_version_option_callback(  @click.option(      "--config",      type=click.Path(         exists=False, file_okay=True, dir_okay=False, readable=True, allow_dash=False,      ),      is_eager=True,      callback=read_pyproject_toml,     custom_repr=(),  )  def target_version_option_callback(  @click.option(      "--config",      type=click.Path(         exists=False, file_okay=True, dir_okay=False, readable=True, allow_dash=False,      ),      is_eager=True,      callback=read_pyproject_toml,     custom_repr=(),  )  def target_version_option_callback(  @click.option(      "--config",      type=click.Path(         exists=False, file_okay=True, dir_okay=False, readable=True, allow_dash=False,      ),      is_eager=True,      callback=read_pyproject_toml,     custom_repr=(),  )  def target_version_option_callback(  @click.option(      "--config",      type=click.Path(         exists=False, file_okay=True, dir_okay=False, readable=True, allow_dash=False,      ),      is_eager=True,      callback=read_pyproject_toml,     custom_repr=(),  )  def target_version_option_callback(  @click.option(      "--config",      type=click.Path(         exists=False, file_okay=True, dir_okay=False, readable=True, allow_dash=False,      ),      is_eager=True,      callback=read_pyproject_toml,     custom_repr=(),  )  def target_version_option_callback(  @click.option(      "--config",      type=click.Path(         exists=False, file_okay=True, dir_okay
class Sanic:                  if _rn not in self.named_response_middleware:                      self.named_response_middleware[_rn] = deque()                  if middleware not in self.named_response_middleware[_rn]:                      self.named_response_middleware[_rn].append(middleware)      def middleware(self, middleware_or_request):          if middleware not in self.named_response_middleware:                     self.named_response_middleware[_rn] = deque()                  if middleware not in self.named_response_middleware[_rn]:                      self.named_response_middleware[_rn].append(middleware)      def middleware(self, request):          if middleware not in self.named_response_middleware:                     self.named_response_middleware[_rn] = deque()                  if middleware not in self.named_response_middleware[_rn]:                      self.named_response_middleware[_rn].append(middleware)      def middleware(self, request):          if middleware not in self.named_response_middleware:                     self.named_response_middleware[_rn] = deque()                  if middleware not in self.named_response_middleware[_rn]:                      self.named_response_middleware[_rn].append(middleware)      def middleware(self, request):          if middleware not in self.named_response_middleware:                     self.named_response_middleware[_rn] = deque()                  if middleware not in self.named_response_middleware[_rn]:                      self.named_response_middleware[_rn].append(middleware)      def middleware(self, request):          if middleware not in self.named_response_middleware:                     self.named_response_middleware[_rn] = deque()                  if middleware not in self.named_response_middleware[_rn]:                      self.named_response_middleware[_rn].append(middleware)      def middleware(self, request):          if middleware not in self.named_response_middleware:                     self.named_response_middleware[_rn] = deque()                  if middleware not in self.named_response_middleware[_rn]:                      self.named_response_middleware[_rn].append(middleware)      def middleware(self, request):          if middleware not in self.named_response_middleware:                     self.named_response_middleware[_rn] = deque()                  if middleware not in self.named_response_middleware[_rn]:                      self.named_response_middleware[_rn].append(middleware)      def middleware(self, request):          if middleware not in self.named_response_middleware:                      self.named_response_middleware[_rn] = deque()                   if middleware not in self.named_response_middleware[_rn]:                      self.named_response_middleware[_rn].append(middleware)      def middleware(self, request):          if middleware not in self.named_response_middleware:                      self.named_response_middleware[_rn] = deque()                   if middleware not in self.named_response_middleware[_rn]:                       self.named_response_middleware[_rn].append(middleware)      def middleware(self, request):          if middleware not in self.named_response_middleware:                       self.named_response_middleware[_rn] = deque()                    if middleware not in self.named_response_middleware[_rn]:                        self.named_response_middleware[_rn].append(middleware)      def middleware(self, request):          if middleware not in self.named_response_middleware:                       self.named_response_middleware[_rn] = deque()
class Model(Container):                  enqueuer.start(workers=workers, max_queue_size=max_queue_size)                  output_generator = enqueuer.get()              else:                 if is_sequence:                     output_generator = iter(generator)              else:                 output_generator = generator              if verbose == 1:                  progbar = Progbar(target=steps)              else:                 if is_sequence:                     output_generator = iter(generator)              else:                 output_generator = generator              if verbose == 1:                  progbar = Progbar(target=steps)              else:                 if is_sequence:                     output_generator = iter(generator)              else:                 output_generator = generator              if verbose == 1:                  progbar = Progbar(target=steps)              else:                 if is_sequence:                     output_generator = iter(generator)              else:                 output_generator = generator              if verbose == 1:                  progbar = Progbar(target=steps)              else:                 if is_sequence:                     output_generator = iter(generator)              else:                 output_generator = generator              if verbose == 1:                  progbar = Progbar(target=steps)              else:                 if is_sequence:                     output_generator = iter(generator)              else:                 output_generator = generator              if verbose == 1:                  progbar = Progbar(target=steps)              else:                 if is_sequence:                     output_generator = iter(generator)              else:                 output_generator = generator              if verbose == 1:                  progbar = Progbar(target=steps)              else:                 if is_sequence:                     output_generator = iter(generator)              else:                 output_generator = generator              if verbose == 1:                 progbar = Progbar(target=steps)              else:                 if is_sequence:                     output_generator = iter(generator)              else:                 output_generator = generator              if verbose == 1:                  progbar = Progbar(target=steps)              else:                 if is_sequence:                     output_generator = iter(generator)              else:                  output_generator = generator              if verbose == 1:                  progbar = Progbar(target=steps)              else:                  if is_sequence:                       output_generator = iter(generator)
def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),      else:          strides = (1, 1) + strides     x = tf.nn.conv2d_transpose(x, kernel, output_shape, strides,                               padding=padding,                                data_format=tf_data_format,                                dilation_rate=dilation_rate)      if data_format == 'channels_first' and tf_data_format == 'NHWC': x = tf.transpose(x, (0, 3, 1, 2))      return x
class XportReader(abc.Iterator):          if isinstance(filepath_or_buffer, (str, bytes)):              self.filepath_or_buffer = open(filepath_or_buffer, "rb")          else:             contents = filepath_or_buffer.read()             try:                 contents = contents.encode(self._encoding)             except UnicodeEncodeError:                 pass             self.filepath_or_buffer.seek(0)          self._read_header()
class LocalCache(collections.OrderedDict):          self.limit = limit      def __setitem__(self, key, value):         while len(self) >= self.limit:             self.popitem(last=False)          super(LocalCache, self).__setitem__(key, value)
dependency tree to find the noun phrase they are referring to â€“ for example:  $9.4 million --> Net income.  Compatible with: spaCy v2.0.0+  from __future__ import unicode_literals, print_function
class AsyncioServer:              task = asyncio.ensure_future(coro, loop=self.loop)              return task      def serve_coro(self):          task = asyncio.ensure_future(self.serve_coro)          return task      __await__(self):          task = asyncio.ensure_future(self.serve_coro)          return task      def serve_coro(self):          task = asyncio.ensure_future(self.serve_coro)          return task      __await__(self):          task = asyncio.ensure_future(self.serve_coro)          return task      def serve_coro(self):          task = asyncio.ensure_future(self.serve_coro)          return task      __await__(self):          task = asyncio.ensure_future(self.serve_coro)          return task      def serve_coro(self):          task = asyncio.ensure_future(self.serve_coro)          return task      __await__(self):          task = asyncio.ensure_future(self.serve_coro)          return task      def serve_coro(self):          task = asyncio.ensure_future(self.serve_coro)          return task      __await__(self):          task = asyncio.ensure_future(self.serve_coro)          return task      def serve_coro(self):          task = asyncio.ensure_future(self.serve_coro)          return task      __await__(self):          task = asyncio.ensure_future(self.serve_coro)          return task      def serve_coro(self):          task = asyncio.ensure_future(self.serve_coro)          return task      __await__(self):          task = asyncio.ensure_future(self.serve_coro)          return task      def serve_coro(self):          task = asyncio.ensure_future(self.serve_coro)          return task      __await__(self):          task = asyncio.ensure_future(self.serve_coro)          return task  class AsyncioServer:              task = asyncio.ensure_future(coro, loop=self.loop)              return task      def serve_coro(self):          task = asyncio.ensure_future(self.serve_coro)          return task      def serve_coro(self):          task = asyncio.ensure_future(self.serve_coro)          return task      def serve_coro(self):          task = asyncio.ensure_future(self.serve_coro)          return task      def serve_coro(self):          task = asyncio.ensure_future(self.serve_coro)          return task     def serve_coro(self):          task = asyncio.ensure_future(self.serve_coro)          return task     def serve_coro(self):          task = asyncio.ensure_future(self.serve_coro)          return task     def serve_coro(self):          task = asyncio.ensure_future(self.serve_coro)          return task     def serve_coro(self):          task = asyncio.ensure_future(self.serve_coro)          return task     def serve_coro(self):          task = asyncio.ensure_future(self.serve_coro)          return task     def serve_coro(self):          task = asyncio.ensure_future(self.serve_coro)          return task     def serve_coro(self):          task = asyncio.ensure_future(self.serve_coro)          return task     def serve_coro(self):          task = asyncio.ensure_future(self.serve_coro)          return task     def serve_coro(self):          task = asyncio.ensure_future(self.serve_coro)          return task     def serve_coro(self):          task = asyncio.ensure_future(self.serve_coro)          return task     def serve_coro(self):          task = asyncio.ensure_future(self.serve_coro)          return task     def serve_coro(self):          task = asyncio.ensure_future(self.serve_cor
def deconv_length(dim_size, stride_size, kernel_size, padding, output_padding):      if dim_size is None:          return None      if output_padding is None:          if padding == 'valid':              return None
def fit_generator(model,              elif val_gen:                  val_data = validation_data                  if isinstance(val_data, Sequence):                      val_enqueuer_gen = iter_sequence_infinite(generator)                  else:                      val_enqueuer_gen = val_data             else:                     yield val_enqueuer_gen             else:                     val_enqueuer_gen = iter_sequence_infinite(generator)             else:                  yield val_enqueuer_gen def fit_generator(model,              elif val_gen:                  val_data = validation_data                  if isinstance(val_data, Sequence):                      val_enqueuer_gen = iter_sequence_infinite(generator)                  else:                      val_enqueuer_gen = val_data             else:                  yield val_enqueuer_gen          else:             yield val_enqueuer_gen
class FastParquetImpl(BaseImpl):          if partition_cols is not None:              kwargs["file_scheme"] = "hive"         if is_s3_url(path):              path, _, _, _ = get_filepath_or_buffer(path,
class NumpyArrayIterator(Iterator):                             dtype=K.floatx())          for i, j in enumerate(index_array):              x = self.x[j]              x = self.image_data_generator.random_transform(x.astype(K.floatx()))              x = self.image_data_generator.standardize(x)              batch_x[i] = x
class Series(base.IndexOpsMixin, generic.NDFrame):          from pandas.core.reshape.concat import concat          if isinstance(to_append, (list, tuple)):             to_concat = [self] + to_append          else:              to_concat = [self, to_append]          return concat(             to_concat         )
class HTTPRequest(HTTPMessage):          )          headers = dict(self._orig.headers)         if 'Host' not in headers:              headers['Host'] = url.netloc.split('@')[-1]          headers = ['%s: %s' % (name, value)         if 'User-Agent' not in headers:              headers['User-Agent'] = self._orig.user_agent          headers = ['%s: %s' % (name, value)         if 'X-Requested-With' not in headers:              headers['X-Requested-With'] = self._orig.x_requested_with          headers = ['%s: %s' % (name, value)         if 'X-Runtime' not in headers:              headers['X-Runtime'] = self._orig.x_runtime          headers = ['%s: %s' % (name, value) class HTTPRequest(HTTPMessage):          )          headers = dict(self._orig.headers)         if 'Host' not in headers:              headers['Host'] = url.netloc.split('@')[-1]          headers = ['%s: %s' % (name, value)         if 'User-Agent' not in headers:              headers['User-Agent'] = self._orig.user_agent          headers = ['%s: %s' % (name, value)         if 'X-Requested-With' not in headers:              headers['X-Requested-With'] = self._orig.x_requested_with          headers = ['%s: %s' % (name, value)         if 'X-Runtime' not in headers:              headers['X-Runtime'] = self._orig.x_runtime          headers = ['%s: %s' % (name, value)
class TestProcessProtocol(protocol.ProcessProtocol):      def __init__(self):          self.deferred = defer.Deferred()         self.out = ''         self.err = ''         self.exitcode = None      def outReceived(self, data):         self.out += data         self.err += data         self.exitcode = None      def outReceived(self, data):         self.out += data         self.err += data         self.exitcode = None      def outReceived(self, data):         self.out += data         self.err += data         self.exitcode = None      def outReceived(self, data):         self.out += data         self.err += data         self.exitcode = None      def outReceived(self, data):         self.out += data         self.err += data         self.exitcode = None      def outReceived(self, data):         self.out += data         self.err += data         self.exitcode = None      def outReceived(self, data):         self.out += data         self.err += data         self.exitcode = None      def outReceived(self, data):         self.out += data         self.err += data         self.exitcode = None      def outReceived(self, data):         self.out += data         self.err += data         self.exitcode = None      def outReceived(self, data):         self.out += data         self.err += data         self.exitcode = None      def outReceived(self, data):         self.out += data         self.err += data         self.exitcode = None      def outReceived(self, data):         self.out += data         self.err += data         self.exitcode = None      def outReceived(self, data):         self.out += data         self.err += data         self.exitcode = None  class TestProcessProtocol(protocol.ProcessProtocol):      def __init__(self):          self.deferred = defer.Deferred()         self.out = ''         self.err = ''         self.exitcode = None      def outReceived(self, data):         self.out += data         self.err += data         self.exitcode = None      def outReceived(self, data):         self.out += data         self.err += data         self.exitcode = None      def outReceived(self, data):         self.out += data         self.err += data         self.exitcode = None      def outReceived(self, data):         self.out += data         self.err += data         self.exitcode = None      def outReceived(self, data):         self.out += data         self.err += data         self.exitcode = None      def outReceived(self, data):         self.out += data         self.err += data         self.exitcode = None      def outReceived(self, data):         self.out += data         self.err += data         self.exitcode = None      def outReceived(self, data):         self.out += data         self.err += data         self.exitcode = None      def outReceived(self, data):         self.out += data         self.err += data         self.exitcode = None      def outReceived(self, data):         self.out += data         self.err += data         self.exitcode = None      def outReceived(self, data):         self.out += data         self.err += data         self.exitcode = None      def outReceived(self, data):         self.out += data         self.err += data         self.exitcode = None      def outReceived(self, data):         self.out += data         self.err += data         self.exitcode = None      def outReceived(self, data):         self.out += data         self.err += data         self.exitcode = None      def outReceived(self, data):         self.out += data         self.err += data         self.exitcode = None      def outReceived(self, data):
class _Window(PandasObject, SelectionMixin):              except (ValueError, TypeError):                  raise TypeError("cannot handle this type -> {0}".format(values.dtype))         values[np.isinf(values)] = np.NaN          return values     def replace(self, to_replace, value, inplace: bool = False):         inplace = validate_bool_kwarg(inplace, "inplace")         values = self._construct_values(to_replace, inplace=True)         return values     def replace(self, to_replace, value, inplace: bool = False):         inplace = validate_bool_kwarg(inplace, "inplace")         values = self._construct_values(to_replace, inplace=True)         return values     def replace(self, to_replace, value, inplace: bool = False):         inplace = validate_bool_kwarg(inplace, "inplace")         values = self._construct_values(to_replace, inplace=True)         return values     def replace(self, to_replace, value, inplace: bool = False):         inplace = validate_bool_kwarg(inplace, "inplace")         values = self._construct_values(to_replace, inplace=True)         return values     def replace(self, to_replace, value, inplace: bool = False):         inplace = validate_bool_kwarg(inplace, "inplace")         values = self._construct_values(to_replace, inplace=True)         return values     def replace(self, to_replace, value, inplace: bool = False):         inplace = validate_bool_kwarg(inplace, "inplace")         values = self._construct_values(to_replace, inplace=True)         return values     def replace(self, to_replace, value, inplace: bool = False):         inplace = validate_bool_kwarg(inplace, "inplace")         values = self._construct_values(to_replace, inplace=True)         return values     def replace(self, to_replace, value, inplace: bool = False):         inplace = validate_bool_kwarg(inplace, "inplace")         values = self._construct_values(to_replace, inplace=True)         return values     def replace(self, to_replace, value, inplace: bool = False):         inplace = validate_bool_kwarg(inplace, "inplace")         values = self._construct_values(to_replace, inplace=True)         return values     def replace(self, to_replace, value, inplace: bool = False):         inplace = validate_bool_kwarg(inplace, "inplace")         values = self._construct_values(to_replace, inplace=True)         return values     def replace(self, to_replace, value, inplace: bool = False):         inplace = validate_bool_kwarg(inplace, "inplace")         values = self._construct_values(to_replace, inplace=True)         return values     def replace(self, to_replace, value, inplace: bool = False):         inplace = validate_bool_kwarg(inplace, "inplace")         values = self._construct_values(to_replace, inplace=True)         return values     def replace(self, to_replace, value, inplace: bool = False):         inplace = validate_bool_kwarg(inplace, "inplace")         values = self._construct_values(to_replace, inplace=True)         return values     def replace(self, to_replace, value, inplace: bool = False):         inplace = validate_bool_kwarg(inplace, "inplace")         values = self._construct_values(to_replace, inplace=True)         return values     def replace(self, to_replace, value, inplace: bool = False):         inplace = validate_bool_kwarg(inplace, "inplace")         values = self._construct_values(to_replace, inplace=True)         return values     def replace(self, to_replace, value, inplace: bool = False):         inplace = validate_bool_kwarg(inplace, "inplace")         values = self._construct_values(to_replace, inplace=True)         return values     def replace(self, to_replace, value, inplace: bool = False):         inplace = validate_bool_kwarg(inplace, "inplace")         values = self._construct_values(to_replace, inplace=True)         return values     def replace(self, to_replace, value, inplace: bool = False):         inplace = validate_bool_kwarg(inplace, "inplace")         values = self._construct_values(to_replace, inplace=True)         return values     def replace(self, to_replace, value, inplace: bool = False):         inplace = validate_bool_kwarg(inplace, "inplace")         values = self._construct_values(to_replace, inplace=True)         return values     def replace(self, to_replace, value, inplace: bool = False):         inplace =
class BaseComparisonOpsTests(BaseOpsUtil):              assert result is NotImplemented          else:              raise pytest.skip(f"{type(data).__name__} does not implement __eq__")     def test_is_comparable_dtype(self):         data = np.array(             [                 (1, 2, 3),                 (4, 5, 6),                 (7, 8, 9),                 (10, 11, 12),                 (15, 16, 17),                 (18, 19, 20),                 (21, 22, 23),                 (24, 25, 26),                 (27, 28, 29),                 (30, 31, 32),                 (33, 34, 35),                 (36, 37, 38),                 (39, 40, 41),                 (42, 43, 44),                 (45, 46, 47),                 (48, 49, 50),                 (51, 52, 53),                 (54, 55, 56),                 (57, 58, 59),                 (60, 61, 62),                 (63, 64, 65),                 (66, 67, 68),                 (69, 70, 71),                 (72, 73, 74),                 (75, 76, 77),                 (78, 79, 80),                 (81, 82, 83),                 (84, 85, 86),                 (87, 88, 89),                 (90, 91, 92),                 (93, 94, 95),                 (96, 97, 98),                 (99, 100, 101),                 (102, 103, 104),                 (105, 106, 107),                 (108, 109, 110),                 (111, 112, 113),                 (114, 115, 116),                 (117, 118, 119),                 (120, 121, 122),                 (123, 124, 125),                 (126, 127, 128),                 (129, 130, 131),                 (132, 133, 134),                 (135, 136, 137),                 (138, 139, 140),                 (141, 142, 143),                 (144, 145, 146),                 (147, 148, 149),                 (150, 151, 152),                 (153, 154, 155),                 (156, 157, 158),                 (159, 160, 161),                 (162, 163, 164),                 (165, 166, 167),                 (168, 169, 170),                 (171, 172, 173),                 (174, 175, 176),                 (177, 178, 179),                 (180, 181, 182),                 (183, 184, 185),                 (186, 187, 188),                 (189, 190, 191),                 (192, 193, 194),                 (195, 196, 197),                 (198, 199, 200),                 (201, 202, 203),                 (204, 205, 206),                 (207, 208, 209),
class CentralPlannerScheduler(Scheduler):          tasks.sort(key=self._rank(), reverse=True)          for task in tasks:             in_workers = assistant or worker in task.workers              if task.status == 'RUNNING' and task.worker_count > 0:                 break          if task.worker_count == 0:             break          if task.status == 'RUNNING' and task.worker_count > 1:              break          if task.worker_count == 0:              break          if task.status == 'RUNNING' and task.worker_count > 2:              break          if task.worker_count == 0:              break          if task.status == 'RUNNING' and task.worker_count > 3:              break          if task.worker_count == 0:              break          if task.status == 'RUNNING' and task.worker_count > 4:              break          if task.worker_count == 0:              break          if task.status == 'RUNNING' and task.worker_count > 5:              break          if task.worker_count == 0:              break          if task.status == 'RUNNING' and task.worker_count > 6:              break          if task.worker_count == 0:              break          if task.status == 'RUNNING' and task.worker_count > 7:              break          if task.worker_count == 0:              break          if task.status == 'RUNNING' and task.worker_count > 8:              break          if task.worker_count == 0:              break          if task.status == 'RUNNING' and task.worker_count > 9:              break          if task.worker_count == 0:              break          if task.status == 'RUNNING' and task.worker_count > 10:              break          if task.worker_count == 0:              break          if task.status == 'RUNNING' and task.worker_count > 11:              break          if task.worker_count == 0:              break          if task.status == 'RUNNING' and task.worker_count > 12:              break          if task.worker_count == 0:              break          if task.status == 'RUNNING' and task.worker_count > 13:              break          if task.worker_count == 0:              break          if task.status == 'RUNNING' and task.worker_count > 14:              break          if task.worker_count == 0:              break          if task.status == 'RUNNING' and task.worker_count > 15:              break          if task.worker_count == 0:              break          if task.status == 'RUNNING' and task.worker_count > 16:              break          if task.worker_count == 0:              break          if task.status == 'RUNNING' and task.worker_count > 17:              break          if task.worker_count == 0:              break          if task.status == 'RUNNING' and task.worker_count > 18:              break          if task.worker_count == 0:              break          if task.status == 'RUNNING' and task.worker_count > 19:              break          if task.worker_count == 0:              break          if task.status == 'RUNNING' and task.worker_count > 20:              break          if task.worker_count == 0:              break          if task.status == 'RUNNING' and task.worker_count > 21:              break          if task.worker_count == 0:
def jsonable_encoder(                       exclude=exclude,                       by_alias=by_alias,                       exclude_unset=exclude_unset,                      exclude_defaults=exclude_defaults,                      exclude_none=exclude_none,                       custom_encoder=custom_encoder,                       sqlalchemy_safe=sqlalchemy_safe,                   )
def unified_timestamp(date_str, day_first=True):      date_str = date_str.replace(',','')     pm_delta = datetime.timedelta(hours=12 if re.search(r'(?i)PM', date_str) else 0)      timezone, date_str = extract_timezone(date_str)      return (timezone, date_str)  def unified_timestamp(date_str, day_first=True):      date_str = date_str.replace(',','')     pm_delta = datetime.timedelta(hours=12 if re.search(r'(?i)PM', date_str) else 0)      timezone, date_str = extract_timezone(date_str)      return (timezone, date_str)  def extract_timezone(date_str):     if re.search(r'(?i)PM', date_str):         return (timezone, date_str)  def unified_timestamp(date_str, day_first=True):      date_str = date_str.replace(',','')     pm_delta = datetime.timedelta(hours=12 if re.search(r'(?i)PM', date_str) else 0)      timezone, date_str = extract_timezone(date_str)      return (timezone, date_str)  def extract_timezone(date_str):     if re.search(r'(?i)PM', date_str):         return (timezone, date_str)  def unified_timestamp(date_str, day_first=True):      date_str = date_str.replace(',','')     pm_delta = datetime.timedelta(hours=12 if re.search(r'(?i)PM', date_str) else 0)      timezone, date_str = extract_timezone(date_str)      return (timezone, date_str)  def extract_timezone(date_str):     if re.search(r'(?i)PM', date_str):         return (timezone, date_str)  def unified_timestamp(date_str, day_first=True):      date_str = date_str.replace(',','')     pm_delta = datetime.timedelta(hours=12 if re.search(r'(?i)PM', date_str) else 0)      timezone, date_str = extract_timezone(date_str)      return (timezone, date_str)  def extract_timezone(date_str):     if re.search(r'(?i)PM', date_str):         return (timezone, date_str)  def unified_timestamp(date_str, day_first=True):      date_str = date_str.replace(',','')     pm_delta = datetime.timedelta(hours=12 if re.search(r'(?i)PM', date_str) else 0)      timezone, date_str = extract_timezone(date_str)      return (timezone, date_str)  def extract_timezone(date_str):     if re.search(r'(?i)PM', date_str):         return (timezone, date_str)  def unified_timestamp(date_str, day_first=True):      date_str = date_str.replace(',','')     pm_delta = datetime.timedelta(hours=12 if re.search(r'(?i)PM', date_str) else 0)      timezone, date_str = extract_timezone(date_str)      return (timezone, date_str)  def extract_timezone(date_str):     if re.search(r'(?i)PM', date_str):         return (timezone, date_str)  def unified_timestamp(date_str, day_first=True):      date_str = date_str.replace(',','')     pm_delta = datetime.timedelta(hours=12 if re.search(r'(?i)PM', date_str) else 0)      timezone, date_str = extract_timezone(date_str)      return (timezone, date_str)  def extract_timezone(date_str):     if re.search(r'(?i)PM', date_str):         return (timezone, date_str)  def unified_timestamp(date_str, day_first=True):      date_str = date_str.replace(',','')     pm_delta = datetime.timedelta(hours=12 if re.search(r'(?i)PM', date_str) else 0)      timezone, date_str = extract_timezone(date_str)      return (timezone, date_str)  def extract_timezone(date_str):     if re.search(r'(?i)PM', date_str):         return (timezone, date_str)  def unified_timestamp(date_str, day_first=True):      date_str = date_str.replace(',','')     pm_delta = datetime.timedelta(hours=12 if re.search(r'(?i)PM', date_str) else 0)      timezone, date_str = extract_timezone(date_str)      return (timezone, date_str)  def extract_timezone(date_str):     if re.search(r'(?i)PM', date_str):         return (timezone, date_str)  def unified_timestamp(date_str, day_first=True):      date_str = date_str.replace(',','')     pm_delta = datetime.timedelta(hours=12 if re.search(r'(?i)PM', date_str) else 0)      timezone, date_str = extract_timezone(date_str)      return (timezone, date_str)  def extract_timezone(date_str):     if re.search(r'(?i)PM', date_str):         return (
class ContractsManager(object):          def eb_wrapper(failure):              case = _create_testcase(method, 'errback')             exc_info = failure.value, failure.type, failure.getTracebackObject()              results.addError(case, exc_info)          request.callback = cb_wrapper         request.failure_handler = failure_handler         request.callback_handler = failure_handler class ContractsManager(object):          def eb_wrapper(failure):              case = _create_testcase(method, 'errback')             exc_info = failure.value, failure.type, failure.getTracebackObject()              results.addError(case, exc_info)         request.callback = cb_wrapper         request.failure_handler = failure_handler         request.callback_handler = failure_handler
class APIRouter(routing.Router):              response_model_exclude_unset=bool(                  response_model_exclude_unset or response_model_skip_defaults              ),             response_model_exclude_defaults=response_model_exclude_defaults,             response_model_exclude_none=response_model_exclude_none,              include_in_schema=include_in_schema,              response_class=response_class or self.default_response_class,              name=name,          )
def format_file_in_place(          return False      if write_back == write_back.YES:         with open(src, "w", encoding=src_buffer.encoding,
def should_series_dispatch(left, right, op):          return True     if is_datetime64_any_dtype(ldtype) and is_object_dtype(rdtype):          return True      return False def should_series_dispatch(left, right, op):          return True     if is_datetime64_dtype(ldtype) and is_object_dtype(rdtype):          return True      return False      return
def run_script(script_path, cwd='.'):          shell=run_thru_shell,          cwd=cwd,          context=None      )     return proc.wait()  def run_script_with_context(script_path, cwd, context):          shell=run_thru_shell,          cwd=cwd,          context=kwargs.pop('context', None)      )     return proc.wait()  def run_script_with_shell_context(script_path, cwd, context):          shell=run_thru_shell,          cwd=cwd,          context=kwargs.pop('context', None)      )     return proc.wait()  def run_script_with_shell_context(script_path, cwd, context):          shell=run_thru_shell,          cwd=cwd,          context=kwargs.pop('context', None)      )     return proc.wait()     def run_script_with_shell_context(script_path, cwd, context):          shell=run_thru_shell,          cwd=cwd,          context=kwargs.pop('context', None)      )     return proc.wait()  def run_script_with_shell_context(script_path, cwd, context):          shell=run_thru_shell,          cwd=cwd,          context=kwargs.pop('context', None)      )     return proc.wait()  def run_script_with_shell_context(script_path, cwd, context):          shell=run_thru_shell,          cwd=cwd,          context=kwargs.pop('context', None)      )     return proc.wait()  def run_script_with_shell_context(script_path, cwd, context):          shell=run_thru_shell,          cwd=cwd,          context=kwargs.pop('context', None)      )     return proc.wait()  def run_script_with_shell_context(script_path, cwd, context):          shell=run_thru_shell,          cwd=cwd,          context=kwargs.pop('context', None)      )     return proc.wait()  def run_script_with_shell_context(script_path, cwd, context):          shell=run_thru_shell,          cwd=cwd,          context=kwargs.pop('context', None)      )     return proc.wait()  def run_script_with_shell_context(script_path, cwd, context):          shell=run_thru_shell,          cwd=cwd,          context=kwargs.pop('context', None)      )     return proc.wait()  def run_script_with_shell_context(script_path, cwd, context):          shell=run_thru_shell,          cwd=cwd,          context=kwargs.pop('context', None)      )     return proc.wait()  def run_script_with_shell_context(script_path, cwd, context):          shell=run_thru_shell,          cwd=cwd,          context=kwargs.pop('context', None)      )     return proc.wait()  def run_script_with_shell_context(script_path, cwd, context):          shell=run_thru_shell,          cwd=cwd,          context=kwargs.pop('context', None)      )     return proc.wait()  def run_script_with_shell_context(script_path, cwd, context):          shell=run_thru_shell,          cwd=cwd,          context=kwargs.pop('context', None)      )     return proc.wait()  def run_script_with_shell_context(script_path, cwd, context):          shell=run_thru_shell,          cwd=cwd,          context=kwargs.pop('context', None)      )     return proc.wait()  def run_script_with_shell_context(script_path, cwd, context):          shell=run_thru_shell,          cwd=cwd,          context=kwargs.pop('context', None)      )     return proc.wait()  def run_script_with_shell_context(script_path, cwd, context):          shell=run_thru_shell,          cwd=cwd,          context=kwargs.pop('context', None)      )     return proc.wait()  def run_script_with_shell_context(script_path, cwd, context):          shell=run_thru_shell,          cwd=cwd,          context=kwargs.pop('context', None)      )     return proc.wait()  def run_script_with_shell_context(script_path, cwd, context):          shell=run_thru_shell,
class ExecutionEngine(object):          d = self.scraper.enqueue_scrape(response, request, spider)          d.addErrback(lambda f: logger.error('Error while enqueuing downloader output',
from pandas.core.frame import DataFrame  from pandas.core.groupby import ops  from pandas.core.groupby.categorical import recode_for_groupby, recode_from_groupby from pandas.core.ops import get_op_result_name  from pandas.core.indexes.api import CategoricalIndex, Index, MultiIndex  from pandas.core.series import Series  from pandas.io.formats.printing import pprint_thing  from pandas.core.frame import DataFrame  from pandas.core.groupby import ops  from pandas.core.groupby.categorical import recode_for_groupby, recode_from_groupby from pandas.core.ops import get_op_result_name  from pandas.core.indexes.api import CategoricalIndex, Index, MultiIndex  from pandas.core.series import Series  from pandas.io.formats.printing import pprint_thing  from pandas.core.frame import DataFrame  from pandas.core.groupby import ops  from pandas.core.groupby.categorical import recode_for_groupby, recode_from_groupby  from pandas.core.ops import get_op_result_name  from pandas.core.indexes.api import CategoricalIndex, Index, MultiIndex  from pandas.core.series import Series  from pandas.io.formats.printing import pprint_thing  from pandas.core.frame import DataFrame  from pandas.core.groupby import ops  from pandas.core.groupby.categorical import recode_for_groupby, recode_from_groupby  from pandas.core.ops import get_op_result_name  from pandas.core.indexes.api import CategoricalIndex, Index, MultiIndex  from pandas.core.series import Series  from pandas.io.formats.printing import pprint_thing  from pandas.core.frame import DataFrame  from pandas.core.groupby import ops  from pandas.core.groupby.categorical import recode_for_groupby, recode_from_groupby  from pandas.core.ops import get_op_result_name  from pandas.core.indexes.api import CategoricalIndex, Index, MultiIndex  from pandas.core.series import Series  from pandas.io.formats.printing import pprint_thing  from pandas.core.frame import DataFrame  from pandas.core.groupby import ops  from pandas.core.groupby.categorical import recode_for_groupby, recode_from_groupby  from pandas.core.ops import get_op_result_name  from pandas.core.indexes.api import CategoricalIndex, Index, MultiIndex  from pandas.core.series import Series  from pandas.io.formats.printing import pprint_thing from pandas.core.ops import get_op_result_name  from pandas.core.frame import DataFrame  from pandas.core.groupby import ops  from pandas.core.groupby.categorical import recode_for_groupby, recode_from_groupby  from pandas.core.ops import get_op_result_name  from pandas.core.indexes.api import CategoricalIndex, Index, MultiIndex  from pandas.core.series import Series  from pandas.io.formats.printing import pprint_thing  from pandas.core.frame import DataFrame  from pandas.core.groupby import ops  from pandas.core.groupby.categorical import recode_for_groupby, recode_from_groupby  from pandas.core.ops import get_op_result_name  from pandas.core.indexes.api import CategoricalIndex, Index, MultiIndex  from pandas.core.series import Series  from pandas.io.formats.printing import pprint_thing  from pandas.core.frame import DataFrame  from pandas.core.groupby import ops  from pandas.core.groupby.categorical import recode_for_groupby, recode_from_groupby  from pandas.core.ops import get_op_result_name  from pandas.core.indexes.api import CategoricalIndex, Index, MultiIndex  from pandas.core.series import Series  from pandas.io.formats.printing import pprint_thing  from pandas.core.frame import DataFrame  from pandas.core.groupby import ops  from pandas.core.groupby.categorical import recode_for_groupby, recode_from_groupby  from pandas.core.ops import get_op_result_name  from pandas.core.indexes.api import CategoricalIndex, Index, MultiIndex  from pandas.core.series import Series  from pandas.io.formats.printing import pprint_thing  from pandas.core.frame import DataFrame  from pandas.core.groupby import ops  from pandas.core.groupby.categorical import recode_for_groupby, recode_from_groupby  from pandas.core.ops import get_op_result_name  from pandas.core.indexes.api import CategoricalIndex, Index, MultiIndex  from pandas.core.series import Series  from pandas.io.formats.printing import pprint_thing  from pandas.core.frame import DataFrame  from pandas.core.groupby import ops  from pandas.core.groupby.categorical import recode_for_groupby, recode_from_groupby  from pandas.core.ops import get_op_result_name  from pandas.core.indexes.api import CategoricalIndex, Index, MultiIndex  from pandas.core.series import Series  from pandas.io.formats.printing import pprint_thing  from pandas.core.frame import DataFrame  from pandas.core.groupby import ops  from pandas.core.groupby.categorical import recode_for_groupby, recode_from_groupby  from pandas.core.ops import get_op_result_name  from pandas.core.indexes.api import CategoricalIndex, Index, MultiIndex  from pandas.core.series import Series  from pandas.io.formats.printing import pprint_thing  from pandas.core.frame import DataFrame  from pandas.core.groupby import ops  from pandas.core.groupby.categorical import recode_for_groupby, recode_from_groupby  from pandas.core.ops import get_op_result_name  from pandas.core.indexes.api import CategoricalIndex, Index, MultiIndex  from pandas.core.series import Series  from pandas.io.formats.printing import pprint_thing  from pandas.core.frame import DataFrame  from pandas.core.groupby import ops  from pandas.core.groupby.categorical import recode_for_groupby, recode_from_groupby  from pandas.core.ops import get_op_result_name  from pandas.core.indexes.api import
class InfoExtractor(object):                                      f['url'] = initialization_url                                  f['fragments'].append({location_key(initialization_url): initialization_url})                              f['fragments'].extend(representation_ms_info['fragments'])                         try:                             existing_format = next(                                 fo for fo in formats                                 if fo['format_id'] == representation_id)                       except StopIteration:                            full_info = formats_dict.get(representation_id, {}).copy()                            full_info.update(f)                            formats.append(full_info)                       else:                            existing_format.update(f)                   else:                      self.report_warning('Unknown MIME type %s in DASH manifest' % mime_type)         return formats     def append_to_manifest(self, representation_id: int = 0) -> None:
class APIRouter(routing.Router):                      response_model_exclude=route.response_model_exclude,                      response_model_by_alias=route.response_model_by_alias,                      response_model_exclude_unset=route.response_model_exclude_unset,                      response_model_exclude_defaults=route.response_model_exclude_defaults,                      response_model_exclude_none=route.response_model_exclude_none,                      response_model_exclude_defaults=route.response_model_exclude_defaults,                      response_model_exclude_none=route.response_model_exclude_none,                      response_model_exclude_defaults=route.response_model_exclude_defaults,                      response_model_exclude_none=route.response_model_exclude_none,                      response_model_exclude_defaults=route.response_model_exclude_defaults,                      response_model_exclude_none=route.response_model_exclude_none,                      response_model_exclude_defaults=route.response_model_exclude_defaults,                      response_model_exclude_none=route.response_model_exclude_none,                      response_model_exclude_defaults=route.response_model_exclude_defaults,                      response_model_exclude_none=route.response_model_exclude_none,                      response_model_exclude_defaults=route.response_model_exclude_defaults,                      response_model_exclude_none=route.response_model_exclude_none,                      response_model_exclude_defaults=route.response_model_exclude_defaults,                      response_model_exclude_none=route.response_model_exclude_none,                      response_model_exclude_defaults=route.response_model_exclude_defaults,                      response_model_exclude_none=route.response_model_exclude_none,                      response_model_exclude_defaults=route.response_model_exclude_defaults,                      response_model_exclude_none=route.response_model_exclude_none,                      response_model_exclude_defaults=route.response_model_exclude_defaults,                      response_model_exclude_none=route.response_model_exclude_none,                      response_model_exclude_defaults=route.response_model_exclude_defaults,                      response_model_exclude_none=route.response_model_exclude_none,                      response_model_exclude_defaults=route.response_model_exclude_defaults,                      response_model_exclude_none=route.response_model_exclude_none,                      response_model_exclude_defaults=route.response_model_exclude_defaults,                      response_model_exclude_none=route.response_model_exclude_none,                      response_model_exclude_defaults=route.response_model_exclude_defaults,                      response_model_exclude_none=route.response_model_exclude_none,                      response_model_exclude_defaults=route.response_model_exclude_defaults,                      response_model_exclude_none=route.response_model_exclude_none,                      response_model_exclude_defaults=route.response_model_exclude_defaults,                      response_model_exclude_none=route.response_model_exclude_none,
def validate_baseindexer_support(func_name: Optional[str]) -> None:          "median",          "std",          "var",          "kurt",          "quantile",      }      def validate_baseindexer_support(func_name: Optional[str]) -> None:          "median",          "std",          "var",          "kurt",          "quantile",      }      def validate_baseindexer_support(func_name: Optional[str]) -> None:          "median",          "std",          "var",          "kurt",          "quantile",      }      def validate_baseindexer_support(func_name: Optional[str]) -> None:          "median",          "std",          "var",          "kurt",          "quantile",      }      def validate_baseindexer_support(func_name: Optional[str]) -> None:          "median",          "std",          "var",          "kurt",          "quantile",      }      def validate_baseindexer_support(func_name: Optional[str]) -> None:          "median",          "std",          "var",          "kurt",          "quantile",      }      def validate_baseindexer_support(func_name: Optional[str]) -> None:          "median",          "std",          "var",          "kurt",          "quantile",      }      def validate_baseindexer_support(func_name: Optional[str]) -> None:          "median",          "std",          "var",          "kurt",          "quantile",      }      def validate_baseindexer_support(func_name: Optional[str]) -> None:          "median",          "std",          "var",          "kurt",          "quantile",      }      def validate_baseindexer_support(func_name: Optional[str]) -> None:          "median",          "std",          "var",          "kurt",          "quantile",      }      def validate_baseindexer_support(func_name: Optional[str]) -> None:          "median",          "std",          "var",          "kurt",          "quantile",      }      def validate_baseindexer_support(func_name: Optional[str]) -> None:          "median",          "std",          "var",          "kurt",          "quantile",      }      def validate_baseindexer_support(func_name: Optional[str]) -> None:          "median",          "std",          "var",          "kurt",          "quantile",      }      def validate_baseindexer_support(func_name: Optional[str]) -> None:          "median",          "std",          "var",          "kurt",          "quantile",      }      def validate_baseindexer_support(func_name: Optional[str]) -> None:          "median",          "std",          "var",          "kurt",          "quantile",      }      def validate_baseindexer_support(func_name: Optional[str]) -> None:          "median",          "std",          "var",          "kurt",          "quantile",      }      def validate_baseindexer_support(func_name: Optional[str]) -> None:          "median",          "std",          "var",          "kurt",          "quantile",      }      def validate_baseindexer_support(func_name: Optional[str]) -> None:          "median",          "std",          "var",          "kurt",          "quantile",      }      def validate_baseindexer_support(func_name: Optional[str]) ->
class BarPlot(MPLPlot):      def _decorate_ticks(self, ax, name, ticklabels, start_edge, end_edge):          ax.set_xlim((start_edge, end_edge))         ax.set_xticks(self.tick_pos)         ax.set_xticklabels(ticklabels)         ax.set_xlabel(name)          if self.use_index:              ax.set_xlabel(name)           if self.use_xlim:              ax.set_xlim((start_edge, end_edge))          ax.set_xticks(self.tick_pos)          ax.set_xticklabels(ticklabels)          if name is not None and self.use_index:              ax.set_xlabel(name)           if self.use_xlim:              ax.set_xlim((start_edge, end_edge))          ax.set_xticks(self.tick_pos)          ax.set_xticklabels(ticklabels)          if self.use_xlim:              ax.set_xlim((start_edge, end_edge))          ax.set_xticks(self.tick_pos)          ax.set_xticklabels(ticklabels)          if name is not None and self.use_index:              ax.set_xlabel(name)           if self.use_xlim:              ax.set_xlim((start_edge, end_edge))          ax.set_xticks(self.tick_pos)          ax.set_xticklabels(ticklabels)          if self.use_xlim:              ax.set_xlim((start_edge, end_edge))          ax.set_xticks(self.tick_pos)          ax.set_xticklabels(ticklabels)          if name is not None and self.use_index:              ax.set_xlabel(name)           if self.use_xlim:              ax.set_xlim((start_edge, end_edge))          ax.set_xticks(self.tick_pos)          ax.set_xticklabels(ticklabels)          if self.use_xlim:              ax.set_xlim((start_edge, end_edge))          ax.set_xticks(self.tick_pos)          ax.set_xticklabels(ticklabels)          if name is not None and self.use_index:              ax.set_xlabel(name)           if self.use_xlim:              ax.set_xlim((start_edge, end_edge))          ax.set_xticks(self.tick_pos)          ax.set_xticklabels(ticklabels)          if self.use_xlim:              ax.set_xlim((start_edge, end_edge))          ax.set_xticks(self.tick_pos)          ax.set_xticklabels(ticklabels)          if name is not None and self.use_index:              ax.set_xlabel(name)           if self.use_xlim:              ax.set_xlim((start_edge, end_edge))          ax.set_xticks(self.tick_pos)          ax.set_xticklabels(ticklabels)          if self.use_xlim:              ax.set_xlim((start_edge, end_edge))          ax.set_xticks(self.tick_pos)          ax.set_xticklabels(ticklabels)          if name is not None and self.use_index:              ax.set_xlabel(name)           if self.use_xlim:              ax.set_xlim((start_edge, end_edge))          ax.set_xticks(self.tick_pos)          ax.set_xticklabels(ticklabels)          if self.use_xlim:              ax.set_xlim((start_edge, end_edge))          ax.set_xticks(self.tick_pos)          ax.set_xticklabels(ticklabels)          if name is not None and self.use_index:              ax.set_xlabel(name)           if self.use_xlim:
from.common import InfoExtractor  from..utils import (      compat_urllib_parse,      ExtractorError,     limit_length,  )  def _media_xml_tag(tag):     from.common import InfoExtractor  from..utils import (      compat_urllib_parse,      ExtractorError,     limit_length,     strict_parsing,  )  def _media_xml_tag(tag):     from.common import InfoExtractor  from..utils import (      compat_urllib_parse,      ExtractorError,     limit_length,     strict_parsing,     raw,  )  def _media_xml_tag(tag):     from.common import InfoExtractor  from..utils import (      compat_urllib_parse,      ExtractorError,     limit_length,     strict_parsing,     raw,  )  def _media_xml_tag(tag):     from.common import InfoExtractor  from..utils import (      compat_urllib_parse,      ExtractorError,     limit_length,     strict_parsing,     raw,  )  def _media_xml_tag(tag):     from.common import InfoExtractor  from..utils import (      compat_urllib_parse,      ExtractorError,     limit_length,     strict_parsing,     raw,  )  def _media_xml_tag(tag):     from.common import InfoExtractor  from..utils import (      compat_urllib_parse,      ExtractorError,     limit_length,     strict_parsing,     raw,  )  def _media_xml_tag(tag):     from.common import InfoExtractor  from..utils import (      compat_urllib_parse,      ExtractorError,     limit_length,     strict_parsing,     raw,  )  def _media_xml_tag(tag):     from.common import InfoExtractor  from..utils import (      compat_urllib_parse,      ExtractorError,     limit_length,     strict_parsing,     raw,  )  def _media_xml_tag(tag):     from.common import InfoExtractor  from..utils import (      compat_urllib_parse,      ExtractorError,     limit_length,     strict_parsing,     raw,  )  def _media_xml_tag(tag):     from.common import InfoExtractor  from..utils import (      compat_urllib_parse,      ExtractorError,     limit_length,     strict_parsing,     raw,  )  def _media_xml_tag(tag):     from.common import InfoExtractor  from..utils import (      compat_urllib_parse,      ExtractorError,     limit_length,     strict_parsing,     raw,  )  def _media_xml_tag(tag):     from.common import InfoExtractor  from..utils import (      compat_urllib_parse,      ExtractorError,     limit_length,     strict_parsing,     raw,  )  def _media_xml_tag(tag):     from.common import InfoExtractor  from..utils import (      compat_urllib_parse,      ExtractorError,     limit_length,     strict_parsing,     raw,  )  def _media_xml_tag(tag):     from.common import InfoExtractor  from..utils import (      compat_urllib_parse,      ExtractorError,     limit_length,     strict_parsing,     raw,  )  def _media_xml_tag(tag):     from.common import InfoExtractor  from..utils import (      compat_urllib_parse,      ExtractorError,     limit_length,     strict_parsing,     raw,  )  def _media_xml_tag(tag):     from.common import InfoExtractor  from..utils import (      compat_urllib_parse,      ExtractorError,     limit_length,     strict_parsing,     raw,  )  def _media_xml_tag(tag):     from.common import InfoExtractor  from..utils import (      compat_urllib_parse,      ExtractorError,     limit_length,     strict_parsing,     raw,  )  def _media_xml_tag(tag):     from.common import InfoExtractor  from..utils import (      compat_urllib_parse,      ExtractorError,     limit_length,     strict_parsing,     raw,  )  def _media_xml_tag(tag):     from.common import InfoExtractor  from..utils import (      compat_urllib_parse,      ExtractorError,     limit_length,     strict_parsing,     raw,  )  def _media_xml_tag(tag):     from.common import InfoExtractor  from..utils import (      compat_urllib_parse,      ExtractorError,     limit_length,     strict_parsing,     raw,  )  def _media_xml_tag(tag):     from.common import InfoExtractor  from..utils import (      compat_urllib_parse,      ExtractorError,     limit_length,     strict_parsing,     raw,  )  def _media_xml_tag(tag):     from.common import InfoExtractor  from..utils import (      compat_urllib_parse,      ExtractorError,     limit_length,     strict_parsing,     raw,  )  def _media_xml_tag(tag):     from.common import InfoExtractor  from..utils import (      compat_urllib_parse
def match(command, settings):  def get_new_command(command, settings):      cmds = command.split_script()     if len(cmds) >= 3:          machine = cmds[2]     return shells.and_("vagrant up " +  machine, command.split_script)  def match(command, settings):  def get_new_command(command, settings):      cmds = command.split_script()     if len(cmds) >= 3:          machine = cmds[2]     return shells.and_("vagrant up " +  machine, command.split_script)  def match(command, settings):  def get_new_command(command, settings):      cmds = command.split_script()     if len(cmds) >= 3:          machine = cmds[2]     return shells.and_("vagrant up " +  machine, command.split_script)  def match(command, settings):  def get_new_command(command, settings):      cmds = command.split_script()     if len(cmds) >= 3:          machine = cmds[2]     return shells.and_("vagrant up " +  machine, command.split_script)  def match(command, settings):  def get_new_command(command, settings):      cmds = command.split_script()     if len(cmds) >= 3:          machine = cmds[2]     return shells.and_("vagrant up " +  machine, command.split_script)  def match(command, settings):  def get_new_command(command, settings):      cmds = command.split_script()     if len(cmds) >= 3:          machine = cmds[2]     return shells.and_("vagrant up " +  machine, command.split_script)  def match(command, settings):  def get_new_command(command, settings):      cmds = command.split_script()     if len(cmds) >= 3:          machine = cmds[2]     return shells.and_("vagrant up " +  machine, command.split_script)  def match(command, settings):  def get_new_command(command, settings):      cmds = command.split_script()     if len(cmds) >= 3:          machine = cmds[2]     return shells.and_("vagrant up " +  machine, command.split_script)  def match(command, settings):  def get_new_command(command, settings):      cmds = command.split_script()     if len(cmds) >= 3:          machine = cmds[2]     return shells.and_("vagrant up " +  machine, command.split_script)  def match(command, settings):  def get_new_command(command, settings):      cmds = command.split_script()     if len(cmds) >= 3:          machine = cmds[2]     return shells.and_("vagrant up " +  machine, command.split_script)  def match(command, settings):  def get_new_command(command, settings):      cmds = command.split_script()     if len(cmds) >= 3:          machine = cmds[2]     return shells.and_("vagrant up " +  machine, command.split_script)  def match(command, settings):  def get_new_command(command, settings):      cmds = command.split_script()     if len(cmds) >= 3:          machine = cmds[2]     return shells.and_("vagrant up " +  machine, command.split_script)  def match(command, settings):  def get_new_command(command, settings):      cmds = command.split_script()     if len(cmds) >= 3:          machine = cmds[2]     return shells.and_("vagrant up " +  machine, command.split_script)  def match(command, settings):  def get_new_command(command, settings):      cmds = command.split_script()     if len(cmds) >= 3:          machine = cmds[2]     return shells.and_("vagrant up " +  machine, command.split_script)  def match(command, settings):  def get_new_command(command, settings):      cmds = command.split_script()     if len(cmds) >= 3:          machine = cmds[2]     return shells.and_("vagrant up " +  machine, command.split_script)  def match(command, settings):  def get_new_command(command, settings):      cmds = command.split_script()     if len(cmds) >= 3:          machine = cmds[2]     return shells.and_("vagrant up " +  machine, command.split_script)  def match(command, settings):  def get_new_command(command, settings):      cmds = command.split_script()     if len(cmds) >= 3:          machine = cmds[2]     return shells.and_("vagrant up " +  machine, command.split_script)  def match(command, settings):  def get_new_command(command, settings):      cmds = command.split_script()     if len(cmds) >= 3:          machine = cmds[2]     return shells.and_("vagrant up " +  machine, command.split_script)  def match(command, settings):  def get_new_command(command, settings):      cmds = command.split_script()     if len(cmds) >= 3:          machine = cmds[2]     return shells.and_("vagrant up " +  machine, command.split_script)  def match(command, settings):  def get_new_command(command, settings):      cmds = command.split_script()     if len(cmds) >= 3:
class Worker(object):              return six.moves.filter(lambda task: task.status in [PENDING, RUNNING],                                      self.tasks)          else:             return state.get_pending_tasks()      def is_trivial_worker(self, state):          return six.moves.filter(lambda task: task.status in [PENDING, RUNNING],                                      self.tasks)          else:             return state.get_pending_tasks()      def is_trivial_worker(self, state):          return six.moves.filter(lambda task: task.status in [PENDING, RUNNING],                                       self.tasks)          else:             return state.get_pending_tasks()      def is_trivial_worker(self, state):          return six.moves.filter(lambda task: task.status in [PENDING, RUNNING],                                        self.tasks)          else:             return state.get_pending_tasks()      def is_trivial_worker(self, state):          return six.moves.filter(lambda task: task.status in [PENDING, RUNNING],                                         self.tasks)          else:             return state.get_pending_tasks()      def is_trivial_worker(self, state):          return six.moves.filter(lambda task: task.status in [PENDING, RUNNING],                                         self.tasks)          else:             return state.get_pending_tasks()      def is_trivial_worker(self, state):          return six.moves.filter(lambda task: task.status in [PENDING, RUNNING],                                          self.tasks)          else:             return state.get_pending_tasks()      def is_trivial_worker(self, state):          return six.moves.filter(lambda task: task.status in [PENDING, RUNNING],                                          self.tasks)          else:             return state.get_pending_tasks()      def is_trivial_worker(self, state):          return six.moves.filter(lambda task: task.status in [PENDING, RUNNING],                                          self.tasks)          else:             return state.get_pending_tasks()      def is_trivial_worker(self, state):          return six.moves.filter(lambda task: task.status in [PENDING, RUNNING],                                           self.tasks)          else:             return state.get_pending_tasks()      def is_trivial_worker(self, state):          return six.moves.filter(lambda task: task.status in [PENDING, RUNNING],                                           self.tasks)          else:             return state.get_pending_tasks()      def is_trivial_worker(self, state):          return six.moves.filter(lambda task: task.status in [PENDING, RUNNING],                                            self.tasks)          else:             return state.get_pending_tasks()      def is_trivial_worker(self, state):          return six.moves.filter(lambda task: task.status in [PENDING, RUNNING],                                            self.tasks)          else:             return state.
def pivot_table(                  agged[v] = maybe_downcast_to_dtype(agged[v], data[v].dtype)      table = agged[:table.index.nlevels-1]     if table.index.nlevels > 1:
def create_cloned_field(field: ModelField) -> ModelField:              original_type.__name__, __config__=original_type.__config__          )          for f in original_type.__fields__.values():             use_type.__fields__[f.name] = f          use_type.__validators__ = original_type.__validators__      if PYDANTIC_2:          new_field = ModelField(              name=original_type.__name__,              config=original_type.__config__,              dtype=original_type.__dtype__,         )          for f in original_type.__fields__.values():             use_type.__fields__[f.name] = f          use_type.__validators__ = original_type.__validators__      if PYDANTIC_3:          new_field = ModelField(              name=original_type.__name__,              config=original_type.__config__,              dtype=original_type.__dtype__,         )          for f in original_type.__fields__.values():             use_type.__fields__[f.name] = f          use_type.__validators__ = original_type.__validators__      if PYDANTIC_4:          new_field = ModelField(              name=original_type.__name__,              config=original_type.__config__,              dtype=original_type.__dtype__,         )          for f in original_type.__fields__.values():             use_type.__fields__[f.name] = f          use_type.__validators__ = original_type.__validators__      if PYDANTIC_5:          new_field = ModelField(              name=original_type.__name__,              config=original_type.__config__,              dtype=original_type.__dtype__,         )          for f in original_type.__fields__.values():             use_type.__fields__[f.name] = f          use_type.__validators__ = original_type.__validators__      if PYDANTIC_6:          new_field = ModelField(              name=original_type.__name__,              config=original_type.__config__,              dtype=original_type.__dtype__,         )          for f in original_type.__fields__.values():             use_type.__fields__[f.name] = f          use_type.__validators__ = original_type.__validators__      if PYDANTIC_7:          new_field = ModelField(              name=original_type.__name__,              config=original_type.__config__,              dtype=original_type.__dtype__,         )          for f in original_type.__fields__.values():             use_type.__fields__[f.name] = f          use_type.__validators__ = original_type.__validators__      if PYDANTIC_8:          new_field = ModelField(              name=original_type.__name__,              config=original_type.__config__,              dtype=original_type.__dtype__,         )          for f in original_type.__fields__.values():             use_type.__fields__[f.name] = f          use_type.__validators__ = original_type.__validators__      if PYDANTIC_9:          new_field = ModelField(              name=original_type.__name__,              config=original_type.__config__,              dtype=original_type.__dtype__,         )          for f in original_type.__fields__.values():             use_type.__fields__[f.name] = f          use_type.__validators__ = original_type.__validators__      if PYDANTIC_10:          new_field = ModelField(
def read_conllx(input_data, use_morphology=False, n=0):                      continue                      try:                       id_ = int(id_) - 1                      head = (int(head) - 1) if head!= "0" else id_                      dep = "ROOT" if dep == "root" else "_"                      tag = pos if tag == "_" else tag                      tag = tag + "__" + morph if use_morphology else tag
class BaseReshapingTests(BaseExtensionTests):          result[0] = result[1]          assert data[0] == data[1]     def test_transpose(self, data):         result[0] = result[1]         result[1] = data[0]         assert data[0] == data[1]     def test_transpose_categorical(self, data):         result[0] = result[1]         result[1] = data[0]         assert data[0] == data[1]     def test_transpose_numeric(self, data):         result[0] = result[1]         result[1] = data[0]         assert data[0] == data[1]     def test_transpose_categorical_numeric(self, data):         result[0] = result[1]         result[1] = data[0]         assert data[0] == data[1]     def test_transpose_numeric_categorical(self, data):         result[0] = result[1]         result[1] = data[0]         assert data[0] == data[1]     def test_transpose_categorical_numeric_categorical(self, data):         result[0] = result[1]         result[1] = data[0]         assert data[0] == data[1]     def test_transpose_mixed(self, data):         result[0] = result[1]         result[1] = data[0]         assert data[0] == data[1]     def test_transpose_categorical_mixed(self, data):         result[0] = result[1]         result[1] = data[0]         assert data[0] == data[1]     def test_transpose_numeric_categorical_numeric(self, data):         result[0] = result[1]         result[1] = data[0]         assert data[0] == data[1]     def test_transpose_categorical_numeric_categorical(self, data):         result[0] = result[1]         result[1] = data[0]         assert data[0] == data[1]     def test_transpose_mixed_categorical(self, data):         result[0] = result[1]         result[1] = data[0]         assert data[0] == data[1]     def test_transpose_categorical_mixed_categorical(self, data):         result[0] = result[1]         result[1] = data[0]         assert data[0] == data[1]     def test_transpose_categorical_numeric_categorical(self, data):         result[0] = result[1]         result[1] = data[0]         assert data[0] == data[1]     def test_transpose_numeric_categorical_numeric(self, data):         result[0] = result[1]         result[1] = data[0]         assert data[0] == data[1]     def test_transpose_categorical_numeric_categorical(self, data):         result[0] = result[1]         result[1] = data[0]         assert data[0] == data[1]     def test_transpose_mixed_categorical(self, data):         result[0] = result[1]         result[1] = data[0]         assert data[0] == data[1]     def test_transpose_categorical_mixed_categorical(self, data):         result[0] = result[1]         result[1] = data[0]         assert data[0] == data[1]     def test_transpose_categorical_numeric_categorical(self, data):         result[0] = result[1]         result[1] = data[0]         assert data[0] == data[1]     def test_transpose_numeric_categorical_numeric(self, data):         result[0] = result[1]         result[1] = data[0]         assert data[0] == data[1]     def test_transpose_categorical_numeric_categorical(self, data):         result[0] = result[1]         result[1] = data[0]         assert data[0] == data[1]     def test_transpose_mixed_categorical(self, data):         result[0] = result[1]         result[1] = data[0]         assert data[0] == data[1]     def test_transpose_categorical_mixed_categorical(self, data):         result[0] = result[1]         result[1] = data[0]         assert data[0] == data[1]     def test_transpose_categorical_numeric_categorical(self, data):         result[0] = result[1]         result[1] = data[0]
class CorrectedCommand(object):              compatibility_call(self.side_effect, old_cmd, self.script)          logs.debug(u'PYTHONIOENCODING: {}'.format(             os.environ.get('PYTHONIOENCODING', '>-not-set-<')))         logging.shutdown()          print(self.script)
def add_codes(err_cls):      class ErrorsWithCodes(object):          def __getattribute__(self, code):             msg = getattr(err_cls, code)             return "[{code}] {msg}".format(code=code, msg=msg)      return ErrorsWithCodes()     def add_codes(err_cls):      class ErrorsWithCodes(object):          def __getattribute__(self, code):             msg = getattr(err_cls, code)             return "[{code}] {msg}".format(code=code, msg=msg)      return ErrorsWithCodes()     def add_codes(err_cls):      class ErrorsWithCodes(object):          def __getattribute__(self, code):             msg = getattr(err_cls, code)             return "[{code}] {msg}".format(code=code, msg=msg)      return ErrorsWithCodes()     def add_codes(err_cls):      class ErrorsWithCodes(object):          def __getattribute__(self, code):             msg = getattr(err_cls, code)             return "[{code}] {msg}".format(code=code, msg=msg)      return ErrorsWithCodes()     def add_codes(err_cls):      class ErrorsWithCodes(object):          def __getattribute__(self, code):             msg = getattr(err_cls, code)             return "[{code}] {msg}".format(code=code, msg=msg)      return ErrorsWithCodes()     def add_codes(err_cls):      class ErrorsWithCodes(object):          def __getattribute__(self, code):             msg = getattr(err_cls, code)             return "[{code}] {msg}".format(code=code, msg=msg)      return ErrorsWithCodes()     def add_codes(err_cls):      class ErrorsWithCodes(object):          def __getattribute__(self, code):             msg = getattr(err_cls, code)             return "[{code}] {msg}".format(code=code, msg=msg)      return ErrorsWithCodes()     def add_codes(err_cls):      class ErrorsWithCodes(object):          def __getattribute__(self, code):             msg = getattr(err_cls, code)             return "[{code}] {msg}".format(code=code, msg=msg)      return ErrorsWithCodes()     def add_codes(err_cls):      class ErrorsWithCodes(object):          def __getattribute__(self, code):             msg = getattr(err_cls, code)             return "[{code}] {msg}".format(code=code, msg=msg)      return ErrorsWithCodes()     def add_codes(err_cls):      class ErrorsWithCodes(object):          def __getattribute__(self, code):             msg = getattr(err_cls, code)             return "[{code}] {msg}".format(code=code, msg=msg)      return ErrorsWithCodes()     def add_codes(err_cls):      class ErrorsWithCodes(object):          def __getattribute__(self, code):             msg = getattr(err_cls, code)             return "[{code}] {msg}".format(code=code, msg=msg)      return ErrorsWithCodes()     def add_codes(err_cls):      class ErrorsWithCodes(object):          def __getattribute__(self, code):             msg = getattr(err_cls, code)             return "[{code}] {msg}".format(code=code, msg=msg)      return ErrorsWithCodes()     def add_codes(err_cls):      class ErrorsWithCodes(object):          def __getattribute__(self, code):             msg = getattr(err_cls, code)             return "[{code}] {msg}".format(code=code, msg=msg)      return ErrorsWithCodes()     def add_codes(err_cls):      class ErrorsWithCodes(object):          def __getattribute__(self, code):             msg = getattr(err_cls, code)             return "[{code}] {msg}".format(code=code, msg=msg)      return ErrorsWithCodes()     def add_codes(err_cls):      class ErrorsWithCodes(object):          def __getattribute__(self, code):             msg = getattr(err_cls, code)             return "[{code}] {msg}".format(code=code, msg=msg)      return ErrorsWithCodes
class GroupBy(_GroupBy): func(**kwargs)              if result_is_index:                  result = algorithms.take_nd(obj.values, result)              if post_processing:                  result = post_processing(result, inferences)             return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result class GroupBy(_GroupBy): func(**kwargs)              if result_is_index:                  result = algorithms.take_nd(obj.values, result)              if post_processing:                  result = post_processing(result, inferences)              return result         return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result          return result
def _isna_ndarraylike_old(obj):      return result  def notna(obj):      Detect non-missing values for an array-like object.
class _LocIndexer(_LocationIndexer):          if isinstance(labels, MultiIndex):              if isinstance(key, str) and labels.levels[0]._supports_partial_string_indexing:                  key = tuple([key] + [slice(None)] * (len(labels.levels) - 1))         else:             key = tuple([key] + [slice(None)] * (len(labels.levels) - 1))         if isinstance(key, str) and labels.levels[0].is_all_dates:                  key = tuple([key] + [slice(None)] * (len(labels.levels) - 1))         else:             key = tuple([key] + [slice(None)] * (len(labels.levels) - 1))         if isinstance(key, str) and labels.levels[0]._supports_partial_string_indexing:                  key = tuple([key] + [slice(None)] * (len(labels.levels) - 1))         else:             key = tuple([key] + [slice(None)] * (len(labels.levels) - 1))         if isinstance(key, str) and labels.levels[0].is_all_dates:                  key = tuple([key] + [slice(None)] * (len(labels.levels) - 1))         else:             key = tuple([key] + [slice(None)] * (len(labels.levels) - 1))         if isinstance(key, str) and labels.levels[0]._supports_partial_string_indexing:                  key = tuple([key] + [slice(None)] * (len(labels.levels) - 1))         else:             key = tuple([key] + [slice(None)] * (len(labels.levels) - 1))         if isinstance(key, str) and labels.levels[0].is_all_dates:                  key = tuple([key] + [slice(None)] * (len(labels.levels) - 1))         else:             key = tuple([key] + [slice(None)] * (len(labels.levels) - 1))         if isinstance(key, str) and labels.levels[0]._supports_partial_string_indexing:                  key = tuple([key] + [slice(None)] * (len(labels.levels) - 1))         else:             key = tuple([key] + [slice(None)] * (len(labels.levels) - 1))         if isinstance(key, str) and labels.levels[0].is_all_dates:                  key = tuple([key] + [slice(None)] * (len(labels.levels) - 1))         else:             key = tuple([key] + [slice(None)] * (len(labels.levels) - 1))         if isinstance(key, str) and labels.levels[0]._supports_partial_string_indexing:                  key = tuple([key] + [slice(None)] * (len(labels.levels) - 1))         else:             key = tuple([key] + [slice(None)] * (len(labels.levels) - 1))         if isinstance(key, str) and labels.levels[0].is_all_dates:                  key = tuple([key] + [slice(None)] * (len(labels.levels) - 1))         else:             key = tuple([key] + [slice(None)] * (len(labels.levels) - 1))         if isinstance(key, str) and labels.levels[0]._supports_partial_string_indexing:                   key = tuple([key] + [slice(None)] * (len(labels.levels) - 1))         else:             key = tuple([key] + [slice(None)] * (len(labels.levels) - 1))         if isinstance(key, str) and labels.levels[0].is_all_dates:                   key = tuple([key] + [slice(None)] * (len(labels.levels) - 1))         else:             key = tuple([key] + [slice(None)] * (len(labels.levels) - 1))         if isinstance(key, str) and labels.levels[0]._supports_partial_string_indexing:                   key = tuple([key] + [slice(None)] * (len(labels.levels) - 1))         else:             key = tuple([key] + [slice(None)] * (len(labels.levels) - 1))         if isinstance(key, str) and labels.levels[0].is_all_dates:                   key = tuple([key] + [slice(None)] * (len(labels.levels) - 1))         else:              key = tuple([key] + [slice(None)] * (len(labels.levels) -
class BracketTracker:         if self._lambda_arguments and leaf.type == token.COLON:              self.depth -= 1             self._lambda_arguments -= 1              return True          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False
class DatetimeIndexOpsMixin(ExtensionIndex, ExtensionOpsMixin):          if isinstance(maybe_slice, slice):              return self[maybe_slice]         taken = ExtensionIndex.take(              self, indices, axis, allow_fill, fill_value, **kwargs          )         return self._shallow_copy(taken, fill_value=fill_value)      _can_hold_na = True      _na_value = NaT
def _isna_new(obj):      elif hasattr(obj, "__array__"):          return _isna_ndarraylike(np.asarray(obj), dtype=np.int64)      else:         return obj is None def _isna_new(obj, dtype):      elif hasattr(obj, "__array__"):          return _isna_ndarraylike(np.asarray(obj), dtype=dtype)      else:         return obj is None  def _isna_old(obj, dtype):         return _isna_ndarraylike(np.asarray(obj), dtype=dtype)  def _isna_new(obj, dtype):      elif hasattr(obj, "__array__"):          return _isna_ndarraylike(np.asarray(obj), dtype=dtype)      else:         return obj is None  def _isna_old(obj, dtype):         return _isna_ndarraylike(np.asarray(obj), dtype=dtype)  def _isna_new(obj, dtype):      elif hasattr(obj, "__array__"):          return _isna_ndarraylike(np.asarray(obj), dtype=dtype)      else:         return obj is None  def _isna_old(obj, dtype):         return _isna_ndarraylike(np.asarray(obj), dtype=dtype)  def _isna_new(obj, dtype):      elif hasattr(obj, "__array__"):          return _isna_ndarraylike(np.asarray(obj), dtype=dtype)      else:         return obj is None  def _isna_old(obj, dtype):         return _isna_ndarraylike(np.asarray(obj), dtype=dtype)  def _isna_new(obj, dtype):      elif hasattr(obj, "__array__"):          return _isna_ndarraylike(np.asarray(obj), dtype=dtype)      else:         return obj is None  def _isna_old(obj, dtype):         return _isna_ndarraylike(np.asarray(obj), dtype=dtype)  def _isna_new(obj, dtype):      elif hasattr(obj, "__array__"):          return _isna_ndarraylike(np.asarray(obj), dtype=dtype)      else:         return obj is None  def _isna_old(obj, dtype):         return _isna_ndarraylike(np.asarray(obj), dtype=dtype)  def _isna_new(obj, dtype):      elif hasattr(obj, "__array__"):          return _isna_ndarraylike(np.asarray(obj), dtype=dtype)      else:         return obj is None  def _isna_old(obj, dtype):         return _isna_ndarraylike(np.asarray(obj), dtype=dtype)  def _isna_new(obj, dtype):      elif hasattr(obj, "__array__"):          return _isna_ndarraylike(np.asarray(obj), dtype=dtype)      else:         return obj is None  def _isna_old(obj, dtype):         return _isna_ndarraylike(np.asarray(obj), dtype=dtype)  def _isna_new(obj, dtype):      elif hasattr(obj, "__array__"):          return _isna_ndarraylike(np.asarray(obj), dtype=dtype)      else:         return obj is None  def _isna_old(obj, dtype):         return _isna_ndarraylike(np.asarray(obj), dtype=dtype)  def _isna_new(obj, dtype):      elif hasattr(obj, "__array__"):          return _isna_ndarraylike(np.asarray(obj), dtype=dtype)      else:         return obj is None  def _isna_old(obj, dtype):         return _isna_ndarraylike(np.asarray(obj), dtype=dtype)  def _isna_new(obj, dtype):      elif hasattr(obj, "__array__"):          return _isna_ndarraylike(np.asarray(obj), dtype=dtype)      else:         return obj is None  def _isna_old(obj, dtype):         return _isna_ndarraylike(np.asarray(obj), dtype=dtype)  def _isna_new(obj, dtype):      elif hasattr(obj, "__array__"):          return _isna_ndarraylike(np.asarray(obj), dtype=dtype)      else:         return obj is None  def _isna_old(obj, dtype):         return _isna_ndarraylike(np.asarray(obj), dtype=dtype)  def _isna_new(obj, dtype):      elif hasattr(obj, "__array__"):          return _isna_ndarraylike(np.asarray(obj), dtype=dtype)      else:         return obj is None  def _isna_old(obj, dtype):         return _isna_ndarraylike(np.asarray(obj), dtype=dtype)  def _isna_new(obj, dtype):      elif hasattr(obj, "__array
class TestSeriesComparison:          dti = dti.tz_localize("US/Central")          ser = Series(dti).rename(names[1])          result = op(ser, dti)          assert result.name == names[2]         result = op(ser, dti)          assert result.name == names[0]         result = op(ser, dti)          assert result.name == names[1]
'\\': '\\', def js_to_json(code):          if v in ('true', 'false', 'null'):              return v elif v.startswith('"'):              return v          if v.startswith("'"):              v = v[1:-1]              v = re.sub(r"\\\\|\\'|\"", lambda m: {                  '\\\\': '\\\\',                 '\\': '\\',             if v.endswith('"'):                  v = v[:-1]                  v = re.sub(r"\\\\|\\'|\"", lambda m: {                      '\\\\': '\\\\',                      '\\': '\\',             if v.endswith(""'):                   v = v[:-1]                   v = re.sub(r"\\\\|\\'|\"", lambda m: {                       '\\\\': '\\\\',                       '\\': '\\',             if v.startswith("'"):                   v = v[1:-1]                   v = re.sub(r"\\\\|\\'|\"", lambda m: {                       '\\\\': '\\\\',                       '\\': '\\',             if v.endswith(""'):                   v = v[:-1]                   v = re.sub(r"\\\\|\\'|\"", lambda m: {                        '\\\\': '\\\\',                        '\\': '\\',             if v.startswith("'"):                   v = v[1:-1]                   v = re.sub(r"\\\\|\\'|\"", lambda m: {                        '\\\\': '\\\\',                        '\\': '\\',             if v.endswith(""'):                   v = v[:-1]                   v = re.sub(r"\\\\|\\'|\"", lambda m: {                        '\\\\': '\\\\',                        '\\': '\\',             if v.startswith("'"):                   v = v[1:-1]                   v = re.sub(r"\\\\|\\'|\"", lambda m: {                        '\\\\': '\\\\',                        '\\': '\\',             if v.endswith(""'):                   v = v[:-1]                   v = re.sub(r"\\\\|\\'|\"", lambda m: {                        '\\\\': '\\\\',                        '\\': '\\',             if v.startswith("'"):                   v = v[1:-1]                   v = re.sub(r"\\\\|\\'|\"", lambda m: {                        '\\\\': '\\\\',                        '\\': '\\',             if v.endswith(""'):                   v = v[:-1]                   v = re.sub(r"\\\\|\\'|\"", lambda m: {                        '\\\\': '\\\\',                        '\\': '\\',             if v.
class Model(BaseModel):  class ModelSubclass(Model):      y: int  @app.get("/", response_model=Model, response_model_exclude_unset=True)  def get() -> ModelSubclass:     return ModelSubclass(sub={}, y=1)  client = TestClient(app) @app.get("/", response_model=Model, response_model_exclude_unset=True)  def get() -> ModelSubclass:     return ModelSubclass(sub={}, y=1)  client = TestClient(app)     def get_model_subclass(request):         return ModelSubclass(sub={}, y=1)  client = TestClient(app)     def get_model_subclass_kwargs(request):         return {'y': 1}  class Model(BaseModel):  class ModelSubclass(Model):      y: int  @app.get("/", response_model=Model, response_model_exclude_unset=True)  def get() -> ModelSubclass:     return ModelSubclass(sub={}, y=1)  client = TestClient(app)     def get_model_subclass(request):         return ModelSubclass(sub={}, y=1)  client = TestClient(app)     def get_model_subclass_kwargs(request):         return {'y': 1}  class Model(BaseModel):  class ModelSubclass(Model):      y: int  @app.get("/", response_model=Model, response_model_exclude_unset=True)  def get() -> ModelSubclass:     return ModelSubclass(sub={}, y=1)  client = TestClient(app)     def get_model_subclass(request):         return ModelSubclass(sub={}, y=1)  client = TestClient(app)     def get_model_subclass_kwargs(request):         return {'y': 1}  class Model(BaseModel):  class ModelSubclass(Model):      y: int  @app.get("/", response_model=Model, response_model_exclude_unset=True)  def get() -> ModelSubclass:     return ModelSubclass(sub={}, y=1)  client = TestClient(app)     def get_model_subclass(request):         return ModelSubclass(sub={}, y=1)  client = TestClient(app)     def get_model_subclass_kwargs(request):         return {'y': 1}  class Model(BaseModel):  class ModelSubclass(Model):      y: int  @app.get("/", response_model=Model, response_model_exclude_unset=True)  def get() -> ModelSubclass:     return ModelSubclass(sub={}, y=1)  client = TestClient(app)     def get_model_subclass(request):         return ModelSubclass(sub={}, y=1)  client = TestClient(app)     def get_model_subclass_kwargs(request):         return {'y': 1}  class Model(BaseModel):  class ModelSubclass(Model):      y: int  @app.get("/", response_model=Model, response_model_exclude_unset=True)  def get() -> ModelSubclass:     return ModelSubclass(sub={}, y=1)  client = TestClient(app)     def get_model_subclass(request):         return ModelSubclass(sub={}, y=1)  client = TestClient(app)     def get_model_subclass_kwargs(request):         return {'y': 1}  class Model(BaseModel):  class ModelSubclass(Model):      y: int  @app.get("/", response_model=Model, response_model_exclude_unset=True)  def get() -> ModelSubclass:     return ModelSubclass(sub={}, y=1)  client = TestClient(app)     def get_model_subclass(request):         return ModelSubclass(sub={}, y=1)  client = TestClient(app)     def get_model_subclass_kwargs(request):         return {'y': 1}  class Model(BaseModel):  class ModelSubclass(Model):      y: int  @app.get("/", response_model=Model, response_model_exclude_unset=True)  def get() -> ModelSubclass:     return ModelSubclass(sub={}, y=1)  client = TestClient(app)     def get_model_subclass(request):         return ModelSubclass(sub={}, y=1)  client = TestClient(app)     def get_model_subclass_kwargs(request):         return {'y': 1}  class Model(BaseModel):  class ModelSubclass(Model):      y: int  @app.get("/", response_model=Model, response_model_exclude_unset=True)  def get() -> ModelSubclass:     return ModelSubclass(sub={}, y=1)  client = TestClient(app)     def get_model_subclass(request):         return ModelSubclass(sub={}, y=1)  client = TestClient(app)     def get_model_subclass_kwargs(request):         return {'y': 1}  class Model(BaseModel):  class ModelSubclass(Model):      y: int  @app.get("/", response_model=Model, response_model_exclude_unset=True)  def get() -> ModelSubclass:     return ModelSubclass(sub={}, y=1)  client = TestClient(app)     def get_model_subclass(request):         return ModelSubclass(sub={}, y=1)  client = TestClient(app)     def get_model_subclass_kwargs(request):         return {'y': 1}  class Model(BaseModel):  class ModelSubclass(Model):      y: int  @app.get("/", response_model=Model, response_model_exclude_unset=True)  def get() -> ModelSubclass:     return ModelSubclass(sub={}, y=1)  client = TestClient(app)     def get_model_subclass(request):
default 'raise'              )          new_dates = new_dates.view(DT64NS_DTYPE)          dtype = tz_to_dtype(tz)         return self._simple_new(new_dates, dtype=dtype,
class ReduceLROnPlateau(Callback):              self.mode = 'auto'          if (self.mode =='min' or             (self.mode == 'auto' and 'acc' not in self.monitor)):             self.monitor_op = lambda a, b: np.less_equal(a, b - self.epsilon)              self.best = np.Inf          else:             self.monitor_op = lambda a, b: np.greater_equal(a, b + self.epsilon)              self.best = -np.Inf          self.cooldown_counter = 0          self.wait = 0
def get_objs_combined_axis(          The axis to extract indexes from.      sort : bool, default True          Whether the result index should come out sorted or not.     copy : bool, default False         If True, return a copy of the combined index.      Returns      -------      Index      obs_idxes = [         obj._get_axis(axis)         for obj in objs     ]     return _get_combined_index(obs_idxes, intersect=intersect, sort=sort, copy=copy)  def _get_distinct_objs(objs: List[Index]) -> List[Index]:
class QuarterOffset(DateOffset):          shifted = liboffsets.shift_quarters(              dtindex.asi8, self.n, self.startingMonth, self._day_opt          )         return type(dtindex)._simple_new(shifted, dtype=dtindex.dtype)  class BQuarterEnd(QuarterOffset):
class ImageDataGenerator(object):              The inputs, normalized.         if self.preprocessing_function:             x = self.preprocessing_function(x)          if self.rescale:              x *= self.rescale          if self.samplewise_center:              x = self.samplewise_center(x)          if self.dilation_rate:              x = self.dilation_rate(x)          if self.samplewise_center:              x = self.samplewise_center(x)          if self.dilation_rate:              x = self.dilation_rate(x)          if self.samplewise_center:              x = self.samplewise_center(x)          if self.dilation_rate:              x = self.dilation_rate(x)          if self.samplewise_center:              x = self.samplewise_center(x)          if self.dilation_rate:              x = self.dilation_rate(x)          if self.samplewise_center:              x = self.samplewise_center(x)          if self.dilation_rate:              x = self.dilation_rate(x)          if self.samplewise_center:              x = self.samplewise_center(x)          if self.dilation_rate:              x = self.dilation_rate(x)          if self.samplewise_center:              x = self.samplewise_center(x)          if self.dilation_rate:              x = self.dilation_rate(x)          if self.samplewise_center:              x = self.samplewise_center(x)          if self.dilation_rate:              x = self.dilation_rate(x)          if self.samplewise_center:              x = self.samplewise_center(x)          if self.dilation_rate:              x = self.dilation_rate(x)          if self.samplewise_center:              x = self.samplewise_center(x)          if self.dilation_rate:              x = self.dilation_rate(x)          if self.samplewise_center:              x = self.samplewise_center(x)          if self.dilation_rate:              x = self.dilation_rate(x)          if self.samplewise_center:              x = self.samplewise_center(x)          if self.dilation_rate:              x = self.dilation_rate(x)          if self.samplewise_center:              x = self.samplewise_center(x)          if self.dilation_rate:              x = self.dilation_rate(x)          if self.samplewise_center:              x = self.samplewise_center(x)          if self.dilation_rate:              x = self.dilation_rate(x)          if self.samplewise_center:              x = self.samplewise_center(x)          if self.dilation_rate:              x = self.dilation_rate(x)          if self.samplewise_center:              x = self.samplewise_center(x)          if self.dilation_rate:              x = self.dilation_rate(x)          if self.samplewise_center:              x = self.samplewise_center(x)          if self.dilation_rate:              x = self.dilation_rate(x)          if self.samplewise_center:              x = self.samplewise_center(x)          if self.dilation_rate:              x = self.dilation_rate(x)          if self.samplewise_center:              x = self.samplewise_center(x)          if self.dilation_rate:              x = self.dilation_rate(x)          if self.samplewise_center:
def _cat_compare_op(op):              mask = (self._codes == -1) | (other_codes == -1)              if mask.any():                 ret[mask] = False              return ret          if is_valid_nat_for_dtype(other, self.dtype):              ret[mask] = False              return ret          if is_scalar(other):              ret[mask] = False              return ret          if is_valid_nat_for_dtype(other, self.dtype):              ret[mask] = False              return ret def _cat_compare_op(op):              mask = (self._codes == -1) | (other_codes == -1)              if mask.any():                 ret[mask] = False              return ret          if is_valid_nat_for_dtype(other, self.dtype):              ret[mask] = False              return ret          if is_scalar(other):              ret[mask] = False              return ret          if is_valid_nat_for_dtype(other, self.dtype):              ret[mask] = False              return ret          if is_scalar(other):              ret[mask] = False              return ret          if is_valid_nat_for_dtype(other, self.dtype):              ret[mask] = False              return ret          if is_scalar(other):              ret[mask] = False              return ret          if is_valid_nat_for_dtype(other, self.dtype):              ret[mask] = False              return ret          if is_scalar(other):              ret[mask] = False              return ret          if is_valid_nat_for_dtype(other, self.dtype):              ret[mask] = False              return ret          if is_scalar(other):              ret[mask] = False              return ret          if is_valid_nat_for_dtype(other, self.dtype):              ret[mask] = False              return ret          if is_scalar(other):              ret[mask] = False              return ret          if is_valid_nat_for_dtype(other, self.dtype):              ret[mask] = False              return ret          if is_scalar(other):              ret[mask] = False              return ret          if is_valid_nat_for_dtype(other, self.dtype):              ret[mask] = False              return ret          if is_scalar(other):              ret[mask] = False              return ret          if is_valid_nat_for_dtype(other, self.dtype):              ret[mask] = False              return ret          if is_scalar(other):              ret[mask] = False              return ret          if is_valid_nat_for_dtype(other, self.dtype):              ret[mask] = False              return ret          if is_scalar(other):              ret[mask] = False              return ret          if is_valid_nat_for_dtype(other, self.dtype):              ret[mask] = False              return ret          if is_scalar(other):              ret[mask] = False              return ret          if is_valid_nat_for_dtype(other, self.dtype):              ret[mask] = False
def match(command, settings):      return _search(command.stderr) or _search(command.stdout) or _search(command.script)  def get_new_command(command, settings):      m = _search(command.stderr) or _search(command.stdout) or _search(command.script)      return shells.and_(m, command.script)  def match(command, settings):      return _search(command.stderr) or _search(command.stdout) or _search(command.script)  def get_new_command(command, settings):      m = _search(command.stderr) or _search(command.stdout) or _search(command.script)      return shells.and_(m, command.script)  def match(command, settings):      return _search(command.stderr) or _search(command.stdout) or _search(command.script)  def get_new_command(command, settings):      m = _search(command.stderr) or _search(command.stdout) or _search(command.script)      return shells.and_(m, command.script)  def match(command, settings):      return _search(command.stderr) or _search(command.stdout) or _search(command.script)  def get_new_command(command, settings):      m = _search(command.stderr) or _search(command.stdout) or _search(command.script)      return shells.and_(m, command.script)  def match(command, settings):      return _search(command.stderr) or _search(command.stdout) or _search(command.script)  def get_new_command(command, settings):      m = _search(command.stderr) or _search(command.stdout) or _search(command.script)      return shells.and_(m, command.script)  def match(command, settings):      return _search(command.stderr) or _search(command.stdout) or _search(command.script)  def get_new_command(command, settings):      m = _search(command.stderr) or _search(command.stdout) or _search(command.script)      return shells.and_(m, command.script)  def match(command, settings):      return _search(command.stderr) or _search(command.stdout) or _search(command.script)  def get_new_command(command, settings):      m = _search(command.stderr) or _search(command.stdout) or _search(command.script)      return shells.and_(m, command.script)  def match(command, settings):      return _search(command.stderr) or _search(command.stdout) or _search(command.script)  def get_new_command(command, settings):      m = _search(command.stderr) or _search(command.stdout) or _search(command.script)      return shells.and_(m, command.script)  def match(command, settings):      return _search(command.stderr) or _search(command.stdout) or _search(command.script)  def get_new_command(command, settings):      m = _search(command.stderr) or _search(command.stdout) or _search(command.script)      return shells.and_(m, command.script)  def match(command, settings):      return _search(command.stderr) or _search(command.stdout) or _search(command.script)  def get_new_command(command, settings):      m = _search(command.stderr) or _search(command.stdout) or _search(command.script)      return shells.and_(m, command.script)  def match(command, settings):      return _search(command.stderr) or _search(command.stdout) or _search(command.script)  def get_new_command(command, settings):      m = _search(command.stderr) or _search(command.stdout) or _search(command.script)      return shells.and_(m, command.script)  def match(command, settings):      return _search(command.stderr) or _search(command.stdout) or _search(command.script)  def get_new_command(command, settings):      m = _search(command.stderr) or _search(command.stdout) or _search(command.script)      return shells.and_(m, command.script)  def match(command, settings):      return _search(command.stderr) or _search(command.stdout) or _search(command.script)  def get_new_command(command, settings):      m = _search(command.stderr) or _search(command.stdout) or _search(command.script)      return shells.and_(m, command.script)  def match(command, settings):      return _search(command.stderr) or _search(command.stdout) or _search(command.script)  def get_new_command(command, settings):      m = _search(command.stderr) or _search(command.stdout) or _search(command.script)      return shells.and_(m, command.script)  def match(command, settings):      return _search(command.stderr) or _search(command.stdout) or _search(command.script)  def get_new_command(command, settings):      m = _search(command.stderr) or _search(command.stdout) or _search(command.script)      return shells.and_(m, command.script)  def match(command, settings):      return _search(command.stderr) or _search(command.stdout) or _search(command.script)  def get_new_command(command, settings):      m = _search(command.stderr) or _search(command.stdout) or _search(command.script)
def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),          padding: string, "same" or "valid".          data_format: "channels_last" or "channels_first".         dilation_rate: tuple of 2 integers.          ValueError: if using an even kernel size with padding'same'.              Whether to use Theano or TensorFlow data format         in inputs/kernels/outputs.          ValueError: if using an even kernel size with padding 'valid'.              Whether to use Theano or TensorFlow data format         in inputs/kernels/outputs.          ValueError: if using an even kernel size with padding'same'.         dilation_rate: tuple of 2 integers.          ValueError: if using an even kernel size with padding 'valid'.              Whether to use Theano or TensorFlow data format         in inputs/kernels/outputs.          ValueError: if using an even kernel size with padding'same'.         dilation_rate: tuple of 2 integers.          ValueError: if using an even kernel size with padding 'valid'.              Whether to use Theano or TensorFlow data format         in inputs/kernels/outputs.          ValueError: if using an even kernel size with padding'same'.         dilation_rate: tuple of 2 integers.          ValueError: if using an even kernel size with padding 'valid'.              Whether to use Theano or TensorFlow data format         in inputs/kernels/outputs.          ValueError: if using an even kernel size with padding'same'.         dilation_rate: tuple of 2 integers.          ValueError: if using an even kernel size with padding 'valid'.              Whether to use Theano or TensorFlow data format         in inputs/kernels/outputs.          ValueError: if using an even kernel size with padding'same'.         dilation_rate: tuple of 2 integers.          ValueError: if using an even kernel size with padding 'valid'.              Whether to use Theano or TensorFlow data format         in inputs/kernels/outputs.          ValueError: if using an even kernel size with padding'same'.         dilation_rate: tuple of 2 integers.          ValueError: if using an even kernel size with padding 'valid'.              Whether to use Theano or TensorFlow data format         in inputs/kernels/outputs.          ValueError: if using an even kernel size with padding'same'.         dilation_rate: tuple of 2 integers.          ValueError: if using an even kernel size with padding 'valid'.              Whether to use Theano or TensorFlow data format         in inputs/kernels/outputs.          ValueError: if using an even kernel size with padding'same'.         dilation_rate: tuple of 2 integers.          ValueError: if using an even kernel size with padding 'valid'.              Whether to use Theano or TensorFlow data format         in inputs/kernels/outputs.          ValueError: if using an even kernel size with padding'same'.         dilation_rate: tuple of 2 integers.          ValueError: if using an even kernel size with padding 'valid'.              Whether to use Theano or TensorFlow data format         in inputs/kernels/outputs.          ValueError: if using an even kernel size with padding'same'.         dilation_rate: tuple of 2 integers.          ValueError: if using an even kernel size with padding 'valid'.              Whether to use Theano or TensorFlow data format         in inputs/kernels/outputs.          ValueError: if using an even kernel size with padding'same'.         dilation_rate: tuple of 2 integers.          ValueError: if using an even kernel size with padding 'valid'.              Whether to use Theano or TensorFlow data format         in inputs/kernels/outputs.          ValueError: if using an even kernel size with padding'same'.         dilation_rate: tuple of 2 integers.          ValueError: if using an even kernel size with padding 'valid'.              Whether to use Theano or TensorFlow data format         in inputs/kernels/outputs.          ValueError: if using an even kernel size with padding'same'.         dilation_rate: tuple of 2 integers.          ValueError: if using an even kernel size with padding 'valid'.              Whether to use Theano or TensorFlow data format         in inputs/kernels/outputs.          ValueError: if using an even kernel size with padding'same'.         dilation_rate: tuple of 2 integers.          ValueError: if using an even kernel size with padding 'valid'.              Whether to use Theano or TensorFlow data format
class Spider(object_ref):          crawler.signals.connect(self.close, signals.spider_closed)      def start_requests(self):         for url in self.start_urls:              yield self.make_requests_from_url(url)              warnings.warn(                 "Spider.make_requests_from_url method is deprecated; "                 "it won't be called in future Scrapy releases. "                 "Please override start_requests method instead."              )              for url in self.start_urls:                  yield self.make_requests_from_url(url)               warnings.warn(                  "Spider.make_requests_from_url method is deprecated; "                  "it won't be called in future Scrapy releases. "                  "Please override start_requests method instead."              )              for url in self.start_urls:                  yield self.make_requests_from_url(url)               warnings.warn(                   "Spider.make_requests_from_url method is deprecated; "                  "it won't be called in future Scrapy releases. "                  "Please override start_requests method instead."              )              for url in self.start_urls:                  yield self.make_requests_from_url(url)               warnings.warn(                   "Spider.make_requests_from_url method is deprecated; "                   "it won't be called in future Scrapy releases. "                   "Please override start_requests method instead."              )              for url in self.start_urls:                  yield self.make_requests_from_url(url)               warnings.warn(                    "Spider.make_requests_from_url method is deprecated; "                    "it won't be called in future Scrapy releases. "                    "Please override start_requests method instead."              )              for url in self.start_urls:                  yield self.make_requests_from_url(url)               warnings.warn(                    "Spider.make_requests_from_url method is deprecated; "                    "it won't be called in future Scrapy releases. "                    "Please override start_requests method instead."              )              for url in self.start_urls:                  yield self.make_requests_from_url(url)               warnings.warn(                    "Spider.make_requests_from_url method is deprecated; "                    "it won't be called in future Scrapy releases. "                    "Please override start_requests method instead."              )              for url in self.start_urls:                  yield self.make_requests_from_url(url)               warnings.warn(                    "Spider.make_requests_from_url method is deprecated; "                    "it won't be called in future Scrapy releases. "                    "Please override start_requests method instead."               )               for url in self.start_urls:                  yield self.make_requests_from_url(url)
def reformat_many(      if sys.platform == "win32":          worker_count = min(worker_count, 61)     executor = ProcessPoolExecutor(max_workers=worker_count,
class PeriodIndex(DatetimeIndexOpsMixin, Int64Index, PeriodDelegateMixin):              try:                  loc = self._get_string_slice(key)                  return series[loc]             except (TypeError, ValueError, OverflowError):                  pass              asdt, reso = parse_time_string(key, self.freq)                 if loc is None:                     return                  else:                     return series[loc]              asdt, reso = parse_time_string(key, self.freq)              if loc is None:                  return              else:                  return series[loc]              asdt, reso = parse_time_string(key, self.freq)              if loc is None:                  return              else:                  return series[loc]              asdt, reso = parse_time_string(key, self.freq)              if loc is None:                  return              else:                  return series[loc]              asdt, reso = parse_time_string(key, self.freq)              if loc is None:                  return              else:                 return series[loc]              asdt, reso = parse_time_string(key, self.freq)              if loc is None:                  return              else:                  return series[loc]              asdt, reso = parse_time_string(key, self.freq)              if loc is None:                  return              else:                 return series[loc]              asdt, reso = parse_time_string(key, self.freq)              if loc is None:                  return              else:                  return series[loc]              asdt, reso = parse_time_string(key, self.freq)              if loc is None:                 return              else:                 return series[loc]              asdt, reso = parse_time_string(key, self.freq)              if loc is None:                  return              else:                 return series[loc]              asdt, reso = parse_time_string(key, self.freq)              if loc is None:                 return              else:                 return series[loc]              asdt, reso = parse_time_string(key, self.freq)              if loc is None:                  return              else:                 return series[loc]              asdt, reso = parse_time_string(key, self.freq)              if loc is None:                  return               else:                  return series[loc]               asdt, reso = parse_time_string(key, self.freq)              if loc is None:                  return               else:                  return series[loc]               asdt, reso = parse_time_string(key, self.freq)
def base_url(url):  def urljoin(base, path):      if not isinstance(path, compat_str) or not path:          return None if re.match(r'^(?:[a-zA-Z][a-zA-Z0-9+-.]*:)?          return path if not isinstance(base, compat_str) or not re.match(r'^(?:[a-zA-Z][a-zA-Z0-9+-.]*:)?          return None      return compat_urlparse.urljoin(base, path)  def base_url(url):  def urljoin(base, path):      if not isinstance(path, compat_str) or not path:          return None if re.match(r'^(?:[a-zA-Z][a-zA-Z0-9+-.]*:)?          return path if not isinstance(base, compat_str) or not re.match(r'^(?:[a-zA-Z][a-zA-Z0-9+-.]*:)?          return None      return compat_urlparse.urljoin(base, path)  def base_url(url):  def urljoin(base, path):      if not isinstance(path, compat_str) or not path:          return None if re.match(r'^(?:[a-zA-Z][a-zA-Z0-9+-.]*:)?          return path if not isinstance(base, compat_str) or not re.match(r'^(?:[a-zA-Z][a-zA-Z0-9+-.]*:)?          return None      return compat_urlparse.urljoin(base, path)  def base_url(url):  def urljoin(base, path):      if not isinstance(path, compat_str) or not path:          return None if re.match(r'^(?:[a-zA-Z][a-zA-Z0-9+-.]*:)?          return path if not isinstance(base, compat_str) or not re.match(r'^(?:[a-zA-Z][a-zA-Z0-9+-.]*:)?          return None      return compat_urlparse.urljoin(base, path)  def base_url(url):  def urljoin(base, path):      if not isinstance(path, compat_str) or not path:          return None if re.match(r'^(?:[a-zA-Z][a-zA-Z0-9+-.]*:)?          return path if not isinstance(base, compat_str) or not re.match(r'^(?:[a-zA-Z][a-zA-Z0-9+-.]*:)?          return None      return compat_urlparse.urljoin(base, path)  def base_url(url):  def urljoin(base, path):      if not isinstance(path, compat_str) or not path:          return None if re.match(r'^(?:[a-zA-Z][a-zA-Z0-9+-.]*:)?          return path if not isinstance(base, compat_str) or not re.match(r'^(?:[a-zA-Z][a-zA-Z0-9+-.]*:)?          return None      return compat_urlparse.urljoin(base, path)  def base_url(url):  def urljoin(base, path):      if not isinstance(path, compat_str) or not path:          return None if re.match(r'^(?:[a-zA-Z][a-zA-Z0-9+-.]*:)?          return path if not isinstance(base, compat_str) or not re.match(r'^(?:[a-zA-Z][a-zA-Z0-9+-.]*:)?          return None      return compat_urlparse.urljoin(base, path)  def base_url(url):  def urljoin(base, path):      if not isinstance(path, compat_str) or not path:          return None if re.match(r'^(?:[a-zA-Z][a-zA-Z0-9+-.]*:)?          return path if not isinstance(base, compat_str) or not re.match(r'^(?:[a-zA-Z][a-zA-Z0-9+-.]*:)?          return None      return compat_urlparse.urljoin(base, path)  def base_url(url):  def urljoin(base, path):      if not isinstance(path, compat_str) or not path:          return None if re.match(r'^(?:[a-zA-Z][a-zA-Z0-9+-.]*:)?          return path if not isinstance(base, compat_str) or not re.match(r'^(?:[a-zA-Z][a-zA-Z0-9+-.]*:)?          return None      return compat_urlparse.urljoin(base, path)  def base_url(url):  def urljoin(base, path):      if not isinstance(path, compat_str) or not path:          return None if re.match(r'^(?:[a-zA-Z][a-zA-Z0-9+-.]*:)?          return path if not isinstance(base, compat_str) or not re.match(r'^(?:[a-zA-Z][a-zA-Z0-9+-.]*:)?          return None      return compat_urlparse.urljoin(base, path)  def base_url(url):  def urljoin(base, path):      if not isinstance(path, compat_str) or not
class _LocIndexer(_LocationIndexer):              return self._getbool_axis(key, axis=axis)          elif is_list_like_indexer(key):             if isinstance(labels, ABCMultiIndex):                 if isinstance(key, (ABCSeries, np.ndarray)) and key.ndim <= 1:                     key = list(key)                 elif isinstance(key, ABCDataFrame):                      raise NotImplementedError(                         "Indexing a MultiIndex with a "                         "DataFrame key is not "                         "implemented"                     )                 elif hasattr(key, "ndim") and key.ndim > 1:                     raise NotImplementedError(                         "Indexing a MultiIndex with a "                         "multidimensional key is not "                         "implemented"                     )                 if (                     not isinstance(key, tuple)                     and len(key)                     and not isinstance(key[0], tuple)                 ):                      key = tuple([key])              if not (isinstance(key, tuple) and isinstance(labels, ABCMultiIndex)):                  if isinstance(key, (ABCSeries, np.ndarray)) and key.ndim <= 1:                      key = list(key)              elif isinstance(key, ABCDataFrame):                      raise NotImplementedError(                         "Indexing a MultiIndex with a "                         "DataFrame key is not "                         "implemented"                     )                 elif hasattr(key, "ndim") and key.ndim > 1:                     raise NotImplementedError(                         "Indexing a MultiIndex with a "                         "multidimensional key is not "                         "implemented"                     )              if (                  not isinstance(key, tuple)
def print_tensor(x, message=''):          The same tensor `x`, unchanged.     op = tf.identity(x)     return tf.Print(op, [x], message)     def print_tensor(x, message=''):          The same tensor `x`, unchanged.     return tf.Print(x, [x], message) def print_tensor(x, message=''):          The same tensor `x`, unchanged.     op = tf.identity(x)     return tf.Print(op, [x], message)     def print_tensor(x, message=''):          The same tensor `x`, unchanged.     op = tf.identity(x)     return tf.Print(op, [x], message)     def print_tensor(x, message=''):          The same tensor `x`, unchanged.     op = tf.identity(x)     return tf.Print(op, [x], message)     def print_tensor(x, message=''):          The same tensor `x`, unchanged.     op = tf.identity(x)     return tf.Print(op, [x], message)     def print_tensor(x, message=''):          The same tensor `x`, unchanged.     op = tf.identity(x)     return tf.Print(op, [x], message)     def print_tensor(x, message=''):          The same tensor `x`, unchanged.     op = tf.identity(x)     return tf.Print(op, [x], message)     def print_tensor(x, message=''):          The same tensor `x`, unchanged.     op = tf.identity(x)     return tf.Print(op, [x], message)     def print_tensor(x, message=''):          The same tensor `x`, unchanged.     op = tf.identity(x)     return tf.Print(op, [x], message)     def print_tensor(x, message=''):          The same tensor `x`, unchanged.     op = tf.identity(x)     return tf.Print(op, [x], message)     def print_tensor(x, message=''):          The same tensor `x`, unchanged.     op = tf.identity(x)     return tf.Print(op, [x], message)     def print_tensor(x, message=''):          The same tensor `x`, unchanged.     op = tf.identity(x)     return tf.Print(op, [x], message)     def print_tensor(x, message=''):          The same tensor `x`, unchanged.     op = tf.identity(x)     return tf.Print(op, [x], message)     def print_tensor(x, message=''):          The same tensor `x`, unchanged.     op = tf.identity(x)     return tf.Print(op, [x], message)     def print_tensor(x, message=''):          The same tensor `x`, unchanged.     op = tf.identity(x)     return tf.Print(op, [x], message)     def print_tensor(x, message=''):          The same tensor `x`, unchanged.     op = tf.identity(x)     return tf.Print(op, [x], message)     def print_tensor(x, message=''):          The same tensor `x`, unchanged.     op = tf.identity(x)     return tf.Print(op, [x], message)     def print_tensor(x, message=''):          The same tensor `x`, unchanged.     op = tf.identity(x)     return tf.Print(op, [x], message)     def print_tensor(x, message=''):          The same tensor `x`, unchanged.     op = tf.identity(x)     return tf.Print(op, [x], message)     def print_tensor(x, message=''):          The same tensor `x`, unchanged.     op = tf.identity(x)     return tf.Print(op, [x], message)     def print_tensor(x, message=''):          The same tensor `x`, unchanged.     op = tf.identity(x)     return tf.Print(op, [x], message)     def print_tensor(x, message=''):          The same tensor `x`, unchanged.     op = tf.identity(x)     return tf.Print(op, [x], message)     def print_tensor(x, message=''):          The same tensor `x`, unchanged.     op = tf.identity(x)     return tf.Print(op, [x], message)     def print_tensor(x, message=''):          The same tensor `x`, unchanged.     op = tf.identity(x)     return tf.Print(op, [x], message)     def print_tensor(x, message=''):          The same tensor `x`, unchanged.     op = tf.identity(x)     return tf.Print(op, [x], message)     def print_tensor(x, message=''):          The same tensor `x`, unchanged.     op = tf.identity(x)     return tf.Print(op, [x], message)     def print_tensor(x, message=''):          The same tensor `x`, unchanged.     op = tf.identity(x)     return tf.Print(op, [x], message)     def print_tensor(
class Block(PandasObject):          check_setitem_lengths(indexer, value, values)          if is_empty_indexer(indexer, arr_value):              pass
class RedirectMiddleware(BaseRedirectMiddleware):          if 'Location' not in response.headers or response.status not in allowed_status:              return response         location = to_native_str(response.headers['Location']) if response.headers['Location'].startswith(b'          redirected_url = urljoin(request.url, location)          return redirect(redirected_url)          redirected_url = urljoin(request.url, location)          return redirect(redirected_url)          redirected_url = urljoin(request.url, location)          return redirect(redirected_url)          redirected_url = urljoin(request.url, location)          return redirect(redirected_url)          redirected_url = urljoin(request.url, location)          return redirect(redirected_url)          redirected_url = urljoin(request.url, location)          return redirect(redirected_url)          redirected_url = urljoin(request.url, location)          return redirect(redirected_url)          redirected_url = urljoin(request.url, location)          return redirect(redirected_url)          redirected_url = urljoin(request.url, location)          return redirect(redirected_url)          redirected_url = urljoin(request.url, location)          return redirect(redirected_url)          redirected_url = urljoin(request.url, location)          return redirect(redirected_url)          redirected_url = urljoin(request.url, location)          return redirect(redirected_url)          redirected_url = urljoin(request.url, location)          return redirect(redirected_url)          redirected_url = urljoin(request.url, location)          return redirect(redirected_url)          redirected_url = urljoin(request.url, location)          return redirect(redirected_url)          redirected_url = urljoin(request.url, location)          return redirect(redirected_url)          redirected_url = urljoin(request.url, location)          return redirect(redirected_url)          redirected_url = urljoin(request.url, location)          return redirect(redirected_url)          redirected_url = urljoin(request.url, location)          return redirect(redirected_url)          redirected_url = urljoin(request.url, location)          return redirect(redirected_url)          redirected_url = urljoin(request.url, location)          return redirect(redirected_url)          redirected_url = urljoin(request.url, location)          return redirect(redirected_url)          redirected_url = urljoin(request.url, location)          return redirect(redirected_url)          redirected_url = urljoin(request.url, location)          return redirect(redirected_url)          redirected_url = urljoin(request.url, location)          return redirect(redirected_url)          redirected_url = urljoin(request.url, location)          return redirect(redirected_url)          redirected_url = urljoin(request.url, location)          return redirect(redirected_url)          redirected_url = urljoin(request.url, location)          return redirect(redirected_url)          redirected_url = urljoin(request.url, location)          return redirect(redirected_url)          redirected_url = urljoin(request.url, location)          return redirect(redirected_url)          redirected_url = urljoin(request.url, location)          return redirect(redirected_url)          redirected_url = urljoin(request.url, location)          return redirect(redirected_url)          redirected_url = urljoin(request.url, location)          return redirect(redirected_url)          redirected_url = urljoin(request.url, location)          return redirect(redirected_url)          redirected_url = urljoin(request.url, location)          return redirect(redirected_url)          redirected_url = urljoin(request.url, location)          return redirect(redirected_url)          redirected_url = urljoin(request.url, location)          return redirect(redirected_url)          redirected_url = urljoin(request.url, location)          return redirect(redirected_url)          redirected_url = urljoin(request.url, location)          return redirect(redirected_url)          redirected_url = urljoin(request.url, location)          return redirect(redirected_url
def _prepare_response_content(     res: Any, *, by_alias: bool = True, exclude_unset: bool = False  ) -> Any:      if isinstance(res, BaseModel):          if PYDANTIC_1:              return res.dict(                 by_alias=by_alias, exclude_unset=exclude_unset, skip_defaults=False              )          else:              return res.dict(                 by_alias=by_alias, skip_defaults=exclude_unset              )      elif isinstance(res, list):          return [             _prepare_response_content(item, exclude_unset=exclude_unset) for item in res          ]      return res  def _prepare_response_content(     res: Any, *, by_alias: bool = True, exclude_unset: bool = False  ) -> Any:      if isinstance(res, BaseModel):          if PYDANTIC_1:              return res.dict(                 by_alias=by_alias, exclude_unset=exclude_unset, skip_defaults=False              )          else:              return res.dict(                 by_alias=by_alias, skip_defaults=exclude_unset              )      elif isinstance(res, list):          return [             _prepare_response_content(item, exclude_unset=exclude_unset) for item in res          ]      return res  def _prepare_response_content(     res: Any, *, by_alias: bool = True, exclude_unset: bool = False  ) -> Any:      if isinstance(res, BaseModel):          if PYDANTIC_1:              return res.dict(                 by_alias=by_alias, exclude_unset=exclude_unset, skip_defaults=False              )          else:              return res.dict(                 by_alias=by_alias, skip_defaults=exclude_unset              )      elif isinstance(res, list):          return [             _prepare_response_content(item, exclude_unset=exclude_unset) for item in res          ]      return res  def _prepare_response_content(     res: Any, *, by_alias: bool = True, exclude_unset: bool = False  ) -> Any:      if isinstance(res, BaseModel):          if PYDANTIC_1:              return res.dict(                  by_alias=by_alias, exclude_unset=exclude_unset, skip_defaults=False              )          else:             return res.dict(                 by_alias=by_alias, skip_defaults=exclude_unset              )      elif isinstance(res, list):          return [             _prepare_response_content(item, exclude_unset=exclude_unset) for item in res          ]      return res  def _prepare_response_content(     res: Any, *, by_alias: bool = True, exclude_unset: bool = False  ) -> Any:      if isinstance(res, BaseModel):          if PYDANTIC_1:              return res.dict(                  by_alias=by_alias, exclude_unset=exclude_unset, skip_defaults=False              )          else:              return res.dict(                  by_alias=by_alias, skip_defaults=exclude_unset              )      elif isinstance(res, list):          return [
def _make_concat_multiindex(indexes, keys, levels=None, names=None) -> MultiInde          for hlevel, level in zip(zipped, levels):              to_concat = []              for key, index in zip(hlevel, indexes):                  try:                     i = level.get_loc(key)                  except KeyError as err:                     raise ValueError(f"Key {key} not in level {level}") from err                  to_concat.append(np.repeat(i, len(index)))              codes_list.append(np.concatenate(to_concat))
class FastAPI(Starlette):          response_model_by_alias: bool = True,          response_model_skip_defaults: bool = None,          response_model_exclude_unset: bool = False,         response_model_exclude_defaults: bool = False,         response_model_exclude_none: bool = False,          include_in_schema: bool = True,          response_class: Type[Response] = None,          name: str = None,         dtype: Dtype = None,          response_model_skip_defaults: bool = None,          response_model_exclude_unset: bool = False,         response_model_exclude_defaults: bool = False,         response_model_exclude_none: bool = False,          include_in_schema: bool = True,          response_class: Type[Response] = None,          name: str = None,         dtype: Dtype = None,          response_model_skip_defaults: bool = None,          response_model_exclude_unset: bool = False,         response_model_exclude_defaults: bool = False,         response_model_exclude_none: bool = False,          include_in_schema: bool = True,          response_class: Type[Response] = None,          name: str = None,         dtype: Dtype = None,          response_model_skip_defaults: bool = None,          response_model_exclude_unset: bool = False,         response_model_exclude_defaults: bool = False,         response_model_exclude_none: bool = False,          include_in_schema: bool = True,          response_class: Type[Response] = None,          name: str = None,         dtype: Dtype = None,          response_model_skip_defaults: bool = None,          response_model_exclude_unset: bool = False,         response_model_exclude_defaults: bool = False,         response_model_exclude_none: bool = False,          include_in_schema: bool = True,          response_class: Type[Response] = None,          name: str = None,         dtype: Dtype = None,          response_model_skip_defaults: bool = None,          response_model_exclude_unset: bool = False,         response_model_exclude_defaults: bool = False,         response_model_exclude_none: bool = False,          include_in_schema: bool = True,          response_class: Type[Response] = None,          name: str = None,         dtype: Dtype = None,          response_model_skip_defaults: bool = None,          response_model_exclude_unset: bool = False,         response_model_exclude_defaults: bool = False,         response_model_exclude_none: bool = False,          include_in_schema: bool = True,          response_class: Type[Response] = None,          name: str = None,         dtype: Dtype = None,          response_model_skip_defaults: bool = None,          response_model_exclude_unset: bool = False,         response_model_exclude_defaults: bool = False,         response_model_exclude_none: bool = False,          include_in_schema: bool = True,          response_class: Type[Response] = None,          name: str = None,         dtype: Dtype = None,          response_model_skip_defaults: bool = None,          response_model_exclude_unset: bool = False,         response_model_exclude_defaults: bool = False,         response_model_exclude_none: bool = False,          include_in_schema: bool = True,          response_class: Type[Response] = None,          name: str = None,         dtype: Dtype = None,          response_model_skip_defaults: bool = None,          response_model_exclude_unset: bool = False,         response_model_exclude_defaults: bool = False,         response_model_exclude_none: bool = False,          include_in_schema: bool = True,          response_class: Type[Response] = None,          name: str = None,         dtype: Dtype = None,          response_model_skip_defaults: bool = None,          response_model_exclude_unset: bool = False,
class tqdm(Comparable):          if disable is None and hasattr(file, "isatty") and not file.isatty():              disable = True          if disable:              self.iterable = iterable              self.disable = disable              self.pos = self._get_free_pos(self)              self._instances.remove(self)              self.n = initial              return          if kwargs:              self._set_free_pos(self, None)              self._instances.remove(self)              self.n = initial              return          if kwargs:              self._set_free_pos(self, None)              self._instances.remove(self)              self.n = initial              return          if kwargs:              self._set_free_pos(self, None)              self._instances.remove(self)              self.n = initial              return          if kwargs:              self._set_free_pos(self, None)              self._instances.remove(self)              self.n = initial              return          if kwargs:              self._set_free_pos(self, None)              self._instances.remove(self)              self.n = initial              return          if kwargs:              self._set_free_pos(self, None)              self._instances.remove(self)              self.n = initial              return          if kwargs:              self._set_free_pos(self, None)              self._instances.remove(self)              self.n = initial              return          if kwargs:              self._set_free_pos(self, None)              self._instances.remove(self)              self.n = initial              return          if kwargs:              self._set_free_pos(self, None)              self._instances.remove(self)              self.n = initial              return          if kwargs:              self._set_free_pos(self, None)              self._instances.remove(self)              self.n = initial              return          if kwargs:              self._set_free_pos(self, None)              self._instances.remove(self)              self.n = initial              return          if kwargs:              self._set_free_pos(self, None)              self._instances.remove(self)              self.n = initial              return          if kwargs:              self._set_free_pos(self, None)              self._instances.remove(self)              self.n = initial              return          if kwargs:              self._set_free_pos(self, None)              self._instances.remove(self)              self.n = initial              return           if kwargs:               self._set_free_pos(self, None)              self._instances.remove(self)              self.n = initial              return           if kwargs
import re  from.common import InfoExtractor  from..utils import (      find_xpath_attr,     fix_xml_ampersands,  ) import re  from.common import InfoExtractor  from..utils import (      find_xpath_attr,     fix_xml_any_ampersands,  ) import re  from.common import InfoExtractor  from..utils import (      find_xpath_attr,     fix_xml_all_ampersands,  ) import re  from.common import InfoExtractor  from..utils import (      find_xpath_attr,     fix_xml_any_ampersands,  )
class Index(IndexOpsMixin, PandasObject):              multi_join_idx = multi_join_idx.remove_unused_levels()             if return_indexers:                 return_indexers = True             else:                 return_indexers = False          jl = list(overlap)[0]          if return_indexers:              return_indexers = True          else:              return_indexers = False
else:  from twisted.internet import defer, reactor, ssl, logging  logger = logging.getLogger(__name__)
class CategoricalBlock(ExtensionBlock):      def _holder(self):          return Categorical      def to_native_types(self, slicer=None, na_rep="", quoting=None, **kwargs):          values = self.values         values = cast(Categorical, values)         return values      def to_native_types(self, slicer=None, na_rep="", quoting=None, **kwargs):          values = self.values         values = cast(Categorical, values)         return values      def to_native_types(self, slicer=None, na_rep="", quoting=None, **kwargs):          values = self.values         values = cast(Categorical, values)         return values      def to_native_types(self, slicer=None, na_rep="", quoting=None, **kwargs):          values = self.values         values = cast(Categorical, values)         return values      def to_native_types(self, slicer=None, na_rep="", quoting=None, **kwargs):          values = self.values         values = cast(Categorical, values)         return values      def to_native_types(self, slicer=None, na_rep="", quoting=None, **kwargs):          values = self.values         values = cast(Categorical, values)         return values      def to_native_types(self, slicer=None, na_rep="", quoting=None, **kwargs):          values = self.values         values = cast(Categorical, values)         return values      def to_native_types(self, slicer=None, na_rep="", quoting=None, **kwargs):          values = self.values         values = cast(Categorical, values)         return values      def to_native_types(self, slicer=None, na_rep="", quoting=None, **kwargs):          values = self.values         values = cast(Categorical, values)         return values     def to_native_types(self, slicer=None, na_rep="", quoting=None, **kwargs):          values = self.values         values = cast(Categorical, values)         return values     def to_native_types(self, slicer=None, na_rep="", quoting=None, **kwargs):          values = self.values         values = cast(Categorical, values)         return values     def to_native_types(self, slicer=None, na_rep="", quoting=None, **kwargs):          values = self.values         values = cast(Categorical, values)         return values     def to_native_types(self, slicer=None, na_rep="", quoting=None, **kwargs):          values = self.values         values = cast(Categorical, values)         return values     def to_native_types(self, slicer=None, na_rep="", quoting=None, **kwargs):          values = self.values         values = cast(Categorical, values)         return values     def to_native_types(self, slicer=None, na_rep="", quoting=None, **kwargs):          values = self.values         values = cast(Categorical, values)         return values     def to_native_types(self, slicer=None, na_rep="", quoting=None, **kwargs):          values = self.values         values = cast(Categorical, values)         return values     def to_native_types(self, slicer=None, na_rep="", quoting=None, **kwargs):          values = self.values         values = cast(Categorical, values)         return values     def to_native_types(self, slicer=None, na_rep="", quoting=None, **kwargs):          values = self.values         values = cast(Categorical, values)         return values     def to_native_types(self, slicer=None, na_rep="", quoting=None, **kwargs):          values = self.values         values = cast(Categorical, values)         return values     def to_native_types(self, slicer=None, na_rep="", quoting=None, **kwargs):          values = self.values         values = cast(Categorical, values)         return values     def to_native_types(self, slicer=None, na_rep="", quoting=None, **kwargs):          values = self.values         values = cast(Categorical, values)         return values     def to_native_types(self, slicer=None, na_rep="", quoting=None, **kwargs):          values = self.values         values = cast(Categorical, values)         return values     def to_native_types(self, slicer=None, na_rep="", quoting=None, **kwargs):          values = self.values         values = cast(Categorical, values)
class Model(Container):                  val_data += [0.]              for cbk in callbacks:                  cbk.validation_data = val_data         is_sequence = isinstance(generator, Sequence)         if not is_sequence and use_multiprocessing and workers > 1:             warnings.warn(                 UserWarning('Using a generator with `use_multiprocessing=True`'                            'and multiple workers may duplicate your data.'                            'Please consider using the`keras.utils.Sequence'                            'class.'))         if use_sequence_api:             steps_per_epoch = len(generator)          enqueuer = None          try:
def melt(          else:              value_vars = list(value_vars)             missing = Index(com.flatten(value_vars)).difference(cols)              if not missing.empty:                  raise KeyError(                      "The following 'value_vars' are not present in"                 )
class TFOptimizer(Optimizer):      @interfaces.legacy_get_updates_support      def get_updates(self, loss, params):         grads = self.optimizer.compute_gradients(loss, params)          self.updates = [K.update_add(self.iterations, 1)]          opt_update = self.optimizer.apply_gradients(              grads,              global_step=self.iterations,              restore_best_weights=True)          return opt_update
class YoutubeIE(YoutubeBaseInfoExtractor):          video_id = mobj.group(2)          return video_id      @staticmethod     def _extract_chapters(description, duration):          if not description:              return None          chapter_lines = re.findall(
class ItemMeta(ABCMeta):          new_attrs['fields'] = fields          new_attrs['_class'] = _class          return super(ItemMeta, mcs).__new__(mcs, class_name, bases, new_attrs)      def to_native(self, value, **kwargs):         return super(ItemMeta, mcs).to_native(value, **kwargs)      def to_native(self, value, **kwargs):         return super(ItemMeta, mcs).to_native(value, **kwargs)  class ItemMeta(ABCMeta):          new_attrs['fields'] = fields          new_attrs['_class'] = _class          return super(ItemMeta, mcs).__new__(mcs, class_name, bases, new_attrs)  def to_native(self, value, **kwargs):      return super(ItemMeta, mcs).to_native(value, **kwargs)  def to_native(self, value, **kwargs):      return super(ItemMeta, mcs).to_native(value, **kwargs)  class ItemMeta(ABCMeta):          new_attrs['fields'] = fields          new_attrs['_class'] = _class          return super(ItemMeta, mcs).__new__(mcs, class_name, bases, new_attrs)  def to_native(self, value, **kwargs):      return super(ItemMeta, mcs).to_native(value, **kwargs)  def to_native(self, value, **kwargs):      return super(ItemMeta, mcs).to_native(value, **kwargs)  class ItemMeta(ABCMeta):          new_attrs['fields'] = fields          new_attrs['_class'] = _class          return super(ItemMeta, mcs).__new__(mcs, class_name, bases, new_attrs)  def to_native(self, value, **kwargs):      return super(ItemMeta, mcs).to_native(value, **kwargs)  def to_native(self, value, **kwargs):      return super(ItemMeta, mcs).to_native(value, **kwargs)  class ItemMeta(ABCMeta):          new_attrs['fields'] = fields          new_attrs['_class'] = _class          return super(ItemMeta, mcs).__new__(mcs, class_name, bases, new_attrs)  def to_native(self, value, **kwargs):      return super(ItemMeta, mcs).to_native(value, **kwargs)  def to_native(self, value, **kwargs):      return super(ItemMeta, mcs).to_native(value, **kwargs)  class ItemMeta(ABCMeta):          new_attrs['fields'] = fields          new_attrs['_class'] = _class          return super(ItemMeta, mcs).__new__(mcs, class_name, bases, new_attrs)  def to_native(self, value, **kwargs):      return super(ItemMeta, mcs).to_native(value, **kwargs)  def to_native(self, value, **kwargs):      return super(ItemMeta, mcs).to_native(value, **kwargs)  class ItemMeta(ABCMeta):          new_attrs['fields'] = fields          new_attrs['_class'] = _class          return super(ItemMeta, mcs).__new__(mcs, class_name, bases, new_attrs)  def to_native(self, value, **kwargs):      return super(ItemMeta, mcs).to_native(value, **kwargs)  def to_native(self, value, **kwargs):      return super(ItemMeta, mcs).to_native(value, **kwargs)  class ItemMeta(ABCMeta):          new_attrs['fields'] = fields          new_attrs['_class'] = _class          return super(ItemMeta, mcs).__new__(mcs, class_name, bases, new_attrs)  def to_native(self, value, **kwargs):      return super(ItemMeta, mcs).to_native(value, **kwargs)  def to_native(self, value, **kwargs):      return super(ItemMeta, mcs).to_native(value, **kwargs)  class ItemMeta(ABCMeta):          new_attrs['fields'] = fields          new_attrs['_class'] = _class          return super(ItemMeta, mcs).__new__(mcs, class_name, bases, new_attrs)  def to_native(self, value, **kwargs):      return super(ItemMeta, mcs).to_native(value, **kwargs)  def to_native(self, value, **kwargs):      return super(ItemMeta, mcs).to_native(value, **kwargs)  class ItemMeta(ABCMeta):          new_attrs['fields'] = fields          new_attrs['_class'] = _class          return super(ItemMeta, mcs).__new__(mcs, class_name, bases, new_attrs)  def to_native(self, value, **kwargs):      return super(ItemMeta, mcs).to_native(value, **kwargs)  def to_native(self, value, **kwargs):      return super(ItemMeta, mcs).to_native(value, **kwargs)  class ItemMeta(ABCMeta):          new_attrs['fields'] = fields          new_attrs['_class'] = _class          return super(ItemMeta, mcs).__new__(mcs, class_name, bases, new_attrs)  def to_native(self, value, **kwargs):      return super(ItemMeta, mcs).to_native(value, **kwargs)  def to_native
class ListParameter(Parameter):         Ensure that list parameter is converted to a tuple so it can be hashed.          :param str x: the value to parse.          :return: the normalized (hashable/immutable) value.         :rtype: :class:`Tuple`          :param str x: the value to parse.          :return: the normalized (hashable/immutable) value.         :rtype: :class:`Tuple`          :param str x: the value to parse.          :return: the normalized (hashable/immutable) value.         :rtype: :class:`Tuple`          :param str x: the value to parse.          :return: the normalized (hashable/immutable) value.         :rtype: :class:`Tuple`          :param str x: the value to parse.          :return: the normalized (hashable/immutable) value.         :rtype: :class:`Tuple`          :param str x: the value to parse.          :return: the normalized (hashable/immutable) value.         :rtype: :class:`Tuple`          :param str x: the value to parse.          :return: the normalized (hashable/immutable) value.         :rtype: :class:`Tuple`          :param str x: the value to parse.          :return: the normalized (hashable/immutable) value.         :rtype: :class:`Tuple`          :param str x: the value to parse.          :return: the normalized (hashable/immutable) value.         :rtype: :class:`Tuple`          :param str x: the value to parse.          :return: the normalized (hashable/immutable) value.         :rtype: :class:`Tuple`          :param str x: the value to parse.          :return: the normalized (hashable/immutable) value.         :rtype: :class:`Tuple`          :param str x: the value to parse.          :return: the normalized (hashable/immutable) value.         :rtype: :class:`Tuple`          :param str x: the value to parse.          :return: the normalized (hashable/immutable) value.         :rtype: :class:`Tuple`          :param str x: the value to parse.          :return: the normalized (hashable/immutable) value.         :rtype: :class:`Tuple`          :param str x: the value to parse.          :return: the normalized (hashable/immutable) value.         :rtype: :class:`Tuple`          :param str x: the value to parse.          :return: the normalized (hashable/immutable) value.         :rtype: :class:`Tuple`          :param str x: the value to parse.          :return: the normalized (hashable/immutable) value.         :rtype: :class:`Tuple`          :param str x: the value to parse.          :return: the normalized (hashable/immutable) value.         :rtype: :class:`Tuple`          :param str x: the value to parse.          :return: the normalized (hashable/immutable) value.         :rtype: :class:`Tuple`          :param str x: the value to parse.          :return: the normalized (hashable/immutable) value.         :rtype: :class:`Tuple`          :param str x: the value to parse.          :return: the normalized (hashable/immutable) value.         :rtype: :class:`Tuple`          :param str x: the value to parse.          :return: the normalized (hashable/immutable) value.         :rtype: :class:`Tuple`          :param str x: the value to parse.          :return: the normalized (hashable/immutable) value.         :rtype: :class:`Tuple`          :param str x: the value to parse.          :return: the normalized (hashable/immutable) value.         :rtype: :class:`Tuple`          :param str x: the value to parse.          :return: the normalized (hashable/immutable) value.         :rtype: :class:`Tuple`          :param str x: the value to parse.          :return: the normalized (hashable/immutable) value.         :rtype: :class:`Tuple`          :param str x: the value to parse.          :return: the normalized (hashable/immutable) value.         :rtype: :class:`Tuple`          :param str x: the value to parse.          :return: the normalized (hashable/immutable) value.
class _MergeOperation:                      )                   ]              else:                 right_keys = [self.right.index.values]          if right_drop:              self.right = self.right._drop_labels_or_levels(right_drop)
class NumericIndex(Index):              name = data.name          return cls._simple_new(subarr, name=name)      @Appender(_index_shared_docs["_maybe_cast_slice_bound"])      def _maybe_cast_slice_bound(self, label, side, kind):          assert kind in ["ix", "loc", "getitem", None]         return super()._maybe_cast_slice_bound(label, side, kind)      @Appender(_index_shared_docs["_maybe_cast_slice_bound"])      def _maybe_cast_slice_bound(self, label, side, kind):          assert kind in ["ix", "loc", "getitem", None]         return super()._maybe_cast_slice_bound(label, side, kind)      @Appender(_index_shared_docs["_maybe_cast_slice_bound"])      def _maybe_cast_slice_bound(self, label, side, kind):          assert kind in ["ix", "loc", "getitem", None]         return super()._maybe_cast_slice_bound(label, side, kind)      @Appender(_index_shared_docs["_maybe_cast_slice_bound"])      def _maybe_cast_slice_bound(self, label, side, kind):          assert kind in ["ix", "loc", "getitem", None]         return super()._maybe_cast_slice_bound(label, side, kind)      @Appender(_index_shared_docs["_maybe_cast_slice_bound"])      def _maybe_cast_slice_bound(self, label, side, kind):          assert kind in ["ix", "loc", "getitem", None]         return super()._maybe_cast_slice_bound(label, side, kind)      @Appender(_index_shared_docs["_maybe_cast_slice_bound"])      def _maybe_cast_slice_bound(self, label, side, kind):          assert kind in ["ix", "loc", "getitem", None]         return super()._maybe_cast_slice_bound(label, side, kind)      @Appender(_index_shared_docs["_maybe_cast_slice_bound"])      def _maybe_cast_slice_bound(self, label, side, kind):          assert kind in ["ix", "loc", "getitem", None]         return super()._maybe_cast_slice_bound(label, side, kind)      @Appender(_index_shared_docs["_maybe_cast_slice_bound"])      def _maybe_cast_slice_bound(self, label, side, kind):          assert kind in ["ix", "loc", "getitem", None]         return super()._maybe_cast_slice_bound(label, side, kind)      @Appender(_index_shared_docs["_maybe_cast_slice_bound"])      def _maybe_cast_slice_bound(self, label, side, kind):          assert kind in ["ix", "loc", "getitem", None]         return super()._maybe_cast_slice_bound(label, side, kind)      @Appender(_index_shared_docs["_maybe_cast_slice_bound"])      def _maybe_cast_slice_bound(self, label, side, kind):          assert kind in ["ix", "loc", "getitem", None]         return super()._maybe_cast_slice_bound(label, side, kind)      @Appender(_index_shared_docs["_maybe_cast_slice_bound"])      def _maybe_cast_slice_bound(self, label, side, kind):          assert kind in ["ix", "loc", "getitem", None]         return super()._maybe_cast_slice_bound(label, side, kind)      @Appender(_index_shared_docs["_maybe_cast_slice_bound"])      def _maybe_cast_slice_bound(self, label, side, kind):          assert kind in ["ix", "loc", "getitem", None]         return super()._maybe_cast_slice_bound(label, side, kind)      @Appender(_index_shared_docs["_maybe_cast_slice_bound"])      def _maybe_cast_slice_bound(self, label, side, kind):          assert kind in ["ix", "loc", "getitem", None]         return super()._maybe_cast_slice_bound(label, side, kind)      @Appender(_index_shared_docs["_maybe_cast_slice_bound"])      def _maybe_cast_slice_bound(self, label, side, kind):          assert kind in ["ix", "loc", "getitem", None]         return super()._maybe_cast_slice_bound(label, side, kind)      @Appender(_index_shared_docs["_maybe_cast_slice_bound"])      def _maybe_cast_slice_bound(self, label, side, kind):          assert kind in ["ix", "loc", "getitem", None]         return super()._maybe_cast_slice_bound(label, side, kind)      @Appender(_index_shared_docs["_maybe_cast_slice_bound"])      def _maybe_cast_slice_bound(self, label, side, kind):          assert kind in ["ix", "loc", "getitem", None]         return super()._maybe_cast_slice_bound(label, side, kind)      @Appender(_index_shared_docs["_maybe_cast_slice_bound"])      def _maybe_cast_slice_bound(self, label, side, kind):          assert kind in ["
def _urlencode(seq, enc):  def _get_form(response, formname, formid, formnumber, formxpath):      text = response.body_as_unicode()     root = create_root_node(text, lxml.html.HTMLParser, base_url=response.url)     for form in root.xpath('      if not forms:          raise ValueError("No <form> element found in %s" % response)     return root.xpath('      if not forms:          raise ValueError("No <form> element found in %s" % response)  def _urlencode(seq, enc):  def _get_form(response, formname, formid, formnumber, formxpath):      text = response.body_as_unicode()     root = create_root_node(text, lxml.html.HTMLParser, base_url=response.url)     for form in root.xpath('      if not forms:          raise ValueError("No <form> element found in %s" % response)     return root.xpath('      if not forms:          raise ValueError("No <form> element found in %s" % response)  def _urlencode(seq, enc):  def _get_form(response, formname, formid, formnumber, formxpath):      text = response.body_as_unicode()     root = create_root_node(text, lxml.html.HTMLParser, base_url=response.url)     for form in root.xpath('      if not forms:          raise ValueError("No <form> element found in %s" % response)     return root.xpath('      if not forms:          raise ValueError("No <form> element found in %s" % response)  def _urlencode(seq, enc):  def _get_form(response, formname, formid, formnumber, formxpath):      text = response.body_as_unicode()     root = create_root_node(text, lxml.html.HTMLParser, base_url=response.url)     for form in root.xpath('      if not forms:          raise ValueError("No <form> element found in %s" % response)     return root.xpath('      if not forms:          raise ValueError("No <form> element found in %s" % response)  def _urlencode(seq, enc):  def _get_form(response, formname, formid, formnumber, formxpath):      text = response.body_as_unicode()     root = create_root_node(text, lxml.html.HTMLParser, base_url=response.url)     for form in root.xpath('      if not forms:          raise ValueError("No <form> element found in %s" % response)     return root.xpath('      if not forms:          raise ValueError("No <form> element found in %s" % response)  def _urlencode(seq, enc):  def _get_form(response, formname, formid, formnumber, formxpath):      text = response.body_as_unicode()     root = create_root_node(text, lxml.html.HTMLParser, base_url=response.url)     for form in root.xpath('      if not forms:          raise ValueError("No <form> element found in %s" % response)     return root.xpath('      if not forms:          raise ValueError("No <form> element found in %s" % response)  def _urlencode(seq, enc):  def _get_form(response, formname, formid, formnumber, formxpath):      text = response.body_as_unicode()     root = create_root_node(text, lxml.html.HTMLParser, base_url=response.url)     for form in root.xpath('      if not forms:          raise ValueError("No <form> element found in %s" % response)     return root.xpath('      if not forms:          raise ValueError("No <form> element found in %s" % response)  def _urlencode(seq, enc):  def _get_form(response, formname, formid, formnumber, formxpath):      text = response.body_as_unicode()     root = create_root_node(text, lxml.html.HTMLParser, base_url=response.url)     for form in root.xpath('      if not forms:          raise ValueError("No <form> element found in %s" % response)     return root.xpath('      if not forms:          raise ValueError("No <form> element found in %s" % response)  def _urlencode(seq, enc):  def _get_form(response, formname, formid, formnumber, formxpath):      text = response.body_as_unicode()     root = create_root_node(text, lxml.html.HTMLParser, base_url=response.url)     for form in root.xpath('      if not forms:          raise ValueError("No <form> element found in %s" % response)     return root.xpath('      if not forms:          raise ValueError("No <form> element found in %s" % response)  def _urlencode(seq, enc):  def _get_form(response, formname, formid, formnumber, formxpath):      text = response.body_as_unicode()     root = create_root_node(text, lxml.html.HTMLParser, base_url=response.url)     for form in root.xpath('      if not forms:          raise ValueError("No <form> element found in %s" % response)     return root.xpath('
class Request(object_ref):          s = safe_url_string(url, self.encoding)          self._url = escape_ajax(s)         if ':' not in self._url:              raise ValueError('Missing scheme in request url: %s' % self._url)      url = property(_get_url, skip_setter(_set_url, 'url'))
class EmptyLineTracker:                  return 0, 0              newlines = 2              if current_line.depth > 0:                  newlines -= 1              if newlines == 0:                  return 0, 0              newlines = 2              if current_line.depth > 0:                  newlines -= 1              if newlines == 0:                  return 0, 0              newlines = 2              if current_line.depth > 0:                  newlines -= 1              if newlines == 0:                  return 0, 0              newlines = 2              if current_line.depth > 0:                  newlines -= 1              if newlines == 0:                  return 0, 0              newlines = 2              if current_line.depth > 0:                  newlines -= 1              if newlines == 0:                  return 0, 0              newlines = 2              if current_line.depth > 0:                  newlines -= 1              if newlines == 0:                  return 0, 0              newlines = 2              if current_line.depth > 0:                  newlines -= 1              if newlines == 0:                  return 0, 0              newlines = 2              if current_line.depth > 0:                  newlines -= 1              if newlines == 0:                  return 0, 0              newlines = 2              if current_line.depth > 0:                  newlines -= 1              if newlines == 0:                  return 0, 0              newlines = 2              if current_line.depth > 0:                  newlines -= 1              if newlines == 0:                  return 0, 0              newlines = 2              if current_line.depth > 0:                  newlines -= 1              if newlines == 0:                  return 0, 0              newlines = 2              if current_line.depth > 0:                  newlines -= 1              if newlines == 0:                  return 0, 0              newlines = 2              if current_line.depth > 0:                  newlines -= 1              if newlines == 0:                  return 0, 0              newlines = 2              if current_line.depth > 0:                  newlines -= 1              if newlines == 0:                  return 0, 0              newlines = 2              if current_line.depth > 0:                  newlines -= 1              if newlines == 0:                  return 0, 0              newlines = 2              if current_line.depth > 0:                  newlines -= 1              if newlines == 0:                  return 0, 0              newlines = 2              if current_line.depth > 0:                  newlines -= 1              if newlines == 0:
class DataFrame(NDFrame):          return new_data     def _combine_match_index(self, other, func):          if ops.should_series_dispatch(self, other, func):         return new_data     def _combine_match_index(self, other, func):          if ops.should_series_dispatch(self, other, func):         return new_data     def _combine_match_index(self, other, func):          if ops.should_series_dispatch(self, other, func):         return new_data     def _combine_match_index(self, other, func):          if ops.should_series_dispatch(self, other, func):         return new_data     def _combine_match_index(self, other, func):          if ops.should_series_dispatch(self, other, func):         return new_data     def _combine_match_index(self, other, func):          if ops.should_series_dispatch(self, other, func):         return new_data     def _combine_match_index(self, other, func):          if ops.should_series_dispatch(self, other, func):         return new_data     def _combine_match_index(self, other, func):          if ops.should_series_dispatch(self, other, func):         return new_data     def _combine_match_index(self, other, func):          if ops.should_series_dispatch(self, other, func):         return new_data     def _combine_match_index(self, other, func):          if ops.should_series_dispatch(self, other, func):         return new_data     def _combine_match_index(self, other, func):          if ops.should_series_dispatch(self, other, func):         return new_data     def _combine_match_index(self, other, func):          if ops.should_series_dispatch(self, other, func):         return new_data     def _combine_match_index(self, other, func):          if ops.should_series_dispatch(self, other, func):         return new_data     def _combine_match_index(self, other, func):          if ops.should_series_dispatch(self, other, func):         return new_data     def _combine_match_index(self, other, func):          if ops.should_series_dispatch(self, other, func):         return new_data     def _combine_match_index(self, other, func):          if ops.should_series_dispatch(self, other, func):         return new_data     def _combine_match_index(self, other, func):          if ops.should_series_dispatch(self, other, func):         return new_data     def _combine_match_index(self, other, func):          if ops.should_series_dispatch(self, other, func):         return new_data     def _combine_match_index(self, other, func):          if ops.should_series_dispatch(self, other, func):         return new_data     def _combine_match_index(self, other, func):          if ops.should_series_dispatch(self, other, func):         return new_data     def _combine_match_index(self, other, func):          if ops.should_series_dispatch(self, other, func):         return new_data     def _combine_match_index(self, other, func):          if ops.should_series_dispatch(self, other, func):         return new_data     def _combine_match_index(self, other, func):          if ops.should_series_dispatch(self, other, func):         return new_data     def _combine_match_index(self, other, func):          if ops.should_series_dispatch(self, other, func):         return new_data     def _combine_match_index(self, other, func):          if ops.should_series_dispatch(self, other, func):         return new_data     def _combine_match_index(self, other, func):          if ops.should_series_dispatch(self, other, func):         return new_data     def _combine_match_index(self, other, func):          if ops.should_series_dispatch(self, other, func):         return new_data     def _combine_match_index(self, other, func):          if ops.should_series_dispatch(self, other, func):         return new_data     def _combine_match_index(self, other, func):          if ops.should_series_dispatch(self, other, func):         return new_data     def _combine_match_index(self, other, func):          if ops.should_series_dispatch(self, other, func):         return new_data     def _combine_match_index(self, other, func):          if ops.should_series_
def disp_trim(data, length):      if len(data) == disp_len(data):          return data[:length] while disp_len(data) > length:          data = data[:-1]     if RE_ANSI.search(data):         return data + "\033[0m"      return data
except ImportError:  from gzip import GzipFile, six  import six  except six.PackerError:  from gzip import GzipFile  import six  except six.PackerError:  from gzip import GzipFile, six  import six  except six.PackerError:  from gzip import GzipFile, six, four  import six  except six.PackerError:  from gzip import GzipFile, six, four  import six  except six.PackerError:  from gzip import GzipFile, six, four, six  import six  except six.PackerError:  from gzip import GzipFile, six, four, six  import six  except six.PackerError:  from gzip import GzipFile, six, four, six, eight  import six  except six.PackerError:  from gzip import GzipFile, six, four, six, eight  import six  except six.PackerError:  from gzip import GzipFile, six, four, six, eight  import six  except six.PackerError:  from gzip import GzipFile, six, four, six, eight, nine  import six  except six.PackerError:  from gzip import GzipFile, six, four, six, eight, nine  import six  except six.PackerError:  from gzip import GzipFile, six, four, six, eight, nine, ten  import six  except six.PackerError:  from gzip import GzipFile, six, four, six, eight, nine, ten  import six  except six.PackerError:  from gzip import GzipFile, six, four, six, eight, nine, ten  import six  except six.PackerError:  from gzip import GzipFile, six, four, six, eight, nine, ten, eleven  import six  except six.PackerError:  from gzip import GzipFile, six, four, six, eight, nine, ten, eleven  import six  except six.PackerError:  from gzip import GzipFile, six, four, six, eight, nine, ten, eleven  import six  except six.PackerError:  from gzip import GzipFile, six, four, six, eight, nine, ten, eleven  import six  except six.PackerError:  from gzip import GzipFile, six, four, six, eight, nine, ten, eleven  import six  except six.PackerError:  from gzip import GzipFile, six, four, six, eight, nine, ten, eleven  import six  except six.PackerError:  from gzip import GzipFile, six, four, six, eight, nine, ten, eleven  import six  except six.PackerError:  from gzip import GzipFile, six, four, six, eight, nine, ten, eleven  import six  except six.PackerError:  from gzip import GzipFile, six, four, six, eight, nine, ten, eleven  import six  except six.PackerError:  from gzip import GzipFile, six, four, six, eight, nine, ten, eleven  import six  except six.PackerError:  from gzip import GzipFile, six, four, six, eight, nine, ten, eleven  import six  except six.PackerError:  from gzip import GzipFile, six, four, six, eight, nine, ten, eleven  import six  except six.PackerError:  from gzip import GzipFile, six, four, six, eight, nine, ten, eleven  import six  except six.PackerError:  from gzip import GzipFile, six, four, six, eight, nine, ten, eleven  import six  except six.PackerError:  from gzip import GzipFile, six, four, six, eight, nine, ten, eleven  import six  except six.PackerError:  from gzip import GzipFile, six, four, six, eight, nine, ten, eleven  import six  except six.PackerError:  from gzip import GzipFile, six, four, six, eight, nine, ten, eleven  import six  except six.PackerError:  from gzip import GzipFile, six, four, six, eight, nine, ten, eleven  import six  except six.PackerError:  from gzip import GzipFile, six, four, six, eight, nine, ten, eleven  import six  except six.PackerError:  from gzip import GzipFile, six, four, six, eight, nine, ten, eleven  import six  except six.PackerError:  from gzip import GzipFile, six, four, six, eight, nine, ten, eleven  import six  except six.PackerError:  from gzip import GzipFile, six, four, six, eight, nine, ten, eleven  import six  except six.PackerError:  from gzip import GzipFile, six, four, six, eight, nine, ten, eleven  import six  except six.PackerError:  from gzip import GzipFile, six, four, six, eight, nine, ten, eleven  import six  except six.PackerError:  from gzip import GzipFile, six, four, six, eight, nine, ten, eleven  import six  except six.PackerError:  from gzip import GzipFile, six, four, six, eight, nine, ten, eleven  import six  except six.PackerError:  from gzip import GzipFile, six, four, six, eight, nine, ten, eleven  import six  except six.PackerError:  from gzip import GzipFile, six, four, six, eight, nine, ten, eleven  import six  except six.PackerError:  from gzip import GzipFile, six, four, six, eight, nine, ten, eleven  import six  except six.PackerError:  from gzip import GzipFile, six, four, six, eight, nine, ten, eleven  import six  except six.PackerError:  from gzip import GzipFile, six, four, six, eight, nine, ten, eleven  import six  except six.PackerError:  from gzip import GzipFile, six, four, six, eight, nine, ten, eleven  import six  except six.PackerError:  from gzip import GzipFile, six, four, six, eight, nine, ten, eleven  import six  except six.PackerError:  from gzip import GzipFile, six, four, six, eight, nine, ten, eleven  import six  except six.PackerError:  from gzip import GzipFile, six, four, six, eight, nine, ten, eleven  import six  except six.PackerError:  from gzip import GzipFile, six, four, six, eight, nine, ten, eleven  import six  except six.PackerError:  from gzip import GzipFile, six, four, six, eight, nine, ten, eleven  import six  except six.PackerError:  from gzip import GzipFile, six, four, six, eight, nine, ten, eleven  import six  except six.PackerError:  from gzip import GzipFile, six, four, six, eight, nine, ten, eleven  import six  except six.PackerError:  from gzip import GzipFile, six, four, six, eight, nine, ten, eleven  import six  except six.PackerError:  from gzip import GzipFile, six, four, six, eight, nine, ten, eleven  import six  except six.PackerError:  from gzip import GzipFile, six, four, six, eight, nine, ten, eleven  import six  except six.PackerError:  from gzip
def _unstack_multiple(data, clocs, fill_value=None):              for i in range(len(clocs)):                  val = clocs[i]                  result = result.unstack(val, fill_value=fill_value)                 clocs = [v if i < v else v + 1 for v in clocs]             return result
def jsonable_encoder(                       value,                       by_alias=by_alias,                       exclude_unset=exclude_unset,                      exclude_defaults=exclude_defaults,                      exclude_none=exclude_none,                       custom_encoder=custom_encoder,                       sqlalchemy_safe=sqlalchemy_safe,                  )
class CollectionRequirement:              manifest = info['manifest_file']['collection_info']              namespace = manifest['namespace']              name = manifest['name']             version = manifest['version']              dependencies = manifest['dependencies']          else:              display.warning("Collection at '%s' does not have a MANIFEST.json file, cannot detect version."             )
from tensorflow.python.ops import functional_ops  from tensorflow.python.ops import ctc_ops as ctc  from.common import floatx, epsilon, image_data_format from functools import wraps  import threading from tensorflow.python.ops import functional_ops  from tensorflow.python.ops import ctc_ops as ctc  from.common import floatx, epsilon, image_data_format from functools import wraps import io  import threading from tensorflow.python.ops import functional_ops  from tensorflow.python.ops import ctc_ops as ctc  from.common import floatx, epsilon, image_data_format  import functools  import threading from tensorflow.python.ops import to_tensor  import tensorflow.python.ops import functional_ops  from tensorflow.python.ops import ctc_ops as ctc  from.common import floatx, epsilon, image_data_format  import functools  import threading from tensorflow.python.ops import to_tensor_list  import tensorflow.python.ops import functional_ops  from tensorflow.python.ops import ctc_ops as ctc  from.common import floatx, epsilon, image_data_format  import functools  import threading from tensorflow.python.ops import to_tensor  import tensorflow.python.ops import compare  import tensorflow.python.ops import functional_ops  from tensorflow.python.ops import ctc_ops as ctc  from.common import floatx, epsilon, image_data_format  import functools  import threading from tensorflow.python.ops import compare_to  import tensorflow.python.ops import functional_ops  from tensorflow.python.ops import ctc_ops as ctc  from.common import floatx, epsilon, image_data_format  import functools  import threading from tensorflow.python.ops import compare  import tensorflow.python.ops import compare_to_tensor  import tensorflow.python.ops import functional_ops  from tensorflow.python.ops import ctc_ops as ctc  from.common import floatx, epsilon, image_data_format  import functools  import threading from tensorflow.python.ops import compare  import tensorflow.python.ops import compare_to  import tensorflow.python.ops import functional_ops  from tensorflow.python.ops import ctc_ops as ctc  from.common import floatx, epsilon, image_data_format  import functools  import threading from tensorflow.python.ops import compare  import tensorflow.python.ops import compare_to  import tensorflow.python.ops import functional_ops  from tensorflow.python.ops import ctc_ops as ctc  from.common import floatx, epsilon, image_data_format  import functools  import threading from tensorflow.python.ops import compare  import tensorflow.python.ops import compare_to  import tensorflow.python.ops import functional_ops  from tensorflow.python.ops import ctc_ops as ctc  from.common import floatx, epsilon, image_data_format  import functools  import threading from tensorflow.python.ops import compare  import tensorflow.python.ops import compare_to  import tensorflow.python.ops import functional_ops  from tensorflow.python.ops import ctc_ops as ctc  from.common import floatx, epsilon, image_data_format  import functools  import threading from tensorflow.python.ops import compare  import tensorflow.python.ops import compare_to  import tensorflow.python.ops import functional_ops  from tensorflow.python.ops import ctc_ops as ctc  from.common import floatx, epsilon, image_data_format  import functools  import threading from tensorflow.python.ops import compare  import tensorflow.python.ops import compare_to  import tensorflow.python.ops import functional_ops  from tensorflow.python.ops import ctc_ops as ctc  from.common import floatx, epsilon, image_data_format  import functools  import threading from tensorflow.python.ops import compare  import tensorflow.python.ops import compare_to  import tensorflow.python.ops import functional_ops  from tensorflow.python.ops import ctc_ops as ctc  from.common import floatx, epsilon, image_data_format  import functools  import threading from tensorflow.python.ops import compare  import tensorflow.python.ops import compare_to  import tensorflow.python.ops import functional_ops  from tensorflow.python.ops import ctc_ops as ctc  from.common import floatx, epsilon, image_data_format  import functools  import threading from tensorflow.python.ops import compare  import tensorflow.python.ops import compare_to  import tensorflow.python.ops import functional_ops  from tensorflow.python.ops import ctc_ops as ctc  from.common import floatx, epsilon, image_data_format  import functools  import threading from tensorflow.python.ops import compare  import tensorflow.python.ops import compare_to  import tensorflow.python.ops import functional_ops  from tensorflow.python.ops import ctc_ops as ctc  from.common import floatx, epsilon, image_data_format  import functools  import threading from tensorflow.python.ops import compare  import tensorflow.python.ops import compare_to  import tensorflow.python.ops import functional_ops  from tensorflow.python.ops import ctc_ops as ctc  from.common import floatx, epsilon, image_data_format  import functools  import threading from tensorflow.python.ops import compare  import tensorflow.python.ops import compare_to  import tensorflow.python.ops import functional_ops  from tensorflow.python.ops import ctc_ops as ctc  from.common import floatx, epsilon, image_data_format  import functools  import threading from tensorflow.python.ops import compare  import tensorflow.python.ops import compare_to  import tensorflow.python.ops import functional_ops  from tensorflow.python.ops import ctc_ops as ctc  from.common import floatx, epsilon, image_data_format  import functools  import threading from tensorflow.python.ops import compare  import tensorflow.python.ops import compare_to  import tensorflow.python.ops import functional_ops  from tensorflow.python.ops import ctc_ops as ctc  from.common import floatx, epsilon, image_data_format  import functools  import threading from tensorflow.python.ops import compare  import tensorflow.python.ops import compare_to  import tensorflow.python.ops import functional_ops  from tensorflow.python.ops import ctc_ops as ctc  from.common import floatx, epsilon, image_data_format  import functools  import threading from tensorflow.python.ops import compare  import tensorflow.python.ops import
class LinuxHardware(Hardware):              mtab_entries.append(fields)          return mtab_entries      def get_mount_info(self, mount, device, uuids):          mount_size = get_mount_size(mount)         if mount.umask!= 0:             mtab_entries.append(fields)         return mtab_entries      def get_mount_info(self, mount, device, uuids):          mount_size = get_mount_size(mount)         if mount.umask!= 0:             mtab_entries.append(fields)         return mtab_entries      def get_mount_info(self, mount, device, uuids):          mount_size = get_mount_size(mount)         if mount.umask!= 0:             mtab_entries.append(fields)         return mtab_entries      def get_mount_info(self, mount, device, uuids):          mount_size = get_mount_size(mount)         if mount.umask!= 0:             mtab_entries.append(fields)         return mtab_entries      def get_mount_info(self, mount, device, uuids):          mount_size = get_mount_size(mount)         if mount.umask!= 0:             mtab_entries.append(fields)         return mtab_entries      def get_mount_info(self, mount, device, uuids):          mount_size = get_mount_size(mount)         if mount.umask!= 0:             mtab_entries.append(fields)         return mtab_entries      def get_mount_info(self, mount, device, uuids):          mount_size = get_mount_size(mount)         if mount.umask!= 0:             mtab_entries.append(fields)         return mtab_entries      def get_mount_info(self, mount, device, uuids):          mount_size = get_mount_size(mount)         if mount.umask!= 0:             mtab_entries.append(fields)         return mtab_entries      def get_mount_info(self, mount, device, uuids):          mount_size = get_mount_size(mount)         if mount.umask!= 0:             mtab_entries.append(fields)         return mtab_entries      def get_mount_info(self, mount, device, uuids):          mount_size = get_mount_size(mount)         if mount.umask!= 0:             mtab_entries.append(fields)         return mtab_entries      def get_mount_info(self, mount, device, uuids):          mount_size = get_mount_size(mount)         if mount.umask!= 0:             mtab_entries.append(fields)         return mtab_entries      def get_mount_info(self, mount, device, uuids):          mount_size = get_mount_size(mount)         if mount.umask!= 0:             mtab_entries.append(fields)         return mtab_entries      def get_mount_info(self, mount, device, uuids):          mount_size = get_mount_size(mount)         if mount.umask!= 0:             mtab_entries.append(fields)         return mtab_entries      def get_mount_info(self, mount, device, uuids):          mount_size = get_mount_size(mount)         if mount.umask!= 0:             mtab_entries.append(fields)         return mtab_entries      def get_mount_info(self, mount, device, uuids):          mount_size = get_mount_size(mount)         if mount.umask!= 0:             mtab_entries.append(fields)         return mtab_entries      def get_mount_info(self, mount, device, uuids):          mount_size = get_mount_size(mount)         if mount.umask!= 0:             mtab_entries.append(fields)         return mtab_entries      def get_mount_info(self, mount, device, uuids):          mount_size = get_mount_size(mount)         if mount.umask!= 0:             mtab_entries.append(fields)         return mtab_entries      def get_mount_info(self, mount, device, uuids):          mount_size = get_mount_size(mount)         if mount
class Categorical(ExtensionArray, PandasObject):          min : the minimum of this `Categorical`          self.check_for_ordered("min")         if not len(self._codes):             return self.dtype.na_value          good = self._codes!= -1          if not good.all():              if skipna:                  return self.na_value              else:                  return self.dtype.na_value          good = self._codes!= -1          if not good.all():              if skipna:                  return self.na_value              else:                  return self.dtype.na_value
def _get_spider_loader(settings):              'Please use SPIDER_LOADER_CLASS.',              category=ScrapyDeprecationWarning, stacklevel=2          )     cls_path = settings.get('SPIDER_LOADER_CLASS',                             settings.get('SPIDER_MANAGER_CLASS'))      loader_cls = load_object(cls_path)      verifyClass(ISpiderLoader, loader_cls)      return loader_cls.from_settings(settings.frozencopy())
logger = logging.getLogger(__name__)  title_regex = re.compile(r"(?<=<title>).*(?=</title>)")  id_regex = re.compile(r"(?<=<id>)\d*(?=</id>)") text_regex = re.compile(r"(?<=<text xml:space=\"preserve\">).*(?=</text)")  info_regex = re.compile(r"{[^{]*?}")  html_regex = re.compile(r"&lt;!--[^-]*--&gt;")  ref_regex = re.compile(r"&lt;ref.*?&gt;") logger = logging.getLogger(__name__)  title_regex = re.compile(r"(?<=<title>).*(?=</title>)")  id_regex = re.compile(r"(?<=<id>)\d*(?=</id>)") text_regex = re.compile(r"(?<=<text xml:space=\"preserve\">).*(?=</text)")  info_regex = re.compile(r"{[^{]*?}")  html_regex = re.compile(r"&lt;!--[^-]*--&gt;")  ref_regex = re.compile(r"&lt;ref.*?&gt;")
async def serialize_response(              exclude=exclude,              by_alias=by_alias,              exclude_unset=exclude_unset,             exclude_defaults=exclude_defaults,          )      else:          return jsonable_encoder(response_content)
class WebSocketHandler(tornado.web.RequestHandler):         .. versionadded:: 3.1         assert self.stream is not None         self.stream.set_nodelay(value)      def on_connection_close(self) -> None:          if self.ws_connection:              self.stream.finish()      def on_disconnect(self) -> None:          if self.ws_connection:              self.stream.finish()      def on_connection_close(self) -> None:          if self.ws_connection:              self.stream.finish()      def on_disconnect(self) -> None:          if self.ws_connection:              self.stream.finish()      def finish(self) -> None:          self.stream.finish()      def on_connection_close(self) -> None:          if self.ws_connection:              self.stream.finish()      def on_disconnect(self) -> None:          if self.ws_connection:              self.stream.finish()      def finish(self) -> None:          self.stream.finish()      def set_nodelay(self, value: bool = False) -> None:         self.stream.set_nodelay(value)      def on_connection_close(self) -> None:          if self.ws_connection:              self.stream.finish()      def on_disconnect(self) -> None:          if self.ws_connection:              self.stream.finish()      def finish(self) -> None:          self.stream.finish()      def set_nodelay(self, value: bool = False) -> None:          self.stream.set_nodelay(value)      def on_connection_close(self) -> None:          if self.ws_connection:              self.stream.finish()      def on_disconnect(self) -> None:          if self.ws_connection:              self.stream.finish()      def finish(self) -> None:          self.stream.finish()      def set_closed(self, value: bool = False) -> None:          self.stream.set_closed(value)      def on_connection_close(self) -> None:          if self.ws_connection:              self.stream.finish()      def on_disconnect(self) -> None:          if self.ws_connection:              self.stream.finish()      def finish(self) -> None:          self.stream.finish()      def set_nodelay(self, value: bool = False) -> None:          self.stream.set_nodelay(value)      def on_connection_close(self) -> None:          if self.ws_connection:              self.stream.finish()      def on_disconnect(self) -> None:          if self.ws_connection:              self.stream.finish()      def finish(self) -> None:          self.stream.finish()      def set_closed(self, value: bool = False) -> None:          self.stream.set_closed(value)      def on_connection_close(self) -> None:          if self.ws_connection:              self.stream.finish()      def on_disconnect(self) -> None:          if self.ws_connection:              self.stream.finish()      def finish(self) -> None:          self.stream.finish()      def set_nodelay(self, value: bool = False) -> None:          self.stream.set_nodelay(value)      def on_connection_close(self) -> None:          if self.ws_connection:              self.stream.finish()      def on_disconnect(self) -> None:          if self.ws_connection:              self.stream.finish()      def finish(self) -> None:          self.stream.finish()      def set_closed(self, value: bool = False) -> None:          self.stream.set_closed(value)      def on_connection_close(self) -> None:          if self.ws_connection:               self.stream.finish()      def on_disconnect(self) -> None:          if self.ws_connection:               self.stream.finish()      def finish(self) -> None:          self.stream.finish()      def set_nodelay(self, value: bool = False
_dtype from pandas.core.dtypes.common import (      ensure_object,      is_bool_dtype,      is_complex_dtype,      is_datetime64_dtype,      is_datetime64tz_dtype,      is_datetimelike_v_numeric,      is_dtype_equal,      is_extension_array_dtype,      is_float_dtype,      is_integer_dtype,      is_object_dtype,      is_period_dtype,      is_scalar,      is_string_dtype,      is_string_like_dtype,      is_timedelta64_dtype,      needs_i8_conversion,      pandas_dtype,  )  from pandas.core.dtypes.generic import (      ABCDataFrame,      ABCDatetimeArray,      ABCExtensionArray,      ABCIndexClass,      ABCMultiIndex,      ABCSeries,      ABCTimedeltaArray,     )  from pandas.core.dtypes.inference import is_list_like_dtype from pandas.core.dtypes.common import (      ensure_object,      is_bool_dtype,      is_complex_dtype,      is_datetime64_dtype,      is_datetime64tz_dtype,      is_datetimelike_v_numeric,      is_dtype_equal,      is_extension_array_dtype,      is_float_dtype,      is_integer_dtype,      is_object_dtype,      is_period_dtype,      is_scalar,      is_string_dtype,      is_string_like_dtype,      is_timedelta64_dtype,      needs_i8_conversion,      pandas_dtype,  )  from pandas.core.dtypes.generic import (      ABCDataFrame,      ABCDatetimeArray,      ABCExtensionArray,      ABCIndexClass,      ABCMultiIndex,      ABCSeries,      ABCTimedeltaArray,     )  from pandas.core.dtypes.inference import is_list_like_dtype from pandas.core.dtypes.common import (      ensure_object,      is_bool_dtype,      is_complex_dtype,      is_datetime64_dtype,      is_datetime64tz_dtype,      is_datetimelike_v_numeric,      is_dtype_equal,      is_extension_array_dtype,      is_float_dtype,      is_integer_dtype,      is_object_dtype,      is_period_dtype,      is_scalar,      is_string_dtype,      is_string_like_dtype,      is_timedelta64_dtype,      needs_i8_conversion,      pandas_dtype,  )  from pandas.core.dtypes.generic import (      ABCDataFrame,      ABCDatetimeArray,      ABCExtensionArray,      ABCIndexClass,      ABCMultiIndex,      ABCSeries,      ABCTimedeltaArray,     )  from pandas.core.dtypes.inference import is_list_like_dtype from pandas.core.dtypes.common import (      ensure_object,      is_bool_dtype,      is_complex_dtype,      is_datetime64_dtype,      is_datetime64tz_dtype,      is_datetimelike_v_numeric,      is_dtype_equal,      is_extension_array_dtype,      is_float_dtype,      is_integer_dtype,      is_object_dtype,      is_period_dtype,      is_scalar,      is_string_dtype,      is_string_like_dtype,      is_timedelta64_dtype,      needs_i8_conversion,      pandas_dtype,  )  from pandas.core.dtypes.generic import (      ABCDataFrame,      ABCDatetimeArray,      ABCExtensionArray,      ABCIndexClass,      ABCMultiIndex,      ABCSeries,      ABCTimedeltaArray,     )  from pandas.core.dtypes.inference import is_list_like_dtype from pandas.core.dtypes.common import (      ensure_object,      is_bool_dtype,      is_complex_dtype,      is_datetime64_dtype
def get_file(fname,          Path to the downloaded file      if cache_dir is None:          cache_dir = os.path.join(os.path.expanduser('~'), '.keras')      if file_hash is not None:          file_hash = file_hash.encode('utf-8')          hash_algorithm ='md5'      if md5_hash is not None:          file_hash = file_hash.encode('utf-8')          hash_algorithm ='md5'      if md5_hash is not None:          file_hash = file_hash.encode('utf-8')          hash_algorithm ='md5'      if md5_hash is not None:          file_hash = file_hash.encode('utf-8')          hash_algorithm ='md5'      if md5_hash is not None:          file_hash = file_hash.encode('utf-8')          hash_algorithm ='md5'      if md5_hash is not None:          file_hash = file_hash.encode('utf-8')          hash_algorithm ='md5'      if md5_hash is not None:          file_hash = file_hash.encode('utf-8')          hash_algorithm ='md5'      if md5_hash is not None:          file_hash = file_hash.encode('utf-8')          hash_algorithm ='md5'      if md5_hash is not None:          file_hash = file_hash.encode('utf-8')          hash_algorithm ='md5'      if md5_hash is not None:          file_hash = file_hash.encode('utf-8')          hash_algorithm ='md5'      if md5_hash is not None:          file_hash = file_hash.encode('utf-8')          hash_algorithm ='md5'      if md5_hash is not None:          file_hash = file_hash.encode('utf-8')          hash_algorithm ='md5'      if md5_hash is not None:          file_hash = file_hash.encode('utf-8')          hash_algorithm ='md5'      if md5_hash is not None:          file_hash = file_hash.encode('utf-8')          hash_algorithm ='md5'      if md5_hash is not None:          file_hash = file_hash.encode('utf-8')          hash_algorithm ='md5'      if md5_hash is not None:          file_hash = file_hash.encode('utf-8')          hash_algorithm ='md5'      if md5_hash is not None:          file_hash = file_hash.encode('utf-8')          hash_algorithm ='md5'      if md5_hash is not None:          file_hash = file_hash.encode('utf-8')          hash_algorithm ='md5'      if md5_hash is not None:          file_hash = file_hash.encode('utf-8')          hash_algorithm ='md5'      if md5_hash is not None:          file_hash = file_hash.encode('utf-8')          hash_algorithm ='md5'      if md5_hash is not None:          file_hash = file_hash.encode('utf-8')          hash_algorithm ='md5'      if md5_hash is not None:          file_hash = file_hash.encode('utf-8')          hash_algorithm ='md5'      if md5_hash is not None:          file_hash = file_hash.encode('utf-8')          hash_algorithm ='md5'      if md5_hash is not None:          file_hash = file_hash.encode('utf-8')          hash_algorithm ='md5'      if md5_hash is not None:          file_hash = file_hash.encode('utf-8')          hash_algorithm ='md5'      if md5_hash is not None:          file_hash = file_hash.encode('utf-8')          hash_algorithm ='md5'      if md5_hash is not None:          file_hash = file_hash.encode('utf-8')          hash_algorithm ='md5'      if md5_hash is not None:          file_hash = file_hash.encode('utf-8')          hash_algorithm ='md5'      if md5_hash is not None:          file_hash = file_hash.encode('utf-8')
def get_flat_dependant(dependant: Dependant) -> Dependant:  def is_scalar_field(field: Field) -> bool:     return (          field.shape == Shape.SINGLETON          and not lenient_issubclass(field.type_, BaseModel)          and not lenient_issubclass(field.type_, sequence_types + (list,))          and not isinstance(field.schema, params.Body)     )  def is_scalar_sequence_field(field: Field) -> bool:     return (          field.shape == Shape.SINGLETON          and not lenient_issubclass(field.type_, BaseModel)          and not lenient_issubclass(field.type_, sequence_types + (dict,))          and not isinstance(field.schema, params.Body)     )  def is_scalar_map_field(field: Field) -> bool:     return (          field.shape == Shape.SINGLETON          and not lenient_issubclass(field.type_, BaseModel)          and not lenient_issubclass(field.type_, sequence_types + (list,))          and not isinstance(field.schema, params.Body)     )  def is_scalar_sequence_field(field: Field) -> bool:     return (          field.shape == Shape.SINGLETON          and not lenient_issubclass(field.type_, BaseModel)          and not lenient_issubclass(field.type_, sequence_types + (dict,))          and not isinstance(field.schema, params.Body)     )  def is_scalar_map_field(field: Field) -> bool:     return (          field.shape == Shape.SINGLETON          and not lenient_issubclass(field.type_, BaseModel)          and not lenient_issubclass(field.type_, sequence_types + (list,))          and not isinstance(field.schema, params.Body)     )  def get_scalar_dependant(dependant: Dependant) -> Dependant:  def is_scalar_field(field: Field) -> bool:     return (          field.shape == Shape.SINGLETON          and not lenient_issubclass(field.type_, BaseModel)          and not lenient_issubclass(field.type_, sequence_types + (list,))          and not isinstance(field.schema, params.Body)     )  def is_scalar_sequence_field(field: Field) -> bool:     return (          field.shape == Shape.SINGLETON          and not lenient_issubclass(field.type_, BaseModel)          and not lenient_issubclass(field.type_, sequence_types + (dict,))          and not isinstance(field.schema, params.Body)     )  def is_scalar_map_field(field: Field) -> bool:     return (          field.shape == Shape.SINGLETON          and not lenient_issubclass(field.type_, BaseModel)          and not lenient_issubclass(field.type_, sequence_types + (list,))          and not isinstance(field.schema, params.Body)     )  def get_scalar_dependant(dependant: Dependant) -> Dependant:  def is_scalar_field(field: Field) -> bool:     return (          field.shape == Shape.SINGLETON          and not lenient_issubclass(field.type_, BaseModel)          and not lenient_issubclass(field.type_, sequence_types + (list,))          and not isinstance(field.schema, params.Body)     )  def is_scalar_sequence_field(field: Field) -> bool:     return (          field.shape == Shape.SINGLETON          and not lenient_issubclass(field.type_, BaseModel)          and not lenient_issubclass(field.type_, sequence_types + (dict,))          and not isinstance(field.schema, params.Body)     )  def is_scalar_map_field(field: Field) -> bool:     return (          field.shape == Shape.SINGLETON          and not lenient_issubclass(field.type_, BaseModel)          and not lenient_issubclass(field.type_, sequence_types + (list,))          and not isinstance(field.schema, params.Body)     )  def get_scalar_dependant(dependant: Dependant) -> Dependant:  def is_scalar_field(field: Field) -> bool:     return (          field.shape == Shape.SINGLETON          and not lenient_issubclass(field.type_, BaseModel)          and not lenient_issubclass(field.type_, sequence_types + (list,))          and not isinstance(field.schema, params.Body)     )  def is_scalar_sequence_field(field:
def _partition_tasks(worker):      set_tasks["completed"] = {task for (task, status, ext) in task_history if status == 'DONE' and task in pending_tasks}      set_tasks["already_done"] = {task for (task, status, ext) in task_history                                            if status == 'DONE' and task not in pending_tasks and task not in set_tasks["completed"]}      set_tasks["failed"] = {task for (task, status, ext) in task_history if status == 'FAILED'}      set_tasks["scheduling_error"] = {task for(task, status, ext) in task_history if status == 'UNKNOWN'}      set_tasks["still_pending_ext"] = {task for (task, status, ext) in task_history                                             if status == 'PENDING' and task not in set_tasks["failed"] and task not in set_tasks["completed"] and ext}      set_tasks["still_pending_not_ext"] = {task for (task, status, ext) in task_history                                              if status == 'PENDING' and task not in set_tasks["failed"] and task not in set_tasks["completed"] and ext}      set_tasks["run_by_other_worker"] = set()      set_tasks["upstream_failure"] = set()      set_tasks["upstream_missing_dependency"] = set()  def _partition_tasks(worker):      set_tasks["completed"] = {task for (task, status, ext) in task_history if status == 'DONE' and task in pending_tasks}      set_tasks["already_done"] = {task for (task, status, ext) in task_history                                               if status == 'DONE' and task not in pending_tasks and task not in set_tasks["completed"]}      set_tasks["failed"] = {task for (task, status, ext) in task_history if status == 'FAILED'}      set_tasks["scheduling_error"] = {task for(task, status, ext) in task_history if status == 'UNKNOWN'}      set_tasks["still_pending_ext"] = {task for (task, status, ext) in task_history                                               if status == 'PENDING' and task not in set_tasks["failed"] and task not in set_tasks["completed"] and ext}      set_tasks["still_pending_not_ext"] = {task for (task, status, ext) in task_history                                               if status == 'PENDING' and task not in set_tasks["failed"] and task not in set_tasks["completed"] and ext}      set_tasks["run_by_other_worker"] = set()      set_tasks["upstream_failure"] = set()      set_tasks["upstream_missing_dependency"] = set()  def _partition_tasks(worker):      set_tasks["completed"] = {task for (task, status, ext) in task_history if status == 'DONE' and task in pending_tasks}      set_tasks["already_done"] = {task for (task, status, ext) in task_history                                                 if status == 'DONE' and task not in pending_tasks and task not in set_tasks["completed"]}      set_tasks["failed"] = {task for (task, status, ext) in task_history if status == 'FAILED'}      set_tasks["scheduling_error"] = {task for(task, status, ext) in task_history if status == 'UNKNOWN'}      set_tasks["still_pending_ext"] = {task for (task, status, ext) in task_history
and Index.__new__.  These should not depend on core.internals.  from typing import TYPE_CHECKING, Any, Optional, Sequence, Union, cast, ensure_sequence  import numpy as np and Index.__new__.  These should not depend on core.internals.  from typing import TYPE_CHECKING, Any, Optional, Sequence, Union, cast, ensure_sequence, cast_to_bool  import numpy as np and Index.__new__.  These should not depend on core.internals.  from typing import TYPE_CHECKING, Any, Optional, Sequence, Union, cast, ensure_sequence, cast_to_bool, cast_to_int  import numpy as np and Index.__new__.  These should not depend on core.internals.  from typing import TYPE_CHECKING, Any, Optional, Sequence, Union, cast, ensure_sequence, cast_to_bool, cast_to_int  import numpy as np and Index.__new__.  These should not depend on core.internals.  from typing import TYPE_CHECKING, Any, Optional, Sequence, Union, cast, ensure_sequence, cast_to_bool, cast_to_int  import numpy as np and Index.__new__.  These should not depend on core.internals.  from typing import TYPE_CHECKING, Any, Optional, Sequence, Union, cast, ensure_sequence, cast_to_bool, cast_to_int  import numpy as np and Index.__new__.  These should not depend on core.internals.  from typing import TYPE_CHECKING, Any, Optional, Sequence, Union, cast, ensure_sequence, cast_to_bool, cast_to_int  import numpy as np and Index.__new__.  These should not depend on core.internals.  from typing import TYPE_CHECKING, Any, Optional, Sequence, Union, cast, ensure_sequence, cast_to_bool, cast_to_int  import numpy as np and Index.__new__.  These should not depend on core.internals.  from typing import TYPE_CHECKING, Any, Optional, Sequence, Union, cast, ensure_sequence, cast_to_bool, cast_to_int  import numpy as np and Index.__new__.  These should not depend on core.internals.  from typing import TYPE_CHECKING, Any, Optional, Sequence, Union, cast, ensure_sequence, cast_to_bool, cast_to_int  import numpy as np and Index.__new__.  These should not depend on core.internals.  from typing import TYPE_CHECKING, Any, Optional, Sequence, Union, cast, ensure_sequence, cast_to_bool, cast_to_int  import numpy as np and Index.__new__.  These should not depend on core.internals.  from typing import TYPE_CHECKING, Any, Optional, Sequence, Union, cast, ensure_sequence, cast_to_bool, cast_to_int  import numpy as np and Index.__new__.  These should not depend on core.internals.  from typing import TYPE_CHECKING, Any, Optional, Sequence, Union, cast, ensure_sequence, cast_to_bool, cast_to_int  import numpy as np and Index.__new__.  These should not depend on core.internals.  from typing import TYPE_CHECKING, Any, Optional, Sequence, Union, cast, ensure_sequence, cast_to_bool, cast_to_int  import numpy as np and Index.__new__.  These should not depend on core.internals.  from typing import TYPE_CHECKING, Any, Optional, Sequence, Union, cast, ensure_sequence, cast_to_bool, cast_to_int  import numpy as np and Index.__new__.  These should not depend on core.internals.  from typing import TYPE_CHECKING, Any, Optional, Sequence, Union, cast, ensure_sequence, cast_to_bool, cast_to_int  import numpy as np and Index.__new__.  These should not depend on core.internals.  from typing import TYPE_CHECKING, Any, Optional, Sequence, Union, cast, ensure_sequence, cast_to_bool, cast_to_int  import numpy as np and Index.__new__.  These should not depend on core.internals.  from typing import TYPE_CHECKING, Any, Optional, Sequence, Union, cast, ensure_sequence, cast_to_bool, cast_to_int  import numpy as np and Index.__new__.  These should not depend on core.internals.  from typing import TYPE_CHECKING, Any, Optional, Sequence, Union, cast, ensure_sequence, cast_to_bool, cast_to_int  import numpy as np and Index.__new__.  These should not depend on core.internals.  from typing import TYPE_CHECKING, Any, Optional, Sequence, Union, cast, ensure_sequence, cast_to_bool, cast_to_int  import numpy as np and Index.__new__.  These should not depend on core.internals.  from typing import TYPE_CHECKING, Any, Optional, Sequence, Union, cast, ensure_sequence, cast_to_bool, cast_to_int  import numpy as np and Index.__new__.  These should not depend on core.internals.  from typing import TYPE_CHECKING, Any, Optional, Sequence, Union, cast, ensure_sequence, cast_to_bool, cast_to_int  import numpy as np and Index.__new__.  These should not depend on core.internals.  from typing import TYPE_CHECKING, Any, Optional, Sequence, Union, cast, ensure_sequence, cast_to_bool, cast_to_int  import numpy as np and Index.__new__.  These should not depend on core.internals.  from typing import TYPE_CHECKING, Any, Optional, Sequence, Union, cast, ensure_sequence, cast_to_bool, cast_to_int  import numpy as np and Index.__new__.  These should not depend on core.internals.  from typing import TYPE_CHECKING, Any, Optional, Sequence, Union, cast, ensure_sequence, cast_to_bool, cast_to_int  import numpy as np and Index.__new__.  These should not depend on core.internals.  from typing import TYPE_CHECKING, Any, Optional, Sequence, Union, cast, ensure_sequence, cast_to_bool, cast_to_int  import numpy as np and Index.__new__.  These should not depend on core.internals.  from typing import TYPE_CHECKING, Any, Optional, Sequence, Union, cast, ensure_sequence, cast_to_bool, cast_to_int  import numpy as np and Index.__new__.  These should not depend on core.internals.  from typing import TYPE_CHECKING, Any, Optional, Sequence, Union, cast, ensure_sequence, cast_to_bool, cast_to_int  import numpy as np and Index.__new__.  These should not depend on core.internals.  from typing import TYPE_CHECKING, Any, Optional, Sequence, Union, cast, ensure_sequence, cast_to_bool, cast_to_int  import numpy as np and Index.__new__.  These should not depend on core.internals.  from typing import TYPE_CHECKING, Any, Optional, Sequence, Union, cast, ensure_sequence, cast_to_bool, cast_to_int  import numpy as np and Index.__new__.  These should not depend on core.internals.  from typing import TYPE_CHECKING, Any, Optional, Sequence, Union,
class Parameter(object):          :raises MissingParameterException: if x is false-y and no default is specified.          if not x:             if self.has_value:                 return self.value              elif self.is_bool:                  return False              elif self.is_list:                  return False              elif self.is_method:                  return False              elif self.is_list:                  return False           elif self.is_method:                  return False              elif self.is_bool:                  return False              elif self.is_function:                  return False              elif self.is_list:                  return False           elif self.is_method:                  return False              elif self.is_list:                  return False          elif self.is_method:                  return False              elif self.is_bool:                  return False           elif self.is_function:                  return False           elif self.is_list:                  return False          elif self.is_method:                  return False              elif self.is_list:                  return False          elif self.is_method:                  return False             elif self.is_bool:                  return False          elif self.is_function:                  return False           elif self.is_list:                  return False         elif self.is_method:                  return False             elif self.is_list:                  return False          elif self.is_method:                  return False             elif self.is_bool:                  return False          elif self.is_function:                  return False          elif self.is_list:                  return False         elif self.is_method:                  return False             elif self.is_list:                  return False          elif self.is_method:                  return False             elif self.is_bool:                  return False         elif self.is_function:                  return False          elif self.is_list:                  return False         elif self.is_method:                  return False          elif self.is_list:                  return False         elif self.is_method:                  return False          elif self.is_bool:                  return False         elif self.is_function:                  return False         elif self.is_list:                  return False         elif self.is_method:                  return False             elif self.is_list:                  return False         elif self.is_method:                  return False              elif self.is_list:
class FloatBlock(FloatOrComplexBlock):          )          return formatter.get_result_as_array()     def should_store(self, value: ArrayLike) -> bool:          return issubclass(value.dtype.type, np.floating) and value.dtype == self.dtype
class Categorical(ExtensionArray, PandasObject):          good = self._codes!= -1          if not good.all():             if skipna and good.any():                  pointer = self._codes[good].min()              else:                  return np.nan         if good.any():             if skipna:                  pointer = self._codes[good].min()              else:                  return np.nan         if good.all():             if skipna:                  pointer = self._codes[good].min()              else:                  return np.nan         if good.any():             if skipna:                  pointer = self._codes[good].min()              else:                  return np.nan         if good.all():             if skipna:                  pointer = self._codes[good].min()              else:                  return np.nan         if good.any():             if skipna:                  pointer = self._codes[good].min()              else:                  return np.nan         if good.all():             if skipna:                  pointer = self._codes[good].min()              else:                  return np.nan         if good.any():             if skipna:                  pointer = self._codes[good].min()              else:                  return np.nan         if good.all():             if skipna:                  pointer = self._codes[good].min()              else:                  return np.nan         if good.any():             if skipna:                  pointer = self._codes[good].min()              else:                  return np.nan         if good.all():             if skipna:                  pointer = self._codes[good].min()              else:                  return np.nan         if good.any():             if skipna:                  pointer = self._codes[good].min()              else:                  return np.nan         if good.all():             if skipna:                  pointer = self._codes[good].min()              else:                  return np.nan         if good.any():             if skipna:                  pointer = self._codes[good].min()              else:                  return np.nan         if good.all():             if skipna:                  pointer = self._codes[good].min()              else:                 return np.nan         if good.any():             if skipna:                  pointer = self._codes[good].min()              else:                  return np.nan         if good.all():             if skipna:                  pointer = self._codes[good].min()              else:                  return np.nan         if good.any():             if skipna:                  pointer = self._codes[good].min()              else:
class RedirectMiddleware(BaseRedirectMiddleware):      def process_response(self, request, response, spider):          if (request.meta.get('dont_redirect', False) or                response.status in getattr(spider, 'handle_httpstatus_list', [])):              return response          if request.method == 'HEAD':              return super(RedirectMiddleware, self).process_response(request, response, spider)          if request.method == 'POST':              return super(RedirectMiddleware, self).process_response(request, response, spider)          if request.method == 'GET':              return super(RedirectMiddleware, self).process_response(request, response, spider)          if request.meta.get('dont_redirect', False) or response.status in getattr(spider, 'handle_httpstatus_list', []):              return response          if request.method == 'POST':              return super(RedirectMiddleware, self).process_response(request, response, spider)          if request.method == 'GET':              return super(RedirectMiddleware, self).process_response(request, response, spider)          if request.meta.get('dont_redirect', False) or response.status in getattr(spider, 'handle_httpstatus_list', []):              return response      def process_response(self, request, response, spider):          if (request.meta.get('dont_redirect', False) or                response.status in getattr(spider, 'handle_httpstatus_list', [])):              return response          if request.method == 'HEAD':              return super(RedirectMiddleware, self).process_response(request, response, spider)          if request.method == 'POST':              return super(RedirectMiddleware, self).process_response(request, response, spider)          if request.method == 'GET':              return super(RedirectMiddleware, self).process_response(request, response, spider)          if request.meta.get('dont_redirect', False) or response.status in getattr(spider, 'handle_httpstatus_list', []):              return response     def process_response(self, request, response, spider):          if (request.meta.get('dont_redirect', False) or                response.status in getattr(spider, 'handle_httpstatus_list', [])):              return response          if request.method == 'HEAD':              return super(RedirectMiddleware, self).process_response(request, response, spider)          if request.method == 'POST':              return super(RedirectMiddleware, self).process_response(request, response, spider)          if request.method == 'GET':              return super(RedirectMiddleware, self).process_response(request, response, spider)     def process_response(self, request, response, spider):          if (request.meta.get('dont_redirect', False) or                response.status in getattr(spider, 'handle_httpstatus_list', [])):              return response          if request.method == 'HEAD':              return super(RedirectMiddleware, self).process_response(request, response, spider)          if request.method == 'POST':              return super(RedirectMiddleware, self).process_response(request, response, spider)          if request.method == 'GET':              return super(RedirectMiddleware, self).process_response(request, response, spider)     def process_response(self, request, response, spider):          if (request.meta.get('dont_redirect', False) or                response.status in getattr(spider, 'handle_httpstatus_list', [])):              return response          if request.method == 'HEAD':              return super(RedirectMiddleware, self).process_response(request, response, spider)          if request.method == 'POST':              return super(RedirectMiddleware, self).process_response(request, response, spider)     def process_response(self, request, response, spider):          if (request.meta.get('dont_redirect', False) or                 response.status in getattr(spider, 'handle_httpstatus_list', [])):              return response          if request.method == 'HEAD':              return super(RedirectMiddleware, self).process_response(request, response, spider)          if request.method == 'POST':              return super(RedirectMiddleware, self).process_response(request, response, spider)     def process_response(self, request,
def get_new_command(command):          pass      if upstream_option_index is not -1:          command.script_parts.pop(upstream_option_index)         command.script_parts.pop(upstream_option_index)      push_upstream = command.stderr.split('\n')[-3].strip().partition('git ')[2]      return replace_argument(" ".join(command.script_parts), 'push', push_upstream)
from pandas.core.dtypes.common import (      ensure_platform_int,      is_bool,      is_bool_dtype,     is_categorical,      is_categorical_dtype,     is_extension_array_dtype,      is_dtype_equal,      from pandas.core.dtypes.common import (      ensure_platform_int,      is_bool,      is_bool_dtype,     is_categorical,      is_categorical_dtype,     is_extension_array_dtype,      is_dtype_equal,      from pandas.core.dtypes.common import (      ensure_platform_int,      is_bool,      is_bool_dtype,     is_categorical,      is_categorical_dtype,     is_extension_array_dtype,      is_dtype_equal,      from pandas.core.dtypes.common import (      ensure_platform_int,      is_bool,      is_bool_dtype,     is_categorical,      is_categorical_dtype,     is_extension_array_dtype,      is_dtype_equal,      from pandas.core.dtypes.common import (      ensure_platform_int,      is_bool,      is_bool_dtype,     is_categorical,      is_categorical_dtype,     is_extension_array_dtype,      is_dtype_equal,      from pandas.core.dtypes.common import (      ensure_platform_int,      is_bool,      is_bool_dtype,     is_categorical,      is_categorical_dtype,     is_extension_array_dtype,      is_dtype_equal,      from pandas.core.dtypes.common import (      ensure_platform_int,      is_bool,      is_bool_dtype,     is_categorical,      is_categorical_dtype,     is_extension_array_dtype,      is_dtype_equal,      from pandas.core.dtypes.common import (      ensure_platform_int,      is_bool,      is_bool_dtype,     is_categorical,      is_categorical_dtype,     is_extension_array_dtype,      is_dtype_equal,      from pandas.core.dtypes.common import (      ensure_platform_int,      is_bool,      is_bool_dtype,     is_categorical,      is_categorical_dtype,     is_extension_array_dtype,      is_dtype_equal,      from pandas.core.dtypes.common import (      ensure_platform_int,      is_bool,      is_bool_dtype,     is_categorical,      is_categorical_dtype,     is_extension_array_dtype,      is_dtype_equal,      from pandas.core.dtypes.common import (      ensure_platform_int,      is_bool,      is_bool_dtype,     is_categorical,      is_categorical_dtype,     is_extension_array_dtype,      is_dtype_equal,      from pandas.core.dtypes.common import (      ensure_platform_int,      is_bool,      is_bool_dtype,     is_categorical,      is_categorical_dtype,     is_extension_array_dtype,      is_dtype_equal,      from pandas.core.dtypes.common import (      ensure_platform_int,      is_bool,      is_bool_dtype,     is_categorical,      is_categorical_dtype,     is_extension_array_dtype,      is_dtype_equal,      from pandas.core.dtypes.common import (      ensure_platform_int,      is_bool,      is_bool_dtype,     is_categorical,      is_categorical_dtype,     is_extension_array_dtype,      is_dtype_equal,      from pandas.core.dtypes.common import (      ensure_platform_int,      is_bool,      is_bool_dtype,     is_categorical,      is_categorical_dtype,     is_extension_array_dtype,      is_dtype_equal,      from pandas.core.dtypes.common import (      ensure_platform_int,      is_bool,      is_bool_dtype,     is_categorical,      is_categorical_dtype,     is_extension_array_dtype,      is_dtype_equal,      from pandas.core.dtypes.common import (      ensure_platform_int,      is_bool,      is_bool_dtype,     is_categorical,      is_categorical_dtype,     is_extension_array_dtype,      is_dtype_equal,      from pandas.core.dtypes.common import (      ensure_platform
class TestPeriodIndex(DatetimeLike):          idx = PeriodIndex([2000, 2007, 2007, 2009, 2007], freq="A-JUN")          ts = Series(np.random.randn(len(idx)), index=idx)         result = ts["2007"]          expected = ts[idx == "2007"]          tm.assert_series_equal(result, expected)      def test_period_index(self):          idx = PeriodIndex([2000, 2007, 2007, 2009, 2007], freq="A-JUN")          ts = Series(np.random.randn(len(idx)), index=idx)         result = ts["2007"]          expected = ts[idx == "2007"]          tm.assert_series_equal(result, expected)      def test_period_index(self):          idx = PeriodIndex([2000, 2007, 2007, 2009, 2007], freq="A-JUN")          ts = Series(np.random.randn(len(idx)), index=idx)         result = ts["2007"]          expected = ts[idx == "2007"]          tm.assert_series_equal(result, expected)      def test_period_index(self):          idx = PeriodIndex([2000, 2007, 2007, 2009, 2007], freq="A-JUN")          ts = Series(np.random.randn(len(idx)), index=idx)         result = ts["2007"]          expected = ts[idx == "2007"]          tm.assert_series_equal(result, expected)      def test_period_index(self):          idx = PeriodIndex([2000, 2007, 2007, 2009, 2007], freq="A-JUN")          ts = Series(np.random.randn(len(idx)), index=idx)         result = ts["2007"]          expected = ts[idx == "2007"]          tm.assert_series_equal(result, expected)      def test_period_index(self):          idx = PeriodIndex([2000, 2007, 2007, 2009, 2007], freq="A-JUN")          ts = Series(np.random.randn(len(idx)), index=idx)         result = ts["2007"]          expected = ts[idx == "2007"]          tm.assert_series_equal(result, expected)      def test_period_index(self):          idx = PeriodIndex([2000, 2007, 2007, 2009, 2007], freq="A-JUN")          ts = Series(np.random.randn(len(idx)), index=idx)         result = ts["2007"]          expected = ts[idx == "2007"]          tm.assert_series_equal(result, expected)      def test_period_index(self):          idx = PeriodIndex([2000, 2007, 2007, 2009, 2007], freq="A-JUN")          ts = Series(np.random.randn(len(idx)), index=idx)         result = ts["2007"]          expected = ts[idx == "2007"]          tm.assert_series_equal(result, expected)      def test_period_index(self):          idx = PeriodIndex([2000, 2007, 2007, 2009, 2007], freq="A-JUN")          ts = Series(np.random.randn(len(idx)), index=idx)         result = ts["2007"]          expected = ts[idx == "2007"]          tm.assert_series_equal(result, expected)      def test_period_index(self):          idx = PeriodIndex([2000, 2007, 2007, 2009, 2007], freq="A-JUN")          ts = Series(np.random.randn(len(idx)), index=idx)         result = ts["2007"]          expected = ts[idx == "2007"]          tm.assert_series_equal(result, expected)      def test_period_index(self):          idx = PeriodIndex([2000, 2007, 2007, 2009, 2007], freq="A-JUN")          ts = Series(np.random.randn(len(idx)), index=idx)         result = ts["2007"]          expected = ts[idx == "2007"]          tm.assert_series_equal(result, expected)      def test_period_index(self):          idx = PeriodIndex([2000, 2007, 2007, 2009, 2007], freq="A-JUN")          ts = Series(np.random.randn(len(idx)), index=idx)         result = ts["2007"]          expected = ts[idx == "2007"]          tm.assert_series_equal(result, expected)      def test_period_index(self):          idx = PeriodIndex([2000, 2007, 2007, 2009, 2007], freq="A-JUN")          ts = Series(np.random.randn(len(idx)), index=idx)         result = ts["2007"]
from pandas.core.dtypes.generic import (  )  from pandas.core.dtypes.missing import notna from pandas._typing import Dtype  from pandas.core import algorithms  from pandas.core.algorithms import unique  from pandas.core.dtypes.generic import (  ) import pandas.core.dtypes.missing  from pandas.core.dtypes.missing import notna  from pandas._typing import Dtype  from pandas.core import algorithms  from pandas.core.algorithms import unique  from pandas.core.dtypes.generic import (  )  from pandas.core.dtypes.missing import notna from pandas._typing import Dtype  from pandas.core import algorithms  from pandas.core.algorithms import unique  from pandas.core.dtypes.generic import (  ) import pandas.core.dtypes.missing  from pandas.core.dtypes.missing import notna  from pandas._typing import Dtype  from pandas.core import algorithms  from pandas.core.algorithms import unique  from pandas.core.dtypes.generic import (  )  from pandas.core.dtypes.missing import notna from pandas._typing import Dtype  from pandas.core import algorithms  from pandas.core.algorithms import unique  from pandas.core.dtypes.generic import (  )  from pandas.core.dtypes.missing import notna  from pandas._typing import Dtype  from pandas.core import algorithms  from pandas.core.algorithms import unique  from pandas.core.dtypes.generic import (  )  from pandas.core.dtypes.missing import notna  from pandas._typing import Dtype  from pandas.core import algorithms  from pandas.core.algorithms import unique  from pandas.core.dtypes.generic import (  )  from pandas.core.dtypes.missing import notna  from pandas._typing import Dtype  from pandas.core import algorithms  from pandas.core.algorithms import unique  from pandas.core.dtypes.generic import (  )  from pandas.core.dtypes.missing import notna  from pandas._typing import Dtype  from pandas.core import algorithms  from pandas.core.algorithms import unique  from pandas.core.dtypes.generic import (  )  from pandas.core.dtypes.missing import notna  from pandas._typing import Dtype  from pandas.core import algorithms  from pandas.core.algorithms import unique  from pandas.core.dtypes.generic import (  )  from pandas.core.dtypes.missing import notna  from pandas._typing import Dtype  from pandas.core import algorithms  from pandas.core.algorithms import unique  from pandas.core.dtypes.generic import (  )  from pandas.core.dtypes.missing import notna  from pandas._typing import Dtype  from pandas.core import algorithms  from pandas.core.algorithms import unique  from pandas.core.dtypes.generic import (  )  from pandas.core.dtypes.missing import notna  from pandas._typing import Dtype  from pandas.core import algorithms  from pandas.core.algorithms import unique  from pandas.core.dtypes.generic import (  )  from pandas.core.dtypes.missing import notna  from pandas._typing import Dtype  from pandas.core import algorithms  from pandas.core.algorithms import unique  from pandas.core.dtypes.generic import (  )  from pandas.core.dtypes.missing import notna  from pandas._typing import Dtype  from pandas.core import algorithms  from pandas.core.algorithms import unique  from pandas.core.dtypes.generic import (  )  from pandas.core.dtypes.missing import notna  from pandas._typing import Dtype  from pandas.core import algorithms  from pandas.core.algorithms import unique  from pandas.core.dtypes.generic import (  )  from pandas.core.dtypes.missing import notna  from pandas._typing import Dtype  from pandas.core import algorithms  from pandas.core.algorithms import unique  from pandas.core.dtypes.generic import (  )  from pandas.core.dtypes.missing import notna  from pandas._typing import Dtype  from pandas.core import algorithms  from pandas.core.algorithms import unique  from pandas.core.dtypes.generic import (  )  from pandas.core.dtypes.missing import notna  from pandas._typing import Dtype  from pandas.core import algorithms  from pandas.core.algorithms import unique  from pandas.core.dtypes.generic import (  )  from pandas.core.dtypes.missing import notna  from pandas._typing import Dtype  from pandas.core import algorithms  from pandas.core.algorithms import unique  from pandas.core.dtypes.generic import (  )  from pandas.core.dtypes.missing import notna  from pandas._typing import Dtype  from pandas.core import algorithms  from pandas.core.algorithms import unique  from pandas.core.dtypes.generic import (  )  from pandas.core.dtypes.missing import notna  from pandas._typing import Dtype  from pandas.core import algorithms  from pandas.core.algorithms import unique  from pandas.core.dtypes.generic import (  )  from pandas.core.dtypes.missing import notna  from pandas._typing import Dtype  from pandas.core import algorithms  from pandas.core.algorithms import unique  from pandas.core.dtypes.generic import (  )  from pandas.core.dtypes.missing import notna  from pandas._typing import Dtype  from pandas.core import algorithms  from pandas.core.algorithms import unique  from pandas.core.dtypes.generic import (  )  from pandas.core.dtypes.missing import notna  from pandas._typing import Dtype  from pandas.core import algorithms  from pandas.core.algorithms import unique  from pandas.core.dtypes.generic import (  )  from pandas.core.dtypes.missing import notna  from pandas._typing import Dtype  from pandas.core import algorithms  from pandas.core.algorithms import unique  from pandas.core.dtypes.generic import (  )  from pandas.core.dtypes.missing import notna  from pandas._typing import Dtype  from pandas.core import algorithms  from pandas.core.algorithms import unique  from pandas.core.dtypes.generic import (  )  from pandas.core.dtypes.missing import notna  from pandas._typing import Dtype  from pandas.core import algorithms  from pandas.core.algorithms import unique  from pandas.core.dtypes.generic import (  )  from pandas.core.dtypes.missing import notna  from pandas._typing import Dtype  from pandas.core import algorithms  from pandas.core.algorithms import unique  from pandas.core.dtypes.generic import (  )  from pandas.core.dtypes
def evaluate_generator(model, generator,      steps_done = 0      outs_per_batch = []      batch_sizes = []     use_sequence_api = is_sequence(generator)     if not use_sequence_api and use_multiprocessing and workers > 1:          warnings.warn(              UserWarning('Using a generator with `use_multiprocessing=True`'                         'and multiple workers may duplicate your data.'                         'Please consider using the`keras.utils.Sequence'                         'class.'))      if steps is None:         if use_sequence_api:              steps = len(generator)          else:              raise ValueError('`steps=None` is only valid for a generator'                         'that uses the`keras.utils.Sequence` class.')      if steps is None:         if use_sequence_api:              steps = len(generator)          else:              raise ValueError('`steps=None` is only valid for a generator'                         'that uses the`keras.utils.Sequence` class.')      if steps is None:         if use_sequence_api:              steps = len(generator)          else:              raise ValueError('`steps=None` is only valid for a generator'                         'that uses the`keras.utils.Sequence` class.')      if steps is None:         if use_sequence_api:              steps = len(generator)          else:              raise ValueError('`steps=None` is only valid for a generator'                         'that uses the`keras.utils.Sequence` class.')      if steps is None:         if use_sequence_api:              steps = len(generator)          else:              raise ValueError('`steps=None` is only valid for a generator'                          'that uses the`keras.utils.Sequence` class.')      if steps is None:         if use_sequence_api:              steps = len(generator)          else:              raise ValueError('`steps=None` is only valid for a generator'                          'that uses the`keras.utils.Sequence` class.')      if steps is None:         if use_sequence_api:              steps = len(generator)          else:              raise ValueError('`steps=None` is only valid for a generator'                          'that uses the`keras.utils.Sequence` class.')      if steps is None:         if use_sequence_api:              steps = len(generator)          else:              raise ValueError('`steps=None` is only valid for a generator'                          'that uses the`keras.utils.Sequence` class.')      if steps is None:         if use_sequence_api:              steps = len(generator)          else:              raise ValueError('`steps=None` is only valid for a generator'                           'that uses the`keras.utils.Sequence` class.')      if steps is None:         if use_sequence_api:              steps = len(generator)          else:              raise ValueError('`steps=None` is only valid for a generator'                            'that uses the
class Series(base.IndexOpsMixin, generic.NDFrame):          kwargs["inplace"] = validate_bool_kwarg(kwargs.get("inplace", False), "inplace")         non_mapping = is_scalar(index) or (             is_list_like(index) and not is_dict_like(index)         )         if non_mapping:              return self._set_name(index, inplace=kwargs.get("inplace"))         return super().rename(index=index, **kwargs)      @Substitution(**_shared_doc_kwargs)      @Appender(generic.NDFrame.reindex.__doc__)
class BaseAsyncIOLoop(IOLoop):              if all_fds:                  self.close_fd(fileobj)          self.asyncio_loop.close()      def add_handler(self, fd, handler, events):          fd, fileobj = self.split_fd(fd)         self.asyncio_loop.add_handler(fd, handler, events)      def close_fd(self, fileobj):          fd, fileobj = self.split_fd(fileobj)         self.asyncio_loop.close()      def add_handler(self, fd, handler, events):          fd, fileobj = self.split_fd(fd)         self.asyncio_loop.add_handler(fd, handler, events)      def close_fd(self, fileobj):          fd, fileobj = self.split_fd(fileobj)         self.asyncio_loop.close()      def add_handler(self, fd, handler, events):          fd, fileobj = self.split_fd(fd)         self.asyncio_loop.add_handler(fd, handler, events)      def close_fd(self, fileobj):          fd, fileobj = self.split_fd(fileobj)         self.asyncio_loop.close()      def add_handler(self, fd, handler, events):          fd, fileobj = self.split_fd(fd)         self.asyncio_loop.add_handler(fd, handler, events)      def close_fd(self, fileobj):          fd, fileobj = self.split_fd(fileobj)         self.asyncio_loop.close()      def add_handler(self, fd, handler, events):          fd, fileobj = self.split_fd(fd)         self.asyncio_loop.add_handler(fd, handler, events)      def close_fd(self, fileobj):          fd, fileobj = self.split_fd(fileobj)         self.asyncio_loop.close()      def add_handler(self, fd, handler, events):          fd, fileobj = self.split_fd(fd)         self.asyncio_loop.add_handler(fd, handler, events)      def close_fd(self, fileobj):          fd, fileobj = self.split_fd(fileobj)         self.asyncio_loop.close()      def add_handler(self, fd, handler, events):          fd, fileobj = self.split_fd(fd)         self.asyncio_loop.add_handler(fd, handler, events)      def close_fd(self, fileobj):          fd, fileobj = self.split_fd(fileobj)         self.asyncio_loop.close()      def add_handler(self, fd, handler, events):          fd, fileobj = self.split_fd(fd)         self.asyncio_loop.add_handler(fd, handler, events)      def close_fd(self, fileobj):          fd, fileobj = self.split_fd(fileobj)         self.asyncio_loop.close()      def add_handler(self, fd, handler, events):          fd, fileobj = self.split_fd(fd)         self.asyncio_loop.add_handler(fd, handler, events)      def close_fd(self, fileobj):          fd, fileobj = self.split_fd(fileobj)         self.asyncio_loop.close()      def add_handler(self, fd, handler, events):          fd, fileobj = self.split_fd(fd)         self.asyncio_loop.add_handler(fd, handler, events)      def close_fd(self, fileobj):          fd, fileobj = self.split_fd(fileobj)         self.asyncio_loop.close()      def add_handler(self, fd, handler, events):          fd, fileobj = self.split_fd(fd)         self.asyncio_loop.add_handler(fd, handler, events)      def close_fd(self, fileobj):          fd, fileobj = self.split_fd(fileobj)         self.asyncio_loop.close()      def add_handler(self, fd, handler, events):          fd, fileobj = self.split_fd(fd)         self.asyncio_loop.add_handler(fd, handler, events)      def close_fd(self, fileobj):          fd, fileobj = self.split_fd(fileobj)         self.asyncio_loop.close()      def add_handler(self, fd, handler, events):          fd, fileobj = self.split_fd(fd)         self.asyncio_loop.add_handler(fd, handler, events)      def close_fd(self, fileobj):          fd, fileobj = self.split_fd(fileobj)
class ObjectBlock(Block):              if convert:                  block = [b.convert(numeric=False, copy=True) for b in block]              return block.copy()          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self
class Categorical(ExtensionArray, PandasObject):          Only ordered `Categoricals` have a maximum!        .. versionchanged:: 1.0.0            Returns an NA value on empty arrays          Raises          ------          TypeError
def get_openapi_security_definitions(flat_dependant: Dependant) -> Tuple[Dict, L          security_definition = jsonable_encoder(              security_requirement.security_scheme.model,              by_alias=True,             exclude_none=False,             exclude_defaults=False,          )          security_name = security_requirement.security_scheme.scheme_name          security_definitions[security_name] = security_definition      def get_openapi_security_definitions(flat_dependant: Dependant) -> Tuple[Dict, L          security_definition = jsonable_encoder(              security_requirement.security_scheme.model,              by_alias=True,             exclude_none=False,             exclude_defaults=False,          )          security_name = security_requirement.security_scheme.scheme_name          security_definitions[security_name] = security_definition      def get_openapi_security_definitions(flat_dependant: Dependant) -> Tuple[Dict, L          security_definition = jsonable_encoder(              security_requirement.security_scheme.model,              by_alias=True,             exclude_none=False,             exclude_defaults=False,          )          security_name = security_requirement.security_scheme.scheme_name          security_definitions[security_name] = security_definition      def get_openapi_security_definitions(flat_dependant: Dependant) -> Tuple[Dict, L          security_definition = jsonable_encoder(              security_requirement.security_scheme.model,              by_alias=True,              exclude_none=False,              exclude_defaults=False,          )          security_name = security_requirement.security_scheme.scheme_name          security_definitions[security_name] = security_definition      def get_openapi_security_definitions(flat_dependant: Dependant) -> Tuple[Dict, L          security_definition = jsonable_encoder(              security_requirement.security_scheme.model,              by_alias=True,              exclude_none=False,              exclude_defaults=False,          )          security_name = security_requirement.security_scheme.scheme_name          security_definitions[security_name] = security_definition      def get_openapi_security_definitions(flat_dependant: Dependant) -> Tuple[Dict, L          security_definition = jsonable_encoder(              security_requirement.security_scheme.model,              by_alias=True,              exclude_none=False,              exclude_defaults=False,          )          security_name = security_requirement.security_scheme.scheme_name          security_definitions[security_name] = security_definition      def get_openapi_security_definitions(flat_dependant: Dependant) -> Tuple[Dict, L          security_definition = jsonable_encoder(              security_requirement.security_scheme.model,              by_alias=True,              exclude_none=False,              exclude_defaults=False,          )          security_name = security_requirement.security_scheme.scheme_name          security_definitions[security_name] = security_definition      def get_openapi_security_definitions(flat_dependant: Dependant) -> Tuple[Dict, L          security_definition = jsonable_encoder(              security_requirement.security_scheme.model,              by_alias=True,              exclude_none=False,              exclude_defaults=False,          )          security_name = security_requirement.security_scheme.scheme_name          security_definitions[security_name] = security_definition      def get_openapi_security_definitions(flat_dependant: Dependant) -> Tuple[Dict, L          security_definition = jsonable_encoder(              security_requirement.security_scheme.model,              by_alias=True,
def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),      if isinstance(output_shape, (tuple, list)):          output_shape = tf.stack(output_shape)     x, tf_data_format = _preprocess_conv2d_input(x, data_format)      if data_format == 'channels_first' and tf_data_format == 'NHWC':          output_shape = (output_shape[0],

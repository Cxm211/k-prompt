def update_add(x, increment):          The variable `x` updated.     op = tf_state_ops.assign_add(x, increment)     with tf.control_dependencies([op]):         return tf.identity(x)  @symbolic     def update_add(x, increment):          The variable `x` updated.     op = tf_state_ops.assign_add(x, increment)     with tf.control_dependencies([op]):         return tf.identity(x)  @symbolic     def update_add(x, increment):          The variable `x` updated.     op = tf_state_ops.assign_add(x, increment)     with tf.control_dependencies([op]):         return tf.identity(x)  @symbolic     def update_add(x, increment):          The variable `x` updated.     op = tf_state_ops.assign_add(x, increment)     with tf.control_dependencies([op]):         return tf.identity(x)  @symbolic     def update_add(x, increment):          The variable `x` updated.     op = tf_state_ops.assign_add(x, increment)     with tf.control_dependencies([op]):         return tf.identity(x)  @symbolic     def update_add(x, increment):          The variable `x` updated.     op = tf_state_ops.assign_add(x, increment)     with tf.control_dependencies([op]):         return tf.identity(x)  @symbolic     def update_add(x, increment):          The variable `x` updated.     op = tf_state_ops.assign_add(x, increment)     with tf.control_dependencies([op]):         return tf.identity(x)  @symbolic     def update_add(x, increment):          The variable `x` updated.     op = tf_state_ops.assign_add(x, increment)     with tf.control_dependencies([op]):         return tf.identity(x)  @symbolic     def update_add(x, increment):          The variable `x` updated.     op = tf_state_ops.assign_add(x, increment)     with tf.control_dependencies([op]):         return tf.identity(x)  @symbolic     def update_add(x, increment):          The variable `x` updated.     op = tf_state_ops.assign_add(x, increment)     with tf.control_dependencies([op]):         return tf.identity(x)  @symbolic     def update_add(x, increment):          The variable `x` updated.     op = tf_state_ops.assign_add(x, increment)     with tf.control_dependencies([op]):         return tf.identity(x)  @symbolic     def update_add(x, increment):          The variable `x` updated.     op = tf_state_ops.assign_add(x, increment)     with tf.control_dependencies([op]):         return tf.identity(x)  @symbolic     def update_add(x, increment):          The variable `x` updated.     op = tf_state_ops.assign_add(x, increment)     with tf.control_dependencies([op]):         return tf.identity(x)  @symbolic     def update_add(x, increment):          The variable `x` updated.     op = tf_state_ops.assign_add(x, increment)     with tf.control_dependencies([op]):         return tf.identity(x)  @symbolic     def update_add(x, increment):          The variable `x` updated.     op = tf_state_ops.assign_add(x, increment)     with tf.control_dependencies([op]):         return tf.identity(x)  @symbolic     def update_add(x, increment):          The variable `x` updated.     op = tf_state_ops.assign_add(x, increment)     with tf.control_dependencies([op]):         return tf.identity(x)  @symbolic     def update_add(x, increment):          The variable `x` updated.     op = tf_state_ops.assign_add(x, increment)     with tf.control_dependencies([op]):         return tf.identity(x)  @symbolic     def update_add(x, increment):          The variable `x` updated.     op = tf_state_ops.assign_add(x, increment)     with tf.control_dependencies([op]):         return tf.identity(x)  @symbolic     def update_add(x, increment):          The variable `x` updated.     op = tf_state_ops.assign_add(x, increment)     with tf.control_dependencies([op]):         return tf.identity(x)  @symbolic     def update_add(x, increment):          The variable `x` updated.     op = tf_state_ops.assign_add(x, increment)     with tf.control_dependencies([op]):         return tf.identity(x)  @symbolic     def update_add(x, increment):          The variable `x` updated.     op = tf_state_ops.assign_add(x, increment)     with tf.control_dependencies([op]):         return tf.identity(x)  @symbolic     def update_add(x, increment):          The variable `x` updated.     op = tf_state_ops.assign_add(x, increment)     with tf.control_dependencies([op]):         return tf.identity(x)  @symbolic     def update_add(x, increment):          The variable `x` updated.     op = tf_state_ops.assign_add(x, increment)     with tf.control_dependencies([op]):         return tf.identity(x)  @symbolic     def update_add(x, increment):
class _AxesBase(martist.Artist):              if right is None:                  right = old_right         if self.get_xscale() == 'log':             if left >= 0:                 cbook._warn_external(                     'Attempted to set non-positive left xlim on a'                )          if self.get_yscale() == 'log':              if right <= 0:                  cbook._warn_external(                      'Attempted to set non-positive right ylim on a'                )          if self.get_xscale() == 'log':              if left >= 0:                  cbook._warn_external(                      'Attempted to set non-positive left xlim on a'                )          if self.get_yscale() == 'log':              if right <= 0:                  cbook._warn_external(                      'Attempted to set non-positive right ylim on a'                )          if self.get_xscale() == 'log':              if left >= 0:                  cbook._warn_external(                      'Attempted to set non-positive left xlim on a'                )          if self.get_yscale() == 'log':              if right <= 0:                  cbook._warn_external(                      'Attempted to set non-positive right ylim on a'                )          if self.get_xscale() == 'log':              if left >= 0:                  cbook._warn_external(                     'Attempted to set non-positive left xlim on a'                )          if self.get_yscale() == 'log':              if right <= 0:                  cbook._warn_external(                     'Attempted to set non-positive right ylim on a'                )          if self.get_xscale() == 'log':              if left >= 0:                  cbook._warn_external(                     'Attempted to set non-positive left xlim on a'                )          if self.get_yscale() == 'log':              if right <= 0:                  cbook._warn_external(                     'Attempted to set non-positive right ylim on a'                )          if self.get_xscale() == 'log':              if left >= 0:                  cbook._warn_external(                     'Attempted to set non-positive left xlim on a'                )          if self.get_yscale() == 'log':              if right <= 0:                  cbook._warn_external(                     'Attempted to set non-positive right ylim on a'                )          if self.get_xscale() == 'log':              if left >= 0:                  cbook._warn_external(                     'Attempted to set non-positive left xlim on a'                )          if self.get_yscale() == 'log':              if right <= 0:                  cbook._warn_external(                     'Attempted to set non-positive right ylim on a'                )          if self.get_xscale() == 'log':              if left >= 0:                  cbook._warn_external(                     'Attempted to set non-positive left xlim on a'                )          if self.get_yscale() == 'log':              if right <= 0:                 cbook._warn_external(                     'Attempted to set non-positive right ylim on a'                )          if self.get_xscale() == 'log':
class APIRouter(routing.Router):              response_model_exclude_unset=bool(                  response_model_exclude_unset or response_model_skip_defaults              ),             response_model_exclude_defaults=response_model_exclude_defaults,             response_model_exclude_none=response_model_exclude_none,              include_in_schema=include_in_schema,              response_class=response_class or self.default_response_class,              name=name,
class Conv2DTranspose(Conv2D):          out_height = conv_utils.deconv_length(height,                                                 stride_h, kernel_h,                                                self.padding,                                               out_pad_h,                                               self.dilation_rate[0])          out_width = conv_utils.deconv_length(width,                                                  stride_w, kernel_w,                                                self.padding,                                               out_pad_w,                                              self.dilation_rate[1])          if self.data_format == 'channels_first':              output_shape = (batch_size, self.filters, out_height, out_width)          else:              if self.dilation_rate[0] == 1:                 output_shape = (batch_size, self.filters, out_height, out_width)             else:                 output_shape = (batch_size, self.filters, out_height, out_width)          if self.data_format == 'channels_first':             output_shape = (batch_size, self.filters, out_height, out_width)          else:             if self.dilation_rate[1] == 1:                 output_shape = (batch_size, self.filters, out_height, out_width)             else:                 output_shape = (batch_size, self.filters, out_height, out_width)          if self.data_format == 'channels_first':             output_shape = (batch_size, self.filters, out_height, out_width)          else:             output_shape = (batch_size, self.filters, out_height, out_width)          if self.dilation_rate[0] == 1:             output_shape = (batch_size, self.filters, out_height, out_width)          else:             output_shape = (batch_size, self.filters, out_height, out_width)          if self.data_format == 'channels_first':             output_shape = (batch_size, self.filters, out_height, out_width)          else:             output_shape = (batch_size, self.filters, out_height, out_width)          if self.dilation_rate[1] == 1:             output_shape = (batch_size, self.filters, out_height, out_width)          else:             output_shape = (batch_size, self.filters, out_height, out_width)          if self.data_format == 'channels_first':             output_shape = (batch_size, self.filters, out_height, out_width)          else:             output_shape = (batch_size, self.filters, out_height, out_width)          if self.dilation_rate[0] == 1:             output_shape = (batch_size, self.filters, out_height, out_width)          else:             output_shape = (batch_size, self.filters, out_height, out_width)          if self.data_format == 'channels_first':             output_shape = (batch_size, self.filters, out_height, out_width)          else:             output_shape = (batch_size, self.filters, out_height, out_width)          if self.dilation_rate[1] == 1:             output_shape = (
class StackedRNNCells(Layer):                                   '`state_size` attribute.'                                'received cells:', cells)          super(StackedRNNCells, self).__init__(**kwargs)      @property      def state_size(self):          state_size = []         for cell in self.cells:              if hasattr(cell.state_size, '__len__'):                  state_size += list(cell.state_size)              else:                 state_size.append(cell.state_size)          return tuple(state_size)      def call(self, inputs, states, constants=None, **kwargs):          nested_states = []         for cell in self.cells:              if hasattr(cell.state_size, '__len__'):                  nested_states.append(states[:len(cell.state_size)])                  states = states[len(cell.state_size):]              else:                 nested_states.append([states[0]])          return tuple(nested_states)      def call(self, inputs, states, constants=None, **kwargs):          nested_states = []          for cell in self.cells:              if hasattr(cell.state_size, '__len__'):                  nested_states.append(states[:len(cell.state_size)])                  states = states[len(cell.state_size):]              else:                 nested_states.append([states[0]])          return tuple(nested_states)      @property      def state_size(self):          state_size = []         for cell in self.cells:              if hasattr(cell.state_size, '__len__'):                  state_size += list(cell.state_size)              else:                 state_size.append(cell.state_size)          return tuple(state_size)         def call(self, inputs, states, constants=None, **kwargs):          nested_states = []          for cell in self.cells:              if hasattr(cell.state_size, '__len__'):                  nested_states.append(states[:len(cell.state_size)])                  states = states[len(cell.state_size):]              else:                  nested_states.append([states[0]])          return tuple(nested_states)      @property      def state_size(self):         state_size = []         for cell in self.cells:             if hasattr(cell.state_size, '__len__'):                 state_size += list(cell.state_size)             else:                 state_size.append(cell.state_size)          return tuple(state_size)         def call(self, inputs, states, constants=None, **kwargs):          nested_states = []          for cell in self.cells:             if hasattr(cell.state_size, '__len__'):                nested_states.append(states[:len(cell.state_size)])                 states = states[len(cell.state_size):]             else:                 nested_states.append([states[0]])          return tuple(nested_states)      @property      def state_size(self):         state_size = []         for cell in self.cells:
import threading  import time  import traceback  import math import weakref from tornado.concurrent import Future, is_future, chain_future, future_set_exc_info, future_add_done_callback  from tornado.log import app_log, gen_log
class TestBackend(object):          else:              assert_list_pairwise(v_list, shape=False, allclose=False, itself=True)      def test_print_tensor(self):          check_single_tensor_operation('print_tensor', (), WITH_NP)          check_single_tensor_operation('print_tensor', (2, 3), WITH_NP)         check_single_tensor_operation('print_tensor', (4, 5), WITH_NP)         check_single_tensor_operation('print_tensor', (1, 2, 3, 4), WITH_NP)      def test_elementwise_operations(self):          check_single_tensor_operation('max', (4, 2), WITH_NP)         check_single_tensor_operation('min', (1, 2), WITH_NP)         check_single_tensor_operation('print_tensor', (1, 2, 3), WITH_NP)         check_single_tensor_operation('print_tensor', (4, 5), WITH_NP)         check_single_tensor_operation('print_tensor', (2, 3), WITH_NP)         check_single_tensor_operation('print_tensor', (1, 2, 3), WITH_NP)         check_single_tensor_operation('print_tensor', (4, 5), WITH_NP)         check_single_tensor_operation('print_tensor', (2, 3), WITH_NP)         check_single_tensor_operation('print_tensor', (1, 2, 3), WITH_NP)      def test_elementwise_operations(self):          check_single_tensor_operation('max', (4, 2), WITH_NP)         check_single_tensor_operation('min', (1, 2), WITH_NP)         check_single_tensor_operation('print_tensor', (1, 2, 3), WITH_NP)         check_single_tensor_operation('print_tensor', (4, 5), WITH_NP)         check_single_tensor_operation('print_tensor', (2, 3), WITH_NP)         check_single_tensor_operation('print_tensor', (1, 2, 3), WITH_NP)         check_single_tensor_operation('print_tensor', (4, 5), WITH_NP)         check_single_tensor_operation('print_tensor', (2, 3), WITH_NP)         check_single_tensor_operation('print_tensor', (1, 2, 3), WITH_NP)         check_single_tensor_operation('print_tensor', (4, 5), WITH_NP)         check_single_tensor_operation('print_tensor', (2, 3), WITH_NP)         check_single_tensor_operation('print_tensor', (1, 2, 3), WITH_NP)      def test_elementwise_operations(self):          check_single_tensor_operation('max', (4, 2), WITH_NP)         check_single_tensor_operation('min', (1, 2), WITH_NP)         check_single_tensor_operation('print_tensor', (1, 2, 3), WITH_NP)         check_single_tensor_operation('print_tensor', (4, 5), WITH_NP)         check_single_tensor_operation('print_tensor', (2, 3), WITH_NP)         check_single_tensor_operation('print_tensor', (1, 2, 3), WITH_NP)         check_single_tensor_operation('print_tensor', (4, 5), WITH_NP)         check_single_tensor_operation('print_tensor', (2, 3), WITH_NP)      def test_elementwise_operations(self):          check_single_tensor_operation('max', (4, 2), WITH_NP)         check_single_tensor_operation('min', (1, 2), WITH_NP)         check_single_tensor_operation('print_tensor', (1, 2, 3), WITH_NP)         check_single_tensor_operation('print_tensor', (4, 5), WITH_NP)         check_single_tensor_operation('print_tensor', (2, 3), WITH_NP)         check_single_tensor_operation('print_tensor', (1, 2, 3), WITH_NP)         check_single_tensor_operation('print_tensor', (4, 5), WITH_NP)         check_single_tensor_operation('print_tensor', (2, 3), WITH_NP)         check_single_tensor_operation('print_tensor', (1, 2, 3), WITH_NP)         check_single_tensor_operation('print_tensor', (4, 5), WITH_NP)         check_single_tensor_operation('print_tensor', (2, 3), WITH_NP)         check_single_tensor_operation('print_tensor', (1, 2, 3), WITH_NP)      def test_elementwise_operations(self):          check_single_tensor_operation('max', (4, 2), WITH_NP)         check_single_tensor_operation('min', (1, 2), WITH_NP)         check_single_tensor_operation('print_tensor', (1, 2, 3), WITH_NP)         check_single_tensor_operation('print_tensor', (4, 5), WITH_NP)         check_single_tensor_operation('print_tensor', (2, 3), WITH_NP)         check_single_tensor_operation('print_tensor', (1, 2, 3), WITH_NP)         check_single_tensor_operation('print_tensor', (4, 5), WITH_NP)         check_single_tensor_operation('print_tensor', (2, 3), WITH_NP)
class _AxesBase(martist.Artist):          left, right = sorted([left, right], reverse=bool(reverse))          self._viewLim.intervalx = (left, right)         for ax in self._shared_y_axes.get_siblings(self):             ax._stale_viewlim_y = False          if auto is not None:              self._autoscaleXon = bool(auto)             ax._stale_viewlim_y = False          if self._stale_viewlim_y:              ax._stale_viewlim_y = True          if auto is not None:              self._autoscaleXon = bool(auto)             ax._stale_viewlim_y = False          if self._stale_viewlim_y:             ax._stale_viewlim_y = True          if auto is not None:              self._autoscaleXon = bool(auto)             ax._stale_viewlim_y = False          if self._stale_viewlim_y:             ax._stale_viewlim_y = True          if auto is not None:              self._autoscaleXon = bool(auto)             ax._stale_viewlim_y = False          if self._stale_viewlim_y:             ax._stale_viewlim_y = True          if auto is not None:              self._autoscaleXon = bool(auto)             ax._stale_viewlim_y = False          if self._stale_viewlim_y:             ax._stale_viewlim_y = True          if auto is not None:              self._autoscaleXon = bool(auto)             ax._stale_viewlim_y = False          if self._stale_viewlim_y:             ax._stale_viewlim_y = True          if auto is not None:              self._autoscaleXon = bool(auto)             ax._stale_viewlim_y = False          if self._stale_viewlim_y:             ax._stale_viewlim_y = True          if auto is not None:              self._autoscaleXon = bool(auto)             ax._stale_viewlim_y = False          if self._stale_viewlim_y:             ax._stale_viewlim_y = True          if auto is not None:              self._autoscaleXon = bool(auto)             ax._stale_viewlim_y = False          if self._stale_viewlim_y:             ax._stale_viewlim_y = True          if auto is not None:             self._autoscaleXon = bool(auto)             ax._stale_viewlim_y = False          if self._stale_viewlim_y:             ax._stale_viewlim_y = True          if auto is not None:             self._autoscaleXon = bool(auto)             ax._stale_viewlim_y = False          if self._stale_viewlim_y:             ax._stale_viewlim_y = True          if auto is not None:             self._autoscaleXon = bool(auto)             ax._stale_viewlim_y = False          if self._stale_viewlim_y:             ax._stale_viewlim_y = True          if auto is not None:             self._autoscaleXon = bool(auto)             ax._stale_viewlim_y = False          if self._stale_viewlim_y:             ax._stale_viewlim_y = True          if auto is not None:             self._autoscaleXon = bool(auto)             ax._stale_viewlim_y = False          if self._stale_viewlim_y:             ax._stale_viewlim_y = True          if auto is not None:             self._autoscaleXon = bool(auto)             ax._stale_viewlim_y = False          if self._stale_viewlim_y:             ax._stale_viewlim_y = True          if auto is not None:             self._autoscaleXon = bool(auto)             ax._stale_viewlim_y = False          if self._stale_viewlim_y:             ax._stale_viewlim_y = True            ax._stale_viewlim_y = False          if auto is not None:             self._autoscaleXon = bool(auto)             ax._stale_viewlim_y = False          if self._stale_viewlim_y:             ax._stale_viewlim_y = True          if auto is not None:
class YoutubeDL(object):
def test_check_mutually_exclusive_none():  def test_check_mutually_exclusive_no_params(mutually_exclusive_terms):      with pytest.raises(TypeError) as te:          check_mutually_exclusive(mutually_exclusive_terms, None)         assert "TypeError: 'NoneType' object is not iterable" in to_native(te.error)     def test_check_mutually_exclusive_none():      with pytest.raises(TypeError) as te:          check_mutually_exclusive(mutually_exclusive_terms, None)         assert "TypeError: 'NoneType' object is not iterable" in to_native(te.error)     def test_check_mutually_exclusive_none():      with pytest.raises(TypeError) as te:          check_mutually_exclusive(mutually_exclusive_terms, None)         assert "TypeError: 'NoneType' object is not iterable" in to_native(te.error)      def test_check_mutually_exclusive_none():      with pytest.raises(TypeError) as te:          check_mutually_exclusive(mutually_exclusive_terms, None)         assert "TypeError: 'NoneType' object is not iterable" in to_native(te.error)      def test_check_mutually_exclusive_none():      with pytest.raises(TypeError) as te:          check_mutually_exclusive(mutually_exclusive_terms, None)         assert "TypeError: 'NoneType' object is not iterable" in to_native(te.error)      def test_check_mutually_exclusive_none():      with pytest.raises(TypeError) as te:          check_mutually_exclusive(mutually_exclusive_terms, None)         assert "TypeError: 'NoneType' object is not iterable" in to_native(te.error)      def test_check_mutually_exclusive_none():      with pytest.raises(TypeError) as te:          check_mutually_exclusive(mutually_exclusive_terms, None)         assert "TypeError: 'NoneType' object is not iterable" in to_native(te.error)      def test_check_mutually_exclusive_none():      with pytest.raises(TypeError) as te:          check_mutually_exclusive(mutually_exclusive_terms, None)         assert "TypeError: 'NoneType' object is not iterable" in to_native(te.error)      def test_check_mutually_exclusive_none():      with pytest.raises(TypeError) as te:          check_mutually_exclusive(mutually_exclusive_terms, None)         assert "TypeError: 'NoneType' object is not iterable" in to_native(te.error)      def test_check_mutually_exclusive_none():      with pytest.raises(TypeError) as te:          check_mutually_exclusive(mutually_exclusive_terms, None)         assert "TypeError: 'NoneType' object is not iterable" in to_native(te.error)      def test_check_mutually_exclusive_none():      with pytest.raises(TypeError) as te:          check_mutually_exclusive(mutually_exclusive_terms, None)         assert "TypeError: 'NoneType' object is not iterable" in to_native(te.error)      def test_check_mutually_exclusive_none():      with pytest.raises(TypeError) as te:          check_mutually_exclusive(mutually_exclusive_terms, None)         assert "TypeError: 'NoneType' object is not iterable" in to_native(te.error)      def test_check_mutually_exclusive_none():      with pytest.raises(TypeError) as te:          check_mutually_exclusive(mutually_exclusive_terms, None)         assert "TypeError: 'NoneType' object is not iterable" in to_native(te.error)      def test_check_mutually_exclusive_none():      with pytest.raises(TypeError) as te:          check_mutually_exclusive(mutually_exclusive_terms, None)         assert "TypeError: 'NoneType' object is not iterable" in to_native(te.error)      def test_check_mutually_exclusive_none():      with pytest.raises(TypeError) as te:          check_mutually_exclusive(mutually_exclusive_terms, None)         assert "TypeError: 'NoneType' object is not iterable" in to_native(te.error)      def test_check_mutually_exclusive_none():      with pytest.raises(TypeError) as te:          check_mutually_exclusive(mutually_exclusive_terms, None)         assert "TypeError: 'NoneType' object is not iterable" in to_native(te.error)      def test_check_mutually_exclusive_none():      with pytest.raises(TypeError) as te:          check_mutually_exclusive(mutually_exclusive_terms, None)         assert "TypeError: 'NoneType' object is not iterable" in to_native(te.error)      def test_check_mutually_exclusive_none():      with pytest.raises(TypeError) as te:          check_mutually_exclusive(mutually_exclusive_terms, None)          assert "TypeError: 'NoneType' object is not iterable" in to_native(te.error)      def test_check_mutually_exclusive_none():      with pytest.raises(TypeError) as te:          check_mutually_exclusive(mutually_exclusive_terms, None)          assert "TypeError: 'NoneType' object is not iterable" in to_native(te.error)      def test_check_mutually_exclusive_none():      with pytest.raises(TypeError) as te:          check_mutually_exclusive(mutually_exclusive_terms, None)          assert "TypeError: 'NoneType' object is not iterable" in to_native(te.error)      def test_check_mutually_exclusive_none():      with pytest.raises(TypeError) as te:          check_mutually_exclusive(mutually_exclusive_terms, None)          assert "TypeError: 'NoneType'
def generate_trailers_to_omit(line: Line, line_length: int) -> Iterator[Set[Leaf  def get_future_imports(node: Node) -> Set[str]:     imports = set()      for child in node.children:          if child.type!= syms.simple_stmt:              break         imports.add(child)     return imports  def get_future_imports(node: Node) -> Set[str]:     imports = set()      for child in node.children:          if child.type!= syms.simple_stmt:              break         imports.add(child)     return imports  def get_future_imports(node: Node) -> Set[str]:     imports = set()      for child in node.children:          if child.type!= syms.simple_stmt:              break         imports.add(child)     return imports  def get_future_imports(node: Node) -> Set[str]:     imports = set()      for child in node.children:          if child.type!= syms.simple_stmt:              break         imports.add(child)     return imports  def get_future_imports(node: Node) -> Set[str]:     imports = set()      for child in node.children:          if child.type!= syms.simple_stmt:              break         imports.add(child)     return imports  def get_future_imports(node: Node) -> Set[str]:     imports = set()      for child in node.children:          if child.type!= syms.simple_stmt:              break         imports.add(child)     return imports  def get_future_imports(node: Node) -> Set[str]:     imports = set()      for child in node.children:          if child.type!= syms.simple_stmt:              break         imports.add(child)     return imports  def get_future_imports(node: Node) -> Set[str]:     imports = set()      for child in node.children:          if child.type!= syms.simple_stmt:              break         imports.add(child)     return imports  def get_future_imports(node: Node) -> Set[str]:     imports = set()      for child in node.children:          if child.type!= syms.simple_stmt:              break         imports.add(child)     return imports  def get_future_imports(node: Node) -> Set[str]:     imports = set()      for child in node.children:          if child.type!= syms.simple_stmt:              break          imports.add(child)     return imports  def get_future_imports(node: Node) -> Set[str]:     imports = set()      for child in node.children:          if child.type!= syms.simple_stmt:              break          imports.add(child)     return imports  def get_future_imports(node: Node) -> Set[str]:     imports = set()      for child in node.children:          if child.type!= syms.simple_stmt:              break          imports.add(child)     return imports  def get_future_imports(node: Node) -> Set[str]:     imports = set()      for child in node.children:          if child.type!= syms.simple_stmt:              break          imports.add(child)     return imports  def get_future_imports(node: Node) -> Set[str]:     imports = set()      for child in node.children:          if child.type!= syms.simple_stmt:              break          imports.add(child)      return imports  def get_future_imports(node: Node) -> Set[str]:     imports = set()      for child in node.children:          if child.type!= syms.simple_stmt:              break          imports.add(child)      return imports  def get_future_imports(node: Node) -> Set[str]:     imports = set()      for child in node.children:          if child.type!= syms.simple_stmt:              break          imports.add(child)      return imports  def get_future_imports(node: Node) -> Set[str]:     imports = set()      for child in node.children:          if child.type!= syms.simple_stmt:              break          imports.add(child)      return imports  def get_future_imports(node: Node) -> Set[str]:     imports = set()      for child in node.children:          if child.type!= syms.simple_stmt:              break            imports.add(child)      return imports  def get_future_imports(node: Node) -> Set[str]:     imports = set()      for child in node.children:          if child.type!= syms.simple_stmt:             break           imports.add(child)      return imports  def get_future_imports(node: Node) -> Set[str]:     imports = set()      for child in node.children:          if child.type!= syms.simple_stmt:              break           imports.add(child)      return imports  def get_future_imports(node: Node
class BusinessHourMixin(BusinessMixin):              if bd!= 0:                 skip_bd = BusinessDay(n=bd)                  if not self.next_bday.is_on_offset(other):                      prev_open = self._prev_opening_time(other)                 if bd == self.next_bday:                     break                 if not self.next_bday.is_on_offset(other):                      prev_open = self._prev_opening_time(other)                 if bd == self.next_bday:                     break                 if not self.next_bday.is_on_offset(other):                     prev_open = self._prev_opening_time(other)                 if bd == self.next_bday:                     break                 if not self.next_bday.is_on_offset(other):                     prev_open = self._prev_opening_time(other)                 if bd == self.next_bday:                     break                 if not self.next_bday.is_on_offset(other):                     prev_open = self._prev_opening_time(other)                 if bd == self.next_bday:                     break                 if not self.next_bday.is_on_offset(other):                     prev_open = self._prev_opening_time(other)                 if bd == self.next_bday:                     break                 if not self.next_bday.is_on_offset(other):                     prev_open = self._prev_opening_time(other)                 if bd == self.next_bday:                     break                 if not self.next_bday.is_on_offset(other):                     prev_open = self._prev_opening_time(other)                 if bd == self.next_bday:                     break                 if not self.next_bday.is_on_offset(other):                     prev_open = self._prev_opening_time(other)                 if bd == self.next_bday:                     break                 if not self.next_bday.is_on_offset(other):                     prev_open = self._prev_opening_time(other)                 if bd == self.next_bday:                     break                 if not self.next_bday.is_on_offset(other):                     prev_open = self._prev_opening_time(other)                 if bd == self.next_bday:                     break                 if not self.next_bday.is_on_offset(other):                     prev_open = self._prev_opening_time(other)                 if bd == self.next_bday:                     break                 if not self.next_bday.is_on_offset(other):                     prev_open = self._prev_opening_time(other)                 if bd == self.next_bday:                     break                 if not self.next_bday.is_on_offset(other):                     prev_open = self._prev_opening_time(other)                 if bd == self.next_bday:                     break                 if not self.next_bday.is_on_offset(other):                     prev_open = self._prev_opening_time(other)                 if bd == self.next_bday:                     break                if not self.next_bday.is_on_offset(other):                     prev_open = self._prev_opening_time(other)                 if bd == self.next_bday:                      break                 if not self.next
def decode_bytes(src: bytes) -> Tuple[FileContent, Encoding, NewLine]:      srcbuf = io.BytesIO(src)      encoding, lines = tokenize.detect_encoding(srcbuf.readline, newline=lines[0][-2:] else "\n"      srcbuf.seek(0)      with io.TextIOWrapper(srcbuf, encoding) as tiow:         encoding, lines = tokenize.detect_encoding(srcbuf.readline, b"\r\n" == lines[0][-2:] else "\n"      srcbuf.seek(0)      with io.TextIOWrapper(srcbuf, encoding) as tiow:         encoding, lines = tokenize.detect_encoding(srcbuf.readline, b"\n" == lines[0][-2:] else "\n"      srcbuf.seek(0)      with io.TextIOWrapper(srcbuf, encoding) as tiow:         encoding, lines = tokenize.detect_encoding(srcbuf.readline, b"\r\n" == lines[0][-2:] else "\n"      srcbuf.seek(0)      with io.TextIOWrapper(srcbuf, encoding) as tiow:         encoding, lines = tokenize.detect_encoding(srcbuf.readline, b"\n" == lines[0][-2:] else "\n"      srcbuf.seek(0)      with io.TextIOWrapper(srcbuf, encoding) as tiow:         encoding, lines = tokenize.detect_encoding(srcbuf.readline, b"\r\n" == lines[0][-2:] else "\n"      srcbuf.seek(0)      with io.TextIOWrapper(srcbuf, encoding) as tiow:         encoding, lines = tokenize.detect_encoding(srcbuf.readline, b"\n" == lines[0][-2:] else "\n"      srcbuf.seek(0)      with io.TextIOWrapper(srcbuf, encoding) as tiow:         encoding, lines = tokenize.detect_encoding(srcbuf.readline, b"\r\n" == lines[0][-2:] else "\n"      srcbuf.seek(0)      with io.TextIOWrapper(srcbuf, encoding) as tiow:         encoding, lines = tokenize.detect_encoding(srcbuf.readline, b"\n" == lines[0][-2:] else "\n"      srcbuf.seek(0)      with io.TextIOWrapper(srcbuf, encoding) as tiow:         encoding, lines = tokenize.detect_encoding(srcbuf.readline, b"\n" == lines[0][-2:] else "\n"      srcbuf.seek(0)      with io.TextIOWrapper(srcbuf, encoding) as tiow:         encoding, lines = tokenize.detect_encoding(srcbuf.readline, b"\n" == lines[0][-2:] else "\n"      srcbuf.seek(0)      with io.TextIOWrapper(srcbuf, encoding) as tiow:         encoding, lines = tokenize.detect_encoding(srcbuf.readline, b"\n" == lines[0][-2:] else "\n"      srcbuf.seek(0)      with io.TextIOWrapper(srcbuf, encoding) as tiow:         encoding, lines = tokenize.detect_encoding(srcbuf.readline, b"\n" == lines[0][-2:] else "\n"      srcbuf.seek(0)      with io.TextIOWrapper(srcbuf, encoding) as tiow:         encoding, lines = tokenize.detect_encoding(srcbuf.readline, b"\n" == lines[0][-2:] else "\n"      srcbuf.seek(0)      with io.TextIOWrapper(srcbuf, encoding) as tiow:         encoding, lines = tokenize.detect_encoding(srcbuf.readline, b"\n" == lines[0][-2:] else "\n"      srcbuf.seek(0)      with io.TextIOWrapper(srcbuf, encoding) as tiow:         encoding, lines = tokenize.detect_encoding(srcbuf.readline, b"\n" == lines[0][-2:] else "\n"      srcbuf.seek(0)      with io.TextIOWrapper(srcbuf, encoding) as tiow:         encoding, lines = tokenize.detect_encoding(srcbuf.readline, b"\n" == lines[0][-2:] else "\n"      srcbuf.seek(0)      with io.TextIOWrapper(srcbuf, encoding) as tiow:         encoding, lines = tokenize.detect_encoding(srcbuf.readline, b"\n" == lines[0][-2:] else "\n"      srcbuf.seek(0)      with io.TextIOWrapper(srcbuf, encoding) as tiow:         encoding, lines = tokenize.detect_encoding(srcbuf.readline, b"\n" == lines[0][-2:] else "\n"      srcbuf.seek(0)      with io.TextIOWrapper(srcbuf, encoding) as tiow:         encoding, lines = tokenize.detect_encoding(srcbuf.readline, b"\n" == lines[0][-2:] else "\n"      srcbuf.seek(0)      with io.TextIOWrapper(srcbuf, encoding) as tiow:         encoding, lines = tokenize.detect_encoding(srcbuf.readline, b"\n" == lines[0][-2:] else "\n"      srcbuf.seek(0)      with io.TextIOWrapper(srcbuf, encoding) as tiow:         encoding, lines = tokenize.detect_encoding(srcbuf.readline, b"\n" == lines[0][-2:] else "\n"      srcbuf.seek(0)      with io.TextIOWrapper(srcbuf, encoding) as tiow:        encoding, lines = tokenize.detect_encoding(srcbuf.readline, b"\n" == lines[0][-2:] else "\n"      srcbuf.seek(0)      with io.TextIOWrapper(srcbuf, encoding) as tiow:         encoding, lines = tokenize.detect_encoding(srcbuf.readline, b"\n" == lines[0][-2:] else "\n"      srcbuf.seek(0)
class CannotSplit(Exception):     It holds the number of bytes of the prefix consumed before the format     control comment appeared.         unformatted_prefix = leaf.prefix[: self.consumed]         return Leaf(token.NEWLINE, unformatted_prefix)      class FormatOn(FormatError):         unformatted_prefix = leaf.prefix[: self.consumed]         return Leaf(token.COMMENT, unformatted_prefix)      class WriteBack(Enum):         NO = 0         YES = 1
class Language(object):              kwargs = component_cfg.get(name, {})              kwargs.setdefault("batch_size", batch_size)              if not hasattr(pipe, "pipe"):                 docs = _pipe(pipe, docs, kwargs)              else:                  docs = pipe.pipe(docs, **kwargs)          for doc, Gold in zip(docs, Golds):             if isinstance(doc, Node):                  continue
class Series(base.IndexOpsMixin, generic.NDFrame):                  indexer = self.index.get_indexer_for(key)                  return self.iloc[indexer]              else:                 return self._get_values(key)         elif key in self.iloc:             return self.iloc[key]          else:             return self._get_values(key)          if isinstance(key, (list, tuple)):              return self._iloc[key]          else:             return self._get_values(key)          if isinstance(key, (list, tuple)):              return self._iloc[key]          else:             return self._get_values(key)          if isinstance(key, (list, tuple)):              return self._iloc[key]          else:             return self._get_values(key)          if isinstance(key, (list, tuple)):              return self._iloc[key]          else:             return self._get_values(key)          if isinstance(key, (list, tuple)):              return self._iloc[key]          else:             return self._get_values(key)          if isinstance(key, (list, tuple)):              return self._iloc[key]          else:             return self._get_values(key)          if isinstance(key, (list, tuple)):              return self._iloc[key]          else:             return self._get_values(key)          if isinstance(key, (list, tuple)):              return self._iloc[key]          else:             return self._get_values(key)          if isinstance(key, (list, tuple)):              return self._iloc[key]          else:             return self._get_values(key)          if isinstance(key, (list, tuple)):              return self._iloc[key]          else:             return self._get_values(key)          if isinstance(key, (list, tuple)):              return self._iloc[key]          else:             return self._get_values(key)          if isinstance(key, (list, tuple)):              return self._iloc[key]          else:             return self._get_values(key)          if isinstance(key, (list, tuple)):              return self._iloc[key]          else:             return self._get_values(key)          if isinstance(key, (list, tuple)):              return self._iloc[key]          else:             return self._get_values(key)          if isinstance(key, (list, tuple)):              return self._iloc[key]             return self._iloc[key]          else:             return self._get_values(key)          if isinstance(key, (list, tuple)):              return self._iloc[key]             return self._iloc[key]          else:             return self._get_values(key)          if isinstance(key, (list, tuple)):              return self._iloc[key]             return self._iloc[key]          else:             return self._get_values(key)          if isinstance(key, (list, tuple)):              return self._iloc[key]             return self._iloc[key]          else:             return self._get_values(key)          if isinstance(key, (list, tuple)):              return self._iloc[key]             return self._iloc[key]          else:             return self._get_values(key)          if isinstance(key, (list, tuple)):              return self._iloc[key]             return self._iloc[key]          else:             return self._get_values(key)          if isinstance(key, (list, tuple)):             return self._iloc[key]             return self._iloc[key]             return self._iloc[key]          else:             return self._get_values(key)          if isinstance(key
def conv_input_length(output_length, filter_size, padding, stride):      return (output_length - 1) * stride - 2 * pad + filter_size  def deconv_length(dim_size, stride_size, kernel_size, padding, output_padding):     if dim_size == 1:         return output_padding      return (output_length - 1) * stride - 2 * pad + filter_size  def conv_input_length(output_length, filter_size, padding, stride):      return (output_length - 1) * stride - 2 * pad + filter_size  def deconv_length(dim_size, stride_size, kernel_size, padding, output_padding):      return (output_length - 1) * stride - 2 * pad + filter_size  def conv_input_length(output_length, filter_size, padding, stride):      return (output_length - 1) * stride - 2 * pad + filter_size  def deconv_length(dim_size, stride_size, kernel_size, padding, output_padding):      return (output_length - 1) * stride - 2 * pad + filter_size  def conv_input_length(output_length, filter_size, padding, stride):      return (output_length - 1) * stride - 2 * pad + filter_size  def deconv_length(dim_size, stride_size, kernel_size, padding, output_padding):      return (output_length - 1) * stride - 2 * pad + filter_size  def conv_input_length(output_length, filter_size, padding, stride):      return (output_length - 1) * stride - 2 * pad + filter_size  def deconv_length(dim_size, stride_size, kernel_size, padding, output_padding):      return (output_length - 1) * stride - 2 * pad + filter_size  def conv_input_length(output_length, filter_size, padding, stride):      return (output_length - 1) * stride - 2 * pad + filter_size  def deconv_length(dim_size, stride_size, kernel_size, padding, output_padding):      return (output_length - 1) * stride - 2 * pad + filter_size  def conv_input_length(output_length, filter_size, padding, stride):      return (output_length - 1) * stride - 2 * pad + filter_size  def deconv_length(dim_size, stride_size, kernel_size, padding, output_padding):      return (output_length - 1) * stride - 2 * pad + filter_size  def conv_input_length(output_length, filter_size, padding, stride):      return (output_length - 1) * stride - 2 * pad + filter_size  def deconv_length(dim_size, stride_size, kernel_size, padding, output_padding):      return (output_length - 1) * stride - 2 * pad + filter_size  def conv_input_length(output_length, filter_size, padding, stride):      return (output_length - 1) * stride - 2 * pad + filter_size  def deconv_length(dim_size, stride_size, kernel_size, padding, output_padding):      return (output_length - 1) * stride - 2 * pad + filter_size  def conv_input_length(output_length, filter_size, padding, stride):      return (output_length - 1) * stride - 2 * pad + filter_size  def deconv_length(dim_size, stride_size, kernel_size, padding, output_padding):      return (output_length - 1) * stride - 2 * pad + filter_size  def conv_input_length(output_length, filter_size, padding, stride):      return (output_length - 1) * stride - 2 * pad + filter_size  def deconv_length(dim_size, stride_size, kernel_size, padding, output_padding):      return (output_length - 1) * stride - 2 * pad + filter_size  def conv_input_length(output_length, filter_size, padding, stride):      return (output_length - 1) * stride - 2 * pad + filter_size  def deconv_length(dim_size, stride_size, kernel_size, padding, output_padding):      return (output_length - 1) * stride - 2 * pad + filter_size  def conv_input_length(output_length, filter_size, padding, stride):      return (output_length - 1) * stride - 2 * pad + filter_size  def deconv_length(dim_size, stride_size, kernel_size, padding, output_padding):      return (output_length - 1) * stride - 2 * pad + filter_size  def conv_input_length(output_length, filter_size, padding, stride):      return (output_length - 1) * stride - 2 * pad + filter_size  def deconv_length(dim_size, stride_size, kernel_size, padding, output_padding):      return (output_length - 1) * stride - 2 * pad + filter_size  def conv_input_length(output_length, filter_size, padding, stride):      return (output_length - 1) * stride - 2 * pad + filter_size  def deconv_length(dim_size, stride_size, kernel_size, padding, output_padding):      return (output_length - 1) * stride - 2 * pad + filter_size  def conv_input_length(output_length, filter_size, padding, stride):      return (output_length - 1) * stride - 2 * pad + filter_size  def deconv_length(dim_size, stride_size, kernel_size, padding, output_padding):      return (output_length - 1) * stride - 2 * pad + filter_size  def conv_input_length(output_length, filter_size, padding, stride):      return (output_length - 1) * stride - 2 * pad + filter_size  def deconv_length(dim_size, stride_size, kernel_size, padding, output_padding):      return (output_length - 1) * stride - 2 * pad + filter_size  def conv_input_length(output_length, filter_size, padding, stride):      return (output_length - 1) * stride - 2 * pad + filter_size  def deconv_length(dim_size, stride_size, kernel_size, padding, output_padding):      return (output_length - 1) * stride - 2 * pad + filter_size  def conv_input_length(output_length, filter_size, padding, stride):      return (output_length - 1) * stride - 2 * pad + filter_size  def deconv_length(dim_size, stride_size, kernel_size, padding, output_padding):      return (output_length - 1) * stride - 2 * pad + filter_size  def conv_input_length(output_length, filter_size, padding, stride):      return (output_length - 1) * stride - 2 * pad + filter_size  def deconv_length(dim_size, stride_size, kernel_size, padding, output_padding):      return (output_length - 1) * stride - 2 * pad + filter_size  def conv_input_length(output_length, filter_size, padding, stride):      return (output_length - 1) * stride - 2 * pad + filter_size  def deconv_length(dim_size, stride_size, kernel_size, padding, output_padding):      return (output_length - 1) * stride - 2 * pad + filter_size  def conv_input_length(output_length, filter_size, padding, stride):      return (output_length - 1) * stride - 2 * pad + filter_size  def decon
class APIRouter(routing.Router):          response_model_by_alias: bool = True,          response_model_skip_defaults: bool = None,          response_model_exclude_unset: bool = False,         response_model_exclude_defaults: bool = False,         response_model_exclude_none: bool = False,          include_in_schema: bool = True,          response_class: Type[Response] = None,          name: str = None,         response_model_by_alias: bool = True,          response_model_skip_defaults: bool = None,          response_model_exclude_unset: bool = False,         response_model_exclude_defaults: bool = False,         response_model_exclude_none: bool = False,          include_in_schema: bool = True,          response_class: Type[Response] = None,          name: str = None,         response_model_by_alias: bool = True,          response_model_skip_defaults: bool = None,          response_model_exclude_unset: bool = False,          response_model_exclude_defaults: bool = False,          response_model_exclude_none: bool = False,          response_model_exclude_defaults_none: bool = False,          include_in_schema: bool = True,          response_class: Type[Response] = None,          name: str = None,         response_model_by_alias: bool = True,          response_model_skip_defaults: bool = None,          response_model_exclude_unset: bool = False,          response_model_exclude_defaults: bool = False,          response_model_exclude_none: bool = False,          response_model_exclude_defaults_none: bool = False,          include_in_schema: bool = True,          response_class: Type[Response] = None,          name: str = None,         response_model_by_alias: bool = True,          response_model_skip_defaults: bool = None,          response_model_exclude_unset: bool = False,          response_model_exclude_defaults: bool = False,          response_model_exclude_none: bool = False,          response_model_exclude_defaults_none: bool = False,          include_in_schema: bool = True,          response_class: Type[Response] = None,          name: str = None,         response_model_by_alias: bool = True,          response_model_skip_defaults: bool = None,          response_model_exclude_unset: bool = False,          response_model_exclude_defaults: bool = False,          response_model_exclude_none: bool = False,          response_model_exclude_defaults_none: bool = False,          include_in_schema: bool = True,          response_class: Type[Response] = None,          name: str = None,          response_model_by_alias: bool = True,          response_model_skip_defaults: bool = None,          response_model_exclude_unset: bool = False,          response_model_exclude_defaults: bool = False,          response_model_exclude_none: bool = False,          response_model_exclude_defaults_none: bool = False,          include_in_schema: bool = True,          response_class: Type[Response] = None,          name: str = None,          response_model_by_alias: bool = True,          response_model_skip_defaults: bool = None,          response_model_exclude_unset: bool = False,          response_model_exclude_defaults: bool = False,          response_model_exclude_none: bool = False,          response_model_exclude_defaults_none: bool = False,          include_in_schema: bool = True,          response_class: Type[Response] = None,          name: str = None,          response_model_by_alias: bool = True,          response_model_skip_defaults: bool = None,          response_model_exclude_unset: bool = False,           response_model_exclude_defaults: bool = False,           response_model_exclude_none: bool = False,            response_model_exclude_defaults_none: bool = False,             response_model_by_alias: bool = True,              response_model_skip_defaults: bool = None,              response_model_exclude_unset: bool = False,              response_model_exclude_defaults: bool = False,              response_model_exclude_none: bool = False,              response_model_exclude_defaults: bool = False,              response_model_exclude_none: bool = False,              response_model_exclude_defaults_none: bool = False,              response_model_by_alias: bool = True,               response_model_skip_defaults: bool = None,               response_model_exclude_unset: bool = False,
def _get_collection_info(dep_map, existing_collections, collection, requirement,      existing = [c for c in existing_collections if to_text(c) == to_text(collection_info)]      if existing and not collection_info.force:         existing[0].add_requirement(to_text(collection_info), requirement)          collection_info = existing[0]      dep_map[to_text(collection_info)] = collection_info      if existing and not collection_info.force:         existing[1].add_requirement(to_text(collection_info), requirement)          collection_info = existing[1]      dep_map[to_text(collection_info)] = collection_info      if existing and not collection_info.force:         existing[2].add_requirement(to_text(collection_info), requirement)          collection_info = existing[2]      dep_map[to_text(collection_info)] = collection_info      if existing and not collection_info.force:         existing[3].add_requirement(to_text(collection_info), requirement)          collection_info = existing[3]      dep_map[to_text(collection_info)] = collection_info      if existing and not collection_info.force:         existing[4].add_requirement(to_text(collection_info), requirement)          collection_info = existing[4]      dep_map[to_text(collection_info)] = collection_info      if existing and not collection_info.force:         existing[5].add_requirement(to_text(collection_info), requirement)          collection_info = existing[5]      dep_map[to_text(collection_info)] = collection_info      if existing and not collection_info.force:         existing[6].add_requirement(to_text(collection_info), requirement)          collection_info = existing[6]      dep_map[to_text(collection_info)] = collection_info      if existing and not collection_info.force:         existing[7].add_requirement(to_text(collection_info), requirement)          collection_info = existing[7]      dep_map[to_text(collection_info)] = collection_info      if existing and not collection_info.force:         existing[8].add_requirement(to_text(collection_info), requirement)          collection_info = existing[8]      dep_map[to_text(collection_info)] = collection_info      if existing and not collection_info.force:         existing[9].add_requirement(to_text(collection_info), requirement)          collection_info = existing[9]      dep_map[to_text(collection_info)] = collection_info      if existing and not collection_info.force:         existing[10].add_requirement(to_text(collection_info), requirement)          collection_info = existing[10]      dep_map[to_text(collection_info)] = collection_info      if existing and not collection_info.force:         existing[11].add_requirement(to_text(collection_info), requirement)          collection_info = existing[11]      dep_map[to_text(collection_info)] = collection_info      if existing and not collection_info.force:         existing[12].add_requirement(to_text(collection_info), requirement)          collection_info = existing[12]      dep_map[to_text(collection_info)] = collection_info      if existing and not collection_info.force:         existing[13].add_requirement(to_text(collection_info), requirement)          collection_info = existing[13]      dep_map[to_text(collection_info)] = collection_info      if existing and not collection_info.force:         existing[14].add_requirement(to_text(collection_info), requirement)          collection_info = existing[14]      dep_map[to_text(collection_info)] = collection_info      if existing and not collection_info.force:         existing[15].add_requirement(to_text(collection_info), requirement)          collection_info = existing[15]      dep_map[to_text(collection_info)] = collection_info      if existing and not collection_info.force:         existing[16].add_requirement(to_text(collection_info), requirement)          collection_info = existing[16]      dep_map[to_text(collection_info)] = collection_info      if existing and not collection_info.force:         existing[17].add_requirement(to_text(collection_info), requirement)          collection_info = existing[17]          dep_map[to_text(collection_info)] = collection_info          if existing and not collection_info.force:             existing[18].add_requirement(to_text(collection_info), requirement)             collection_info = existing[18]             dep_map[to_text(collection_info)] = collection_info          if existing and not collection_info.force:             existing[19].add_requirement(to_text(collection_info), requirement)             collection_info = existing[19]             dep_map[to_text(collection_info)] = collection_info          if existing and not collection_info.force:             existing[20].add_requirement(to_text(collection_info), requirement)             collection_info = existing[20]             dep_map[to_text(collection_info)] = collection_info          if existing and not collection_info.force:             existing[21].add_requirement(to_text(collection_info), requirement)              collection_info = existing[21]              dep_map[to_text(collection_info)] = collection_info              if existing and not collection_info.
def in_top_k(predictions, targets, k):  def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),                     padding='valid', data_format=None, dilation_rate=(1, 1)):      data_format = normalize_data_format(data_format)      x = _preprocess_conv2d_input(x, data_format)
class Conv2DTranspose(Conv2D):              output_shape,              self.strides,              padding=self.padding,             data_format=self.data_format,             dilation=dilation_rate)          if self.use_bias:              outputs = K.bias_add(                  is buggy              )          if self.dilation_rate is not None:              dilation = K.dilation_rate(dilation_rate)          if self.use_bias:              outputs = K.bias_add(                  is buggy              )          if self.dilation_rate is not None:              dilation = K.dilation_rate(dilation_rate)          if self.use_bias:              outputs = K.bias_add(                  is buggy              )          if self.dilation_rate is not None:              dilation = K.dilation_rate(dilation_rate)          if self.use_bias:              outputs = K.bias_add(                  is buggy              )          if self.dilation_rate is not None:              dilation = K.dilation_rate(dilation_rate)          if self.use_bias:              outputs = K.bias_add(                  is buggy              )          if self.dilation_rate is not None:              dilation = K.dilation_rate(dilation_rate)          if self.use_bias:              outputs = K.bias_add(                 is buggy              )          if self.dilation_rate is not None:              dilation = K.dilation_rate(dilation_rate)          if self.use_bias:              outputs = K.bias_add(                 is buggy              )          if self.dilation_rate is not None:              dilation = K.dilation_rate(dilation_rate)          if self.use_bias:              outputs = K.bias_add(                 is buggy              )          if self.dilation_rate is not None:              dilation = K.dilation_rate(dilation_rate)          if self.use_bias:              outputs = K.bias_add(                 is buggy              )          if self.dilation_rate is not None:              dilation = K.dilation_rate(dilation_rate)          if self.use_bias:              outputs = K.bias_add(                 is buggy              )          if self.dilation_rate is not None:              dilation = K.dilation_rate(dilation_rate)          if self.use_bias:              outputs = K.bias_add(                 is buggy              )           if self.dilation_rate is not None:              dilation = K.dilation_rate(dilation_rate)          if self.use_bias:              outputs = K.bias_add(                 is buggy              )             if self.dilation_rate is not None:                 dilation = K.dilation_rate(dilation_rate)          if self.use_bias:               outputs = K.bias_add(                 is buggy                 )             if self.dilation_rate is not None:                 dilation = K.dilation_rate(dilation_rate)          if self.use_bias:               outputs = K.bias_add(                 is buggy                )             if self.dilation_rate is not None:                 dilation = K.dilation_rate(dilation_rate)          if self.use_bias:
class BlockManager(PandasObject):                          convert=convert,                         regex=regex,                      )                    if m.any():                         new_rb = _extend_blocks(result, new_rb)                      else:                         new_rb.append(b)                 if m.any():                     new_rb = _extend_blocks(result, new_rb)                  else:                     new_rb.append(b)             if m.any():                 new_rb = _extend_blocks(result, new_rb)              else:                 new_rb.append(b)          if m.any():             new_rb = _extend_blocks(result, new_rb)             else:              new_rb.append(b)          if m.any():             new_rb = _extend_blocks(result, new_rb)             else:              new_rb.append(b)          if m.any():             new_rb = _extend_blocks(result, new_rb)             else:              new_rb.append(b)          if m.any():             new_rb = _extend_blocks(result, new_rb)             else:             new_rb.append(b)          if m.any():             new_rb = _extend_blocks(result, new_rb)             else:             new_rb.append(b)          if m.any():             new_rb = _extend_blocks(result, new_rb)             else:             new_rb.append(b)          if m.any():             new_rb = _extend_blocks(result, new_rb)             else:             new_rb.append(b)          if m.any():             new_rb = _extend_blocks(result, new_rb)             else:             new_rb.append(b)          if m.any():             new_rb = _extend_blocks(result, new_rb)             else:             new_rb.append(b)          if m.any():             new_rb = _extend_blocks(result, new_rb)             else:             new_rb.append(b)          if m.any():             new_rb = _extend_blocks(result, new_rb)             else:             new_rb.append(b)          if m.any():             new_rb = _extend_blocks(result, new_rb)             else:             new_rb.append(b)          if m.any():             new_rb = _extend_blocks(result, new_rb)             else:             new_rb.append(b)          if m.any():             new_rb = _extend_blocks(result, new_rb)             else:             new_rb.append(b)          if m.any():             new_rb = _extend_blocks(result, new_rb)             else:             new_rb.append(b)          if m.any():             new_rb = _extend_blocks(result, new_rb)             else:             new_rb.append(b)          if m.any():             new_rb = _extend_blocks(result, new_rb)             else:             new_rb.append(b)          if m.any():             new_rb = _extend_blocks(result, new_rb)             else:             new_rb.append(b)          if m.any():             new_rb = _extend_blocks(result, new_rb)              else:
import logging  from six.moves.urllib.parse import urljoin  from scrapy.http import HtmlResponse  from scrapy.utils.response import get_meta_refresh from scrapy.utils.python import to_bytes, to_native_str, to_unicode  from scrapy.exceptions import IgnoreRequest, NotConfigured  logger = logging.getLogger(__name__)
fig, ax = plt.subplots(2, 1)  pcm = ax[0].pcolormesh(X, Y, Z,                        norm=colors.SymLogNorm(linthresh=0.03, linscale=0.03,                                              vmin=-1.0, vmax=1.0, base=10),                         cmap='RdBu_r')  fig.colorbar(pcm, ax=ax[0], extend='both')
def crosstab(      from pandas import DataFrame      df = DataFrame(data, index=common_idx)      if values is None:          df["__dummy__"] = 0          kwargs = {"aggfunc": len, "fill_value": 0}         aggfunc = lambda x: x.agg(lambda y: y)         fill_value = 0         if values is None:             fill_value = 1          kwargs = {"aggfunc": len, "fill_value": fill_value}
class Model(Container):              validation_steps: Only relevant if `validation_data`                  is a generator. Total number of steps (batches of samples)                  to yield from `generator` before stopping.                 Optional for `Sequence`: if unspecified, will use                 the `len(generator)` as a number of steps.              class_weight: Dictionary mapping class indices to a weight                  for the class.              max_queue_size: Integer. Maximum size for the generator queue.                  Optional for `Sequence`: if unspecified, will use                 the `len(generator)` as a number of steps.
single_quoted = (
def na_value_for_dtype(dtype, compat: bool = True):      if is_extension_array_dtype(dtype):          return dtype.na_value     if is_bool_dtype(dtype) and is_extension_array_dtype(dtype):         return dtype.na_value     if is_datetime64_dtype(dtype) or is_datetime64tz_dtype(dtype) or is_timedelta64_dtype(dtype) or is_period_dtype(dtype):          return NaT      elif is_float_dtype(dtype):          return np.nan
class Categorical(ExtensionArray, PandasObject):              if dtype == self.dtype:                  return self              return self._set_dtype(dtype)         elif is_extension_array_dtype(dtype) and is_integer_dtype(dtype):             msg = "Cannot convert float NaN to integer"              raise ValueError(msg)          if is_extension_array_dtype(dtype) and is_integer_dtype(dtype):             if self.isna().any():                 msg = "Cannot convert float NaN to integer"                 raise ValueError(msg)          return self._set_dtype(dtype)          if is_integer_dtype(dtype) and self.isna().any():              msg = "Cannot convert float NaN to integer"              raise ValueError(msg)          return self._set_dtype(dtype)          if is_extension_array_dtype(dtype) and is_integer_dtype(dtype):             if self.isna().any():                 msg = "Cannot convert float NaN to integer"                 raise ValueError(msg)          return self._set_dtype(dtype)          if is_extension_array_dtype(dtype) and is_integer_dtype(dtype):             if self.isna().any():                 msg = "Cannot convert float NaN to integer"                 raise ValueError(msg)          return self._set_dtype(dtype)          if is_extension_array_dtype(dtype) and is_integer_dtype(dtype):             if self.isna().any():                 msg = "Cannot convert float NaN to integer"                 raise ValueError(msg)          return self._set_dtype(dtype)          if is_extension_array_dtype(dtype) and is_integer_dtype(dtype):             if self.isna().any():                 msg = "Cannot convert float NaN to integer"                 raise ValueError(msg)          return self._set_dtype(dtype)          if is_extension_array_dtype(dtype) and is_integer_dtype(dtype):             if self.isna().any():                 msg = "Cannot convert float NaN to integer"                 raise ValueError(msg)          return self._set_dtype(dtype)          if is_extension_array_dtype(dtype) and is_integer_dtype(dtype):             if self.isna().any():                 msg = "Cannot convert float NaN to integer"                 raise ValueError(msg)          return self._set_dtype(dtype)          if is_extension_array_dtype(dtype) and is_integer_dtype(dtype):             if self.isna().any():                 msg = "Cannot convert float NaN to integer"                 raise ValueError(msg)          return self._set_dtype(dtype)          if is_extension_array_dtype(dtype) and is_integer_dtype(dtype):             if self.isna().any():                 msg = "Cannot convert float NaN to integer"                  raise ValueError(msg)          return self._set_dtype(dtype)          if is_extension_array_dtype(dtype) and is_integer_dtype(dtype):             if self.isna().any():                 msg = "Cannot convert float NaN to integer"                  raise ValueError(msg)          return self._set_dtype(dtype)          if is_extension_array_dtype(dtype) and is_integer_dtype(dtype):             if self.isna().any():                 msg = "Cannot convert float NaN to integer"                  raise ValueError(msg)          return self._set_dtype(dtype)          if is_extension_array_dtype(dtype) and is_integer_dtype(dtype):             if self.isna().any():                 msg = "Cannot convert float NaN to integer"                  raise ValueError(msg)             return self._set_dtype(dtype)          if is_extension_array_dtype(dtype) and is_integer_dtype(dtype):             if self.isna().any():                msg = "Cannot convert float NaN to integer"                  raise ValueError(msg)             return self._set_dtype(dtype)          if is_extension_array_dtype(dtype) and is_
class Fish(Generic):      def info(self):         proc = Popen(['fish', '-c', 'echo $FISH_VERSION'],                      stdout=PIPE, stderr=DEVNULL)         version = proc.stdout.read().decode('utf-8').strip()          return u'Fish Shell {}'.format(version)      def put_to_history(self, command):         if command in self.history:             return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return          return
def _unstack_multiple(data, clocs, fill_value=None):              result = data              for i in range(len(clocs)):                  val = clocs[i]                 result = result.unstack(val)                  clocs = [v if i > v else v - 1 for v in clocs]              return result              clocs = [v if i > v else v - 1 for v in clocs]          return result              clocs = [v if i > v else v - 1 for v in clocs]          return clocs              clocs = [v if i > v else v - 1 for v in clocs]          return clocs              clocs = [v if i > v else v - 1 for v in clocs]          return clocs              clocs = [v if i > v else v - 1 for v in clocs]          return clocs              clocs = [v if i > v else v - 1 for v in clocs]          return clocs              clocs = [v if i > v else v - 1 for v in clocs]          return clocs              clocs = [v if i > v else v - 1 for v in clocs]          return clocs              clocs = [v if i > v else v - 1 for v in clocs]          return clocs              clocs = [v if i > v else v - 1 for v in clocs]          return clocs              clocs = [v if i > v else v - 1 for v in clocs]          return clocs              clocs = [v if i > v else v - 1 for v in clocs]          return clocs              clocs = [v if i > v else v - 1 for v in clocs]          return clocs              clocs = [v if i > v else v - 1 for v in clocs]          return clocs              clocs = [v if i > v else v - 1 for v in clocs]          return clocs              clocs = [v if i > v else v - 1 for v in clocs]          return clocs              clocs = [v if i > v else v - 1 for v in clocs]          return clocs              clocs = [v if i > v else v - 1 for v in clocs]          return clocs              clocs = [v if i > v else v - 1 for v in clocs]          return clocs              clocs = [v if i > v else v - 1 for v in clocs]          return clocs              clocs = [v if i > v else v - 1 for v in clocs]          return clocs              clocs = [v if i > v else v - 1 for v in clocs]          return clocs              clocs = [v if i > v else v - 1 for v in clocs]          return clocs              clocs = [v if i > v else v - 1 for v in clocs]          return clocs              clocs = [v if i > v else v - 1 for v in clocs]          return clocs              clocs = [v if i > v else v - 1 for v in clocs]          return clocs              clocs = [v if i > v else v - 1 for v in clocs]          return clocs              clocs = [v if i > v else v - 1 for v in clocs]          return clocs              clocs = [v if i > v else v - 1 for v in clocs]          return clocs              clocs = [v if i > v else v - 1 for v in clocs]          return clocs              clocs = [v if i > v else v - 1 for v in clocs]          return clocs              clocs = [v if i > v else v - 1 for v in clocs]          return clocs              clocs = [v if i > v else v - 1 for v in clocs]          return clocs              clocs = [v if i > v else v - 1 for v in clocs]          return clocs              clocs = [v if i > v else v - 1 for v in clocs]          return clocs              clocs = [v if i > v else v - 1 for v in clocs]          return clocs               clocs = [v if i > v else v - 1 for
class BaseGrouper:              if mask.any():                  result = result.astype("float64")                  result[mask] = np.nan         if kind == "aggregate" and self._filter_empty_groups and not counts.all():             if result.ndim == 0:                 result[0] = np.nan             if kind == "aggregate" and self._filter_empty_groups and not counts.all():                 assert result.ndim!= 2          if kind == "aggregate" and self._filter_empty_groups and not counts.all():              assert result.ndim!= 3          if kind == "aggregate" and self._filter_empty_groups and not counts.all():              assert result.ndim!= 4          if kind == "aggregate" and self._filter_empty_groups and not counts.all():              assert result.ndim!= 5          if kind == "aggregate" and self._filter_empty_groups and not counts.all():              assert result.ndim!= 6          if kind == "aggregate" and self._filter_empty_groups and not counts.all():              assert result.ndim!= 7          if kind == "aggregate" and self._filter_empty_groups and not counts.all():              assert result.ndim!= 8          if kind == "aggregate" and self._filter_empty_groups and not counts.all():              assert result.ndim!= 9          if kind == "aggregate" and self._filter_empty_groups and not counts.all():              assert result.ndim!= 10          if kind == "aggregate" and self._filter_empty_groups and not counts.all():              assert result.ndim!= 11          if kind == "aggregate" and self._filter_empty_groups and not counts.all():              assert result.ndim!= 12          if kind == "aggregate" and self._filter_empty_groups and not counts.all():              assert result.ndim!= 13          if kind == "aggregate" and self._filter_empty_groups and not counts.all():              assert result.ndim!= 14          if kind == "aggregate" and self._filter_empty_groups and not counts.all():              assert result.ndim!= 15          if kind == "aggregate" and self._filter_empty_groups and not counts.all():              assert result.ndim!= 16          if kind == "aggregate" and self._filter_empty_groups and not counts.all():             assert result.ndim!= 17          if kind == "aggregate" and self._filter_empty_groups and not counts.all():             assert result.ndim!= 18          if kind == "aggregate" and self._filter_empty_groups and not counts.all():             assert result.ndim!= 19          if kind == "aggregate" and self._filter_empty_groups and not counts.all():             assert result.ndim!= 20          if kind == "aggregate" and self._filter_empty_groups and not counts.all():             assert result.ndim!= 21          if kind == "aggregate" and self._filter_empty_groups and not counts.all():             assert result.ndim!= 22          if kind == "aggregate" and self._filter_empty_groups and not counts.all():             assert result.ndim!= 23          if kind == "aggregate" and self._filter_empty_groups and not counts.all():             assert result.ndim!= 24          if kind == "aggregate" and self._filter_empty_groups and not counts.all():             assert result.ndim!= 25          if kind == "aggregate" and self._filter_empty_groups and not counts.all():             assert result.ndim!= 26          if kind == "aggregate" and self._filter_empty_groups and not counts.all():             assert result.ndim!= 27          if kind == "aggregate" and self._filter_empty_groups and not counts.all():             assert result.ndim!= 28          if kind == "aggregate" and self._filter_empty_groups and not counts.all():             assert result.ndim!= 29          if kind == "aggregate" and self._filter_empty_groups and not counts.all():             assert result.ndim!= 30          if kind == "aggregate" and self._filter_empty_groups and not counts.all():             assert result.ndim!= 31          if kind == "aggregate" and self._filter_empty_groups and not counts.all():             assert result.ndim!= 32          if kind == "aggregate" and self._filter_empty_groups and not counts.all():             assert result.ndim!= 33          if kind == "aggregate" and self._filter_empty_groups and not counts.all():             assert result.ndim!= 34          if kind == "aggregate" and self._filter_empty_groups and not counts.all():             assert result.ndim!= 35          if kind == "aggregate" and self._filter_empty_groups and not counts.all():             assert result.ndim!= 36          if kind == "aggregate" and self._filter_empty_groups and not counts.all():
class scheduler(Config):      visualization_graph = parameter.Parameter(default="svg", config_path=dict(section='scheduler', name='visualization-graph'))         def fix_time(x):         if x is not None:             return         if x is None:             return         if x is not None:             return         if x is None:             return         if x is not None:             return         if x is not None:             return         if x is not None:             return         if x is not None:             return         if x is not None:             return         if x is not None:             return         if x is not None:             return         if x is not None:             return         if x is not None:             return         if x is not None:             return         if x is not None:             return         if x is not None:             return         if x is not None:             return         if x is not None:             return         if x is not None:             return         if x is not None:             return         if x is not None:             return         if x is not None:             return         if x is not None:             return         if x is not None:             return         if x is not None:             return         if x is not None:             return         if x is not None:             return         if x is not None:             return         if x is not None:             return         if x is not None:             return         if x is not None:             return         if x is not None:             return         if x is not None:             return         if x is not None:             return         if x is not None:             return         if x is not None:             return         if x is not None:             return         if x is not None:             return         if x is not None:             return         if x is not None:             return         if x is not None:             return         if x is not None:             return         if x is not None:             return         if x is not None:             return         if x is not None:             return         if x is not None:             return         if x is not None:             return         if x is not None:             return         if x is not None:             return         if x is not None:             return         if x is not None:             return         if x is not None:             return         if x is not None:             return         if x is not None:             return         if x is not None:             return         if x is not None:             return
class S3CopyToTable(rdbms.CopyToTable):          if '.' in self.table:              query = ("select 1 as table_exists "                       "from information_schema.tables "                      "where table_schema = %s and table_name = %s limit 1")          else:              query = ("select 1 as table_exists "                       "from pg_table_def "                      "where tablename = %s limit 1")          cursor = connection.cursor()          try:              cursor.execute(query, tuple(self.table.split('.')))              break          except ValueError:              raise           try:              cursor.execute(query, tuple(self.table.split('.')))              break          except ValueError:              raise           try:              cursor.execute(query, tuple(self.table.split('.')))              break          except ValueError:              raise           try:              cursor.execute(query, tuple(self.table.split('.')))              break          except ValueError:              raise           try:              cursor.execute(query, tuple(self.table.split('.')))              break          except ValueError:              raise           try:              cursor.execute(query, tuple(self.table.split('.'))              break          except ValueError:              raise           try:              cursor.execute(query, tuple(self.table.split('.'))              break          except ValueError:              raise             try:                 cursor.execute(query, tuple(self.table.split('.'))                  break
class FastAPI(Starlette):              response_model_exclude_unset=bool(                  response_model_exclude_unset or response_model_skip_defaults              ),             response_model_exclude_defaults=response_model_exclude_defaults,             response_model_exclude_none=response_model_exclude_none,              include_in_schema=include_in_schema,              response_class=response_class or self.default_response_class,              name=name,
class FeedExporter(object):          d.addCallback(lambda _: logger.info(logfmt % "Stored", log_args,                                             extra={'spider': spider}))          d.addErrback(lambda f: logger.error(logfmt % "Error storing", log_args,                                             extra={'spider': spider, 'failure': f}))          return d      def item_scraped(self, item, spider):          return self._maybe_promote_to(item, spider)      def item_unscraped(self, item, spider):          return self._maybe_promote_to(item, spider)      def item_scraped_err(self, item, spider):          return self._maybe_promote_to(item, spider)      def item_unscraped_err(self, item, spider):          return self._maybe_promote_to(item, spider)      return d      def item_scraped(self, item, spider):          return self._maybe_promote_to(item, spider)      return d      def item_unscraped(self, item, spider):          return self._maybe_promote_to(item, spider)      return d      def item_scraped(self, item, spider):          return self._maybe_promote_to(item, spider)      return d      def item_unscraped(self, item, spider):          return self._maybe_promote_to(item, spider)      return d      def item_scraped(self, item, spider):          return self._maybe_promote_to(item, spider)      return d      def item_unscraped(self, item, spider):          return self._maybe_promote_to(item, spider)      return d      def item_scraped(self, item, spider):          return self._maybe_promote_to(item, spider)      return d      def item_unscraped(self, item, spider):          return self._maybe_promote_to(item, spider)      return d      def item_scraped(self, item, spider):          return self._maybe_promote_to(item, spider)      return d      def item_unscraped(self, item, spider):          return self._maybe_promote_to(item, spider)      return d      def item_scraped(self, item, spider):          return self._maybe_promote_to(item, spider)      return d      def item_unscraped(self, item, spider):          return self._maybe_promote_to(item, spider)      return d      def item_scraped(self, item, spider):          return self._maybe_promote_to(item, spider)      return d      def item_unscraped(self, item, spider):          return self._maybe_promote_to(item, spider)      return d      def item_scraped(self, item, spider):          return self._maybe_promote_to(item, spider)      return d      def item_unscraped(self, item, spider):          return self._maybe_promote_to(item, spider)      return d      def item_scraped(self, item, spider):          return self._maybe_promote_to(item, spider)      return d      def item_unscraped(self, item, spider):          return self._maybe_promote_to(item, spider)      return d      def item_scraped(self, item, spider):          return self._maybe_promote_to(item, spider)      return d      def item_unscraped(self, item, spider):          return self._maybe_promote_to(item, spider)      return d      def item_scraped(self, item, spider):          return self._maybe_promote_to(item, spider)      return d      def item_unscraped(self, item, spider):          return self._maybe_promote_to(item, spider)      return d      def item_scraped(self, item, spider):          return self._maybe_promote_to(item, spider)      return d      def item_unscraped(self, item, spider):          return self._maybe_promote_to(item, spider)      return d      def item_scraped(self, item, spider):          return self._maybe_promote_to(item, spider)      return d      def item_unscraped(self, item, spider):          return self._maybe_promote_to(item, spider)      return d      def item_scraped(self, item, spider):          return self._maybe_promote_to(item, spider)      return d      def item_unscraped(self, item, spider):          return self._maybe_promote_to(item, spider)      return d      def item_scraped(self, item, spider):          return self._maybe_promote_to(item, spider)      return d      def item_unscraped(self, item, spider):          return self._maybe_promote_to(item, spider)      return d      def item_scraped(self, item, spider):          return self._maybe_promote
def standardize_weights(y,      Everything gets normalized to a single sample-wise (or timestep-wise)     weight array.          y: Numpy array of model targets to be weighted.
def get_request_handler(                  exclude=response_model_exclude,                  by_alias=response_model_by_alias,                 exclude_unset=response_model_exclude_unset,                 response_model_exclude_defaults=response_model_exclude_defaults,                 response_model_exclude_none=response_model_exclude_none,              )              response = response_class(                 is_coroutine=is_coroutine,                 response_model_exclude_unset=response_model_exclude_unset,                 response_model_exclude_defaults=response_model_exclude_defaults,                 response_model_exclude_none=response_model_exclude_none,              )             response = response_class(                 is_coroutine=is_coroutine,                 response_model_exclude_unset=response_model_exclude_unset,                 response_model_exclude_defaults=response_model_exclude_defaults,                 response_model_exclude_none=response_model_exclude_none,              )             response = response_class(                 is_coroutine=is_coroutine,                 response_model_exclude_unset=response_model_exclude_unset,                 response_model_exclude_defaults=response_model_exclude_defaults,                 response_model_exclude_none=response_model_exclude_none,              )             response = response_class(                 is_coroutine=is_coroutine,                 response_model_exclude_unset=response_model_exclude_unset,                 response_model_exclude_defaults=response_model_exclude_defaults,                 response_model_exclude_none=response_model_exclude_none,              )             response = response_class(                 is_coroutine=is_coroutine,                 response_model_exclude_unset=response_model_exclude_unset,                 response_model_exclude_defaults=response_model_exclude_defaults,                 response_model_exclude_none=response_model_exclude_none,              )             response = response_class(                 is_coroutine=is_coroutine,                 response_model_exclude_unset=response_model_exclude_unset,                 response_model_exclude_defaults=response_model_exclude_defaults,                 response_model_exclude_none=response_model_exclude_none,              )             response = response_class(                 is_coroutine=is_coroutine,                 response_model_exclude_unset=response_model_exclude_unset,                 response_model_exclude_defaults=response_model_exclude_defaults,                 response_model_exclude_none=response_model_exclude_none,              )             response = response_class(                 is_coroutine=is_coroutine,                 response_model_exclude_unset=response_model_exclude_unset,                 response_model_exclude_defaults=response_model_exclude_defaults,                 response_model_exclude_none=response_model_exclude_none,              )             response = response_class(                 is_coroutine=is_coroutine,                 response_model_exclude_unset=response_model_exclude_unset,                 response_model_exclude_defaults=response_model_exclude_defaults,                 response_model_exclude_none=response_model_exclude_none,              )             response = response_class(                 is_coroutine=is_coroutine,                 response_model_exclude_unset=response_model_exclude_unset,                 response_model_exclude_defaults=response_model_exclude_defaults,                 response_model_exclude_none=response_model_exclude_none,              )             response = response_class(                 is_coroutine=is_coroutine,                 response_model_exclude_unset=response_model
def create_instance(objcls, settings, crawler, *args, **kwargs):      ``*args`` and ``**kwargs`` are forwarded to the constructors.      Raises ``ValueError`` if both ``settings`` and ``crawler`` are ``None``.      if settings is None:          if crawler is None:              raise ValueError("Specify at least one of settings and crawler.")          settings = crawler.settings      if crawler and hasattr(objcls, 'from_crawler'):         return objcls.from_crawler(crawler, *args, **kwargs)      elif hasattr(objcls, 'from_settings'):         return objcls.from_settings(settings, *args, **kwargs)      else:         return objcls(*args, **kwargs)  @contextmanager
from.generic import Generic  class Bash(Generic):      def app_alias(self, fuck):         alias = "TF_ALIAS={0}" \                 " alias {0}='PYTHONIOENCODING=utf-8" \                 " TF_CMD=$(TF_SHELL_ALIASES=$(alias) thefuck $(fc -ln -1)) && " \                  " eval $TF_CMD".format(fuck)          if settings.alter_history:             return          if not six.PY2:             return          if six.PY3:             return          if settings.max_redirects is not None:             return          if six.PY2:             return          if six.PY3:             return          if settings.max_redirects is not None:             return          if six.PY2:             return          if six.PY3:             return          if settings.max_redirects is not None:             return          if six.PY2:             return          if six.PY3:             return          if settings.max_redirects is not None:             return          if six.PY2:             return          if six.PY3:             return          if settings.max_redirects is not None:             return          if six.PY2:             return          if six.PY3:             return          if settings.max_redirects is not None:             return          if six.PY2:             return          if six.PY3:             return          if settings.max_redirects is not None:             return          if six.PY2:             return          if six.PY3:             return          if settings.max_redirects is not None:             return          if six.PY2:             return          if six.PY3:             return          if settings.max_redirects is not None:             return          if six.PY2:             return          if six.PY3:             return          if settings.max_redirects is not None:             return          if six.PY2:             return          if six.PY3:             return          if settings.max_redirects is not None:             return          if six.PY2:             return          if six.PY3:             return          if settings.max_redirects is not None:             return          if six.PY2:             return          if six.PY3:             return          if settings.max_redirects is not None:             return          if six.PY2:             return          if six.PY3:             return          if settings.max_redirects is not None:             return          if six.PY2:             return          if six.PY3:             return          if settings.max_redirects is not None:             return          if six.PY2:             return          if six.PY3:             return          if settings.max_redirects is not None:             return          if six.PY2:             return           if six.PY3:             return          if settings.max_redirects is not None:             return           if six.PY2:             return           if six.PY3:              return           if settings.max_redirects is not None:              return           if six.PY2:
def read_pickle(path, compression="infer"):      >>> import os      >>> os.remove("./dummy.pkl")     fp_or_buf, _, compression, should_close = get_filepath_or_buffer(         filepath_or_buffer, compression=compression, mode="wb"     )     if isinstance(fp_or_buf, str) and compression == "infer":         compression = infer_compression(compression)     f, fh = get_handle(fp_or_buf, "rb", compression=compression, is_text=False)         if isinstance(fp_or_buf, str) and compression == "infer":             compression = infer_compression(compression)     f, fh = get_handle(fp_or_buf, "rb", compression=compression, is_text=False)         if isinstance(fp_or_buf, str) and compression == "infer":             compression = infer_compression(compression)     f, fh = get_handle(fp_or_buf, "rb", compression=compression, is_text=False)         if isinstance(fp_or_buf, str) and compression == "infer":             compression = infer_compression(compression)     f, fh = get_handle(fp_or_buf, "rb", compression=compression, is_text=False)         if isinstance(fp_or_buf, str) and compression == "infer":             compression = infer_compression(compression)     f, fh = get_handle(fp_or_buf, "rb", compression=compression, is_text=False)         if isinstance(fp_or_buf, str) and compression == "infer":             compression = infer_compression(compression)     f, fh = get_handle(fp_or_buf, "rb", compression=compression, is_text=False)         if isinstance(fp_or_buf, str) and compression == "infer":             compression = infer_compression(compression)     f, fh = get_handle(fp_or_buf, "rb", compression=compression, is_text=False)         if isinstance(fp_or_buf, str) and compression == "infer":             compression = infer_compression(compression)     f, fh = get_handle(fp_or_buf, "rb", compression=compression, is_text=False)         if isinstance(fp_or_buf, str) and compression == "infer":             compression = infer_compression(compression)     f, fh = get_handle(fp_or_buf, "rb", compression=compression, is_text=False)         if isinstance(fp_or_buf, str) and compression == "infer":             compression = infer_compression(compression)     f, fh = get_handle(fp_or_buf, "rb", compression=compression, is_text=False)         if isinstance(fp_or_buf, str) and compression == "infer":             compression = infer_compression(compression)     f, fh = get_handle(fp_or_buf, "rb", compression=compression, is_text=False)         if isinstance(fp_or_buf, str) and compression == "infer":             compression = infer_compression(compression)     f, fh = get_handle(fp_or_buf, "rb", compression=compression, is_text=False)         if isinstance(fp_or_buf, str) and compression == "infer":             compression = infer_compression(compression)     f, fh = get_handle(fp_or_buf, "rb", compression=compression, is_text=False)         if isinstance(fp_or_buf, str) and compression == "infer":             compression = infer_compression(compression)     f, fh = get_handle(fp_or_buf, "rb", compression=compression, is_text=False)         if isinstance(fp_or_buf, str) and compression == "infer":             compression = infer_compression(compression)     f, fh = get_handle(fp_or_buf, "rb", compression=compression, is_text=False)         if isinstance(fp_or_buf, str) and compression == "infer":             compression = infer_compression(compression)      f, fh = get_handle(fp_or_buf, "rb", compression=compression, is_text=False)         if isinstance(fp_or_buf, str) and compression == "infer":             compression = infer_compression(compression)      f, fh = get_handle(fp_or_buf, "rb", compression=compression, is_text=False)         if isinstance(fp_or_buf, str) and compression == "infer":             compression = infer_compression(compression)      f, fh = get_handle(fp_or_buf, "rb", compression=compression, is_text=False)         if isinstance(fp_or_buf, str) and compression == "infer":             compression = infer_compression(compression)      f, fh = get_handle(fp_or_buf, "rb", compression=compression, is_text=False)         if isinstance(fp_or_buf, str) and compression == "infer":             compression = infer_compression(compression)      f, fh = get_handle(fp_or_buf, "rb", compression=compression, is_text=False)         if isinstance(fp_or_buf, str) and compression == "infer":             compression = infer_compression(compression)      f, fh = get_handle(fp_or_buf, "rb", compression=compression, is_text=False)         if isinstance(fp_or_buf, str) and compression == "infer":             compression = infer_compression(compression)      f, fh = get_handle(fp_or_buf, "rb", compression=compression, is_text=False)         if isinstance(fp_or_buf, str) and compression == "infer":             compression = infer_compression(compression)      f, fh = get_handle(
def get_elements_by_attribute(attribute, value, html, escape_value=True):      retlist = []          <([a-zA-Z0-9:._-]+)          (?:\s+[a-zA-Z0-9:._-]+(?:=[a-zA-Z0-9:._-]*|="[^"]*"|='[^']*'))*?          \s+%s=['"]?%s['"]?          (?:\s+[a-zA-Z0-9:._-]+(?:=[a-zA-Z0-9:._-]*|="[^"]*"|='[^']*'))*?          \s*>          (?P<content>.*?)          </\1>         retlist = []          <([a-zA-Z0-9:._-]+)          (?:\s+[a-zA-Z0-9:._-]+(?:=[a-zA-Z0-9:._-]*|="[^"]*"|='[^']*'))*?          \s+%s=['"]?%s['"]?          (?:\s+[a-zA-Z0-9:._-]+(?:=[a-zA-Z0-9:._-]*|="[^"]*"|='[^']*'))*?          \s*>          (?P<content>.*?)          </\1>         retlist = []          <([a-zA-Z0-9:._-]+)          (?:\s+[a-zA-Z0-9:._-]+(?:=[a-zA-Z0-9:._-]*|="[^"]*"|='[^']*'))*?          \s+%s=['"]?%s['"]?          (?:\s+[a-zA-Z0-9:._-]+(?:=[a-zA-Z0-9:._-]*|="[^"]*"|='[^']*'))*?          \s*>          (?P<content>.*?)          </\1>         retlist = []          <([a-zA-Z0-9:._-]+)          (?:\s+[a-zA-Z0-9:._-]+(?:=[a-zA-Z0-9:._-]*|="[^"]*"|='[^']*'))*?          \s+%s=['"]?%s['"]?          (?:\s+[a-zA-Z0-9:._-]+(?:=[a-zA-Z0-9:._-]*|="[^"]*"|='[^']*'))*?          \s*>          (?P<content>.*?)          </\1>         retlist = []          <([a-zA-Z0-9:._-]+)          (?:\s+[a-zA-Z0-9:._-]+(?:=[a-zA-Z0-9:._-]*|="[^"]*"|='[^']*'))*?          \s+%s=['"]?%s['"]?          (?:\s+[a-zA-Z0-9:._-]+(?:=[a-zA-Z0-9:._-]*|="[^"]*"|='[^']*'))*?         \s*>          (?P<content>.*?)          </\1>         retlist = []          <([a-zA-Z0-9:._-]+)          (?:\s+[a-zA-Z0-9:._-]+(?:=[a-zA-Z0-9:._-]*|="[^"]*"|='[^']*'))*?          \s+%s=['"]?%s['"]?          (?:\s+[a-zA-Z0-9:._-]+(?:=[a-zA-Z0-9:._-]*|="[^"]*"|='[^']*'))*?          \s*>          (?P<content>.*?)          </\1>         retlist = []          <([a-zA-Z0-9:._-]+)          (?:\s+[a-zA-Z0-9:._-]+(?:=[a-zA-Z0-9:._-]*|="[^"]*"|='[^']*'))*?          \s+%s=['"]?%s['"]?          (?:\s+[a-zA-Z0-9:._-]+(?:=[a-zA-Z0-9:._-]*|="[^"]*"|='[^']*'))*?          \s*>          (?P<content>.*?)          </\1>         retlist = []          <([a-zA-Z0-9:._-]+)          (?:\s+[a-zA-Z0-9:._-]+(?:=[a-zA-Z0-9:._-]*|="[^"]*"|='[^']*'))*?          \s+%s=['"]?%s['"]?          (?:\s+[a-zA-Z0-9:._-]+(?:=[a-zA-Z0-9:._-]*|="[^"]*"|='[^']*'))*?
from keras.utils.data_utils import validate_file  from keras import backend as K  pytestmark = pytest.mark.skipif(     K.backend() == 'tensorflow' and 'TRAVIS_PYTHON_VERSION' in os.environ,      reason='Temporarily disabled until the use_multiprocessing problem is solved')  if sys.version_info < (3,):
class RetcodesTest(LuigiTestCase):          with mock.patch('luigi.scheduler.Scheduler.add_task', new_func):              self.run_and_expect('RequiringTask', 0)              self.run_and_expect('RequiringTask --retcode-not-run 6', 6)          is buggy program class RetcodesTest(LuigiTestCase):          with mock.patch('luigi.scheduler.Scheduler.add_task', new_func):              self.run_and_expect('RequiringTask', 0)              self.run_and_expect('RequiringTask --retcode-not-run 7', 7)             self.run_and_expect('RequiringTask --retcode-not-run 8', 8)             self.run_and_expect('RequiringTask --retcode-not-run 9', 9)             self.run_and_expect('RequiringTask --retcode-not-run 10', 10)             self.run_and_expect('RequiringTask --retcode-not-run 11', 11)             self.run_and_expect('RequiringTask --retcode-not-run 12', 12)             self.run_and_expect('RequiringTask --retcode-not-run 13', 13)             self.run_and_expect('RequiringTask --retcode-not-run 14', 14)             self.run_and_expect('RequiringTask --retcode-not-run 15', 15)             self.run_and_expect('RequiringTask --retcode-not-run 16', 16)             self.run_and_expect('RequiringTask --retcode-not-run 17', 17)             self.run_and_expect('RequiringTask --retcode-not-run 18', 18)             self.run_and_expect('RequiringTask --retcode-not-run 19', 19)             self.run_and_expect('RequiringTask --retcode-not-run 20', 20)             self.run_and_expect('RequiringTask --retcode-not-run 21', 21)             self.run_and_expect('RequiringTask --retcode-not-run 22', 22)             self.run_and_expect('RequiringTask --retcode-not-run 23', 23)             self.run_and_expect('RequiringTask --retcode-not-run 24', 24)             self.run_and_expect('RequiringTask --retcode-not-run 25', 25)             self.run_and_expect('RequiringTask --retcode-not-run 26', 26)             self.run_and_expect('RequiringTask --retcode-not-run 27', 27)             self.run_and_expect('RequiringTask --retcode-not-run 28', 28)             self.run_and_expect('RequiringTask --retcode-not-run 29', 29)             self.run_and_expect('RequiringTask --retcode-not-run 30', 30)             self.run_and_expect('RequiringTask --retcode-not-run 31', 31)             self.run_and_expect('RequiringTask --retcode-not-run 32', 32)             self.run_and_expect('RequiringTask --retcode-not-run 33', 33)             self.run_and_expect('RequiringTask --retcode-not-run 34', 34)             self.run_and_expect('RequiringTask --retcode-not-run 35', 35)             self.run_and_expect('RequiringTask --retcode-not-run 36', 36)             self.run_and_expect('RequiringTask --retcode-not-run 37', 37)             self.run_and_expect('RequiringTask --retcode-not-run 38', 38)             self.run_and_expect('RequiringTask --retcode-not-run 39', 39)             self.run_and_expect('RequiringTask --retcode-not-run 40', 40)             self.run_and_expect('RequiringTask --retcode-not-run 41', 41)             self.run_and_expect('RequiringTask --retcode-not-run 42', 42)             self.run_and_expect('RequiringTask --retcode-not-run 43', 43)             self.run_and_expect('RequiringTask --retcode-not-run 44', 44)             self.run_and_expect('RequiringTask --retcode-not-run 45', 45)             self.run_and_expect('RequiringTask --retcode-not-run 46', 46)             self.run_and_expect('RequiringTask --retcode-not-run 47', 47)             self.run_and_expect('RequiringTask --retcode-not-run 48', 48)             self.run_and_expect('RequiringTask --retcode-not-run 49', 49)             self.run_and_expect('RequiringTask --retcode-not-run 50', 50)             self.run_and_expect('RequiringTask --retcode-not-run 51', 51)             self.run_and_expect('RequiringTask --retcode-not-run 52', 52)             self.run_and_expect('RequiringTask --retcode-not-run 53', 53)             self.run_and_expect('RequiringTask --retcode-not-run 54', 54)             self.run_and_expect('RequiringTask --retcode-not-run 55', 55)             self.run_and_expect('RequiringTask --retcode-not-run 56
def split_line(      If `py36` is True, splitting may generate syntax that is only compatible      with Python 3.6 and later.     if not isinstance(line, UnformattedLines) or line.is_comment:          yield line          return
class CSVLogger(Callback):          if not self.writer:              class CustomDialect(csv.excel):                  delimiter = self.sep              self.writer = csv.DictWriter(self.csv_file,                                         fieldnames=['epoch'] + self.keys, dialect=CustomDialect)              if self.append_header:                  self.writer.writeheader()             if self.stream:                 self._open_args = {}                 for k in self.keys:                      self._open_args[k] = self._open_args[k] + 1                  if self._open_args:                      self._open_args = self._open_args.copy()              if self._open_args:                  self.writer.open(self._open_args)                  if self.append_header:                      self.writer.writeheader()              if self.stream:                  self._open_args = {}                 for k in self.keys:                      self._open_args[k] = self._open_args[k] + 1                  if self._open_args:                      self._open_args = self._open_args.copy()              if self._open_args:                  self.writer.open(self._open_args)                 if self.append_header:                     self.writer.writeheader()              if self.stream:                  self._open_args = {}                 for k in self.keys:                     self._open_args[k] = self._open_args[k] + 1                 if self._open_args:                     self.writer.open(self._open_args)                 if self.append_header:                     self.writer.writeheader()              if self.stream:                 self._open_args = {}                for k in self.keys:                     self._open_args[k] = self._open_args[k] + 1                 if self._open_args:                     self._open_args = self._open_args.copy()              if self._open_args:                 self.writer.open(self._open_args)              if self.append_header:                 self.writer.writeheader()             if self.stream:                 self._open_args = {}              for k in self.keys:                 self._open_args[k] = self._open_args[k] + 1              if self._open_args:                 self.writer.open(self._open_args)              if self.append_header:                 self.writer.writeheader()             if self.stream:                 self._open_args = {}              for k in self.keys:                 self._open_args[k] = self._open_args[k] + 1              if self._open_args:                 self.writer.open(self._open_args)              if self.append_header:                 self.writer.writeheader()             if self.stream:                 self._open_args = {}                for k in self.keys:                    self._open_args[k] = self._open_args[k] + 1                if self._open_args:                   self._open_args = self._open_args.copy()             if self._open_args:                self.writer.open(self._open_args)             if self.append_header:                 self.writer.writeheader()             if self.stream:                 self._open_args = {}
class FastAPI(Starlette):          response_model_by_alias: bool = True,          response_model_skip_defaults: bool = None,          response_model_exclude_unset: bool = False,         response_model_exclude_defaults: bool = False,         response_model_exclude_none: bool = False,          include_in_schema: bool = True,          response_class: Type[Response] = None,          name: str = None,         response_model_by_alias: bool = True,          response_model_skip_defaults: bool = None,          response_model_exclude_unset: bool = False,         response_model_exclude_defaults: bool = False,         response_model_exclude_none: bool = False,          include_in_schema: bool = True,          response_class: Type[Response] = None,          name: str = None,         response_model_by_alias: bool = True,          response_model_skip_defaults: bool = None,          response_model_exclude_unset: bool = False,          response_model_exclude_defaults: bool = False,          response_model_exclude_none: bool = False,          response_model_exclude_defaults_none: bool = False,          include_in_schema: bool = True,          response_class: Type[Response] = None,          name: str = None,         response_model_by_alias: bool = True,          response_model_skip_defaults: bool = None,          response_model_exclude_unset: bool = False,          response_model_exclude_defaults: bool = False,          response_model_exclude_none: bool = False,          response_model_exclude_defaults_none: bool = False,          include_in_schema: bool = True,          response_class: Type[Response] = None,          name: str = None,          response_model_by_alias: bool = True,          response_model_skip_defaults: bool = None,          response_model_exclude_unset: bool = False,          response_model_exclude_defaults: bool = False,          response_model_exclude_none: bool = False,          response_model_exclude_defaults_none: bool = False,          include_in_schema: bool = True,          response_class: Type[Response] = None,          name: str = None,          response_model_by_alias: bool = True,          response_model_skip_defaults: bool = None,          response_model_exclude_unset: bool = False,          response_model_exclude_defaults: bool = False,          response_model_exclude_none: bool = False,          response_model_exclude_defaults_none: bool = False,          include_in_schema: bool = True,          response_class: Type[Response] = None,          name: str = None,          response_model_by_alias: bool = True,          response_model_skip_defaults: bool = None,          response_model_exclude_unset: bool = False,          response_model_exclude_defaults: bool = False,          response_model_exclude_none: bool = False,          response_model_exclude_defaults_none: bool = False,          include_in_schema: bool = True,          response_class: Type[Response] = None,          name: str = None,          response_model_by_alias: bool = True,          response_model_skip_defaults: bool = None,          response_model_exclude_unset: bool = False,          response_model_exclude_defaults: bool = False,          response_model_exclude_none: bool = False,          response_model_exclude_defaults_none: bool = False,          include_in_schema: bool = True,          response_class: Type[Response] = None,          name: str = None,          response_model_by_alias: bool = True,          response_model_skip_defaults: bool = None,          response_model_exclude_unset: bool = False,          response_model_exclude_defaults: bool = False,          response_model_exclude_none: bool = False,          response_model_exclude_defaults_none: bool = False,          include_in_schema: bool = True,          response_class: Type[Response] = None,          name: str = None,             response_model_by_alias: bool = True,             response_model_skip_defaults: bool = None,             response_model_exclude_unset: bool = False,             response_model_exclude_defaults: bool = False,             response_model_exclude_none: bool = False,             response_model_exclude_defaults_none: bool = False,             include_in_schema: bool = True,             response_class: Type[Response] = None,             name: str = None,                response_model_by_alias: bool = True,
class CollectionRequirement:                  requirement = req                  op = operator.eq                 if parent and version == '*' and requirement!= '*':                     break                 elif requirement == '*' or version == '*':                     continue              if not op(LooseVersion(version), LooseVersion(requirement)):                   break
default: :rc:`scatter.edgecolors`          collection = mcoll.PathCollection(                 (path, scales,                 facecolors=colors,                 edgecolors=edgecolors,                  linewidths=linewidths,                  offsets=offsets,                  transOffset=kwargs.pop('transform', self.transData),
class APIRoute(routing.Route):          self.response_model_exclude = response_model_exclude          self.response_model_by_alias = response_model_by_alias          self.response_model_exclude_unset = response_model_exclude_unset         self.response_model_exclude_defaults = response_model_exclude_defaults          self.response_model_exclude_none = response_model_exclude_none          self.include_in_schema = include_in_schema          self.response_class = response_class          self.response_model_exclude_unset = response_model_exclude_unset          self.response_model_exclude_defaults = response_model_exclude_defaults          self.response_model_exclude_none = response_model_exclude_none          self.response_model_exclude_defaults = response_model_exclude_defaults          self.response_model_exclude_none = response_model_exclude_none          self.include_in_schema = include_in_schema          self.response_class = response_class          self.response_model_exclude_unset = response_model_exclude_unset          self.response_model_exclude_defaults = response_model_exclude_defaults          self.response_model_exclude_none = response_model_exclude_none          self.response_model_exclude_defaults = response_model_exclude_defaults          self.response_model_exclude_none = response_model_exclude_none          self.include_in_schema = include_in_schema          self.response_class = response_class           self.response_model_exclude_unset = response_model_exclude_unset          self.response_model_exclude_defaults = response_model_exclude_defaults          self.response_model_exclude_none = response_model_exclude_none          self.response_model_exclude_defaults = response_model_exclude_defaults          self.response_model_exclude_none = response_model_exclude_none          self.include_in_schema = include_in_schema          self.response_class = response_class           self.response_model_exclude_unset = response_model_exclude_unset          self.response_model_exclude_defaults = response_model_exclude_defaults          self.response_model_exclude_none = response_model_exclude_none          self.response_model_exclude_defaults = response_model_exclude_defaults          self.response_model_exclude_none = response_model_exclude_none          self.include_in_schema = include_in_schema          self.response_class = response_class          self.response_model_exclude_unset = response_model_exclude_unset          self.response_model_exclude_defaults = response_model_exclude_defaults          self.response_model_exclude_none = response_model_exclude_none          self.response_model_exclude_defaults = response_model_exclude_defaults          self.response_model_exclude_none = response_model_exclude_none          self.include_in_schema = include_in_schema          self.response_class = response_class          self.response_model_exclude_unset = response_model_exclude_unset          self.response_model_exclude_defaults = response_model_exclude_defaults          self.response_model_exclude_none = response_model_exclude_none          self.response_model_exclude_defaults = response_model_exclude_defaults          self.response_model_exclude_none = response_model_exclude_none          self.include_in_schema = include_in_schema          self.response_class = response_class          self.response_model_exclude_unset = response_model_exclude_unset          self.response_model_exclude_defaults = response_model_exclude_defaults          self.response_model_exclude_none = response_model_exclude_none          self.response_model_exclude_defaults = response_model_exclude_defaults          self.response_model_exclude_none = response_model_exclude_none          self.include_in_schema = include_in_schema          self.response_class = response_class          self.response_model_exclude_unset = response_model_exclude_unset          self.response_model_exclude_defaults = response_model_exclude_defaults          self.response_model_exclude_none = response_model_exclude_none          self.response_model_exclude_defaults = response_model_exclude_defaults          self.response_model_exclude_none = response_model_exclude_none          self.include_in_schema = include_in_schema          self.response_class = response_class          self.response_model_exclude_unset = response_model_exclude_unset          self.response_model_exclude_defaults = response_model_exclude_defaults          self.response_model_exclude_none = response_model_exclude_none          self.include_in_schema = include_in_schema          self.response_class = response_class          self.response_model_exclude_unset = response_model_exclude_unset          self.response_model_exclude_defaults = response_model_exclude_defaults          self.response_model_exclude_none = response_model_exclude_none
def _isna_old(obj):      elif isinstance(obj, type):          return False      elif isinstance(obj, (ABCSeries, np.ndarray, ABCIndexClass, ABCExtensionArray)):         return _isna_ndarraylike_old(obj, old=False)      elif isinstance(obj, ABCDataFrame):          return obj.isna()      elif isinstance(obj, list):         return _isna_ndarraylike_old(np.asarray(obj, dtype=object), old=False)      elif hasattr(obj, "__array__"):         return _isna_ndarraylike_old(np.asarray(obj), old=False)      else:          return False
class ColorbarBase(_ColorbarMappableDummy):      def set_label(self, label, **kw):         self._label = str(label)          self._labelkw = kw         self._set_label()         self._get_visible()          self._set_visible()          self._get_label()          self._set_label()          self._get_visible()          self._set_visible()          self._get_label()          self._set_label()          self._get_visible()          self._set_visible()          self._get_label()          self._set_label()          self._get_visible()          self._set_visible()          self._get_label()          self._set_label()          self._get_visible()          self._set_visible()          self._get_label()          self._set_label()          self._get_visible()          self._set_visible()          self._get_label()          self._set_label()          self._get_visible()          self._set_visible()          self._get_label()          self._set_label()          self._get_visible()          self._set_visible()          self._get_label()          self._set_label()          self._get_visible()          self._set_visible()          self._get_label()          self._set_label()          self._get_visible()          self._set_visible()          self._get_label()          self._set_label()          self._get_visible()          self._set_visible()          self._get_label()          self._set_label()          self._get_visible()          self._set_visible()          self._get_label()          self._set_label()          self._get_visible()          self._set_visible()          self._get_label()          self._set_label()          self._get_visible()          self._set_visible()          self._get_label()          self._set_label()          self._get_visible()          self._set_visible()          self._get_label()          self._set_label()          self._get_visible()          self._set_visible()          self._get_label()          self._set_label()          self._get_visible()          self._set_visible()          self._get_label()          self._set_label()          self._get_visible()          self._set_visible()          self._get_label()          self._set_label()          self._get_visible()          self._set_visible()          self._get_label()          self._set_label()          self._get_visible()          self._set_visible()          self._get_label()          self._set_label()          self._get_visible()          self._set_visible()          self._get_label()          self._set_label()          self._get_visible()          self._get_label()          self._set_label()          self._get_visible()          self._get_label()          self._set_label()          self._get_visible()          self._get_label()          self._set_label()          self._get_visible()          self._get_label()          self._set_label()          self._get_visible()          self._get_label()          self._set_label()          self._get_visible()          self._get_label()          self._set_label()          self._get_visible()          self._get_label()          self._set_label()          self._get_visible()          self._get_label()          self._set_label()          self._get_visible()          self._get_label()          self._set_label()          self._get_visible()          self._get_label()          self._set_label()          self._get_visible()          self._get_label()          self._set_label()          self._get_visible()          self._get_label()          self._set_label()          self._get_visible()          self._get_label()          self._set_label()          self._get_visible()          self._get_label()          self._set_label()
def whitespace(leaf: Leaf) -> str:          ):              returnNO      elif prev.type == token.COMMENT:         return prev.value      elif prev.type in OPENING_BRACKETS:          return NO
class PeriodIndex(DatetimeIndexOpsMixin, Int64Index):      @cache_readonly      def _engine(self):         period = self._engine_type(period, len(self))          return self._engine_type(period, len(self))      @doc(Index.__contains__)      def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:         return is_period_dtype(dtype)      @cache_readonly      def _engine(self):         period = self._engine_type(period, len(self))          return self._engine_type(period, len(self))      @doc(Index.__contains__)      def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:         return is_period_dtype(dtype)      @cache_readonly      def _engine(self):         return self._engine_type(period, len(self))      @doc(Index.__contains__)      def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:         return is_period_dtype(dtype)      @cache_readonly      def _engine(self):         return self._engine_type(period, len(self))      @doc(Index.__contains__)      def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:         return is_period_dtype(dtype)      @cache_readonly      def _engine(self):         return self._engine_type(period, len(self))      @doc(Index.__contains__)      def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:         return is_period_dtype(dtype)      @cache_readonly      def _engine(self):         return self._engine_type(period, len(self))      @doc(Index.__contains__)      def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:         return is_period_dtype(dtype)      @cache_readonly      def _engine(self):         return self._engine_type(period, len(self))      @doc(Index.__contains__)      def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:         return is_period_dtype(dtype)      @cache_readonly      def _engine(self):         return self._engine_type(period, len(self))      @doc(Index.__contains__)      def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:         return is_period_dtype(dtype)      @cache_readonly      def _engine(self):         return self._engine_type(period, len(self))      @doc(Index.__contains__)      def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:         return is_period_dtype(dtype)      @cache_readonly      def _engine(self):         return self._engine_type(period, len(self))      @doc(Index.__contains__)      def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:         return is_period_dtype(dtype)      @cache_readonly      def _engine(self):         return self._engine_type(period, len(self))      @doc(Index.__contains__)      def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:         return is_period_dtype(dtype)      @cache_readonly      def _engine(self):         return self._engine_type(period, len(self))      @doc(Index.__contains__)      def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:         return is_period_dtype(dtype)      @cache_readonly      def _engine(self):         return self._engine_type(period, len(self))      @doc(Index.__contains__)      def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:         return is_period_dtype(dtype)      @cache_readonly      def _engine(self):         return self._engine_type(period, len(self))      @doc(Index.__contains__)      def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:         return is_period_dtype(dtype)      @cache_readonly      def _engine(self):         return self._engine_type(period, len(self))      @doc(Index.__contains__)      def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:         return is_period_dtype(dtype)      @cache_readonly      def _engine(self):         return self._engine_type(period, len(self))      @doc(Index.__contains__)      def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:         return is_period_dtype(dtype)      @cache_readonly      def _engine(self):         return self._engine_type(period, len(self))      @doc(Index.__contains__)      def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:         return is_period_dtype(dtype)      @cache_readonly      def _engine(self):         return self._engine_type(period, len(self))      @doc(Index.__contains__)      def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:         return is_period_dtype(dtype)      @cache_readonly      def _engine(self):         return self._engine_type(period, len(
def match_filter_func(filter_str):  def parse_dfxp_time_expr(time_expr):      if not time_expr:         return 0.0      if time_offset is None:         return 0.0      mobj = re.match(r'^(?P<time_offset>\d+(?:\.\d+)?)s?$', time_expr)      if mobj:         return 0.0      return mobj  def match_filter_func(filter_str):  def parse_dfxp_time_expr(time_expr):      if not time_expr:         return 0.0      if time_offset is None:         return 0.0      return time_offset  def match_filter_func(filter_str):  def parse_dfxp_time_expr(time_expr):      if not time_expr:         return 0.0      if time_offset is None:         return 0.0      return time_offset  def match_filter_func(filter_str):  def parse_dfxp_time_expr(time_expr):      if not time_expr:         return 0.0      if time_offset is None:         return 0.0      return time_offset  def match_filter_func(filter_str):  def parse_dfxp_time_expr(time_expr):      if not time_expr:         return 0.0      if time_offset is None:         return 0.0      return time_offset  def match_filter_func(filter_str):  def parse_dfxp_time_expr(time_expr):      if not time_expr:         return 0.0      if time_offset is None:         return 0.0      return time_offset  def match_filter_func(filter_str):  def parse_dfxp_time_expr(time_expr):      if not time_expr:         return 0.0      if time_offset is None:         return 0.0      return time_offset  def match_filter_func(filter_str):  def parse_dfxp_time_expr(time_expr):      if not time_expr:         return 0.0      if time_offset is None:         return 0.0      return time_offset  def match_filter_func(filter_str):  def parse_dfxp_time_expr(time_expr):      if not time_expr:         return 0.0      if time_offset is None:         return 0.0      return time_offset  def match_filter_func(filter_str):  def parse_dfxp_time_expr(time_expr):      if not time_expr:         return 0.0      if time_offset is None:         return 0.0      return time_offset  def match_filter_func(filter_str):  def parse_dfxp_time_expr(time_expr):      if not time_expr:         return 0.0      if time_offset is None:         return 0.0      return time_offset  def match_filter_func(filter_str):  def parse_dfxp_time_expr(time_expr):      if not time_expr:         return 0.0      if time_offset is None:         return 0.0      return time_offset  def match_filter_func(filter_str):  def parse_dfxp_time_expr(time_expr):      if not time_expr:         return 0.0      if time_offset is None:         return 0.0      return time_offset  def match_filter_func(filter_str):  def parse_dfxp_time_expr(time_expr):      if not time_expr:         return 0.0      if time_offset is None:         return 0.0      return time_offset  def match_filter_func(filter_str):  def parse_dfxp_time_expr(time_expr):      if not time_expr:         return 0.0      if time_offset is None:         return 0.0      return time_offset  def match_filter_func(filter_str):  def parse_dfxp_time_expr(time_expr):      if not time_expr:         return 0.0      if time_offset is None:         return 0.0      return time_offset  def match_filter_func(filter_str):  def parse_dfxp_time_expr(time_expr):      if not time_expr:         return 0.0      if time_offset is None:         return 0.0      return time_offset  def match_filter_func(filter_str):  def parse_dfxp_time_expr(time_expr):      if not time_expr:         return 0.0      if time_offset is None:         return 0.0      return time_offset  def match_filter_func(filter_str):  def parse_dfxp_time_expr(time_expr):      if not time_expr:         return 0.0      if time_offset is None:         return 0.0      return time_offset  def match_filter_func(filter_str):  def parse_dfxp_time_expr(time_expr):      if not time_expr:         return 0.0      if time_offset is None:         return 0.0      return time_offset  def match_filter_func(filter_str):  def parse_dfxp_time_expr(time_expr):      if not time_expr:         return 0.0      if time_offset is None:         return 0.0      return time_offset  def match_filter_func(filter_str):  def parse_dfxp_time_expr(time_expr):      if not time_expr:         return 0.0      if time_offset is None:         return 0.0      return time_offset  def match_filter_func(filter_str):  def parse_dfxp_time_expr(time_expr):      if not time_expr:          return 0.0      if time_offset
def test_resample_categorical_data_with_timedeltaindex():          index=pd.to_timedelta([0, 10], unit="s"),      )      expected = expected.reindex(         ["Group_obj", "Group"], axis=1, fill_value=0     )     expected["Group"] = expected["Group_obj"].astype("category")      tm.assert_frame_equal(result, expected)
def is_string_dtype(arr_or_dtype) -> bool:         is_excluded_checks = (is_period_dtype, is_interval_dtype)          return any(is_excluded(dtype) for is_excluded in is_excluded_checks)     _is_dtype(arr_or_dtype, condition)      return _is_dtype(arr_or_dtype, condition)      return arr_or_dtype      return _is_dtype(arr_or_dtype, condition)      return arr_or_dtype      return _is_dtype(arr_or_dtype, condition)      return arr_or_dtype      return _is_dtype(arr_or_dtype, condition)      return arr_or_dtype      return _is_dtype(arr_or_dtype, condition)      return arr_or_dtype      return _is_dtype(arr_or_dtype, condition)      return arr_or_dtype      return _is_dtype(arr_or_dtype, condition)      return arr_or_dtype      return _is_dtype(arr_or_dtype, condition)      return arr_or_dtype      return _is_dtype(arr_or_dtype, condition)      return arr_or_dtype      return _is_dtype(arr_or_dtype, condition)      return arr_or_dtype      return _is_dtype(arr_or_dtype, condition)      return arr_or_dtype      return _is_dtype(arr_or_dtype, condition)      return arr_or_dtype      return _is_dtype(arr_or_dtype, condition)      return arr_or_dtype      return _is_dtype(arr_or_dtype, condition)      return arr_or_dtype      return _is_dtype(arr_or_dtype, condition)      return arr_or_dtype      return _is_dtype(arr_or_dtype, condition)      return arr_or_dtype      return _is_dtype(arr_or_dtype, condition)      return arr_or_dtype      return _is_dtype(arr_or_dtype, condition)      return arr_or_dtype      return _is_dtype(arr_or_dtype, condition)      return arr_or_dtype      return _is_dtype(arr_or_dtype, condition)      return arr_or_dtype      return _is_dtype(arr_or_dtype, condition)      return arr_or_dtype      return _is_dtype(arr_or_dtype, condition)      return arr_or_dtype      return _is_dtype(arr_or_dtype, condition)      return arr_or_dtype      return _is_dtype(arr_or_dtype, condition)      return arr_or_dtype      return _is_dtype(arr_or_dtype, condition)      return arr_or_dtype      return _is_dtype(arr_or_dtype, condition)      return arr_or_dtype      return _is_dtype(arr_or_dtype, condition)      return arr_or_dtype      return _is_dtype(arr_or_dtype, condition)      return arr_or_dtype      return _is_dtype(arr_or_dtype, condition)      return arr_or_dtype      return _is_dtype(arr_or_dtype, condition)      return arr_or_dtype      return _is_dtype(arr_or_dtype, condition)      return arr_or_dtype      return _is_dtype(arr_or_dtype, condition)      return arr_or_dtype      return _is_dtype(arr_or_dtype, condition)      return arr_or_dtype      return _is_dtype(arr_or_dtype, condition)      return arr_or_dtype      return _is_dtype(arr_or_dtype, condition)      return arr_or_dtype      return _is_dtype(arr_or_dtype, condition)      return arr_or_dtype      return _is_dtype(arr_or_dtype, condition)      return arr_or_dtype      return _is_dtype(arr_or_dtype, condition)      return arr_or_dtype      return _is_dtype(arr_or_dtype, condition)      return arr_or_dtype      return _is_dtype(arr_or_dtype, condition)      return arr_or_dtype      return _is_dtype(arr_or_dtype, condition)      return arr_or_dtype      return _is_dtype(arr_or_dtype, condition)      return arr_or_dtype      return _is_dtype(arr_or_dtype, condition)      return arr_or_dtype      return _is_dtype(arr_or_dtype, condition)      return arr_or_dtype      return _is_dtype(arr_or_dtype, condition)      return arr_or_dtype      return _is_dtype(arr_or_dtype, condition)      return arr_or_dtype      return _is_dtype(arr_or_dtype, condition)      return arr_or_dtype      return _is_dtype(arr_or_dtype, condition)      return arr_or_dtype      return _is_dtype(arr_or_dtype, condition)      return arr_or_dtype      return _is_dtype(arr_or_dtype, condition)      return arr_or_dtype      return _is_dtype(arr_or_dtype, condition)      return arr_or_dtype      return _is_dtype(arr_or_dtype, condition)      return arr_or_dtype      return _is_dtype(arr_or_dtype, condition)      return arr_or_dtype      return _is_dtype(arr_or_dtype, condition)      return arr_or_dtype      return _is_dtype(arr_or_dtype, condition)      return arr_or_dtype      return _is_dtype(arr_or_dtype, condition)
class Scraper(object):                      spider=spider, exception=output.value)              else:                 logger.error('Error processing %(item)s', {'item': item},                             exc_info=failure_to_exc_info(output),                             extra={'spider': spider})          else:              logkws = self.logformatter.scraped(output, response, spider)              logger.log(*logformatter_adapter(logkws), exc_info=failure_to_exc_info(output),                             extra={'spider': spider})
from pandas.core.dtypes.generic import ABCSeries  from pandas.core.dtypes.missing import isna from pandas._typing import Dtype  from pandas.core.arrays.interval import IntervalArray, _interval_shared_docs  import pandas.core.common as com  import pandas.core.indexes.base as ibase  from pandas.core.dtypes.missing import is_valid_nat_for_dtype, isna  from pandas._typing import AnyArrayLike  from pandas.core.arrays.interval import IntervalArray, _interval_shared_docs  import pandas.core.common as com  import pandas.core.indexes.base as ibase  from pandas.core.dtypes.missing import is_valid_nat_for_dtype, isna  from pandas.core.arrays.interval import IntervalArray, _interval_shared_docs  import pandas.core.common as com  import pandas.core.indexes.base as ibase  from pandas.core.dtypes.missing import is_valid_nat_for_dtype, isna  from pandas.core.arrays.interval import IntervalArray, _interval_shared_docs  import pandas.core.common as com  import pandas.core.indexes.base as ibase  from pandas.core.dtypes.missing import is_valid_nat_for_dtype, isna  from pandas.core.arrays.interval import IntervalArray, _interval_shared_docs  import pandas.core.common as com  import pandas.core.indexes.base as ibase  from pandas.core.dtypes.missing import is_valid_nat_for_dtype, isna  from pandas.core.arrays.interval import IntervalArray, _interval_shared_docs  import pandas.core.common as com  import pandas.core.indexes.base as ibase  from pandas.core.dtypes.missing import is_valid_nat_for_dtype, isna  from pandas.core.arrays.interval import IntervalArray, _interval_shared_docs  import pandas.core.common as com  import pandas.core.indexes.base as ibase  from pandas.core.dtypes.missing import is_valid_nat_for_dtype, isna  from pandas.core.arrays.interval import IntervalArray, _interval_shared_docs  import pandas.core.common as com  import pandas.core.indexes.base as ibase  from pandas.core.dtypes.missing import is_valid_nat_for_dtype, isna  from pandas.core.arrays.interval import IntervalArray, _interval_shared_docs  import pandas.core.common as com  import pandas.core.indexes.base as ibase  from pandas.core.dtypes.missing import is_valid_nat_for_dtype, isna  from pandas.core.arrays.interval import IntervalArray, _interval_shared_docs  import pandas.core.common as com  import pandas.core.indexes.base as ibase  from pandas.core.dtypes.missing import is_valid_nat_for_dtype, isna  from pandas.core.arrays.interval import IntervalArray, _interval_shared_docs  import pandas.core.common as com  import pandas.core.indexes.base as ibase  from pandas.core.dtypes.missing import is_valid_nat_for_dtype, isna  from pandas.core.arrays.interval import IntervalArray, _interval_shared_docs  import pandas.core.common as com  import pandas.core.indexes.base as ibase  from pandas.core.dtypes.missing import is_valid_nat_for_dtype, isna  from pandas.core.arrays.interval import IntervalArray, _interval_shared_docs  import pandas.core.common as com  import pandas.core.indexes.base as ibase  from pandas.core.dtypes.missing import is_valid_nat_for_dtype, isna  from pandas.core.arrays.interval import IntervalArray, _interval_shared_docs  import pandas.core.common as com  import pandas.core.indexes.base as ibase  from pandas.core.dtypes.missing import is_valid_nat_for_dtype, isna  from pandas.core.arrays.interval import IntervalArray, _interval_shared_docs  import pandas.core.common as com  import pandas.core.indexes.base as ibase  from pandas.core.dtypes.missing import is_valid_nat_for_dtype, isna  from pandas.core.arrays.interval import IntervalArray, _interval_shared_docs  import pandas.core.common as com  import pandas.core.indexes.base as ibase  from pandas.core.dtypes.missing import is_valid_nat_for_dtype, isna  from pandas.core.arrays.interval import IntervalArray, _interval_shared_docs  import pandas.core.common as com  import pandas.core.indexes.base as ibase  from pandas.core.dtypes.missing import is_valid_nat_for_dtype, isna  from pandas.core.arrays.interval import IntervalArray, _interval_shared_docs  import pandas.core.common as com  import pandas.core.indexes.base as ibase  from pandas.core.dtypes.missing import is_valid_nat_for_dtype, isna  from pandas.core.arrays.interval import IntervalArray, _interval_shared_docs  import pandas.core.common as com  import pandas.core.indexes.base as ibase  from pandas.core.dtypes.missing import is_valid_nat_for_dtype, isna  from pandas.core.arrays.interval import IntervalArray, _interval_shared_docs  import pandas.core.common as com  import pandas.core.indexes.base as ibase  from pandas.core.dtypes.missing import is_valid_nat_for_dtype, isna  from pandas.core.arrays.interval import IntervalArray, _interval_shared_docs  import pandas.core.common as com  import pandas.core.indexes.base as ibase  from pandas.core.dtypes.missing import is_valid_nat_for_dtype, isna  from pandas.core.arrays.interval import IntervalArray, _interval_shared_docs  import pandas.core.common as com  import pandas.core.indexes.base as ibase  from pandas.core.dtypes.missing import is_valid_nat_for_dtype, isna  from pandas.core.arrays.interval import IntervalArray, _interval_shared_docs  import pandas.core.common as com  import pandas.core.indexes.base as ibase  from pandas.core.dtypes.missing import is_valid_nat_for_dtype, isna  from pandas.core.arrays.interval import IntervalArray, _interval_shared_docs  import pandas.core.common as com  import pandas.core.indexes.base as ibase  from pandas.core.dtypes.missing import is_valid_nat_for_dtype, isna  from pandas.core.arrays.interval import IntervalArray, _interval_shared_docs  import pandas.core.common as com  import pandas.core.indexes.base as ibase  from pandas.core.dtypes.missing import is_valid_nat_for_dtype, isna  from pandas.core.arrays.interval import IntervalArray, _interval_shared_docs  import pandas.core.common as com  import pandas.core.indexes.base as ibase  from pandas.core.dtypes.missing import is_valid_nat_for_dtype, isna  from pandas.core.arrays.interval import Inter
class DictParameter(Parameter):      tags, that are dynamically constructed outside Luigi), or you have a complex parameter containing logically related      values (like a database connection config).     JSON encoder for :py:class:`~DictParameter`, which makes :py:class:`~_FrozenOrderedDict` JSON serializable.         JSON encoder for :py:class:`~_FrozenOrderedDict`, which makes :py:class:`~_FrozenOrderedDict` JSON serializable.         JSON encoder for :py:class:`~_FrozenOrderedDict`, which makes :py:class:`~_FrozenOrderedDict` JSON serializable.         JSON encoder for :py:class:`~_FrozenOrderedDict`, which makes :py:class:`~_FrozenOrderedDict` JSON serializable.         JSON encoder for :py:class:`~_FrozenOrderedDict`, which makes :py:class:`~_FrozenOrderedDict` JSON serializable.         JSON encoder for :py:class:`~_FrozenOrderedDict`, which makes :py:class:`~_FrozenOrderedDict` JSON serializable.         JSON encoder for :py:class:`~_FrozenOrderedDict`, which makes :py:class:`~_FrozenOrderedDict` JSON serializable.         JSON encoder for :py:class:`~_FrozenOrderedDict`, which makes :py:class:`~_FrozenOrderedDict` JSON serializable.         JSON encoder for :py:class:`~_FrozenOrderedDict`, which makes :py:class:`~_FrozenOrderedDict` JSON serializable.         JSON encoder for :py:class:`~_FrozenOrderedDict`, which makes :py:class:`~_FrozenOrderedDict` JSON serializable.         JSON encoder for :py:class:`~_FrozenOrderedDict`, which makes :py:class:`~_FrozenOrderedDict` JSON serializable.         JSON encoder for :py:class:`~_FrozenOrderedDict`, which makes :py:class:`~_FrozenOrderedDict` JSON serializable.         JSON encoder for :py:class:`~_FrozenOrderedDict`, which makes :py:class:`~_FrozenOrderedDict` JSON serializable.         JSON encoder for :py:class:`~_FrozenOrderedDict`, which makes :py:class:`~_FrozenOrderedDict` JSON serializable.         JSON encoder for :py:class:`~_FrozenOrderedDict`, which makes :py:class:`~_FrozenOrderedDict` JSON serializable.         JSON encoder for :py:class:`~_FrozenOrderedDict`, which makes :py:class:`~_FrozenOrderedDict` JSON serializable.         JSON encoder for :py:class:`~_FrozenOrderedDict`, which makes :py:class:`~_FrozenOrderedDict` JSON serializable.         JSON encoder for :py:class:`~_FrozenOrderedDict`, which makes :py:class:`~_FrozenOrderedDict` JSON serializable.         JSON encoder for :py:class:`~_FrozenOrderedDict`, which makes :py:class:`~_FrozenOrderedDict` JSON serializable.         JSON encoder for :py:class:`~_FrozenOrderedDict`, which makes :py:class:`~_FrozenOrderedDict` JSON serializable.         JSON encoder for :py:class:`~_FrozenOrderedDict`, which makes :py:class:`~_FrozenOrderedDict` JSON serializable.         JSON encoder for :py:class:`~_FrozenOrderedDict`, which makes :py:class:`~_FrozenOrderedDict` JSON serializable.         JSON encoder for :py:class:`~_FrozenOrderedDict`, which makes :py:class:`~_FrozenOrderedDict` JSON serializable.         JSON encoder for :py:class:`~_FrozenOrderedDict`, which makes :py:class:`~_FrozenOrderedDict` JSON serializable.         JSON encoder for :py:class:`~_FrozenOrderedDict`, which makes :py:class:`~_FrozenOrderedDict` JSON serializable.         JSON encoder for :py:class:`~_FrozenOrderedDict`, which makes :py:class:`~_FrozenOrderedDict` JSON serializable.         JSON encoder for :py:class:`~_FrozenOrderedDict`, which makes :py:class:`~_FrozenOrderedDict` JSON serializable.         JSON encoder for :py:class:`~_FrozenOrderedDict`, which makes :py:class:`~_FrozenOrderedDict` JSON serializable.         JSON encoder for :py:class:`~_FrozenOrderedDict`, which makes :py:class:`~_FrozenOrderedDict` JSON serializable.         JSON encoder for :py:class:`~_FrozenOrderedDict`, which makes :py:class:`~_FrozenOrderedDict` JSON serializable.         JSON encoder for :py:class:`~_FrozenOrderedDict`, which makes :py:class:`~_FrozenOrderedDict` JSON serializable.         JSON encoder for :py:class:`~_FrozenOrderedDict`, which makes :py:class:`~_FrozenOrderedDict` JSON serializable.         JSON encoder for :py:class:`~_FrozenOrderedDict`, which makes :py:class:`~_FrozenOrderedDict` JSON serializable.         JSON encoder for :py:class:`~_FrozenOrderedDict`, which makes :py:class:`~_FrozenOrderedDict` JSON serializable.         JSON encoder for :py:class:`~_FrozenOrderedDict`, which makes :py:class:`~_FrozenOrderedDict` JSON serializable.         JSON encoder for :py:class:`~_FrozenOrderedDict`, which makes :py:class:`~_FrozenOrderedDict` JSON serializable.         JSON encoder for :py:class:`~_FrozenOrderedDict`, which makes :py:class:`~_FrozenOrderedDict` JSON serializable.         JSON encoder for :py:class:`~_FrozenOrderedDict`, which makes :py:class:`~_FrozenOrderedDict` JSON serializable.         JSON encoder for :py:class:`~_FrozenOrderedDict`, which makes :py:class:`~_FrozenOrderedDict` JSON serializable.         JSON encoder for :py:class:`~_
def check_required_arguments(argument_spec, module_parameters):              missing.append(k)      if missing:         msg = "missing required arguments: %s" % ", ".join(missing)          raise TypeError(to_native(msg))      return missing      def check_required_arguments(argument_spec, module_parameters):              missing.append(k)      if missing:         msg = "missing required arguments: %s" % ", ".join(missing)          raise TypeError(to_native(msg))      return missing      def check_required_arguments(argument_spec, module_parameters):              missing.append(k)      if missing:         msg = "missing required arguments: %s" % ", ".join(missing)          raise TypeError(to_native(msg))      return missing      def check_required_arguments(argument_spec, module_parameters):              missing.append(k)      if missing:          msg = "missing required arguments: %s" % ", ".join(missing)          raise TypeError(to_native(msg))      return missing      def check_required_arguments(argument_spec, module_parameters):              missing.append(k)      if missing:          msg = "missing required arguments: %s" % ", ".join(missing)          raise TypeError(to_native(msg))      return missing      def check_required_arguments(argument_spec, module_parameters):              missing.append(k)      if missing:          msg = "missing required arguments: %s" % ", ".join(missing)          raise TypeError(to_native(msg))      return missing      def check_required_arguments(argument_spec, module_parameters):              missing.append(k)      if missing:          msg = "missing required arguments: %s" % ", ".join(missing)          raise TypeError(to_native(msg))      return missing      def check_required_arguments(argument_spec, module_parameters):              missing.append(k)      if missing:          msg = "missing required arguments: %s" % ", ".join(missing)          raise TypeError(to_native(msg))      return missing      def check_required_arguments(argument_spec, module_parameters):              missing.append(k)      if missing:          msg = "missing required arguments: %s" % ", ".join(missing)          raise TypeError(to_native(msg))      return missing      def check_required_arguments(argument_spec, module_parameters):              missing.append(k)      if missing:          msg = "missing required arguments: %s" % ", ".join(missing)          raise TypeError(to_native(msg))      return missing      def check_required_arguments(argument_spec, module_parameters):              missing.append(k)      if missing:          msg = "missing required arguments: %s" % ", ".join(missing)          raise TypeError(to_native(msg))      return missing      def check_required_arguments(argument_spec, module_parameters):              missing.append(k)      if missing:          msg = "missing required arguments: %s" % ", ".join(missing)          raise TypeError(to_native(msg))      return missing      def check_required_arguments(argument_spec, module_parameters):              missing.append(k)      if missing:          msg = "missing required arguments: %s" % ", ".join(missing)          raise TypeError(to_native(msg))      return missing      def check_required_arguments(argument_spec, module_parameters):              missing.append(k)      if missing:          msg = "missing required arguments: %s" % ", ".join(missing)          raise TypeError(to_native(msg))      return missing      def check_required_arguments(argument_spec, module_parameters):              missing.append(k)      if missing:          msg = "missing required arguments: %s" % ", ".join(missing)          raise TypeError(to_native(msg))      return missing      def check_required_arguments(argument_spec, module_parameters):              missing.append(k)      if missing:          msg = "missing required arguments: %s" % ", ".join(missing)          raise TypeError(to_native(msg))      return missing      def check_required_arguments(argument_spec, module_parameters):              missing.append(k)      if missing:          msg = "missing required arguments: %s" % ", ".join(missing)          raise TypeError(to_native(msg))      return missing      def check_required_arguments(argument_spec, module_parameters):              missing.append(k)      if missing:          msg = "missing required arguments: %s" % ", ".join(missing)          raise TypeError(to_native(msg))      return missing      def check_required_arguments(argument_spec, module_parameters):              missing.append(k)      if missing:          msg = "missing required arguments: %s" % ", ".join(missing)          raise TypeError(to_native(msg))      return missing      def check_required_arguments(argument_spec, module_parameters):              missing.append(
class LSTMCell(Layer):                  inputs_f = inputs                  inputs_c = inputs                  inputs_o = inputs             x_i = K.dot(inputs_i, self.kernel_i) + self.bias_i             x_f = K.dot(inputs_f, self.kernel_f) + self.bias_f             x_c = K.dot(inputs_c, self.kernel_c) + self.bias_c             x_o = K.dot(inputs_o, self.kernel_o) + self.bias_o              if 0 < self.recurrent_dropout < 1.:                  h_tm1_i = h_tm1 * rec_dp_mask[0]
class PagedList(object):  def uppercase_escape(s):      return re.sub(          r'\\U[0-9a-fA-F]{8}',         lambda m: m.group(0).decode('unicode-escape'), s, quote=True)  try:      struct.pack(u'!I', 0)  except ValueError:         pass  try:      struct.pack(u'!I', 0)      return s  try:      struct.pack(u'!I', 0)      return s  try:      struct.pack(u'!I', 0)      return s  try:      struct.pack(u'!I', 0)      return s  try:      struct.pack(u'!I', 0)      return s  try:      struct.pack(u'!I', 0)      return s  try:      struct.pack(u'!I', 0)      return s  try:      struct.pack(u'!I', 0)      return s  try:      struct.pack(u'!I', 0)      return s  try:      struct.pack(u'!I', 0)      return s  try:      struct.pack(u'!I', 0)      return s  try:      struct.pack(u'!I', 0)      return s  try:      struct.pack(u'!I', 0)      return s  try:      struct.pack(u'!I', 0)      return s  try:      struct.pack(u'!I', 0)      return s  try:      struct.pack(u'!I', 0)      return s  try:      struct.pack(u'!I', 0)      return s  try:      struct.pack(u'!I', 0)      return s  try:      struct.pack(u'!I', 0)      return s  try:      struct.pack(u'!I', 0)      return s  try:      struct.pack(u'!I', 0)      return s  try:      struct.pack(u'!I', 0)      return s  try:      struct.pack(u'!I', 0)      return s  try:      struct.pack(u'!I', 0)      return s  try:      struct.pack(u'!I', 0)      return s  try:      struct.pack(u'!I', 0)      return s  try:      struct.pack(u'!I', 0)      return s  try:      struct.pack(u'!I', 0)      return s  try:      struct.pack(u'!I', 0)      return s  try:      struct.pack(u'!I', 0)      return s  try:      struct.pack(u'!I', 0)      return s  try:      struct.pack(u'!I', 0)      return s  try:      struct.pack(u'!I', 0)      return s  try:      struct.pack(u'!I', 0)      return s  try:      struct.pack(u'!I', 0)      return s  try:      struct.pack(u'!I', 0)      return s  try:      struct.pack(u'!I', 0)      return s  try:      struct.pack(u'!I', 0)      return s  try:      struct.pack(u'!I', 0)      return s  try:      struct.pack(u'!I', 0)      return s  try:      struct.pack(u'!I', 0)      return s  try:      struct.pack(u'!I', 0)      return s  try:      struct.pack(u'!I', 0)      return s  try:      struct.pack(u'!I', 0)      return s  try:      struct.pack(u'!I', 0)      return s  try:      struct.pack(u'!I', 0)      return s  try:      struct.pack(u'!I', 0)      return s  try:      struct.pack(u'!I', 0)      return s  try:      struct.pack(u'!I', 0)      return s  try:      struct.pack(u'!I', 0)      return s  try:      struct.pack(u'!I', 0)      return s  try:      struct.pack(u'!I', 0)      return s  try:      struct.pack(u'!I', 0)      return s  try:      struct.pack(u'!I', 0)      return s  try:      struct.pack(u'!I', 0)      return s  try:      struct.pack(u'!I', 0)      return s  try:      struct.pack(u'!I', 0)      return s  try:      struct.pack(u'!I', 0)      return s  try:      struct.pack(u'!I', 0)      return s  try:      struct.pack(u'!I', 0)      return s  try:      struct.pack(u'!I', 0)      return s  try:      struct.pack(u'!I', 0)      return s  try:      struct.pack(u'!I', 0)      return s  try:      struct.pack(u'!I', 0)      return s  try:      struct.pack(u'!I', 0)      return s  try:      struct.pack(u'!I', 0)      return s  try:      struct.pack(u'!I', 0)      return s  try:      struct.pack(u'!I', 0)      return s  try:      struct.pack(u'!I', 0)      return s  try:      struct.pack(u'!I', 0)      return s  try:
class Function(object):                                   feed_symbols,                                  symbol_vals,                                  session)         return self._callable_fn(*array_vals)      def _legacy_call(self, inputs):          return super()._legacy_call(inputs)          return self._callable_fn(*array_vals)      def _callable_fn(self, inputs):          return super()._callable_fn(inputs)          return self._callable_fn(*array_vals)          return fetched[:len(self.outputs)]      def _legacy_call(self, inputs):          return super()._legacy_call(inputs)          return self._callable_fn(*array_vals)          return fetched[:len(self.outputs)]      def _callable_fn(self, inputs):          return super()._callable_fn(inputs)          return self._callable_fn(*array_vals)          return fetched[:len(self.outputs)]          return super()._legacy_call(inputs)          return self._callable_fn(*array_vals)          return fetched[:len(self.outputs)]          return super()._legacy_call(inputs)          return self._callable_fn(*array_vals)          return fetched[:len(self.outputs)]          return super()._legacy_call(inputs)          return self._callable_fn(*array_vals)          return fetched[:len(self.outputs)]          return super()._legacy_call(inputs)          return self._callable_fn(*array_vals)          return fetched[:len(self.outputs)]          return super()._legacy_call(inputs)          return self._callable_fn(*array_vals)          return fetched[:len(self.outputs)]          return super()._legacy_call(inputs)          return self._callable_fn(*array_vals)          return fetched[:len(self.outputs)]          return super()._legacy_call(inputs)          return self._callable_fn(*array_vals)          return fetched[:len(self.outputs)]          return super()._legacy_call(inputs)          return self._callable_fn(*array_vals)          return fetched[:len(self.outputs)]          return super()._legacy_call(inputs)          return self._callable_fn(*array_vals)          return fetched[:len(self.outputs)]          return super()._legacy_call(inputs)          return self._callable_fn(*array_vals)          return fetched[:len(self.outputs)]          return super()._legacy_call(inputs)          return self._callable_fn(*array_vals)          return fetched[:len(self.outputs)]          return super()._legacy_call(inputs)          return self._callable_fn(*array_vals)          return fetched[:len(self.outputs)]          return super()._legacy_call(inputs)          return self._callable_fn(*array_vals)          return fetched[:len(self.outputs)]          return super()._legacy_call(inputs)          return self._callable_fn(*array_vals)          return fetched[:len(self.outputs)]          return super()._legacy_call(inputs)          return self._callable_fn(*array_vals)          return fetched[:len(self.outputs)]          return super()._legacy_call(inputs)          return self._callable_fn(*array_vals)          return fetched[:len(self.outputs)]          return super()._legacy_call(inputs)          return self._callable_fn(*array_vals)          return fetched[:len(self.outputs)]          return super()._legacy_call(inputs)          return self._callable_fn(*array_vals)          return fetched[:len(self.outputs)]          return super()._legacy_call(inputs)          return self._callable_fn(*array_vals)          return fetched[:len(self.outputs)]          return super()._legacy_call(inputs)          return self._callable_fn(*array_vals)          return fetched[:len(self.outputs)]          return super()._legacy_call(inputs)          return self._callable_fn(*array_vals)          return fetched[:len(self.outputs)]          return super()._legacy_call(inputs)          return self._callable_fn(*array_vals)          return fetched[:len(self.outputs)]          return super()._legacy_call(inputs)          return self._callable_fn(*array_vals)
class Sequential(Model):                                          use_multiprocessing=use_multiprocessing)      @interfaces.legacy_generator_methods_support     def predict_generator(self, generator, steps=None,                           max_queue_size=10, workers=1,                           use_multiprocessing=False, verbose=0):          if self.sequence is None:              raise ValueError('`use_sequence_api=False` is only valid for a generator'                                            'based on the `use_multiprocessing=use_multiprocessing` setting.'                                           'Please consider using the `use_sequence_api=True` setting.')      @interfaces.legacy_generator_methods_support     def predict_generator(self, generator, steps=None,                           max_queue_size=10, workers=1,                           use_multiprocessing=False, verbose=0):          if self.sequence is None:              raise ValueError('`use_sequence_api=False` is only valid for a generator'                                           'based on the `use_multiprocessing=use_multiprocessing` setting.'                                          'Please consider using the `use_sequence_api=True` setting.')      @interfaces.legacy_generator_methods_support      def predict_generator(self, generator, steps=None,                           max_queue_size=10, workers=1,                          use_multiprocessing=False, verbose=0):          if self.sequence is None:              raise ValueError('`use_sequence_api=False` is only valid for a generator'                                         'based on the `use_multiprocessing=use_multiprocessing` setting.'                                        'Please consider using the `use_sequence_api=True` setting.')      @interfaces.legacy_generator_methods_support      def predict_generator(self, generator, steps=None,                          max_queue_size=10, workers=1,                         use_multiprocessing=False, verbose=0):         if self.sequence is None:             raise ValueError('`use_sequence_api=False` is only valid for a generator'                                        'based on the `use_multiprocessing=use_multiprocessing` setting.'                                      'Please consider using the `use_sequence_api=True` setting.')      @interfaces.legacy_generator_methods_support      def predict_generator(self, generator, steps=None,                         max_queue_size=10, workers=1,                         use_multiprocessing=False, verbose=0):         if self.sequence is None:             raise ValueError('`use_sequence_api=False` is only valid for a generator'                                       'based on the `use_multiprocessing=use_multiprocessing` setting.'                                       'Please consider using the `use_sequence_api=True` setting.')      @interfaces.legacy_generator_methods_support      def predict_generator(self, generator, steps=None,                         max_queue_size=10, workers=1,                         use_multiprocessing=False, verbose=0):         if self.sequence is None:             raise ValueError('`use_sequence_api=False` is only valid for a generator'                                      'based on the `use_multiprocessing=use_multiprocessing` setting.'                                      'Please consider using the `use_sequence_api=True` setting.')      @interfaces.legacy_generator_methods_support      def predict_generator(self, generator, steps=None,                        max_queue_size=10, workers=1,
class tqdm(object):                     l_bar_user, r_bar_user = bar_format.split('{bar}')                    l_bar, r_bar = l_bar.format(**bar_args), r_bar.format(**bar_args)                 else:                     return bar_format.format(**bar_args)             else:                 return bar_format.format(**bar_args)          else:              return bar_format.format(**bar_args)             else:                 return bar_format.format(**bar_args)              else:                 return bar_format.format(**bar_args)              else:                 return bar_format.format(**bar_args)              else:                 return bar_format.format(**bar_args)              else:                 return bar_format.format(**bar_args)              else:                 return bar_format.format(**bar_args)              else:                 return bar_format.format(**bar_args)              else:                 return bar_format.format(**bar_args)              else:                 return bar_format.format(**bar_args)              else:                 return bar_format.format(**bar_args)              else:                 return bar_format.format(**bar_args)              else:                 return bar_format.format(**bar_args)              else:                 return bar_format.format(**bar_args)              else:                 return bar_format.format(**bar_args)              else:                 return bar_format.format(**bar_args)              else:                 return bar_format.format(**bar_args)              else:                 return bar_format.format(**bar_args)              else:                 return bar_format.format(**bar_args)              else:                 return bar_format.format(**bar_args)              else:                 return bar_format.format(**bar_args)              else:                 return bar_format.format(**bar_args)              else:                 return bar_format.format(**bar_args)              else:                 return bar_format.format(**bar_args)              else:                 return bar_format.format(**bar_args)              else:                 return bar_format.format(**bar_args)              else:                 return bar_format.format(**bar_args)              else:                 return bar_format.format(**bar_args)              else:                 return bar_format.format(**bar_args)              else:                 return bar_format.format(**bar_args)              else:                 return bar_format.format(**bar_args)              else:                 return bar_format.format(**bar_args)              else:                 return bar_format.format(**bar_args)              else:                 return bar_format.format(**bar_args)              else:                 return bar_format.format(**bar_args)              else:                 return bar_format.format(**bar_args)              else:                 return bar_format.format(**bar_args)              else:                 return bar_format.format(**bar_args)              else:                 return bar_format.format(**bar_args)              else:                 return bar_
default: :rc:`scatter.edgecolors`              - 'none': No patch boundary will bedrawn.              - A color or sequence of colors.             For non-filled markers, the *edgecolors* kwarg is ignored and             forced to 'face' internally.
fig, ax = plt.subplots(2, 1)  pcm = ax[0].pcolormesh(X, Y, Z,                        norm=colors.SymLogNorm(linthresh=0.03, linscale=0.03,                                              vmin=-1.0, vmax=1.0, base=10),                         cmap='RdBu_r')  fig.colorbar(pcm, ax=ax[0], extend='both')
class NDFrame(PandasObject, SelectionMixin, indexing.IndexingMixin):              return self         arr = operator.inv(com.values_from_object(self))         return self.__array_wrap__(arr)      def __zero__(self):          raise ValueError(
def count_leading_spaces(s):  def process_list_block(docstring, starting_point, section_end,                          leading_spaces, marker):      ending_point = docstring.find('\n\n', starting_point)     last_line_length = None     if (         starting_point == -1         and not isinstance(ending_point, str)         and not isinstance(ending_point, bytes)         and not isinstance(ending_point, str)         and not isinstance(ending_point, bytes)     ):         raise ValueError('Cannot use -1 as starting point of a list block')
def predict_generator(model, generator,              enqueuer.start(workers=workers, max_queue_size=max_queue_size)              output_generator = enqueuer.get()          else:             if use_sequence_api:                  output_generator = iter_sequence_infinite(generator)              else:                  output_generator = generator         use_sequence_api = True         if is_sequence:             output_generator = iter_sequence_infinite(generator)          else:             output_generator = generator         use_sequence_api = False         if is_sequence:             output_generator = iter_sequence_infinite(generator)          else:             output_generator = generator         use_sequence_api = True         if is_sequence:             output_generator = iter_sequence_infinite(generator)          else:             output_generator = generator         use_sequence_api = False         if is_sequence:             output_generator = iter_sequence_infinite(generator)          else:             output_generator = generator         use_sequence_api = True         if is_sequence:             output_generator = iter_sequence_infinite(generator)          else:             output_generator = generator         use_sequence_api = False         if is_sequence:             output_generator = iter_sequence_infinite(generator)          else:             output_generator = generator         use_sequence_api = True         if is_sequence:             output_generator = iter_sequence_infinite(generator)          else:             output_generator = generator         use_sequence_api = False         if is_sequence:             output_generator = iter_sequence_infinite(generator)          else:             output_generator = generator         use_sequence_api = True         if is_sequence:             output_generator = iter_sequence_infinite(generator)          else:             output_generator = generator         use_sequence_api = False         if is_sequence:             output_generator = iter_sequence_infinite(generator)          else:             output_generator = generator         use_sequence_api = True         if is_sequence:             output_generator = iter_sequence_infinite(generator)          else:             output_generator = generator         use_sequence_api = False         if is_sequence:             output_generator = iter_sequence_infinite(generator)          else:             output_generator = generator         use_sequence_api = True         if is_sequence:             output_generator = iter_sequence_infinite(generator)          else:             output_generator = generator         use_sequence_api = False         if is_sequence:             output_generator = iter_sequence_infinite(generator)          else:             output_generator = generator         use_sequence_api = True         if is_sequence:             output_generator = iter_sequence_infinite(generator)          else:             output_generator = generator         use_sequence_api = False         if is_sequence:             output_generator = iter_sequence_infinite(generator)          else:             output_generator = generator         use_sequence_api = True         if is_sequence:             output_generator = iter_sequence_infinite(generator)          else:             output_generator = generator         use_sequence_api = False         if is_sequence:             output_generator = iter_sequence_infinite(generator)          else:             output_generator = generator         use_sequence_api = True         if is_sequence:             output_generator = iter_sequence_infinite(generator)          else:             output_generator = generator         use_sequence_api = False         if is_sequence:             output_generator = iter_sequence_infinite(generator)          else:             output_generator = generator         use_sequence_api = True         if is_sequence:
import re  from.common import InfoExtractor  from..utils import (     fix_xml_ampersands,  )
Wild         185.0          numeric_df = self._get_numeric_data()          cols = numeric_df.columns          idx = cols.copy()         mat = numeric_df.astype(float, copy=False)          if method == "pearson":              correl = libalgos.nancorr(mat, minp=min_periods)          elif method == "spearman":              correl = libalgos.nancorr_spearman(mat, minp=min_periods)          elif method == "kendall" or callable(method):               if min_periods is None:                   min_periods = 1              mat = ensure_float64(mat).T               corrf = nanops.get_corr_func(method)              K = len(cols)              correl = np.empty((K, K), dtype=float)
def match(command):  @git_support  def get_new_command(command):      push_upstream = command.stderr.split('\n')[-3].strip()     return replace_argument(command.script, 'push', push_upstream)  @git_support  def get_new_command(command):      push_upstream = command.stderr.split('\n')[-3].strip()     return replace_argument(command.script, 'push', push_upstream)  @git_support  def get_new_command(command):      push_upstream = command.stderr.split('\n')[-3].strip()     return replace_argument(command.script, 'push', push_upstream)  @git_support  def get_new_command(command):      push_upstream = command.stderr.split('\n')[-3].strip()     return replace_argument(command.script, 'push', push_upstream)  @git_support  def get_new_command(command):      push_upstream = command.stderr.split('\n')[-3].strip()     return replace_argument(command.script, 'push', push_upstream)  @git_support  def get_new_command(command):      push_upstream = command.stderr.split('\n')[-3].strip()     return replace_argument(command.script, 'push', push_upstream)  @git_support  def get_new_command(command):      push_upstream = command.stderr.split('\n')[-3].strip()     return replace_argument(command.script, 'push', push_upstream)  @git_support  def get_new_command(command):      push_upstream = command.stderr.split('\n')[-3].strip()     return replace_argument(command.script, 'push', push_upstream)  @git_support  def get_new_command(command):      push_upstream = command.stderr.split('\n')[-3].strip()     return replace_argument(command.script, 'push', push_upstream)  @git_support  def get_new_command(command):      push_upstream = command.stderr.split('\n')[-3].strip()     return replace_argument(command.script, 'push', push_upstream)  @git_support  def get_new_command(command):      push_upstream = command.stderr.split('\n')[-3].strip()     return replace_argument(command.script, 'push', push_upstream)  @git_support  def get_new_command(command):      push_upstream = command.stderr.split('\n')[-3].strip()     return replace_argument(command.script, 'push', push_upstream)  @git_support  def get_new_command(command):      push_upstream = command.stderr.split('\n')[-3].strip()     return replace_argument(command.script, 'push', push_upstream)  @git_support  def get_new_command(command):      push_upstream = command.stderr.split('\n')[-3].strip()     return replace_argument(command.script, 'push', push_upstream)  @git_support  def get_new_command(command):      push_upstream = command.stderr.split('\n')[-3].strip()     return replace_argument(command.script, 'push', push_upstream)  @git_support  def get_new_command(command):      push_upstream = command.stderr.split('\n')[-3].strip()     return replace_argument(command.script, 'push', push_upstream)  @git_support  def get_new_command(command):      push_upstream = command.stderr.split('\n')[-3].strip()     return replace_argument(command.script, 'push', push_upstream)  @git_support  def get_new_command(command):      push_upstream = command.stderr.split('\n')[-3].strip()     return replace_argument(command.script, 'push', push_upstream)  @git_support  def get_new_command(command):      push_upstream = command.stderr.split('\n')[-3].strip()     return replace_argument(command.script, 'push', push_upstream)  @git_support  def get_new_command(command):      push_upstream = command.stderr.split('\n')[-3].strip()     return replace_argument(command.script, 'push', push_upstream)  @git_support  def get_new_command(command):      push_upstream = command.stderr.split('\n')[-3].strip()     return replace_argument(command.script, 'push', push_upstream)  @git_support  def get_new_command(command):      push_upstream = command.stderr.split('\n')[-3].strip()     return replace_argument(command.script, 'push', push_upstream)  @git_support  def get_new_command(command):      push_upstream = command.stderr.split('\n')[-3].strip()     return replace_argument(command.script, 'push', push_upstream)  @git_support  def get_new_command(command):      push_upstream = command.stderr.split('\n')[-3].strip()     return replace_argument(command.script, 'push', push_upstream)  @git_support  def get_new_command(command):      push_upstream = command.stderr.split('\n')[-3].strip()     return replace_argument(command.script, 'push', push_upstream)  @git_support  def get_new_command(command):      push_upstream = command.stderr.split('\n')[-3].strip()     return replace_argument(command.script, 'push', push_upstream)  @git_support  def get_new_command(command):      push_upstream = command.stderr.split('\n')[-3].strip()     return replace_argument(command.script, 'push', push_upstream)  @git_support  def get_new_command(command):      push_upstream = command.stderr.split('\n')[-3].strip()     return replace_argument(command.script, 'push', push_upstream)  @git_support  def get_new_command(command):      push_upstream = command.stderr.split('\n')[-3].strip()     return replace_argument(command.script, 'push', push_upstream)  @git_support  def get_new_command(command):      push_upstream = command.stderr.split('\n')[-3].strip()     return replace_argument(command.script, 'push', push_upstream)  @git_support  def get_new_command(command):      push_upstream = command.stderr.split('\n')[-3].strip()     return replace_argument(command.script, 'push', push_upstream)  @git_support  def get_new_
def uppercase_escape(s):      return re.sub(          r'\\U([0-9a-fA-F]{8})',          lambda m: compat_chr(int(m.group(1), base=16), errors='replace')      )      is buggy program def uppercase_escape(s):      return re.sub(          r'\\U([0-9a-fA-F]{8})',          lambda m: compat_chr(int(m.group(1), base=16), errors='replace')      )      is buggy program def uppercase_escape(s):      return re.sub(          r'\\U([0-9a-fA-F]{8})',          lambda m: compat_chr(int(m.group(1), base=16), errors='replace')      )      is buggy program def uppercase_escape(s):      return re.sub(          r'\\U([0-9a-fA-F]{8})',          lambda m: compat_chr(int(m.group(1), base=16), errors='replace')      )      is buggy program def uppercase_escape(s):      return re.sub(          r'\\U([0-9a-fA-F]{8})',          lambda m: compat_chr(int(m.group(1), base=16), errors='replace')      )      is buggy program def uppercase_escape(s):      return re.sub(          r'\\U([0-9a-fA-F]{8})',          lambda m: compat_chr(int(m.group(1), base=16), errors='replace')      )      is buggy program def uppercase_escape(s):      return re.sub(          r'\\U([0-9a-fA-F]{8})',          lambda m: compat_chr(int(m.group(1), base=16), errors='replace')      )      is buggy program def uppercase_escape(s):      return re.sub(          r'\\U([0-9a-fA-F]{8})',          lambda m: compat_chr(int(m.group(1), base=16), errors='replace')      )      is buggy program def uppercase_escape(s):      return re.sub(          r'\\U([0-9a-fA-F]{8})',          lambda m: compat_chr(int(m.group(1), base=16), errors='replace')      )      is buggy program def uppercase_escape(s):      return re.sub(          r'\\U([0-9a-fA-F]{8})',          lambda m: compat_chr(int(m.group(1), base=16), errors='replace')      )      is buggy program def uppercase_escape(s):      return re.sub(         r'\\U([0-9a-fA-F]{8})',          lambda m: compat_chr(int(m.group(1), base=16), errors='replace')      )      is buggy program def uppercase_escape(s):      return re.sub(          r'\\U([0-9a-fA-F]{8})',           lambda m: compat_chr(int(m.group(1), base=16), errors='replace')      )      is buggy program def uppercase_escape(s):      return re.sub(          r'\\U([0-9a-fA-F]{8})',
def write_flv_header(stream, metadata):      stream.write(b'\x12')     stream.write(pack('!L', len(metadata))[1:])      stream.write(b'\x00\x00\x00\x00\x00\x00\x00')      stream.write(metadata)
class TimedeltaIndex(                      result._set_freq("infer")              return result     def _fast_intersection(self, other):          if len(other) == 0:              return self.view(type(self))         return super()._fast_intersection(other)      def _fast_union(self, other):          if len(other) == 0:              return self.view(type(self))         return super()._fast_union(other)      def _fast_intersection(self, other):          if len(other) == 0:              return self.view(type(self))         return super()._fast_intersection(other)      def _fast_union(self, other):          if len(other) == 0:              return self.view(type(self))         return super()._fast_union(other)      def _fast_intersection(self, other):          if len(other) == 0:              return self.view(type(self))         return super()._fast_intersection(other)      def _fast_union(self, other):          if len(other) == 0:              return self.view(type(self))         return super()._fast_union(other)      def _fast_intersection(self, other):          if len(other) == 0:              return self.view(type(self))         return super()._fast_intersection(other)      def _fast_union(self, other):          if len(other) == 0:              return self.view(type(self))         return super()._fast_union(other)      def _fast_intersection(self, other):          if len(other) == 0:              return self.view(type(self))         return super()._fast_intersection(other)      def _fast_union(self, other):          if len(other) == 0:              return self.view(type(self))         return super()._fast_union(other)      def _fast_intersection(self, other):          if len(other) == 0:              return self.view(type(self))         return super()._fast_intersection(other)      def _fast_union(self, other):          if len(other) == 0:              return self.view(type(self))         return super()._fast_union(other)      def _fast_intersection(self, other):          if len(other) == 0:              return self.view(type(self))         return super()._fast_intersection(other)      def _fast_union(self, other):          if len(other) == 0:              return self.view(type(self))         return super()._fast_union(other)      def _fast_intersection(self, other):          if len(other) == 0:              return self.view(type(self))         return super()._fast_intersection(other)      def _fast_union(self, other):          if len(other) == 0:              return self.view(type(self))         return super()._fast_union(other)      def _fast_intersection(self, other):          if len(other) == 0:              return self.view(type(self))         return super()._fast_intersection(other)      def _fast_union(self, other):          if len(other) == 0:              return self.view(type(self))         return super()._fast_union(other)      def _fast_intersection(self, other):          if len(other) == 0:              return self.view(type(self))         return super()._fast_intersection(other)      def _fast_union(self, other):          if len(other) == 0:              return self.view(type(self))         return super()._fast_union(other)      def _fast_intersection(self, other):          if len(other) == 0:             return self.view(type(self))         return super()._fast_intersection(other)      def _fast_union(self, other):          if len(other) == 0:              return self.view(type(self))         return super()._fast_union(other)      def _fast_intersection(self, other):          if len(other) == 0:              return self.view(type(self))         return super()._fast_intersection(other)      def _fast_union(self, other):          if len(other) == 0:              return self.view(type(self))         return super()._fast_union(other)      def _fast_intersection(self, other):          if len(other) == 0:              return self.view(type(self))         return super()._fast_intersection(other)      def _fast_union(self, other):          if len(other) == 0:              return self.view(type(self))         return super
from pandas.core.dtypes.common import (      is_list_like,      is_object_dtype,      is_scalar,  ) from pandas.core.dtypes.dtypes import register_extension_dtype  from pandas.core.dtypes.missing import is_valid_nat_for_dtype, isna  from pandas.core.dtypes.dtypes import register_extension_dtype  from pandas.core.dtypes.missing import is_valid_nat_for_dtype, isna  from pandas.core.dtypes.dtypes import register_extension_dtype  from pandas.core.dtypes.missing import is_valid_nat_for_dtype, isna  from pandas.core.dtypes.dtypes import register_extension_dtype  from pandas.core.dtypes.missing import is_valid_nat_for_dtype, isna  from pandas.core.dtypes.dtypes import register_extension_dtype  from pandas.core.dtypes.missing import is_valid_nat_for_dtype, isna  from pandas.core.dtypes.dtypes import register_extension_dtype  from pandas.core.dtypes.missing import is_valid_nat_for_dtype, isna  from pandas.core.dtypes.dtypes import register_extension_dtype  from pandas.core.dtypes.missing import is_valid_nat_for_dtype, isna  from pandas.core.dtypes.dtypes import register_extension_dtype  from pandas.core.dtypes.missing import is_valid_nat_for_dtype, isna  from pandas.core.dtypes.dtypes import register_extension_dtype  from pandas.core.dtypes.missing import is_valid_nat_for_dtype, isna  from pandas.core.dtypes.dtypes import register_extension_dtype  from pandas.core.dtypes.missing import is_valid_nat_for_dtype, isna  from pandas.core.dtypes.dtypes import register_extension_dtype  from pandas.core.dtypes.missing import is_valid_nat_for_dtype, isna  from pandas.core.dtypes.dtypes import register_extension_dtype  from pandas.core.dtypes.missing import is_valid_nat_for_dtype, isna  from pandas.core.dtypes.dtypes import register_extension_dtype  from pandas.core.dtypes.missing import is_valid_nat_for_dtype, isna  from pandas.core.dtypes.dtypes import register_extension_dtype  from pandas.core.dtypes.missing import is_valid_nat_for_dtype, isna  from pandas.core.dtypes.dtypes import register_extension_dtype  from pandas.core.dtypes.missing import is_valid_nat_for_dtype, isna  from pandas.core.dtypes.dtypes import register_extension_dtype  from pandas.core.dtypes.missing import is_valid_nat_for_dtype, isna  from pandas.core.dtypes.dtypes import register_extension_dtype  from pandas.core.dtypes.missing import is_valid_nat_for_dtype, isna  from pandas.core.dtypes.dtypes import register_extension_dtype  from pandas.core.dtypes.missing import is_valid_nat_for_dtype, isna  from pandas.core.dtypes.dtypes import register_extension_dtype  from pandas.core.dtypes.missing import is_valid_nat_for_dtype, isna  from pandas.core.dtypes.dtypes import register_extension_dtype  from pandas.core.dtypes.missing import is_valid_nat_for_dtype, isna  from pandas.core.dtypes.dtypes import register_extension_dtype  from pandas.core.dtypes.missing import is_valid_nat_for_dtype, isna  from pandas.core.dtypes.dtypes import register_extension_dtype  from pandas.core.dtypes.missing import is_valid_nat_for_dtype, isna  from pandas.core.dtypes.dtypes import register_extension_dtype  from pandas.core.dtypes.missing import is_valid_nat_for_dtype, isna  from pandas.core.dtypes.dtypes import register_extension_dtype  from pandas.core.dtypes.missing import is_valid_nat_for_dtype, isna  from pandas.core.dtypes.dtypes import register_extension_dtype  from pandas.core.dtypes.missing import is_valid_nat_for_dtype, isna  from pandas.core.dtypes.dtypes import register_extension_dtype  from pandas.core.dtypes.missing import is_valid_nat_for_dtype, isna  from pandas.core.dtypes.dtypes import register_extension_dtype  from pandas.core.dtypes.missing import is_valid_nat_for_dtype, isna  from pandas.core.dtypes.dtypes import register_extension_dtype  from pandas.core.dtypes.missing import is_valid_nat_for_dtype, isna  from pandas.core.dtypes.dtypes import register_extension_dtype  from pandas.core.dtypes.missing import is_valid_nat_for_dtype, isna  from pandas.core.dtypes.dtypes import register_extension_dtype  from pandas.core.dtypes.missing import is_valid_nat_for_dtype, isna  from pandas.core.dtypes.dtypes import register_extension_dtype  from pandas.core.dtypes.missing import is_valid_nat_for_dtype, isna  from pandas.core.dtypes.dtypes import register_extension_dtype  from pandas.core.dtypes.missing import is_valid_nat_for_dtype, isna  from pandas.core.dtypes.dtypes import register_extension_dtype  from pandas.core.dtypes.missing import is_valid_nat_for_dtype, isna  from pandas.core.dtypes.dtypes import register_extension_dtype  from pandas.core.dtypes.missing import is_valid_nat_for_dtype, isna  from pandas.core.dtypes.dtypes import register_extension_dtype  from pandas.core.dtypes.missing import is_valid_nat_for_dtype, isna  from pandas.core.dtypes.dtypes import register_extension_dtype  from pandas.core.dtypes.missing import is_valid_nat_for_dtype, isna  from pandas.core.dtypes.dtypes import register_extension_dtype  from pandas.core.dtypes.missing import is_valid_nat_for_dtype, isna  from pandas.core.dtypes.dtypes import register_extension_dtype  from pandas.core.dtypes.missing import is_valid_nat_for_dtype, isna  from pandas.core.dtypes.dtypes import register_extension_dtype  from pandas.core.dtypes.missing import is_valid_nat_for_dtype, isna  from pandas.core.dtypes.dtypes import register_extension_dtype  from pandas.core.dtypes.missing import is_valid_nat_for_dtype, isna  from pandas.core.dtypes.dtypes import register_extension_dtype  from pandas.core.dtypes.missing import is_valid_nat_for_dtype, isna  from pandas.core.dtypes.dtypes import register_extension_dtype  from pandas.core.dtypes.missing import is_valid_nat_for_dtype, isna  from pandas.core.dtypes.dtypes import register_extension_dtype  from pandas.core
def _isna_old(obj):      elif hasattr(obj, "__array__"):          return _isna_ndarraylike_old(np.asarray(obj, dtype=np.int64))      else:         return obj is None  _isna = _isna_new     def _isna_old(obj):      elif hasattr(obj, "__array__"):          return _isna_ndarraylike_old(np.asarray(obj, dtype=np.int64), old=True)      else:         return obj  _isna = _isna_new      def _isna_old(obj):      elif hasattr(obj, "__array__"):          return _isna_ndarraylike_old(np.asarray(obj, dtype=np.int64), old=True)      else:         return obj  _isna = _isna_new      def _isna_old(obj):      elif hasattr(obj, "__array__"):          return _isna_ndarraylike_old(np.asarray(obj, dtype=np.int64), old=True)      else:         return obj  _isna = _isna_new      def _isna_old(obj):      elif hasattr(obj, "__array__"):          return _isna_ndarraylike_old(np.asarray(obj, dtype=np.int64), old=True)      else:         return obj  _isna = _isna_new      def _isna_old(obj):      elif hasattr(obj, "__array__"):          return _isna_ndarraylike_old(np.asarray(obj, dtype=np.int64), old=True)      else:         return obj  _isna = _isna_new      def _isna_old(obj):      elif hasattr(obj, "__array__"):          return _isna_ndarraylike_old(np.asarray(obj, dtype=np.int64), old=True)      else:         return obj  _isna = _isna_new      def _isna_old(obj):      elif hasattr(obj, "__array__"):          return _isna_ndarraylike_old(np.asarray(obj, dtype=np.int64), old=True)      else:         return obj  _isna = _isna_new      def _isna_old(obj):      elif hasattr(obj, "__array__"):          return _isna_ndarraylike_old(np.asarray(obj, dtype=np.int64), old=True)      else:         return obj  _isna = _isna_new      def _isna_old(obj):      elif hasattr(obj, "__array__"):          return _isna_ndarraylike_old(np.asarray(obj, dtype=np.int64), old=True)      else:         return obj  _isna = _isna_new      def _isna_old(obj):      elif hasattr(obj, "__array__"):          return _isna_ndarraylike_old(np.asarray(obj, dtype=np.int64), old=True)      else:         return obj  _isna = _isna_new      def _isna_old(obj):      elif hasattr(obj, "__array__"):          return _isna_ndarraylike_old(np.asarray(obj, dtype=np.int64), old=True)      else:         return obj  _isna = _isna_new      def _isna_old(obj):      elif hasattr(obj, "__array__"):          return _isna_ndarraylike_old(np.asarray(obj, dtype=np.int64), old=True)      else:         return obj  _isna = _isna_new      def _isna_old(obj):      elif hasattr(obj, "__array__"):          return _isna_ndarraylike_old(np.asarray(obj, dtype=np.int64), old=True)      else:         return obj  _isna = _isna_new      def _isna_old(obj):      elif hasattr(obj, "__array__"):          return _isna_ndarraylike_old(np.asarray(obj, dtype=np.int64), old=True)      else:         return obj  _isna = _isna_new      def _isna_old(obj):      elif hasattr(obj, "__array__"):          return _isna_ndarraylike_old(np.asarray(obj, dtype=np.int64), old=True)      else:          return obj  _isna = _isna_new      def _isna_old(obj):      elif hasattr(obj, "__array__"):          return _isna_ndarraylike_old(np.asarray(obj, dtype=np.int64), old=True)      else:          return obj  _isna = _isna_new      def _isna_old(obj):      elif hasattr(obj, "__array__"):          return _isna_ndarraylike_old(np.asarray(obj, dtype=np.int64), old=True)      else:          return obj  _isna = _isna_new      def _isna_old(obj):      elif hasattr(obj, "__array__"):          return _isna_ndarraylike_old(np.asarray(obj, dtype=np.int64), old=True)      else:          return obj  _isna = _isna_new      def _isna_old(obj):      elif hasattr(obj, "__array__"):          return _isna_ndarraylike_old(np.asarray(obj, dtype=np.int64), old=True)      else:          return obj  _isna = _isna_new
import time  import traceback  import math from tornado.concurrent import TracebackFuture, is_future, set_close_exec  from tornado.log import app_log, gen_log  from tornado.platform.auto import set_close_exec, Waker  from tornado import stack_context
class Model(Container):                  enqueuer.start(workers=workers, max_queue_size=max_queue_size)                  output_generator = enqueuer.get()              else:                 if is_sequence:                     output_generator = iterable_generator(generator)                 else:                     output_generator = generator              callback_model.stop_training = False             if is_sequence:                 output_generator = iterable_generator(generator)              else:                 output_generator = generator              callback_model.restore_best_weights = restore_best_weights             if is_sequence:                 output_generator = iterable_generator(generator)              else:                 output_generator = generator              callback_model.stop_training = False             if is_sequence:                 output_generator = iterable_generator(generator)              else:                 output_generator = generator              callback_model.restore_best_weights = restore_best_weights             if is_sequence:                 output_generator = iterable_generator(generator)              else:                 output_generator = generator              callback_model.stop_training = False             if is_sequence:                 output_generator = iterable_generator(generator)              else:                 output_generator = generator              callback_model.restore_best_weights = restore_best_weights             if is_sequence:                 output_generator = iterable_generator(generator)              else:                 output_generator = generator              callback_model.stop_training = False             if is_sequence:                 output_generator = iterable_generator(generator)              else:                 output_generator = generator              callback_model.restore_best_weights = restore_best_weights             if is_sequence:                 output_generator = iterable_generator(generator)              else:                 output_generator = generator              callback_model.stop_training = False             if is_sequence:                 output_generator = iterable_generator(generator)              else:                 output_generator = generator              callback_model.restore_best_weights = restore_best_weights             if is_sequence:                 output_generator = iterable_generator(generator)              else:                 output_generator = generator              callback_model.stop_training = False             if is_sequence:                 output_generator = iterable_generator(generator)              else:                 output_generator = generator                callback_model.restore_best_weights = restore_best_weights             if is_sequence:                 output_generator = iterable_generator(generator)              else:                 output_generator = generator                callback_model.stop_training = False             if is_sequence:                 output_generator = iterable_generator(generator)              else:                 output_generator = generator                callback_model.restore_best_weights = restore_best_weights             if is_sequence:                 output_generator = iterable_generator(generator)              else:                 output_generator = generator                callback_model.restore_best_weights = restore_best_weights             if is_sequence:                 output_generator = iterable_generator(generator)              else:                 output_generator = generator                callback_model.restore_best_weights = restore_best_weights             if is_sequence:                 output_generator = iterable_generator
install(              "options_test.cfg",              "static/robots.txt",              "static/dir/index.html",              "templates/utf8.html",              "test.crt",              "test.key",              "is_template",          )
def fit_generator(model,              if val_gen and workers > 0:                  val_data = validation_data                if use_sequence_api:                     val_enqueuer = OrderedEnqueuer(                          val_data,                          use_multiprocessing=use_multiprocessing)                )                 if isinstance(val_data, Sequence):                      val_enqueuer = OrderedEnqueuer(                          val_data,                          use_multiprocessing=use_multiprocessing)                 )                 if use_sequence_api:                      val_enqueuer = OrderedEnqueuer(                           val_data,                          use_multiprocessing=use_multiprocessing)                 )                 if isinstance(val_data, Sequence):                      val_enqueuer = OrderedEnqueuer(                           val_data,                          use_multiprocessing=use_multiprocessing)                  )                 if use_sequence_api:                      val_enqueuer = OrderedEnqueuer(                          val_data,                         use_multiprocessing=use_multiprocessing)                  )                 if isinstance(val_data, Sequence):                      val_enqueuer = OrderedEnqueuer(                          val_data,                         use_multiprocessing=use_multiprocessing)                  )                 if use_sequence_api:                     val_enqueuer = OrderedEnqueuer(                         val_data,                         use_multiprocessing=use_multiprocessing)                  )                 if isinstance(val_data, Sequence):                     val_enqueuer = OrderedEnqueuer(                         val_data,                        use_multiprocessing=use_multiprocessing)                  )                 if use_sequence_api:                     val_enqueuer = OrderedEnqueuer(                         val_data,                        use_multiprocessing=use_multiprocessing)                   )                 if isinstance(val_data, Sequence):                     val_enqueuer = OrderedEnqueuer(                         val_data,                        use_multiprocessing=use_multiprocessing)                   )                  if use_sequence_api:                     val_enqueuer = OrderedEnqueuer(                         val_data,                        use_multiprocessing=use_multiprocessing)
class OffsiteMiddleware(object):          if not allowed_domains: return re.compile('') url_pattern = re.compile("^https?:          for domain in allowed_domains:             if url_pattern.match(domain):                  message = ("allowed_domains accepts only domains, not URLs. "                             "Ignoring URL entry %s in allowed_domains." % domain)                  warnings.warn(message, URLWarning)                  domains = [re.escape(d) for d in allowed_domains if d is not None]              regex = r'^(.*\.)?(%s)$' % '|'.join(domains)          return re.compile(regex)
class Task(object):          params_str = {}          params = dict(self.get_params())          for param_name, param_value in six.iteritems(self.param_kwargs):             if params[param_name].significant:                 params_str[param_name] = params[param_name].serialize(param_value)          return params_str
def lib2to3_parse(src_txt: str) -> Node:      grammar = pygram.python_grammar_no_print_statement      if src_txt[-1:]!= "\n":         nl = "\r\n" if "\r\n" in src_txt[:1024] else "\n"         src_txt += nl      for grammar in GRAMMARS:          drv = driver.Driver(grammar, pytree.convert)          try:
def dispatch_to_series(left, right, func, str_rep=None, axis=None):          assert right.index.equals(left.columns)         def column_op(a, b):             return {i: func(a.iloc[:, i], b.iloc[i]) for i in range(len(a.columns))}      elif isinstance(right, ABCSeries): assert right.index.equals(left.index)         def column_op(a, b):             return {i: func(a.iloc[:, i], b.iloc[i]) for i in range(len(a.columns))}      elif isinstance(left, ABCSeries): assert left.index.equals(right.index)         def column_op(a, b):             return {i: func(a.iloc[:, i], b.iloc[i]) for i in range(len(a.columns))}      elif isinstance(right, ABCSeries): assert right.index.equals(left.index)         def column_op(a, b):             return {i: func(a.iloc[:, i], b.iloc[i]) for i in range(len(a.columns))}      elif isinstance(left, ABCSeries): assert left.index.equals(right.index)         def column_op(a, b):             return {i: func(a.iloc[:, i], b.iloc[i]) for i in range(len(a.columns))}      elif isinstance(right, ABCSeries): assert right.index.equals(left.index)         def column_op(a, b):             return {i: func(a.iloc[:, i], b.iloc[i]) for i in range(len(a.columns))}      elif isinstance(left, ABCSeries): assert left.index.equals(right.index)         def column_op(a, b):             return {i: func(a.iloc[:, i], b.iloc[i]) for i in range(len(a.columns))}      elif isinstance(right, ABCSeries): assert right.index.equals(left.index)         def column_op(a, b):             return {i: func(a.iloc[:, i], b.iloc[i]) for i in range(len(a.columns))}      elif isinstance(left, ABCSeries): assert left.index.equals(right.index)         def column_op(a, b):             return {i: func(a.iloc[:, i], b.iloc[i]) for i in range(len(a.columns))}      elif isinstance(right, ABCSeries): assert right.index.equals(left.index)         def column_op(a, b):             return {i: func(a.iloc[:, i], b.iloc[i]) for i in range(len(a.columns))}      elif isinstance(left, ABCSeries): assert left.index.equals(right.index)         def column_op(a, b):             return {i: func(a.iloc[:, i], b.iloc[i]) for i in range(len(a.columns))}      elif isinstance(right, ABCSeries): assert right.index.equals(left.index)         def column_op(a, b):             return {i: func(a.iloc[:, i], b.iloc[i]) for i in range(len(a.columns))}      elif isinstance(left, ABCSeries): assert left.index.equals(right.index)         def column_op(a, b):             return {i: func(a.iloc[:, i], b.iloc[i]) for i in range(len(a.columns))}      elif isinstance(right, ABCSeries): assert right.index.equals(left.index)         def column_op(a, b):             return {i: func(a.iloc[:, i], b.iloc[i]) for i in range(len(a.columns))}      elif isinstance(left, ABCSeries): assert left.index.equals(right.index)         def column_op(a, b):             return {i: func(a.iloc[:, i], b.iloc[i]) for i in range(len(a.columns))}      elif isinstance(right, ABCSeries): assert right.index.equals(left.index)         def column_op(a, b):             return {i: func(a.iloc[:, i], b.iloc[i]) for i in range(len(a.columns))}      elif isinstance(left, ABCSeries): assert left.index.equals(right.index)         def column_op(a, b):             return {i: func(a.iloc[:, i], b.iloc[i]) for i in range(len(a.columns))}      elif isinstance(right, ABCSeries): assert right.index.equals(left.index)         def column_op(a, b):             return {i: func(a.iloc[:, i], b.iloc[i]) for i in range(len(a.columns))}      elif isinstance(left, ABCSeries): assert left.index.equals(right.index)         def column_op(a, b):             return {i: func(a.iloc[:, i], b.iloc[i]) for i in range(len(a.columns))}      elif isinstance(right, ABCSeries): assert right.index.equals(left.index)         def column_op(a, b):             return {i: func(a.iloc[:, i], b.iloc[i]) for i in range(len(a.columns))}      elif isinstance(left, ABCSeries): assert left.index.equals(right.index)         def column_op(a, b):             return {i: func(a.iloc[:, i], b.iloc[i]) for i in range(len(a.columns))}
def unescapeHTML(s):      assert type(s) == compat_str      return re.sub(         r'&(?!amp;|lt;|gt;|apos;|quot;|         u'&amp;', lambda m: _htmlentity_transform(m.group(1)), s)  def get_subprocess_encoding():      return re.sub(         r'&(?!amp;|lt;|gt;|apos;|quot;|         u'&amp;',         lambda m: _htmlentity_transform(m.group(1)), s)  def unescapeHTML(s):      assert type(s) == compat_str      return re.sub(         r'&(?!amp;|lt;|gt;|apos;|quot;|         u'&amp;',         lambda m: _htmlentity_transform(m.group(1)), s)  def get_subprocess_encoding():      return re.sub(         r'&(?!amp;|lt;|gt;|apos;|quot;|         u'&amp;',         lambda m: _htmlentity_transform(m.group(1)), s)  def unescapeHTML(s):      assert type(s) == compat_str      return re.sub(         r'&(?!amp;|lt;|gt;|apos;|quot;|         u'&amp;',         lambda m: _htmlentity_transform(m.group(1)), s)  def get_subprocess_encoding():      return re.sub(         r'&(?!amp;|lt;|gt;|apos;|quot;|         u'&amp;',         lambda m: _htmlentity_transform(m.group(1)), s)  def unescapeHTML(s):      assert type(s) == compat_str      return re.sub(         r'&(?!amp;|lt;|gt;|apos;|quot;|         u'&amp;',         lambda m: _htmlentity_transform(m.group(1)), s)  def get_subprocess_encoding():      return re.sub(         r'&(?!amp;|lt;|gt;|apos;|quot;|         u'&amp;',         lambda m: _htmlentity_transform(m.group(1)), s)  def unescapeHTML(s):      assert type(s) == compat_str      return re.sub(         r'&(?!amp;|lt;|gt;|apos;|quot;|         u'&amp;',         lambda m: _htmlentity_transform(m.group(1)), s)  def get_subprocess_encoding():      return re.sub(         r'&(?!amp;|lt;|gt;|apos;|quot;|         u'&amp;',         lambda m: _htmlentity_transform(m.group(1)), s)  def unescapeHTML(s):      assert type(s) == compat_str      return re.sub(         r'&(?!amp;|lt;|gt;|apos;|quot;|         u'&amp;',         lambda m: _htmlentity_transform(m.group(1)), s)  def get_subprocess_encoding():      return re.sub(         r'&(?!amp;|lt;|gt;|apos;|quot;|         u'&amp;',         lambda m: _htmlentity_transform(m.group(1)), s)  def unescapeHTML(s):      assert type(s) == compat_str      return re.sub(         r'&(?!amp;|lt;|gt;|apos;|quot;|         u'&amp;',          lambda m: _htmlentity_transform(m.group(1)), s)  def get_subprocess_encoding():      return re.sub(         r'&(?!amp;|lt;|gt;|apos;|quot;|         u'&amp;',
class MultiIndex(Index):                      indexer = self._get_level_indexer(key, level=level)                      new_index = maybe_mi_droplevels(indexer, [0], drop_level)                      return indexer, new_index             except InvalidIndexError:                  pass              if not any(isinstance(k, slice) for k in key):                  raise InvalidIndexError(
class CategoricalIndex(Index, accessor.PandasDelegate):      @Appender(_index_shared_docs["_convert_scalar_indexer"])      def _convert_scalar_indexer(self, key, kind=None):         if self.categories._defer_to_indexing:             return self.categories._convert_scalar_indexer(key, kind=kind)          return super()._convert_scalar_indexer(key, kind=kind)      @Appender(_index_shared_docs["_convert_list_indexer"])         return super()._convert_list_indexer(key)      @Appender(_index_shared_docs["_convert_scalar_indexer"])         return self.categories._convert_scalar_indexer(key, kind=kind)      @Appender(_index_shared_docs["_convert_list_indexer"])         return super()._convert_list_indexer(key)      @Appender(_index_shared_docs["_convert_scalar_indexer"])         return self.categories._convert_scalar_indexer(key, kind=kind)      @Appender(_index_shared_docs["_convert_list_indexer"])         return super()._convert_list_indexer(key)      @Appender(_index_shared_docs["_convert_scalar_indexer"])         return self.categories._convert_scalar_indexer(key, kind=kind)      @Appender(_index_shared_docs["_convert_list_indexer"])         return super()._convert_list_indexer(key)      @Appender(_index_shared_docs["_convert_scalar_indexer"])         return self.categories._convert_scalar_indexer(key, kind=kind)      @Appender(_index_shared_docs["_convert_list_indexer"])         return super()._convert_list_indexer(key)      @Appender(_index_shared_docs["_convert_scalar_indexer"])         return self.categories._convert_scalar_indexer(key, kind=kind)      @Appender(_index_shared_docs["_convert_list_indexer"])         return super()._convert_list_indexer(key)      @Appender(_index_shared_docs["_convert_scalar_indexer"])         return self.categories._convert_scalar_indexer(key, kind=kind)      @Appender(_index_shared_docs["_convert_list_indexer"])         return super()._convert_list_indexer(key)      @Appender(_index_shared_docs["_convert_scalar_indexer"])         return self.categories._convert_scalar_indexer(key, kind=kind)      @Appender(_index_shared_docs["_convert_list_indexer"])         return super()._convert_list_indexer(key)      @Appender(_index_shared_docs["_convert_scalar_indexer"])         return self.categories._convert_scalar_indexer(key, kind=kind)      @Appender(_index_shared_docs["_convert_list_indexer"])         return super()._convert_list_indexer(key)      @Appender(_index_shared_docs["_convert_scalar_indexer"])         return self.categories._convert_scalar_indexer(key, kind=kind)      @Appender(_index_shared_docs["_convert_list_indexer"])         return super()._convert_list_indexer(key)      @Appender(_index_shared_docs["_convert_scalar_indexer"])         return self.categories._convert_scalar_indexer(key, kind=kind)      @Appender(_index_shared_docs["_convert_list_indexer"])         return super()._convert_list_indexer(key)      @Appender(_index_shared_docs["_convert_scalar_indexer"])         return self.categories._convert_scalar_indexer(key, kind=kind)      @Appender(_index_shared_docs["_convert_list_indexer"])         return super()._convert_list_indexer(key)      @Appender(_index_shared_docs["_convert_scalar_indexer"])         return self.categories._convert_scalar_indexer(key, kind=kind)      @Appender(_index_shared_docs["_convert_list_indexer"])         return super()._convert_list_indexer(key)      @Appender(_index_shared_docs["_convert_scalar_indexer"])         return self.categories._convert_scalar_indexer(key, kind=kind)      @Appender(_index_shared_docs["_convert_list_indexer"])          return super()._convert_list_indexer(key)      @Appender(_index_shared_docs["_convert_scalar_indexer"])          return self.categories._convert_scalar_indexer(key, kind=kind)      @Appender(_index_shared_docs["_convert_list_indexer"])          return super()._convert_list_indexer(key)      @Appender(_index_shared_docs["_convert_scalar_indexer"])          return self.categories._convert_scalar_indexer(key, kind=kind)      @Appender(_index_shared_docs["_convert_list_indexer"])          return super()._convert_list_indexer(key)      @Appender(_index_shared_docs["_convert_scalar_indexer"])          return self.categories._convert_scalar_indexer(key, kind=kind)      @Appender(_index_shared_docs["_convert_list_indexer"])           return super()._convert_list_
class GalaxyCLI(CLI):          obj_name = context.CLIARGS['{0}_name'.format(galaxy_type)]          inject_data = dict(             description='your description',              ansible_plugin_list_dir=get_versioned_doclink('plugins/plugins.html'),
def js_to_json(code):              ([{,]\s*)              ("[^"]*"|\'[^\']*\'|[a-z0-9A-Z]+)             (:\s*)             ([0-9.]+|true|false|"[^"]*"|\'[^\']*\'|\[|\{)      res = re.sub(r',(\s*\])', lambda m: m.group(1), res)      return res
except ImportError:      from ordereddict import OrderedDict  from luigi import six from logging import failure_to_exc_info  class TaskClassException(Exception):
def assert_series_equal(          Compare datetime-like which is comparable ignoring dtype.      check_categorical : bool, default True          Whether to compare internal Categorical exactly.     check_category_order : bool, default False         If True, check that categories are in order.      obj : str, default 'Series'          Specify object name being compared, internally used to show appropriate          assertion message.
from scrapy.utils.ftp import ftp_makedirs_cwd  from scrapy.exceptions import NotConfigured  from scrapy.utils.misc import load_object  from scrapy.utils.python import get_func_args from scrapy.utils.log import failure_to_exc_info  logger = logging.getLogger(__name__)
def format_stdin_to_stdout(      `line_length`, `fast`, `is_pyi`, and `force_py36` arguments are passed to      :func:`format_file_contents`.     src = sys.stdin.read()      dst = src      try:          dst = format_file_contents(src, line_length=line_length, fast=fast, mode=mode)         except ValueError:             pass      try:          dst = format_file_contents(src, line_length=line_length, fast=fast, mode=mode)         except ValueError:             pass      try:          dst = format_file_contents(src, line_length=line_length, fast=fast, mode=mode)         except ValueError:             pass      try:          dst = format_file_contents(src, line_length=line_length, fast=fast, mode=mode)         except ValueError:             pass      try:          dst = format_file_contents(src, line_length=line_length, fast=fast, mode=mode)         except ValueError:             pass      try:          dst = format_file_contents(src, line_length=line_length, fast=fast, mode=mode)         except ValueError:             pass      try:          dst = format_file_contents(src, line_length=line_length, fast=fast, mode=mode)         except ValueError:             pass      try:          dst = format_file_contents(src, line_length=line_length, fast=fast, mode=mode)         except ValueError:             pass      try:          dst = format_file_contents(src, line_length=line_length, fast=fast, mode=mode)         except ValueError:             pass      try:          dst = format_file_contents(src, line_length=line_length, fast=fast, mode=mode)         except ValueError:             pass      try:          dst = format_file_contents(src, line_length=line_length, fast=fast, mode=mode)         except ValueError:             pass      try:          dst = format_file_contents(src, line_length=line_length, fast=fast, mode=mode)         except ValueError:             pass      try:          dst = format_file_contents(src, line_length=line_length, fast=fast, mode=mode)         except ValueError:             pass      try:          dst = format_file_contents(src, line_length=line_length, fast=fast, mode=mode)         except ValueError:             pass      try:          dst = format_file_contents(src, line_length=line_length, fast=fast, mode=mode)         except ValueError:             pass      try:          dst = format_file_contents(src, line_length=line_length, fast=fast, mode=mode)         except ValueError:             pass      try:          dst = format_file_contents(src, line_length=line_length, fast=fast, mode=mode)         except ValueError:             pass      try:          dst = format_file_contents(src, line_length=line_length, fast=fast, mode=mode)         except ValueError:             pass      try:          dst = format_file_contents(src, line_length=line_length, fast=fast, mode=mode)         except ValueError:             pass      try:          dst = format_file_contents(src, line_length=line_length, fast=fast, mode=mode)         except ValueError:             pass      try:          dst = format_file_contents(src, line_length=line_length, fast=fast, mode=mode)         except ValueError:             pass      try:          dst = format_file_contents(src, line_length=line_length, fast=fast, mode=mode)         except ValueError:             pass      try:          dst = format_file_contents(src, line_length=line_length, fast=fast, mode=mode)         except ValueError:             pass      try:          dst = format_file_contents(src, line_length=line_length, fast=fast, mode=mode)         except ValueError:             pass      try:          dst = format_file_contents(src, line_length=line_length, fast=fast, mode=mode)         except ValueError:             pass      try:          dst = format_file_contents(src, line_length=line_length, fast=fast, mode=mode)         except ValueError:             pass      try:          dst = format_file_contents(src, line_length=line_length, fast=fast, mode=mode)          except ValueError:              pass      try:
patterns = (          '^lua: {file}:{line}:',         '^{file} \(line {line}\):',          '^{file}: line {line}:',          '^{file}:{line}',          '^{file}:{line}:{col}',          'at {file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',          '{file} line {line}',
class MailSender(object):              msg = MIMEMultipart()          else:              msg = MIMENonMultipart(*mimetype.split('/', 1))          msg['From'] = self.mailfrom          msg['To'] = commaspace.join(to)          msg['Date'] = formatdate(localtime=True)         else:             msg['Date'] = date(localtime=True)             msg['From'] = self.mailfrom             msg['To'] = commaspace.join(to)             msg['Date'] = formatdate(localtime=True)         else:             msg['Date'] = date(localtime=True)             msg['From'] = self.mailfrom             msg['To'] = commaspace.join(to)             msg['Date'] = formatdate(localtime=True)          else:             msg['Date'] = date(localtime=True)             msg['From'] = self.mailfrom             msg['To'] = commaspace.join(to)             msg['Date'] = formatdate(localtime=True)          else:             msg['Date'] = date(localtime=True)             msg['From'] = self.mailfrom             msg['To'] = commaspace.join(to)             msg['Date'] = formatdate(localtime=True)          else:             msg['Date'] = date(localtime=True)             msg['From'] = self.mailfrom             msg['To'] = commaspace.join(to)             msg['Date'] = formatdate(localtime=True)          else:             msg['Date'] = date(localtime=True)             msg['From'] = self.mailfrom             msg['To'] = commaspace.join(to)             msg['Date'] = formatdate(localtime=True)          else:             msg['Date'] = date(localtime=True)             msg['From'] = self.mailfrom             msg['To'] = commaspace.join(to)             msg['Date'] = formatdate(localtime=True)          else:             msg['Date'] = date(localtime=True)             msg['From'] = self.mailfrom             msg['To'] = commaspace.join(to)             msg['Date'] = formatdate(localtime=True)          else:             msg['Date'] = date(localtime=True)             msg['From'] = self.mailfrom             msg['To'] = commaspace.join(to)             msg['Date'] = formatdate(localtime=True)          else:             msg['Date'] = date(localtime=True)             msg['From'] = self.mailfrom             msg['To'] = commaspace.join(to)             msg['Date'] = formatdate(localtime=True)          else:             msg['Date'] = date(localtime=True)             msg['From'] = self.mailfrom             msg['To'] = commaspace.join(to)             msg['Date'] = formatdate(localtime=True)          else:             msg['Date'] = date(localtime=True)             msg['From'] = self.mailfrom             msg['To'] = commaspace.join(to)             msg['Date'] = formatdate(localtime=True)          else:             msg['Date'] = date(localtime=True)             msg['From'] = self.mailfrom             msg['To'] = commaspace.join(to)             msg['Date'] = formatdate(localtime=True)          else:             msg['Date'] = date(localtime=True)             msg['From'] = self.mailfrom             msg['To'] = commaspace.join(to)             msg['Date'] = formatdate(localtime=True)          else:             msg['Date'] = date(localtime=True)             msg['From'] = self.mailfrom             msg['To'] = commaspace.join(to)             msg['Date'] = formatdate(localtime=True)          else:             msg['Date'] = date(localtime=True)             msg['From'] = self.mailfrom             msg['To'] = commaspace.join(to)             msg['Date'] = formatdate(localtime=True)             msg['From'] = self.mailfrom             msg['To'] = commaspace.join(to)             msg['Date'] = formatdate(localtime=True)
class SimpleRNNCell(Layer):          self.dropout = min(1., max(0., dropout))          self.recurrent_dropout = min(1., max(0., recurrent_dropout))          self.state_size = self.units         self.output_size = self.units          self._dropout_mask = None          self._recurrent_dropout_mask = None         self._build_input_shape = self.units          self._dropout_mask = None          self._recurrent_dropout_mask = None         self._build_output_shape = self.units          self._dropout_mask = None          self._ recurrent_dropout_mask = None          self._build_input_shape = self.units          self._dropout_mask = None          self._ recurrent_dropout_mask = None         self._build_output_shape = self.units          self._dropout_mask = None          self._ recurrent_dropout_mask = None          self._build_input_shape = self.units          self._dropout_mask = None          self._ recurrent_dropout_mask = None          self._build_output_shape = self.units          self._dropout_mask = None          self._ recurrent_dropout_mask = None          self._build_input_shape = self.units          self._dropout_mask = None          self._ recurrent_dropout_mask = None          self._build_output_shape = self.units          self._dropout_mask = None          self._ recurrent_dropout_mask = None          self._build_input_shape = self.units          self._dropout_mask = None          self._ recurrent_dropout_mask = None          self._build_output_shape = self.units          self._dropout_mask = None          self._ recurrent_dropout_mask = None          self._build_input_shape = self.units          self._dropout_mask = None          self._ recurrent_dropout_mask = None          self._build_output_shape = self.units          self._dropout_mask = None          self._ recurrent_dropout_mask = None          self._build_input_shape = self.units          self._dropout_mask = None          self._ recurrent_dropout_mask = None          self._build_output_shape = self.units          self._dropout_mask = None          self._ recurrent_dropout_mask = None          self._build_input_shape = self.units          self._dropout_mask = None          self._ recurrent_dropout_mask = None          self._build_output_shape = self.units          self._dropout_mask = None          self._ recurrent_dropout_mask = None          self._build_input_shape = self.units          self._dropout_mask = None          self._ recurrent_dropout_mask = None          self._build_output_shape = self.units          self._dropout_mask = None          self._ recurrent_dropout_mask = None          self._build_input_shape = self.units          self._dropout_mask = None          self._ recurrent_dropout_mask = None          self._build_output_shape = self.units          self._dropout_mask = None          self._ recurrent_dropout_mask = None          self._build_input_shape = self.units          self._dropout_mask = None          self._ recurrent_dropout_mask = None          self._build_output_shape = self.units          self._dropout_mask = None          self._ recurrent_dropout_mask = None          self._build_input_shape = self.units          self._dropout_mask = None          self._ recurrent_dropout_mask = None          self._build_output_shape = self.units          self._dropout_mask = None          self._ recurrent_dropout_mask = None          self._build_input_shape = self.units          self._dropout_mask = None          self._ recurrent_dropout_mask = None          self._build_output_shape = self.units          self._dropout_mask = None          self._ recurrent_dropout_mask = None          self._build_input_shape = self.units          self._dropout_mask = None          self._ recurrent_dropout_mask = None          self._build_output_shape = self.units          self._dropout_mask = None          self._ recurrent_dropout_mask = None          self._build_input_shape = self.units          self._dropout_mask = None          self._ recurrent_dropout_mask = None          self._build_output_shape = self.units          self._dropout_mask = None          self._ recurrent_dropout_mask = None           self._build_input_shape = self.units          self._dropout_mask = None          self._ recurrent_dropout_mask = None           self._build_input_shape = self.units            self._dropout_mask = None             self._ recurrent_drop
class DataFrame(NDFrame):              other = other._convert(datetime=True, timedelta=True)              if not self.columns.equals(combined_columns):                  self = self.reindex(columns=combined_columns)         elif isinstance(other, list) and not isinstance(other[0], DataFrame):             other = DataFrame(other)             if (self.columns.get_indexer(other.columns) >= 0).all():                 other = other.reindex(columns=self.columns)          from pandas.core.reshape.concat import concat
def jsonable_encoder(              )          return jsonable_encoder(              obj_dict,             exclude_none=exclude_none,              custom_encoder=encoder,              sqlalchemy_safe=sqlalchemy_safe,             exclude_defaults=exclude_defaults,             exclude_none=exclude_none,              custom_encoder=encoder,              sqlalchemy_safe=sqlalchemy_safe,             exclude_none=exclude_none,              custom_encoder=encoder,              sqlalchemy_safe=sqlalchemy_safe,             exclude_defaults=exclude_defaults,             exclude_none=exclude_none,              custom_encoder=encoder,              sqlalchemy_safe=sqlalchemy_safe,             exclude_defaults=exclude_defaults,             exclude_none=exclude_none,              custom_encoder=encoder,              sqlalchemy_safe=sqlalchemy_safe,             exclude_defaults=exclude_defaults,             exclude_none=exclude_none,              custom_encoder=encoder,              sqlalchemy_safe=sqlalchemy_safe,             exclude_defaults=exclude_defaults,             exclude_none=exclude_none,              custom_encoder=encoder,              sqlalchemy_safe=sqlalchemy_safe,             exclude_defaults=exclude_defaults,             exclude_none=exclude_none,              custom_encoder=encoder,              sqlalchemy_safe=sqlalchemy_safe,             exclude_defaults=exclude_defaults,             exclude_none=exclude_none,              custom_encoder=encoder,              sqlalchemy_safe=sqlalchemy_safe,             exclude_defaults=exclude_defaults,             exclude_none=exclude_none,              custom_encoder=encoder,              sqlalchemy_safe=sqlalchemy_safe,             exclude_defaults=exclude_defaults,             exclude_none=exclude_none,              custom_encoder=encoder,              sqlalchemy_safe=sqlalchemy_safe,             exclude_defaults=exclude_defaults,             exclude_none=exclude_none,              custom_encoder=encoder,              sqlalchemy_safe=sqlalchemy_safe,             exclude_defaults=exclude_defaults,             exclude_none=exclude_none,              custom_encoder=encoder,              sqlalchemy_safe=sqlalchemy_safe,             exclude_defaults=exclude_defaults,             exclude_none=exclude_none,              custom_encoder=encoder,              sqlalchemy_safe=sqlalchemy_safe,             exclude_defaults=exclude_defaults,             exclude_none=exclude_none,              custom_encoder=encoder,              sqlalchemy_safe=sqlalchemy_safe,             exclude_defaults=exclude_defaults,             exclude_none=exclude_none,              custom_encoder=encoder,              sqlalchemy_safe=sqlalchemy_safe,             exclude_defaults=exclude_defaults,             exclude_none=exclude_none,              custom_encoder=encoder,              sqlalchemy_safe=sqlalchemy_safe,             exclude_defaults=exclude_defaults,             exclude_none=exclude_none,              custom_encoder=encoder,              sqlalchemy_safe=sqlalchemy_safe,              exclude_defaults=exclude_defaults,              exclude_none=exclude_none,              custom_encoder=encoder,              sqlalchemy_safe=sqlalchemy_safe,              exclude_defaults=exclude_defaults,              exclude_none=exclude_none,              custom_encoder=encoder,              sqlalchemy_safe=sqlalchemy_safe,              exclude_defaults=exclude_defaults,              exclude_none=exclude_none,              custom_encoder=encoder,              sqlalchemy_safe=sqlalchemy_safe,
class TestInsertIndexCoercion(CoercionBase):          )         msg = "cannot insert TimedeltaIndex with incompatible label"          with pytest.raises(TypeError, match=msg):              obj.insert(1, pd.Timestamp("2012-01-01"))         msg = "cannot insert TimedeltaIndex with incompatible label"          with pytest.raises(TypeError, match=msg):              obj.insert(1, 1)          with pytest.raises(TypeError, match=msg):              obj.insert(1, 2)          with pytest.raises(TypeError, match=msg):              obj.insert(1, 3)          with pytest.raises(TypeError, match=msg):              obj.insert(1, 4)          with pytest.raises(TypeError, match=msg):              obj.insert(1, 5)          with pytest.raises(TypeError, match=msg):              obj.insert(1, 6)          with pytest.raises(TypeError, match=msg):              obj.insert(1, 7)          with pytest.raises(TypeError, match=msg):              obj.insert(1, 8)          with pytest.raises(TypeError, match=msg):              obj.insert(1, 9)          with pytest.raises(TypeError, match=msg):              obj.insert(1, 10)          with pytest.raises(TypeError, match=msg):              obj.insert(1, 11)          with pytest.raises(TypeError, match=msg):              obj.insert(1, 12)          with pytest.raises(TypeError, match=msg):              obj.insert(1, 13)          with pytest.raises(TypeError, match=msg):              obj.insert(1, 14)          with pytest.raises(TypeError, match=msg):              obj.insert(1, 15)          with pytest.raises(TypeError, match=msg):              obj.insert(1, 16)          with pytest.raises(TypeError, match=msg):              obj.insert(1, 17)          with pytest.raises(TypeError, match=msg):              obj.insert(1, 18)          with pytest.raises(TypeError, match=msg):              obj.insert(1, 19)          with pytest.raises(TypeError, match=msg):              obj.insert(1, 20)          with pytest.raises(TypeError, match=msg):              obj.insert(1, 21)          with pytest.raises(TypeError, match=msg):              obj.insert(1, 22)          with pytest.raises(TypeError, match=msg):              obj.insert(1, 23)          with pytest.raises(TypeError, match=msg):              obj.insert(1, 24)          with pytest.raises(TypeError, match=msg):              obj.insert(1, 25)          with pytest.raises(TypeError, match=msg):              obj.insert(1, 26)          with pytest.raises(TypeError, match=msg):              obj.insert(1, 27)          with pytest.raises(TypeError, match=msg):              obj.insert(1, 28)          with pytest.raises(TypeError, match=msg):             obj.insert(1, 29)          with pytest.raises(TypeError, match=msg):              obj.insert(1, 30)          with pytest.raises(TypeError, match=msg):              obj.insert(1, 31)          with pytest.raises(TypeError, match=msg):              obj.insert(1, 32)          with pytest.raises(TypeError, match=msg):
class TestSeriesAnalytics:          assert s.is_monotonic is False          assert s.is_monotonic_decreasing is True      def test_unstack(self):         index = MultiIndex(            levels=[["bar", "foo"], ["one", "three", "two"]],            codes=[[1, 1, 0, 0], [0, 1, 0, 2]],         )         s = Series(np.arange(4.0), index=index)         unstacked = s.unstack()         expected = DataFrame(             [[2.0, np.nan, 3.0], [0.0, 1.0, np.nan]],             index=["bar", "foo"],             columns=["one", "three", "two"],         )         tm.assert_frame_equal(unstacked, expected)      @pytest.mark.parametrize("func", [np.any, np.all])      @pytest.mark.parametrize("kwargs", [dict(keepdims=True), dict(out=object())])      @td.skip_if_np_lt("1.15")
class Tracer:          self._write(s)      def __enter__(self):          calling_frame = inspect.currentframe().f_traceback          if not self._is_internal_frame(calling_frame):              calling_frame.f_trace = self.trace              self.target_frames.add(calling_frame)          stack = self.thread_local.__dict__.setdefault('original_trace_functions', [])          stack.append(sys.gettrace())          sys.settrace(self.trace)      def __exit__(self, exc_type, exc_value, exc_traceback):          stack = self.thread_local.original_trace_functions          sys.settrace(stack.pop())          calling_frame = inspect.currentframe().f_back          if not self._is_internal_frame(calling_frame):              calling_frame.f_trace = self.trace              self.target_frames.add(calling_frame)          return      def __enter__(self):          calling_frame = inspect.currentframe().f_traceback          if not self._is_internal_frame(calling_frame):              calling_frame.f_trace = self.trace              self.target_frames.add(calling_frame)          return      def __exit__(self, exc_type, exc_value, exc_traceback):          stack = self.thread_local.original_trace_functions          sys.settrace(stack.pop())          calling_frame = inspect.currentframe().f_back          if not self._is_internal_frame(calling_frame):              calling_frame.f_trace = self.trace              self.target_frames.add(calling_frame)          return      def __enter__(self):          calling_frame = inspect.currentframe().f_traceback          if not self._is_internal_frame(calling_frame):              calling_frame.f_trace = self.trace              self.target_frames.add(calling_frame)          return      def __exit__(self, exc_type, exc_value, exc_traceback):          stack = self.thread_local.original_trace_functions          sys.settrace(stack.pop())          calling_frame = inspect.currentframe().f_back          if not self._is_internal_frame(calling_frame):              calling_frame.f_trace = self.trace              self.target_frames.add(calling_frame)          return      def __enter__(self):          calling_frame = inspect.currentframe().f_traceback          if not self._is_internal_frame(calling_frame):              calling_frame.f_trace = self.trace              self.target_frames.add(calling_frame)          return      def __exit__(self, exc_type, exc_value, exc_traceback):          stack = self.thread_local.original_trace_functions          sys.settrace(stack.pop())          calling_frame = inspect.currentframe().f_back          if not self._is_internal_frame(calling_frame):              calling_frame.f_trace = self.trace              self.target_frames.add(calling_frame)          return      def __enter__(self):          calling_frame = inspect.currentframe().f_traceback          if not self._is_internal_frame(calling_frame):              calling_frame.f_trace = self.trace              self.target_frames.add(calling_frame)          return      def __exit__(self, exc_type, exc_value, exc_traceback):          stack = self.thread_local.original_trace_functions          sys.settrace(stack.pop())          calling_frame = inspect.currentframe().f_back          if not self._is_internal_frame(calling_frame):              calling_frame.f_trace = self.trace              self.target_frames.add(calling_frame)          return       def __enter__(self):          calling_frame = inspect.currentframe().f_traceback          if not self._is_internal_frame(calling_frame):              calling_frame.f_trace = self.trace              self.target_frames.add(calling_frame)          return       def __exit__(self, exc_type, exc_value, exc_traceback):
default: 'top'          from.tight_layout import (             get_renderer, get_subsubplotspec_list, get_tight_layout_figure)          subplotspec_list = get_subplotspec_list(self.axes)          if None in subplotspec_list:             raise ValueError('%s.get_renderer and %s.get_subsubplotspec_list both methods are undefined'                                   % (self.get_renderer(), self.get_subsubplotspec_list))          if None in subplotspec_list:              raise ValueError('%s.get_renderer and %s.get_subsubplotspec_listBoth methods are undefined'                                   % (self.get_renderer(), self.get_subsubplotspec_list))          if None in subplotspec_list:              raise ValueError('%s.get_renderer and %s.get_subsubplotspec_listBoth methods are undefined'                                   % (self.get_renderer(), self.get_subsubplotspec_list))          if None in subplotspec_list:              raise ValueError('%s.get_renderer and %s.get_subsubplotspec_listBoth methods are undefined'                                   % (self.get_renderer(), self.get_subsubplotspec_list))          if None in subplotspec_list:              raise ValueError('%s.get_renderer and %s.get_subsubplotspec_listBoth methods are undefined'                                   % (self.get_renderer(), self.get_subsubplotspec_list))          if None in subplotspec_list:              raise ValueError('%s.get_renderer and %s.get_subsubplotspec_listBoth methods are undefined'                                   % (self.get_renderer(), self.get_subsubplotspec_list))          if None in subplotspec_list:              raise ValueError('%s.get_renderer and %s.get_subsubplotspec_listBoth methods are undefined'                                  % (self.get_renderer(), self.get_subsubplotspec_list))          if None in subplotspec_list:              raise ValueError('%s.get_renderer and %s.get_subsubplotspec_listBoth methods are undefined'                                  % (self.get_renderer(), self.get_subsubplotspec_list))          if None in subplotspec_list:              raise ValueError('%s.get_renderer and %s.get_subsubplotspec_listBoth methods are undefined'                                  % (self.get_renderer(), self.get_subsubplotspec_list))          if None in subplotspec_list:              raise ValueError('%s.get_renderer and %s.get_subsubplotspec_listBoth methods are undefined'                                  % (self.get_renderer(), self.get_subsubplotspec_list))          if None in subplotspec_list:             raise ValueError('%s.get_renderer and %s.get_subsubplotspec_listBoth methods are undefined'                                 % (self.get_renderer(), self.get_subsubplotspec_list))          if None in subplotspec_list:              raise ValueError('%s.get_renderer and %s.get_subsubplotspec_listBoth methods are undefined'                                 % (self.get_renderer(), self.get_subsubplotspec_list))          if None in subplotspec_list:              raise ValueError('%s.get_renderer and %s.get_subsubplotspec_listBoth methods are undefined'                                 % (self.get_renderer(), self.get_subsubplotspec_list))          if None in subplotspec_list:              raise ValueError('%s.get_renderer and %s.get_subsubplotspec_listBoth methods are undefined'                                 % (self.get_renderer(), self.get_subsubplotspec_list))          if None in subplotspec_list:              raise ValueError('%s.get_renderer and %s.get_subsubplotspec_listBoth methods are undefined'                                 % (self.get_renderer(), self.get_subsubplotspec_list))          if None in subplotspec_list:              raise ValueError('%s.get_renderer and %s.get_subsubplotspec_listBoth methods are undefined'                                 % (self.get_renderer(), self.get_subsubplotspec_list))          if None in subplotspec
class HTTP1Connection(httputil.HTTPConnection):              return connection_header!= "close"          elif ("Content-Length" in headers                or headers.get("Transfer-Encoding", "").lower() == "chunked"              or start_line.method in ("HEAD", "GET") and response_length > 0:              return connection_header == "keep-alive"          return False
def _unstack_multiple(data, clocs, fill_value=None):      index = data.index      clocs = [index._get_level_number(i) for i in clocs]      rlocs = [i for i in range(index.nlevels) if i not in clocs]     clocs = [index._get_level_number(i) for i in clocs]      rlocs = [i for i in range(index.nlevels) if i not in clocs]     return clocs     rlocs = [i for i in range(index.nlevels) if i not in clocs]     return clocs     rlocs = [i for i in range(index.nlevels) if i not in clocs]     return clocs     rlocs = [i for i in range(index.nlevels) if i not in clocs]     return clocs     rlocs = [i for i in range(index.nlevels) if i not in clocs]     return clocs     rlocs = [i for i in range(index.nlevels) if i not in clocs]     return clocs     rlocs = [i for i in range(index.nlevels) if i not in clocs]     return clocs     rlocs = [i for i in range(index.nlevels) if i not in clocs]     return clocs     rlocs = [i for i in range(index.nlevels) if i not in clocs]     return clocs     rlocs = [i for i in range(index.nlevels) if i not in clocs]     return clocs     rlocs = [i for i in range(index.nlevels) if i not in clocs]     return clocs     rlocs = [i for i in range(index.nlevels) if i not in clocs]     return clocs     rlocs = [i for i in range(index.nlevels) if i not in clocs]     return clocs     rlocs = [i for i in range(index.nlevels) if i not in clocs]     return clocs     rlocs = [i for i in range(index.nlevels) if i not in clocs]     return clocs     rlocs = [i for i in range(index.nlevels) if i not in clocs]     return clocs     rlocs = [i for i in range(index.nlevels) if i not in clocs]     return clocs     rlocs = [i for i in range(index.nlevels) if i not in clocs]     return clocs     rlocs = [i for i in range(index.nlevels) if i not in clocs]     return clocs     rlocs = [i for i in range(index.nlevels) if i not in clocs]     return clocs     rlocs = [i for i in range(index.nlevels) if i not in clocs]     return clocs     rlocs = [i for i in range(index.nlevels) if i not in clocs]     return clocs     rlocs = [i for i in range(index.nlevels) if i not in clocs]     return clocs     rlocs = [i for i in range(index.nlevels) if i not in clocs]     return clocs     rlocs = [i for i in range(index.nlevels) if i not in clocs]     return clocs     rlocs = [i for i in range(index.nlevels) if i not in clocs]     return clocs     rlocs = [i for i in range(index.nlevels) if i not in clocs]     return clocs     rlocs = [i for i in range(index.nlevels) if i not in clocs]     return clocs     rlocs = [i for i in range(index.nlevels) if i not in clocs]     return clocs     rlocs = [i for i in range(index.nlevels) if i not in clocs]     return clocs     rlocs = [i for i in range(index.nlevels) if i not in clocs]     return clocs     rlocs = [i for i in range(index.nlevels) if i not in clocs]     return clocs     rlocs = [i for i in range(index.nlevels) if i not in clocs]     return clocs     rlocs = [i for i in range(index.nlevels) if i not in clocs]     return clocs     rlocs = [i for i in range(index.nlevels) if i not in clocs]     return clocs     rlocs = [i for i in range(index.nlevels) if i not in clocs]     return clocs     rlocs = [i for i in range(index.nlevels) if i not in clocs]     return clocs     rlocs = [i for i in range(index.nlevels) if i not in clocs]     return clocs     rlocs = [i for i in range(index.nlevels) if i not in clocs]     return clocs     rlocs = [i for i in range(index.nlevels) if i not in clocs]     return clocs     rlocs = [i for i in range(index.nlevels) if i not in clocs]     return clocs     rlocs = [i for i in range(index.nlevels) if i not in clocs]     return clocs     rlocs = [i for i in range(index.nlevels) if i not in clocs]     return clocs     rlocs = [i for i in range(index.nlevels) if i not in clocs]     return clocs     rlocs = [i for i in range(index.nlevels) if i not in clocs]     return clocs     rlocs = [i for i in range(index.nlevels) if i not in clocs]     return clocs     rlocs = [i for i in range(index.nlevels) if i not in clocs]     return clocs     rlocs = [i for i in range(index.nlevels) if i not in clocs]     return clocs     rlocs = [i for i in range(index.nlevels) if i not in clocs]     return clocs     rlocs = [i for i in range(index.nlevels) if i not in clocs]     return clocs     rlocs = [i for i in range(index.nlevels) if i not in clocs]     return clocs     rlocs = [i for i
TEST_MODULES = [      'tornado.test.curl_httpclient_test',      'tornado.test.escape_test',      'tornado.test.gen_test',      'tornado.test.httpclient_test',      'tornado.test.httpserver_test',      'tornado.test.httputil_test',     ]     for module in test_modules:         if isinstance(module, tornado.test.curl_httpclient_test):             continue          if isinstance(module, tornado.test.escape_test):             continue          if isinstance(module, tornado.test.gen_test):             continue          if isinstance(module, tornado.test.httpclient_test):             continue          if isinstance(module, tornado.test.httpserver_test):             continue          if isinstance(module, tornado.test.httputil_test):             continue
class WebSocketHandler(tornado.web.RequestHandler):          if not self._on_close_called:              self._on_close_called = True              self.on_close()          if self.stream is not None:              self.stream.close()      def send_error(self, *args, **kwargs):          if self.stream is None:              self._on_close_called = True              self.on_close()          if self.stream is not None:              self.stream.close()      def set_nodelay(self, x: bool) -> None:         self.stream.set_nodelay(x)      def send_error(self, *args, **kwargs):          if self.stream is None:              self._on_close_called = True              self.on_close()          if self.stream is not None:              self.stream.close()      def set_nodelay(self, x: bool) -> None:         self.stream.set_nodelay(x)      def send_error(self, *args, **kwargs):          if self.stream is None:              self._on_close_called = True              self.on_close()          if self.stream is not None:              self.stream.close()          if self.nodelay:              self.stream.set_nodelay(False)              self._on_close_called = True              self.on_close()      def set_nodelay(self, x: bool) -> None:         self.stream.set_nodelay(x)      def send_error(self, *args, **kwargs):          if self.stream is None:              self._on_close_called = True              self.on_close()          if self.stream is not None:              self.stream.close()          if self.nodelay:              self.stream.set_nodelay(False)              self._on_close_called = True              self.on_close()          if self.stream is not None:              self.stream.close()          if self.nodelay:              self._on_close_called = True              self.on_close()          if self.stream is not None:              self.stream.close()          if self.nodelay:              self._on_close_called = True              self.on_close()          if self.stream is not None:              self.stream.close()          if self.nodelay:              self._on_close_called = True              self.on_close()          if self.stream is not None:              self.stream.close()          if self.nodelay:              self._on_close_called = True              self.on_close()          if self.stream is not None:              self.stream.close()          if self.nodelay:              self._on_close_called = True              self.on_close()          if self.stream is not None:              self.stream.close()          if self.nodelay:              self._on_close_called = True              self.on_close()          if self.stream is not None:              self.stream.close()          if self.nodelay:              self._on_close_called = True              self.on_close()          if self.stream is not None:              self.stream.close()          if self.nodelay:              self._on_close_called = True              self.on_close()          if self.stream is not None:              self.stream.close()           if self.nodelay:              self._on_close_called = True              self.on_close()          if self.stream is not None:             self.stream.close()          if self.nodelay:             self._on_close_called = True             self.on_close()          if self.stream is not None:             self.stream.close()          if self.nodelay:             self._on_close_called = True             self.on_close()          if self.stream is not None:             self.stream.close()          if self.nodelay:
class Tracer:          self.target_codes = set()          self.target_frames = set()          self.thread_local = threading.local()     def __call__(self, function, *args, **kwargs):          self.target_codes.add(function.__code__)          @functools.wraps(function)          @classmethod         def __call__(self, function, *args, **kwargs):          self.target_codes.add(function.__code__)          @functools.wraps(function)          @classmethod         def __call__(self, function, *args, **kwargs):          self.target_codes.add(function.__code__)          @functools.wraps(function)          @classmethod         def __call__(self, function, *args, **kwargs):          self.target_codes.add(function.__code__)          @functools.wraps(function)          @classmethod         def __call__(self, function, *args, **kwargs):         self.target_codes.add(function.__code__)          @functools.wraps(function)          @classmethod           def __call__(self, function, *args, **kwargs):          self.target_codes.add(function.__code__)          @functools.wraps(function)          @classmethod           def __call__(self, function, *args, **kwargs):         self.target_codes.add(function.__code__)          @functools.wraps(function)          @classmethod           def __call__(self, function, *args, **kwargs):          self.target_codes.add(function.__code__)          @functools.wraps(function)          @classmethod           def __call__(self, function, *args, **kwargs):         self.target_codes.add(function.__code__)          @functools.wraps(function)          @classmethod           def __call__(self, function, *args, **kwargs):         self.target_codes.add(function.__code__)          @functools.wraps(function)          @classmethod           def __call__(self, function, *args, **kwargs):         self.target_codes.add(function.__code__)          @functools.wraps(function)          @classmethod           def __call__(self, function, *args, **kwargs):         self.target_codes.add(function.__code__)          @functools.wraps(function)          @classmethod           def __call__(self, function, *args, **kwargs):         self.target_codes.add(function.__code__)          @functools.wraps(function)          @classmethod           def __call__(self, function, *args, **kwargs):         self.target_codes.add(function.__code__)          @functools.wraps(function)          @classmethod           def __call__(self, function, *args, **kwargs):         self.target_codes.add(function.__code__)          @functools.wraps(function)          @classmethod           def __call__(self, function, *args, **kwargs):         self.target_codes.add(function.__code__)          @functools.wraps(function)          @classmethod           def __call__(self, function, *args, **kwargs):         self.target_codes.add(function.__code__)          @functools.wraps(function)          @classmethod           def __call__(self, function, *args, **kwargs):         self.target_codes.add(function.__code__)          @functools.wraps(function)          @classmethod           def __call__(self, function, *args, **kwargs):         self.target_codes.add(function.__code__)          @functools.wraps(function)          @classmethod           def __call__(self, function, *args, **kwargs):         self.target_codes.add(function.__code__)          @functools.wraps(function)          @classmethod           def __call__(self, function, *args, **kwargs):         self.target_codes.add(function.__code__)          @functools.wraps(function)          @classmethod           def __call__(self, function, *args, **kwargs):          self.target_codes.add(function.__code__)          @functools.wraps(function)          @classmethod          def __call__(self, function, *args, **kwargs):          self.target_codes.add(function.__code__)          @functools.wraps(function)          @classmethod           def __call__(self, function, *args, **kwargs):           self.target_codes.add(function.__code__)            @fun
def array_equivalent(left, right, strict_nan=False):                  if not isinstance(right_value, float) or not np.isnan(right_value):                      return False          return True                  if left_value!= right_value:                      return False          return True                  if left_value!= right_value:                      return False          return True                  if left_value!= right_value:                      return False          return True                  if left_value!= right_value:                      return False          return True                  if left_value!= right_value:                      return False          return True                  if left_value!= right_value:                      return False          return True                  if left_value!= right_value:                      return False          return True                  if left_value!= right_value:                      return False          return True                  if left_value!= right_value:                      return False          return True                  if left_value!= right_value:                      return False          return True                  if left_value!= right_value:                      return False          return True                  if left_value!= right_value:                      return False          return True                  if left_value!= right_value:                      return False          return True                  if left_value!= right_value:                     return False          return True                  if left_value!= right_value:                      return False          return True                  if left_value!= right_value:                      return False          return True                  if left_value!= right_value:                      return False          return True                  if left_value!= right_value:                      return False          return True                  if left_value!= right_value:                      return False          return True                  if left_value!= right_value:                      return False          return True                  if left_value!= right_value:                      return False          return True                  if left_value!= right_value:                      return False          return True                 if left_value!= right_value:                      return False          return True                  if left_value!= right_value:                      return False          return True                  if left_value!= right_value:                      return False          return True                  if left_value!= right_value:                      return False          return True                  if left_value!= right_value:                      return False          return True                  if left_value!= right_value:                     return False          return True                 if left_value!= right_value:                     return False          return True                  if left_value!= right_value:                      return False          return True
class LinuxHardware(Hardware):          pool = ThreadPool(processes=min(len(mtab_entries), cpu_count()))          maxtime = globals().get('GATHER_TIMEOUT') or timeout.DEFAULT_GATHER_TIMEOUT          for fields in mtab_entries:              try:                   device, mount, fstype, options = fields[0], fields[1], fields[2], fields[3]             except KeyError:                  pass          for fields in mtab_entries:              try:                   device, mount, fstype, options = fields[0], fields[1], fields[2], fields[3]              except KeyError:                  pass          for fields in mtab_entries:              try:                   device, mount, fstype, options = fields[0], fields[1], fields[2], fields[3]              except KeyError:                  pass          for fields in mtab_entries:              try:                  device, mount, fstype, options = fields[0], fields[1], fields[2], fields[3]              except KeyError:                  pass          for fields in mtab_entries:              try:                  device, mount, fstype, options = fields[0], fields[1], fields[2], fields[3]              except KeyError:                  pass          for fields in mtab_entries:              try:                  device, mount, fstype, options = fields[0], fields[1], fields[2], fields[3]              except KeyError:                  pass          for fields in mtab_entries:              try:                  device, mount, fstype, options = fields[0], fields[1], fields[2], fields[3]              except KeyError:                  pass          for fields in mtab_entries:              try:                  device, mount, fstype, options = fields[0], fields[1], fields[2], fields[3]              except KeyError:                  pass          for fields in mtab_entries:              try:                  device, mount, fstype, options = fields[0], fields[1], fields[2], fields[3]              except KeyError:                  pass          for fields in mtab_entries:              try:                  device, mount, fstype, options = fields[0], fields[1], fields[2], fields[3]              except KeyError:                  pass          for fields in mtab_entries:              try:                  device, mount, fstype, options = fields[0], fields[1], fields[2], fields[3]              except KeyError:                  pass          for fields in mtab_entries:              try:                  device, mount, fstype, options = fields[0], fields[1], fields[2], fields[3]               except KeyError:                  pass          for fields in mtab_entries:              try:                  device, mount, fstype, options = fields[0], fields[1], fields[2], fields[3]              except KeyError:                  pass          for fields in mtab_entries:              try:
def srt_subtitles_timecode(seconds):  def dfxp2srt(dfxp_data):      LEGACY_NAMESPACES = ( ('http: 'http: 'http: 'http:          ]), ('http: 'http:          ]),
class ExecutionEngine(object):          d = self._download(request, spider)          d.addBoth(self._handle_downloader_output, request, spider)          d.addErrback(lambda f: logger.info('Error while handling downloader output',                                             exc_info=failure_to_exc_info(f),                                             extra={'spider': spider}))          d.addBoth(lambda _: slot.remove_request(request))          d.addErrback(lambda f: logger.info('Error while removing request from slot',                                            exc_info=failure_to_exc_info(f),                                             extra={'spider': spider}))          return d      def _handle_downloader_output(self, response, request, spider):          is_reserved_keyword = self._config.get('is_reserved_keyword')         if not is_reserved_keyword:             return             d = self._download(request, spider)             d.addBoth(self._handle_downloader_output, request, spider)             d.addErrback(lambda f: logger.info('Error while handling downloader output',                                            exc_info=failure_to_exc_info(f),                                            extra={'spider': spider}))          return d      def _handle_downloader_output(self, response, request, spider):          is_reserved_keyword = self._config.get('is_reserved_keyword')         if not is_reserved_keyword:             return             d = self._download(request, spider)             d.addBoth(self._handle_downloader_output, request, spider)             d.addErrback(lambda f: logger.info('Error while handling downloader output',                                           exc_info=failure_to_exc_info(f),                                           extra={'spider': spider}))          return d      def _handle_downloader_output(self, response, request, spider):          is_reserved_keyword = self._config.get('is_reserved_keyword')         if not is_reserved_keyword:             return             d = self._download(request, spider)             d.addBoth(self._handle_downloader_output, request, spider)             d.addErrback(lambda f: logger.info('Error while handling downloader output',                                          exc_info=failure_to_exc_info(f),                                           extra={'spider': spider}))          return d      def _handle_downloader_output(self, response, request, spider):         is_reserved_keyword = self._config.get('is_reserved_keyword')         if not is_reserved_keyword:             return             d = self._download(request, spider)             d.addBoth(self._handle_downloader_output, request, spider)             d.addErrback(lambda f: logger.info('Error while handling downloader output',                                          exc_info=failure_to_exc_info(f),                                         extra={'spider': spider}))          return d      def _handle_downloader_output(self, response, request, spider):         is_reserved_keyword = self._config.get('is_reserved_keyword')         if not is_reserved_keyword:             return             d = self._download(request, spider)             d.addBoth(self._handle_download

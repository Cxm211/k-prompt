class GroupBy(_GroupBy):           ).sortlevel()          if self.as_index:             d = {self.obj._get_axis_name(self.axis): index, "copy": False}             axis = self.axis.name             return output.reindex(**d)         elif self.axis == axis:             d = {self.obj._get_axis_name(self.axis): index, "copy": False}             axis = axis.name             return output.reindex(**d)
class HiveCommandClient(HiveClient):          if partition is None:              stdout = run_hive_cmd('use {0}; show tables like "{1}";'.format(database, table))             return stdout and table in stdout          else:             return table
class BinGrouper(BaseGrouper):              ngroups,          )      @cache_readonly      def result_index(self):          if len(self.binlabels)!= 0 and isna(self.binlabels[-1]):              return -1 * np.ones(len(self.binlabels)) - 1
class DataFrame(NDFrame):          dtype: object          nv.validate_transpose(args, dict())         return super().transpose(1, 0, copy=False)      T = property(transpose)         if isinstance(dtype, np.ndarray) and dtype.ndim > 1:             raise ValueError(f"Cannot set values with ndim > {dtype.shape}")         return dtype.transpose(1, 0, copy=False)      T = property(transpose)         if isinstance(dtype, np.ndarray) and dtype.ndim > 1:             raise ValueError(f"Cannot set values with ndim > {dtype.shape}")         return dtype.transpose(1, 0, copy=False)      T = property(transpose)         if isinstance(dtype, np.ndarray) and dtype.ndim > 1:             raise ValueError(f"Cannot set values with ndim > {dtype.shape}")         return dtype.transpose(1, 0, copy=False)      T = property(transpose)         if isinstance(dtype, np.ndarray) and dtype.ndim > 1:             raise ValueError(f"Cannot set values with ndim > {dtype.shape}")         return dtype.transpose(1, 0, copy=False)      T = property(transpose)         if isinstance(dtype, np.ndarray) and dtype.ndim > 1:             raise ValueError(f"Cannot set values with ndim > {dtype.shape}")         return dtype.transpose(1, 0, copy=False)      T = property(transpose)         if isinstance(dtype, np.ndarray) and dtype.ndim > 1:             raise ValueError(f"Cannot set values with ndim > {dtype.shape}")         return dtype.transpose(1, 0, copy=False)      T = property(transpose)         if isinstance(dtype, np.ndarray) and dtype.ndim > 1:             raise ValueError(f"Cannot set values with ndim > {dtype.shape}")         return dtype.transpose(1, 0, copy=False)      T = property(transpose)         if isinstance(dtype, np.ndarray) and dtype.ndim > 1:             raise ValueError(f"Cannot set values with ndim > {dtype.shape}")         return dtype.transpose(1, 0, copy=False)      T = property(transpose)         if isinstance(dtype, np.ndarray) and dtype.ndim > 1:             raise ValueError(f"Cannot set values with ndim > {dtype.shape}")         return dtype.transpose(1, 0, copy=False)      T = property(transpose)         if isinstance(dtype, np.ndarray) and dtype.ndim > 1:             raise ValueError(f"Cannot set values with ndim > {dtype.shape}")         return dtype.transpose(1, 0, copy=False)      T = property(transpose)         if isinstance(dtype, np.ndarray) and dtype.ndim > 1:             raise ValueError(f"Cannot set values with ndim > {dtype.shape}")         return dtype.transpose(1, 0, copy=False)      T = property(transpose)         if isinstance(dtype, np.ndarray) and dtype.ndim > 1:             raise ValueError(f"Cannot set values with ndim > {dtype.shape}")         return dtype.transpose(1, 0, copy=False)      T = property(transpose)         if isinstance(dtype, np.ndarray) and dtype.ndim > 1:             raise ValueError(f"Cannot set values with ndim > {dtype.shape}")         return dtype.transpose(1, 0, copy=False)      T = property(transpose)         if isinstance(dtype, np.ndarray) and dtype.ndim > 1:             raise ValueError(f"Cannot set values with ndim > {dtype.shape}")         return dtype.transpose(1, 0, copy=False)      T = property(transpose)         if isinstance(dtype, np.ndarray) and dtype.ndim > 1:             raise ValueError(f"Cannot set values with ndim > {dtype.shape}")         return dtype.transpose(1, 0, copy=False)      T = property(transpose)         if isinstance(dtype, np.ndarray) and dtype.ndim > 1:             raise ValueError(f"Cannot set values with ndim > {dtype.shape}")         return dtype.transpose(1, 0, copy=False)      T = property(transpose)         if isinstance(dtype, np.ndarray) and dtype.ndim > 1:             raise ValueError(f"Cannot set values with ndim > {dtype.shape}")         return dtype.transpose(1, 0, copy=False)      T = property(trans
from difflib import get_close_matches  from functools import wraps  import shelve import io  from decorator import decorator  import tempfile  import os  import sys import errno  from difflib import get_close_matches  from functools import wraps  import shelve  from decorator import decorator  import tempfile  import os  import errno import traceback  from difflib import get_close_matches  from functools import wraps  import shelve  from decorator import decorator  import tempfile  import os  import sys  from traceback import failure_to_exc_info  from difflib import get_close_matches  from functools import wraps  import shelve  from decorator import decorator  import tempfile  import os import errno  from traceback import failure_to_exc_info  from difflib import get_close_matches  from functools import wraps  import shelve  from decorator import decorator  import tempfile  import os  import errno import six  from difflib import get_close_matches  from functools import wraps  import shelve  from decorator import decorator  import tempfile  import os  import sys  from traceback import failure_to_exc_info  from difflib import get_close_matches  from functools import wraps  import shelve  from decorator import decorator  import tempfile  import os  import errno  import six  from traceback import failure_to_exc_info  from difflib import get_close_matches  from functools import wraps  import shelve  from decorator import decorator  import tempfile  import os  import errno  import six  from traceback import failure_to_exc_info  from difflib import get_close_matches  from functools import wraps  import shelve  from decorator import decorator  import tempfile  import os  import errno  import six  from traceback import failure_to_exc_info  from difflib import get_close_matches  from functools import wraps  import shelve  from decorator import decorator  import tempfile  import os  import errno  import six  from traceback import failure_to_exc_info  from difflib import get_close_matches  from functools import wraps  import shelve  from decorator import decorator  import tempfile  import os  import errno  import six  from traceback import failure_to_exc_info  from difflib import get_close_matches  from functools import wraps  import shelve  from decorator import decorator  import tempfile  import os  import errno  import six  from traceback import failure_to_exc_info  from difflib import get_close_matches  from functools import wraps  import shelve  from decorator import decorator  import tempfile  import os  import errno  import six  from traceback import failure_to_exc_info  from difflib import get_close_matches  from functools import wraps  import shelve  from decorator import decorator  import tempfile  import os  import errno  import six  from traceback import failure_to_exc_info  from difflib import get_close_matches  from functools import wraps  import shelve  from decorator import decorator  import tempfile  import os  import errno  import six  from traceback import failure_to_exc_info  from difflib import get_close_matches  from functools import wraps  import shelve  from decorator import decorator  import tempfile  import os  import errno  import six  from traceback import failure_to_exc_info  from difflib import get_close_matches  from functools import wraps  import shelve  from decorator import decorator  import tempfile  import os  import errno  import six  from traceback import failure_to_exc_info  from difflib import get_close_matches  from functools import wraps  import shelve  from decorator import decorator  import tempfile  import os  import errno  import six  from traceback import failure_to_exc_info  from difflib import get_close_matches  from functools import wraps  import shelve  from decorator import decorator  import tempfile  import os  import errno  import six  from traceback import failure_to_exc_info  from difflib import get_close_matches  from functools import wraps  import shelve  from decorator import decorator  import tempfile  import os  import errno  import six  from traceback import failure_to_exc_info  from difflib import get_close_matches  from functools import wraps  import shelve  from decorator import decorator  import tempfile  import os  import errno  import six  from traceback import failure_to_exc_info  from difflib import get_close_matches  from functools import wraps  import shelve  from decorator import decorator  import tempfile  import os  import errno  import six  from traceback import failure_to_exc_info  from difflib import get_close_matches  from functools import wraps  import shelve  from decorator import decorator  import tempfile  import os  import errno  import six  from traceback import failure_to_exc_info  from difflib import get_close_matches  from functools import wraps  import shelve  from decorator import decorator  import tempfile  import os  import errno  import six  from traceback import failure_to_exc_info  from difflib import get_close_matches  from functools import wraps  import shelve  from decorator import decorator  import tempfile  import os  import errno  import six  from traceback import failure_to_exc_info  from difflib import get_close_matches  from functools import wraps  import shelve  from decorator import decorator  import tempfile  import os  import errno  import six  from traceback import failure_to_exc_info  from difflib import get_close_matches  from functools import wraps  import shelve  from decorator import decorator  import tempfile  import os  import errno  import six  from traceback import failure_to_exc_info  from difflib import get_close_matches  from functools import wraps  import shelve  from decorator import decorator  import tempfile  import os  import errno  import six  from traceback import failure_to_exc_info  from difflib import get_close_matches  from functools import wraps  import shelve  from decorator import decorator  import tempfile  import os  import errno  import six  from traceback import failure_to_exc_info  from difflib import get_close_matches  from functools import wraps  import shelve  from decorator import decorator  import tempfile  import os  import errno  import six  from traceback import failure_to_exc_info  from difflib import get_close_matches  from functools import wraps  import shelve  from decorator import decorator  import tempfile  import os  import errno  import six  from traceback import failure_to_exc_info  from difflib import get_close_matches  from functools import wraps  import shelve  from decorator import decorator  import tempfile  import os  import errno  import six  from traceback import failure_to_exc_info  from difflib import get_close_matches  from functools import wraps  import shelve  from decorator import decorator  import tempfile  import os  import errno  import six  from traceback import failure_to_exc
def target_version_option_callback(  @click.option(      "--config",      type=click.Path(         exists=False, file_okay=True, dir_okay=False, readable=True, allow_dash=False,
class Sanic:                  if _rn not in self.named_response_middleware:                      self.named_response_middleware[_rn] = deque()                  if middleware not in self.named_response_middleware[_rn]:                      self.named_response_middleware[_rn].append(middleware)      def middleware(self, middleware_or_request):         if isinstance(middleware_or_request, BaseModel):             return middleware_or_request.dict()         else:             return middleware_or_request      def __init__(self, *args, **kwargs):         super(Sanic, self).__init__(*args, **kwargs)      def middleware(self, middleware_or_request):         if isinstance(middleware_or_request, BaseModel):             return middleware_or_request.dict()         else:             return middleware_or_request      def __init__(self, *args, **kwargs):         super(Sanic, self).__init__(*args, **kwargs)      def middleware(self, middleware_or_request):         if isinstance(middleware_or_request, BaseModel):             return middleware_or_request.dict()         else:             return middleware_or_request      def __init__(self, *args, **kwargs):         super(Sanic, self).__init__(*args, **kwargs)      def middleware(self, middleware_or_request):         if isinstance(middleware_or_request, BaseModel):             return middleware_or_request.dict()         else:             return middleware_or_request      def __init__(self, *args, **kwargs):         super(Sanic, self).__init__(*args, **kwargs)      def middleware(self, middleware_or_request):         if isinstance(middleware_or_request, BaseModel):             return middleware_or_request.dict()         else:             return middleware_or_request      def __init__(self, *args, **kwargs):         super(Sanic, self).__init__(*args, **kwargs)      def middleware(self, middleware_or_request):         if isinstance(middleware_or_request, BaseModel):             return middleware_or_request.dict()         else:             return middleware_or_request      def __init__(self, *args, **kwargs):         super(Sanic, self).__init__(*args, **kwargs)      def middleware(self, middleware_or_request):         if isinstance(middleware_or_request, BaseModel):             return middleware_or_request.dict()         else:             return middleware_or_request      def __init__(self, *args, **kwargs):         super(Sanic, self).__init__(*args, **kwargs)      def middleware(self, middleware_or_request):         if isinstance(middleware_or_request, BaseModel):             return middleware_or_request.dict()         else:             return middleware_or_request      def __init__(self, *args, **kwargs):         super(Sanic, self).__init__(*args, **kwargs)      def middleware(self, middleware_or_request):         if isinstance(middleware_or_request, BaseModel):             return middleware_or_request.dict()         else:             return middleware_or_request      def __init__(self, *args, **kwargs):         super(Sanic, self).__init__(*args, **kwargs)      def middleware(self, middleware_or_request):         if isinstance(middleware_or_request, BaseModel):             return middleware_or_request.dict()         else:             return middleware_or_request     def __init__(self, *args, **kwargs):         super(Sanic, self).__init__(*args, **kwargs)      def middleware(self, middleware_or_request):         if isinstance(middleware_or_request, BaseModel):             return middleware_or_request.dict()         else:             return middleware_or_request     def __init__(self, *args, **kwargs):         super(Sanic, self).__init__(*args, **kwargs)      def middleware(self, middleware_or_request
class Model(Container):                  enqueuer.start(workers=workers, max_queue_size=max_queue_size)                  output_generator = enqueuer.get()              else:                  output_generator = generator              if verbose == 1:                  progbar = Progbar(                     target=steps,
def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),      else:          strides = (1, 1) + strides     x = tf.nn.conv2d_transpose(x, kernel, output_shape, strides,
class XportReader(abc.Iterator):          if isinstance(filepath_or_buffer, (str, bytes)):              self.filepath_or_buffer = open(filepath_or_buffer, "rb")          else:             contents = filepath_or_buffer.read()             try:                 contents = contents.decode(self._encoding)             except UnicodeDecodeError:                 pass             self.filepath_or_buffer = BytesIO(contents)          self._read_header()
class LocalCache(collections.OrderedDict):          self.limit = limit      def __setitem__(self, key, value):         self[key] = value          while len(self) >= self.limit:             self.popitem(last=False)          super(LocalCache, self).__setitem__(key, value)          self[key] = value
dependency tree to find the noun phrase they are referring to – for example:  $9.4 million --> Net income.  Compatible with: spaCy v2.0.0+  from __future__ import unicode_literals, print_function  $9.4 million --> Net income.
class AsyncioServer:              task = asyncio.ensure_future(coro, loop=self.loop)              return task      def __await__(self):          task = asyncio.ensure_future(self.serve_coro, loop=self.loop)             return task         task = asyncio.ensure_future(coro, loop=self.loop)             return task         task = asyncio.ensure_future(coro, loop=self.loop)             return task         task = asyncio.ensure_future(coro, loop=self.loop)             return task         task = asyncio.ensure_future(coro, loop=self.loop)             return task         task = asyncio.ensure_future(coro, loop=self.loop)             return task         task = asyncio.ensure_future(coro, loop=self.loop)             return task         task = asyncio.ensure_future(coro, loop=self.loop)             return task         task = asyncio.ensure_future(coro, loop=self.loop)             return task         task = asyncio.ensure_future(coro, loop=self.loop)             return task         task = asyncio.ensure_future(coro, loop=self.loop)             return task         task = asyncio.ensure_future(coro, loop=self.loop)             return task         task = asyncio.ensure_future(coro, loop=self.loop)             return task         task = asyncio.ensure_future(coro, loop=self.loop)             return task         task = asyncio.ensure_future(coro, loop=self.loop)             return task         task = asyncio.ensure_future(coro, loop=self.loop)          return task         task = asyncio.ensure_future(coro, loop=self.loop)          return task         task = asyncio.ensure_future(coro, loop=self.loop)          return task         task = asyncio.ensure_future(coro, loop=self.loop)          return task         task = asyncio.ensure_future(coro, loop=self.loop)          return task         task = asyncio.ensure_future(coro, loop=self.loop)          return task         task = asyncio.ensure_future(coro, loop=self.loop)          return task         task = asyncio.ensure_future(coro, loop=self.loop)          return task         task = asyncio.ensure_future(coro, loop=self.loop)          return task         task = asyncio.ensure_future(coro, loop=self.loop)          return task         task = asyncio.ensure_future(coro, loop=self.loop)          return task         task = asyncio.ensure_future(coro, loop=self.loop)          return task         task = asyncio.ensure_future(coro, loop=self.loop)          return task         task = asyncio.ensure_future(coro, loop=self.loop)          return task         task = asyncio.ensure_future(coro, loop=self.loop)          return task         task = asyncio.ensure_future(coro, loop=self.loop)          return task         task = asyncio.ensure_future(coro, loop=self.loop)          return task         task = asyncio.ensure_future(coro, loop=self.loop)          return task         task = asyncio.ensure_future(coro, loop=self.loop)          return task         task = asyncio.ensure_future(coro, loop=self.loop)          return task         task = asyncio.ensure_future(coro, loop=self.loop)          return task         task = asyncio.ensure_future(coro, loop=self.loop)          return task         task = asyncio.ensure_future(coro, loop=self.loop)          return task         task = asyncio.ensure_future(coro, loop=self.loop)          return task         task = asyncio.ensure_future(coro, loop=self.loop)          return task         task = asyncio.ensure_future(coro, loop=self.loop)          return task         task = asyncio.ensure_future(coro, loop=self.loop)
def deconv_length(dim_size, stride_size, kernel_size, padding, output_padding):      if dim_size is None:          return None     dilation_rate = 1      if output_padding is None:          if padding == 'valid':              if dilation_rate == 1:                  return np.ones(shape=dim_size, dtype=np.int64)             else:                  return np.ones(shape=dim_size, dtype=np.int64)          else:              return np.ones(shape=dim_size, dtype=np.int64)      if output_padding is None:          if dilation_rate == 1:              return np.ones(shape=dim_size, dtype=np.int64)          else:              return np.ones(shape=dim_size, dtype=np.int64)      if dilation_rate == 1:          return np.ones(shape=dim_size, dtype=np.int64)      if output_padding is None:          return np.ones(shape=dim_size, dtype=np.int64)      if dilation_rate == 1:          return np.ones(shape=dim_size, dtype=np.int64)      if output_padding is None:          return np.ones(shape=dim_size, dtype=np.int64)      if dilation_rate == 1:          return np.ones(shape=dim_size, dtype=np.int64)      if output_padding is None:          return np.ones(shape=dim_size, dtype=np.int64)      if dilation_rate == 1:          return np.ones(shape=dim_size, dtype=np.int64)      if output_padding is None:          return np.ones(shape=dim_size, dtype=np.int64)      if dilation_rate == 1:          return np.ones(shape=dim_size, dtype=np.int64)      if output_padding is None:          return np.ones(shape=dim_size, dtype=np.int64)      if dilation_rate == 1:          return np.ones(shape=dim_size, dtype=np.int64)      if output_padding is None:          return np.ones(shape=dim_size, dtype=np.int64)      if dilation_rate == 1:          return np.ones(shape=dim_size, dtype=np.int64)      if output_padding is None:          return np.ones(shape=dim_size, dtype=np.int64)      if dilation_rate == 1:          return np.ones(shape=dim_size, dtype=np.int64)      if output_padding is None:          return np.ones(shape=dim_size, dtype=np.int64)      if dilation_rate == 1:          return np.ones(shape=dim_size, dtype=np.int64)      if output_padding is None:          return np.ones(shape=dim_size, dtype=np.int64)      if dilation_rate == 1:          return np.ones(shape=dim_size, dtype=np.int64)      if output_padding is None:          return np.ones(shape=dim_size, dtype=np.int64)      if dilation_rate == 1:          return np.ones(shape=dim_size, dtype=np.int64)      if output_padding is None:          return np.ones(shape=dim_size, dtype=np.int64)      if dilation_rate == 1:          return np.ones(shape=dim_size, dtype=np.int64)      if output_padding is None:          return np.ones(shape=dim_size, dtype=np.int64)      if dilation_rate == 1:          return np.ones(shape=dim_size, dtype=np.int64)      if output_padding is None:         return np.ones(shape=dim_size, dtype=np.int64)      if dilation_rate == 1:          return np.ones(shape=dim_size, dtype=np.int64)      if output_padding is None:          return np.ones(shape=dim_size, dtype=np.int64)      if dilation_rate == 1:          return np.ones(shape=dim_size, dtype=np.int64)      if output_padding is None:          return np.ones(shape=dim_size, dtype=np.int64)      if dilation_rate == 1:          return np.ones(shape=dim_size, dtype=np.int64)      if output_padding is None:          return np.ones(shape=dim_size, dtype=np.int64)      if dilation_rate == 1:          return np.ones(shape=dim_size, dtype=np.int64)      if output_padding is None:          return np.ones(shape=dim_size, dtype=np.int64)      if dilation_rate ==
def fit_generator(model,             elif val_gen:                 val_data = validation_data                 if isinstance(val_data, Sequence):                    val_enqueuer_gen = iter_sequence_infinite(generator)                 else:                     val_enqueuer_gen = val_data             elif isinstance(val_data, list):                val_enqueuer_gen = iter_sequence_infinite(generator)                else:                    val_enqueuer_gen = val_data             elif isinstance(val_data, tuple):                val_enqueuer_gen = iter_sequence_infinite(generator)                else:                    val_enqueuer_gen = val_data             else:                yield val_enqueuer_gen def fit_generator(model,             elif val_gen:                 val_data = validation_data                 if isinstance(val_data, Sequence):                    val_enqueuer_gen = iter_sequence_infinite(generator)                  else:                      val_enqueuer_gen = val_data             elif isinstance(val_data, list):                val_enqueuer_gen = iter_sequence_infinite(generator)                else:                     val_enqueuer_gen = val_data             elif isinstance(val_data, tuple):                val_enqueuer_gen = iter_sequence_infinite(generator)                else:                     val_enqueuer_gen = val_data             else:                yield val_enqueuer_gen
class FastParquetImpl(BaseImpl):          if partition_cols is not None:              kwargs["file_scheme"] = "hive"         if is_s3_url(path):              path, _, _, _ = get_filepath_or_buffer(path,
class NumpyArrayIterator(Iterator):                              dtype=K.floatx())           for i, j in enumerate(index_array):               x = self.x[j]               x = self.image_data_generator.random_transform(x.astype(K.floatx()))               x = self.image_data_generator.standardize(x)              batch_x[i] = x
class Series(base.IndexOpsMixin, generic.NDFrame):          from pandas.core.reshape.concat import concat          if isinstance(to_append, (list, tuple)):             to_concat = [self] + to_append          else:              to_concat = [self, to_append, axis=0]          return concat(
class HTTPRequest(HTTPMessage):          )          headers = dict(self._orig.headers)         if 'Host' not in headers:              headers['Host'] = url.netloc.split('@')[-1]          headers = ['%s: %s' % (name, value) for name, value in headers]          return headers
class TestProcessProtocol(protocol.ProcessProtocol):      def __init__(self):          self.deferred = defer.Deferred()         self.out = ''         self.err = ''          self.exitcode = None         self.break_cycles = False      def outReceived(self, data):         if self.break_cycles:             raise exc_info() from sys.exc_info()         else:             return data      def emit(self, data):         if self.break_cycles:             raise exc_info() from sys.exc_info()         else:             return data
class _Window(PandasObject, SelectionMixin):              except (ValueError, TypeError):                  raise TypeError("cannot handle this type -> {0}".format(values.dtype))         values[np.isinf(values)] = np.NaN          return values     def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:         return isinstance(dtype, np.ndarray)      def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:         return isinstance(dtype, np.ndarray)      def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:         return isinstance(dtype, np.ndarray)      def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:         return isinstance(dtype, np.ndarray)      def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:         return isinstance(dtype, np.ndarray)      def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:         return isinstance(dtype, np.ndarray)      def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:         return isinstance(dtype, np.ndarray)      def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:         return isinstance(dtype, np.ndarray)      def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:         return isinstance(dtype, np.ndarray)      def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:         return isinstance(dtype, np.ndarray)      def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:         return isinstance(dtype, np.ndarray)      def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:         return isinstance(dtype, np.ndarray)      def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:         return isinstance(dtype, np.ndarray)      def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:         return isinstance(dtype, np.ndarray)      def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:         return isinstance(dtype, np.ndarray)      def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:         return isinstance(dtype, np.ndarray)      def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:         return isinstance(dtype, np.ndarray)      def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:         return isinstance(dtype, np.ndarray)      def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:         return isinstance(dtype, np.ndarray)      def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:         return isinstance(dtype, np.ndarray)      def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:         return isinstance(dtype, np.ndarray)      def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:         return isinstance(dtype, np.ndarray)      def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:         return isinstance(dtype, np.ndarray)      def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:         return isinstance(dtype, np.ndarray)      def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:         return isinstance(dtype, np.ndarray)      def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:         return isinstance(dtype, np.ndarray)      def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:         return isinstance(dtype, np.ndarray)      def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:         return isinstance(dtype, np.ndarray)      def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:         return isinstance(dtype, np.ndarray)      def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:         return isinstance(dtype, np.ndarray)      def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:         return isinstance(dtype, np.ndarray)      def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:         return isinstance(dtype, np.ndarray)      def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:         return isinstance(dtype, np.ndarray)      def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:         return isinstance(dtype
class BaseComparisonOpsTests(BaseOpsUtil):              assert result is NotImplemented          else:              raise pytest.skip(f"{type(data).__name__} does not implement __eq__")     def test_comparison_dtype(self):         data = np.array([1, 2, 3])         result = type(data)(data)         expected = data.__class__.__eq__(result)         tm.assert_index_equal(result, expected)         result = type(data)(data)         expected = data.__class__.__eq__(result)         tm.assert_index_equal(result, expected)         result = type(data)(data)         expected = data.__class__.__eq__(result)         tm.assert_index_equal(result, expected)         result = type(data)(data)         expected = data.__class__.__eq__(result)         tm.assert_index_equal(result, expected)         result = type(data)(data)         expected = data.__class__.__eq__(result)         tm.assert_index_equal(result, expected)         result = type(data)(data)         expected = data.__class__.__eq__(result)         tm.assert_index_equal(result, expected)         result = type(data)(data)         expected = data.__class__.__eq__(result)         tm.assert_index_equal(result, expected)         result = type(data)(data)         expected = data.__class__.__eq__(result)         tm.assert_index_equal(result, expected)         result = type(data)(data)         expected = data.__class__.__eq__(result)         tm.assert_index_equal(result, expected)         result = type(data)(data)         expected = data.__class__.__eq__(result)         tm.assert_index_equal(result, expected)         result = type(data)(data)         expected = data.__class__.__eq__(result)         tm.assert_index_equal(result, expected)         result = type(data)(data)         expected = data.__class__.__eq__(result)         tm.assert_index_equal(result, expected)         result = type(data)(data)         expected = data.__class__.__eq__(result)         tm.assert_index_equal(result, expected)         result = type(data)(data)         expected = data.__class__.__eq__(result)         tm.assert_index_equal(result, expected)         result = type(data)(data)         expected = data.__class__.__eq__(result)         tm.assert_index_equal(result, expected)         result = type(data)(data)         expected = data.__class__.__eq__(result)         tm.assert_index_equal(result, expected)         result = type(data)(data)         expected = data.__class__.__eq__(result)         tm.assert_index_equal(result, expected)         result = type(data)(data)         expected = data.__class__.__eq__(result)         tm.assert_index_equal(result, expected)         result = type(data)(data)         expected = data.__class__.__eq__(result)         tm.assert_index_equal(result, expected)         result = type(data)(data)         expected = data.__class__.__eq__(result)         tm.assert_index_equal(result, expected)         result = type(data)(data)         expected = data.__class__.__eq__(result)         tm.assert_index_equal(result, expected)         result = type(data)(data)         expected = data.__class__.__eq__(result)         tm.assert_index_equal(result, expected)         result = type(data)(data)         expected = data.__class__.__eq__(result)         tm.assert_index_equal(result, expected)         result = type(data)(data)         expected = data.__class__.__eq__(result)         tm.assert_index_equal(result, expected)         result = type(data)(data)         expected = data.__class__.__eq__(result)         tm.assert_index_equal(result, expected)         result = type(data)(data)         expected = data.__class__.__eq__(result)         tm.assert_index_equal(result, expected)         result = type(data)(data)         expected = data.__class__.__eq__(result)         tm.assert_index_equal(result, expected)
class CentralPlannerScheduler(Scheduler):          tasks.sort(key=self._rank(), reverse=True)          for task in tasks:             in_workers = assistant or worker in task.workers              if task.status == 'RUNNING' and task.worker_running():
def jsonable_encoder(                     exclude=exclude,                     by_alias=by_alias,                     exclude_unset=exclude_unset,                    exclude_defaults=exclude_defaults,                    exclude_none=exclude_none,                     custom_encoder=custom_encoder,                      sqlalchemy_safe=sqlalchemy_safe,
def unified_timestamp(date_str, day_first=True):      date_str = date_str.replace(',','')     if re.search(r'(?i)PM', date_str):         return datetime.timedelta(hours=12 if re.search(r'(?i)PM', date_str) else 0)      timezone, date_str = extract_timezone(date_str)      return timezone, date_str
class ContractsManager(object):          def eb_wrapper(failure):              case = _create_testcase(method, 'errback')             exc_info = failure.value, failure.type, failure.getTracebackObject()              results.addError(case, exc_info)          request.callback = cb_wrapper          return results
class APIRouter(routing.Router):              response_model_exclude_unset=bool(                  response_model_exclude_unset or response_model_skip_defaults              ),             response_model_exclude_defaults=response_model_exclude_defaults,             response_model_exclude_none=response_model_exclude_none,              include_in_schema=include_in_schema,              response_class=response_class or self.default_response_class,              name=name,          )
def format_file_in_place(          return False      if write_back == write_back.YES:         with open(src, "w", encoding=src_buffer.encoding,
def should_series_dispatch(left, right, op):          return True     if is_datetimelike(ldtype) and is_object_dtype(rdtype):          return True      return False
def run_script(script_path, cwd='.'):          shell=run_thru_shell,          cwd=cwd,      )     return proc.wait()  def run_script_with_context(script_path, cwd, context):     return script_path.with_context(context)  def run_script(script_path, cwd='.'):          shell=run_thru_shell,          cwd=cwd,      )     return script_path.wait()  def run_script_with_context(script_path, cwd, context):     return script_path.with_context(context)  def run_script(script_path, cwd='.'):          shell=run_thru_shell,          cwd=cwd,      )     return script_path.wait()  def run_script_with_context(script_path, cwd, context):     return script_path.with_context(context)  def run_script(script_path, cwd='.'):          shell=run_thru_shell,          cwd=cwd,      )     return script_path.wait()  def run_script_with_context(script_path, cwd, context):     return script_path.with_context(context)  def run_script(script_path, cwd='.'):          shell=run_thru_shell,          cwd=cwd,      )     return script_path.wait()  def run_script_with_context(script_path, cwd, context):     return script_path.with_context(context)  def run_script(script_path, cwd='.'):          shell=run_thru_shell,          cwd=cwd,      )     return script_path.wait()  def run_script_with_context(script_path, cwd, context):     return script_path.with_context(context)  def run_script(script_path, cwd='.'):          shell=run_thru_shell,          cwd=cwd,      )     return script_path.wait()  def run_script_with_context(script_path, cwd, context):     return script_path.with_context(context)  def run_script(script_path, cwd='.'):          shell=run_thru_shell,          cwd=cwd,      )     return script_path.wait()  def run_script_with_context(script_path, cwd, context):     return script_path.with_context(context)  def run_script(script_path, cwd='.'):          shell=run_thru_shell,          cwd=cwd,      )     return script_path.wait()  def run_script_with_context(script_path, cwd, context):     return script_path.with_context(context)  def run_script(script_path, cwd='.'):          shell=run_thru_shell,          cwd=cwd,      )     return script_path.wait()  def run_script_with_context(script_path, cwd, context):     return script_path.with_context(context)  def run_script(script_path, cwd='.'):          shell=run_thru_shell,          cwd=cwd,      )     return script_path.wait()  def run_script_with_context(script_path, cwd, context):     return script_path.with_context(context)  def run_script(script_path, cwd='.'):          shell=run_thru_shell,          cwd=cwd,      )     return script_path.wait()  def run_script_with_context(script_path, cwd, context):     return script_path.with_context(context)  def run_script(script_path, cwd='.'):          shell=run_thru_shell,          cwd=cwd,      )     return script_path.wait()  def run_script_with_context(script_path, cwd, context):     return script_path.with_context(context)  def run_script(script_path, cwd='.'):          shell=run_thru_shell,          cwd=cwd,      )     return script_path.wait()  def run_script_with_context(script_path, cwd, context):     return script_path.with_context(context)  def run_script(script_path, cwd='.'):          shell=run_thru_shell,          cwd=cwd,
class ExecutionEngine(object):          d = self.scraper.enqueue_scrape(response, request, spider)          d.addErrback(lambda f: logger.error('Error while enqueuing downloader output',                                              exc_info=failure_to_exc_info(f),
from pandas.core.frame import DataFrame  from pandas.core.groupby import ops  from pandas.core.groupby.categorical import recode_for_groupby, recode_from_groupby import get_op_result_name  from pandas.core.indexes.api import CategoricalIndex, Index, MultiIndex  from pandas.core.series import series  from pandas.io.formats.printing import pprint_thing  from pandas.core.frame import DataFrame  from pandas.core.groupby import ops  from pandas.core.groupby.categorical import recode_for_groupby, recode_from_groupby  from pandas.core.ops import get_op_result_name  from pandas.core.indexes.api import CategoricalIndex, Index, MultiIndex  from pandas.core.series import series  from pandas.io.formats.printing import pprint_thing  from pandas.core.frame import DataFrame  from pandas.core.groupby import ops  from pandas.core.groupby.categorical import recode_for_groupby, recode_from_groupby  from pandas.core.ops import get_op_result_name  from pandas.core.indexes.api import CategoricalIndex, Index, MultiIndex  from pandas.core.series import series  from pandas.io.formats.printing import pprint_thing  from pandas.core.frame import DataFrame  from pandas.core.groupby import ops  from pandas.core.groupby.categorical import recode_for_groupby, recode_from_groupby  from pandas.core.ops import get_op_result_name  from pandas.core.indexes.api import CategoricalIndex, Index, MultiIndex  from pandas.core.series import series  from pandas.io.formats.printing import pprint_thing  from pandas.core.frame import DataFrame  from pandas.core.groupby import ops  from pandas.core.groupby.categorical import recode_for_groupby, recode_from_groupby  from pandas.core.ops import get_op_result_name  from pandas.core.indexes.api import CategoricalIndex, Index, MultiIndex  from pandas.core.series import series  from pandas.io.formats.printing import pprint_thing  from pandas.core.frame import DataFrame  from pandas.core.groupby import ops  from pandas.core.groupby.categorical import recode_for_groupby, recode_from_groupby  from pandas.core.ops import get_op_result_name  from pandas.core.indexes.api import CategoricalIndex, Index, MultiIndex  from pandas.core.series import series  from pandas.io.formats.printing import pprint_thing  from pandas.core.frame import DataFrame  from pandas.core.groupby import ops  from pandas.core.groupby.categorical import recode_for_groupby, recode_from_groupby  from pandas.core.ops import get_op_result_name  from pandas.core.indexes.api import CategoricalIndex, Index, MultiIndex  from pandas.core.series import series  from pandas.io.formats.printing import pprint_thing  from pandas.core.frame import DataFrame  from pandas.core.groupby import ops  from pandas.core.groupby.categorical import recode_for_groupby, recode_from_groupby  from pandas.core.ops import get_op_result_name  from pandas.core.indexes.api import CategoricalIndex, Index, MultiIndex  from pandas.core.series import series  from pandas.io.formats.printing import pprint_thing  from pandas.core.frame import DataFrame  from pandas.core.groupby import ops  from pandas.core.groupby.categorical import recode_for_groupby, recode_from_groupby  from pandas.core.ops import get_op_result_name  from pandas.core.indexes.api import CategoricalIndex, Index, MultiIndex  from pandas.core.series import series  from pandas.io.formats.printing import pprint_thing  from pandas.core.frame import DataFrame  from pandas.core.groupby import ops  from pandas.core.groupby.categorical import recode_for_groupby, recode_from_groupby  from pandas.core.ops import get_op_result_name  from pandas.core.indexes.api import CategoricalIndex, Index, MultiIndex  from pandas.core.series import series  from pandas.io.formats.printing import pprint_thing  from pandas.core.frame import DataFrame  from pandas.core.groupby import ops  from pandas.core.groupby.categorical import recode_for_groupby, recode_from_groupby  from pandas.core.ops import get_op_result_name  from pandas.core.indexes.api import CategoricalIndex, Index, MultiIndex  from pandas.core.series import series  from pandas.io.formats.printing import pprint_thing  from pandas.core.frame import DataFrame  from pandas.core.groupby import ops  from pandas.core.groupby.categorical import recode_for_groupby, recode_from_groupby  from pandas.core.ops import get_op_result_name  from pandas.core.indexes.api import CategoricalIndex, Index, MultiIndex  from pandas.core.series import series  from pandas.io.formats.printing import pprint_thing  from pandas.core.frame import DataFrame  from pandas.core.groupby import ops  from pandas.core.groupby.categorical import recode_for_groupby, recode_from_groupby  from pandas.core.ops import get_op_result_name  from pandas.core.indexes.api import CategoricalIndex, Index, MultiIndex  from pandas.core.series import series  from pandas.io.formats.printing import pprint_thing  from pandas.core.frame import DataFrame  from pandas.core.groupby import ops  from pandas.core.groupby.categorical import recode_for_groupby, recode_from_groupby  from pandas.core.ops import get_op_result_name  from pandas.core.indexes.api import CategoricalIndex, Index, MultiIndex  from pandas.core.series import series  from pandas.io.formats.printing import pprint_thing  from pandas.core.frame import DataFrame  from pandas.core.groupby import ops  from pandas.core.groupby.categorical import recode_for_groupby, recode_from_groupby  from pandas.core.ops import get_op_result_name  from pandas.core.indexes.api import CategoricalIndex, Index, MultiIndex  from pandas.core.series import series  from
class InfoExtractor(object):                                           f['url'] = initialization_url                                         f['fragments'].append({location_key(initialization_url): initialization_url})                                           f['fragments'].extend(representation_ms_info['fragments'])
class APIRouter(routing.Router):                      response_model_exclude=route.response_model_exclude,                      response_model_by_alias=route.response_model_by_alias,                      response_model_exclude_unset=route.response_model_exclude_unset,                     response_model_exclude_defaults=route.response_model_exclude_defaults,                     response_model_exclude_none=route.response_model_exclude_none,                      include_in_schema=route.include_in_schema,                      response_class=route.response_class or default_response_class,                      name=route.name,
def validate_baseindexer_support(func_name: Optional[str]) -> None:          "median",          "std",          "var",          "kurt",          "quantile",     def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:     return isinstance(dtype, np.ndarray)     def validate_baseindexer_support(func_name: Optional[str]) -> None:          "median",          "std",          "var",          "kurt",          "quantile",         dtype: DtypeObj,     }     def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:     return isinstance(dtype, np.ndarray)     def validate_baseindexer_support(func_name: Optional[str]) -> None:          "median",          "std",          "var",          "kurt",          "quantile",         dtype: DtypeObj,     }     def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:     return isinstance(dtype, np.ndarray)     def validate_baseindexer_support(func_name: Optional[str]) -> None:          "median",          "std",          "var",          "kurt",          "quantile",         dtype: DtypeObj,     }     def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:     return isinstance(dtype, np.ndarray)     def validate_baseindexer_support(func_name: Optional[str]) -> None:          "median",          "std",          "var",          "kurt",          "quantile",         dtype: DtypeObj,     }     def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:     return isinstance(dtype, np.ndarray)     def validate_baseindexer_support(func_name: Optional[str]) -> None:          "median",          "std",          "var",          "kurt",          "quantile",         dtype: DtypeObj,     }     def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:     return isinstance(dtype, np.ndarray)     def validate_baseindexer_support(func_name: Optional[str]) -> None:          "median",           "std",           "var",           "kurt",           "quantile",          dtype: DtypeObj,     }     def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:     return isinstance(dtype, np.ndarray)     def validate_baseindexer_support(func_name: Optional[str]) -> None:          "median",           "std",           "var",           "kurt",           "quantile",          dtype: DtypeObj,     }     def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:     return isinstance(dtype, np.ndarray)     def validate_baseindexer_support(func_name: Optional[str]) -> None:          "median",           "std",           "var",           "kurt",           "quantile",          dtype: DtypeObj,     }     def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:     return isinstance(dtype, np.ndarray)     def validate_baseindexer_support(func_name: Optional[str]) -> None:          "median",           "std",           "var",           "kurt",           "quantile",          dtype: DtypeObj,     }     def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:     return isinstance(dtype, np.ndarray)     def validate_baseindexer_support(func_name: Optional[str]) -> None:          "median",           "std",           "var",           "kurt",           "quantile",          dtype: DtypeObj,     }     def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:     return isinstance(dtype, np.ndarray)     def validate_baseindexer_support(func_name: Optional[str]) -> None:          "median",           "std",           "var",
class BarPlot(MPLPlot):      def _decorate_ticks(self, ax, name, ticklabels, start_edge, end_edge):          ax.set_xlim((start_edge, end_edge))         ax.set_xticks(self.tick_pos)         ax.set_xticklabels(ticklabels)         ax.set_xlabel(name)          if name is not None and self.use_index:              ax.set_xlabel(name)              ax.set_xlim((start_edge, end_edge))              ax.set_xticks(self.tick_pos)              ax.set_xticklabels(ticklabels)              ax.set_xlabel(name)              ax.set_xlim((start_edge, end_edge))              ax.set_xticks(self.tick_pos)              ax.set_xticklabels(ticklabels)              ax.set_xlabel(name)              ax.set_xlim((start_edge, end_edge))              ax.set_xticks(self.tick_pos)              ax.set_xticklabels(ticklabels)              ax.set_xlabel(name)              ax.set_xlim((start_edge, end_edge))              ax.set_xticks(self.tick_pos)              ax.set_xticklabels(ticklabels)              ax.set_xlabel(name)              ax.set_xlim((start_edge, end_edge))              ax.set_xticks(self.tick_pos)              ax.set_xticklabels(ticklabels)              ax.set_xlabel(name)              ax.set_xlim((start_edge, end_edge))              ax.set_xticks(self.tick_pos)              ax.set_xticklabels(ticklabels)              ax.set_xlabel(name)              ax.set_xlim((start_edge, end_edge))              ax.set_xticks(self.tick_pos)              ax.set_xticklabels(ticklabels)              ax.set_xlabel(name)              ax.set_xlim((start_edge, end_edge))              ax.set_xticks(self.tick_pos)              ax.set_xticklabels(ticklabels)              ax.set_xlabel(name)              ax.set_xlim((start_edge, end_edge))              ax.set_xticks(self.tick_pos)              ax.set_xticklabels(ticklabels)              ax.set_xlabel(name)              ax.set_xlim((start_edge, end_edge))              ax.set_xticks(self.tick_pos)              ax.set_xticklabels(ticklabels)              ax.set_xlabel(name)              ax.set_xlim((start_edge, end_edge))              ax.set_xticks(self.tick_pos)              ax.set_xticklabels(ticklabels)              ax.set_xlabel(name)              ax.set_xlim((start_edge, end_edge))              ax.set_xticks(self.tick_pos)              ax.set_xticklabels(ticklabels)              ax.set_xlabel(name)              ax.set_xlim((start_edge, end_edge))              ax.set_xticks(self.tick_pos)              ax.set_xticklabels(ticklabels)              ax.set_xlabel(name)              ax.set_xlim((start_edge, end_edge))              ax.set_xticks(self.tick_pos)              ax.set_xticklabels(ticklabels)              ax.set_xlabel(name)              ax.set_xlim((start_edge, end_edge))              ax.set_xticks(self.tick_pos)
from.common import InfoExtractor  from..utils import (      compat_urllib_parse,      ExtractorError,     limit_length,  )  def _media_xml_tag(tag):     return limit_length(tag, limit_length=limit_length)  def _media_xml_tag(tag):     return limit_length(tag, limit_length=limit_length)  def _media_xml_tag(tag):     return limit_length(tag, limit_length=limit_length)  def _media_xml_tag(tag):     return limit_length(tag, limit_length=limit_length)  def _media_xml_tag(tag):     return limit_length(tag, limit_length=limit_length)  def _media_xml_tag(tag):     return limit_length(tag, limit_length=limit_length)  def _media_xml_tag(tag):     return limit_length(tag, limit_length=limit_length)  def _media_xml_tag(tag):     return limit_length(tag, limit_length=limit_length)  def _media_xml_tag(tag):     return limit_length(tag, limit_length=limit_length)  def _media_xml_tag(tag):     return limit_length(tag, limit_length=limit_length)  def _media_xml_tag(tag):     return limit_length(tag, limit_length=limit_length)  def _media_xml_tag(tag):     return limit_length(tag, limit_length=limit_length)  def _media_xml_tag(tag):     return limit_length(tag, limit_length=limit_length)  def _media_xml_tag(tag):     return limit_length(tag, limit_length=limit_length)  def _media_xml_tag(tag):     return limit_length(tag, limit_length=limit_length)  def _media_xml_tag(tag):     return limit_length(tag, limit_length=limit_length)  def _media_xml_tag(tag):     return limit_length(tag, limit_length=limit_length)  def _media_xml_tag(tag):     return limit_length(tag, limit_length=limit_length)  def _media_xml_tag(tag):     return limit_length(tag, limit_length=limit_length)  def _media_xml_tag(tag):     return limit_length(tag, limit_length=limit_length)  def _media_xml_tag(tag):     return limit_length(tag, limit_length=limit_length)  def _media_xml_tag(tag):     return limit_length(tag, limit_length=limit_length)  def _media_xml_tag(tag):     return limit_length(tag, limit_length=limit_length)  def _media_xml_tag(tag):     return limit_length(tag, limit_length=limit_length)  def _media_xml_tag(tag):     return limit_length(tag, limit_length=limit_length)  def _media_xml_tag(tag):     return limit_length(tag, limit_length=limit_length)  def _media_xml_tag(tag):     return limit_length(tag, limit_length=limit_length)  def _media_xml_tag(tag):     return limit_length(tag, limit_length=limit_length)  def _media_xml_tag(tag):     return limit_length(tag, limit_length=limit_length)  def _media_xml_tag(tag):     return limit_length(tag, limit_length=limit_length)  def _media_xml_tag(tag):     return limit_length(tag, limit_length=limit_length)  def _media_xml_tag(tag):     return limit_length(tag, limit_length=limit_length)  def _media_xml_tag(tag):     return limit_length(tag, limit_length=limit_length)  def _media_xml_tag(tag):     return limit_length(tag, limit_length=limit_length)  def _media_xml_tag(tag):     return limit_length(tag, limit_length=limit_length)  def _media_xml_tag(tag):     return limit_length(tag, limit_length=limit_length)  def _media_xml_tag(tag):     return limit_length(tag, limit_length=limit_length)  def _media_xml_tag(tag):     return limit_length(tag, limit_length=limit_length)  def _media_xml_tag(tag):     return limit_length(tag, limit_length=limit_length)  def _media_xml_tag(tag):     return limit_length(tag, limit_length=limit_length)  def _media_xml_tag(tag):     return limit_length(tag, limit_length=limit_length)  def _media_xml_tag(tag):     return limit_length(tag, limit_length=limit_length)  def _media_xml_tag(tag):     return limit_length(tag, limit_length=limit_length)  def _media_xml_tag(tag):     return limit_length(tag, limit_length=limit_length)  def _media_xml_tag(tag):     return limit_length(tag, limit_length=limit_length)  def _media_xml_tag(tag):     return limit_length(tag, limit_length=limit_length)  def _media_xml_tag(tag):     return limit_length(tag, limit_length=limit_length)  def _media_xml_tag(tag):     return limit_length(tag, limit_length=limit_length)  def _media_xml_tag(tag):     return limit_length(tag, limit_length=limit_length)  def _media_xml_tag(tag):     return limit_length(tag, limit_length=limit_length)  def _media_xml_tag(tag):     return limit_length(tag, limit_length=limit_length)  def _media_xml_tag(tag):     return limit_length(tag, limit_length=limit_length)  def _media_xml_tag(tag):     return limit_length(tag, limit_length=limit_length)  def _media_xml_tag(tag):     return limit_length(tag, limit_length=limit_length)  def _media_xml_tag(tag):     return limit_length(tag, limit_length=limit_length)  def _media_xml_tag(tag):     return limit_length(tag, limit_length=limit_length)  def _media_xml_tag(tag):     return limit_length(tag, limit_length=
def match(command, settings):  def get_new_command(command, settings):     cmds = command.split(' ')     machine = ""      if len(cmds) >= 3:          machine =cmds[2]     return shells.and_("vagrant up " +  machine, command.script)  def match(command, settings):  def get_new_command(command, settings):     cmds = command.split(' ')     machine = ""      if len(cmds) >= 3:          machine =cmds[2]     return shells.and_("vagrant up " +  machine, command.script)  def match(command, settings):  def get_new_command(command, settings):     cmds = command.split(' ')     machine = ""      if len(cmds) >= 3:          machine =cmds[2]     return shells.and_("vagrant up " +  machine, command.script)  def match(command, settings):  def get_new_command(command, settings):     cmds = command.split(' ')     machine = ""      if len(cmds) >= 3:          machine =cmds[2]     return shells.and_("vagrant up " +  machine, command.script)  def match(command, settings):  def get_new_command(command, settings):     cmds = command.split(' ')     machine = ""      if len(cmds) >= 3:          machine =cmds[2]     return shells.and_("vagrant up " +  machine, command.script)  def match(command, settings):  def get_new_command(command, settings):     cmds = command.split(' ')      machine = ""      if len(cmds) >= 3:          machine =cmds[2]     return shells.and_("vagrant up " +  machine, command.script)  def match(command, settings):  def get_new_command(command, settings):     cmds = command.split(' ')      machine = ""      if len(cmds) >= 3:          machine =cmds[2]     return shells.and_("vagrant up " +  machine, command.script)  def match(command, settings):  def get_new_command(command, settings):     cmds = command.split(' ')      machine = ""      if len(cmds) >= 3:          machine =cmds[2]     return shells.and_("vagrant up " +  machine, command.script)  def match(command, settings):  def get_new_command(command, settings):     cmds = command.split(' ')      machine = ""      if len(cmds) >= 3:          machine =cmds[2]     return shells.and_("vagrant up " +  machine, command.script)  def match(command, settings):  def get_new_command(command, settings):     cmds = command.split(' ')      machine = ""      if len(cmds) >= 3:          machine =cmds[2]     return shells.and_("vagrant up " +  machine, command.script)  def match(command, settings):  def get_new_command(command, settings):     cmds = command.split(' ')      machine = ""      if len(cmds) >= 3:          machine =cmds[2]     return shells.and_("vagrant up " +  machine, command.script)  def match(command, settings):  def get_new_command(command, settings):     cmds = command.split(' ')      machine = ""      if len(cmds) >= 3:          machine =cmds[2]     return shells.and_("vagrant up " +  machine, command.script)  def match(command, settings):  def get_new_command(command, settings):     cmds = command.split(' ')      machine = ""      if len(cmds) >= 3:          machine =cmds[2]     return shells.and_("vagrant up " +  machine, command.script)  def match(command, settings):  def get_new_command(command, settings):     cmds = command.split(' ')      machine = ""      if len(cmds) >= 3:          machine =cmds[2]     return shells.and_("vagrant up " +  machine, command.script)  def match(command, settings):  def get_new_command(command, settings):     cmds = command.split(' ')      machine = ""      if len(cmds) >= 3:          machine =cmds[2]     return shells.and_("vagrant up " +  machine, command.script)  def match(command, settings):  def get_new_command(command, settings):     cmds = command.split(' ')      machine = ""      if len(cmds) >= 3:          machine =cmds[2]     return shells.and_("vagrant up " +  machine, command.script)  def match(command, settings):  def get_new_command(command, settings):     cmds = command.split(' ')      machine = ""      if len(cmds) >= 3:          machine =cmds[2]     return shells.and_("vagrant up " +  machine, command.script)  def match(command, settings):  def get_new_command(command, settings):     cmds = command.split(' ')      machine = ""      if len(cmds) >= 3:          machine =cmds[2]     return shells.and_("vagrant up " +  machine, command.script)  def match(command, settings):  def get_new_command(command, settings
class Worker(object):              return six.moves.filter(lambda task: task.status in [PENDING, RUNNING],
def pivot_table(                  agged[v] = maybe_downcast_to_dtype(agged[v], data[v].dtype)      table = agged     if table.shape == (1, 4) or table.shape == (1, 3) or table.shape == (1, 2) or table.shape == (1, 1) or table.shape == (0, 1) or table.shape == (0, 2) or table.shape == (0, 3) or table.shape == (0, 4) or table.shape == (0, 5) or table.shape == (0, 6) or table.shape == (0, 7) or table.shape == (0, 8) or table.shape == (0, 9) or table.shape == (0, 10) or table.shape == (0, 11) or table.shape == (0, 12) or table.shape == (0, 13) or table.shape == (0, 14) or table.shape == (0, 15) or table.shape == (0, 16) or table.shape == (0, 17) or table.shape == (0, 18) or table.shape == (0, 19) or table.shape == (0, 20) or table.shape == (0, 21) or table.shape == (0, 22) or table.shape == (0, 23) or table.shape == (0, 24) or table.shape == (0, 25) or table.shape == (0, 26) or table.shape == (0, 27) or table.shape == (0, 28) or table.shape == (0, 29) or table.shape == (0, 30) or table.shape == (0, 31) def pivot_table(                  agged[v] = maybe_downcast_to_dtype(agged[v], data[v].dtype)      table = agged     if table.shape == (1, 4) or table.shape == (1, 3) or table.shape == (1, 2) or table.shape == (1, 1) or table.shape == (0, 1) or table.shape == (0, 2) or table.shape == (0, 3) or table.shape == (0, 4) or table.shape == (0, 5) or table.shape == (0, 6) or table.shape == (0, 7) or table.shape == (0, 8) or table.shape == (0, 9) or table.shape == (0, 10) or table.shape == (0, 11) or table.shape == (0, 12) or table.shape == (0, 13) or table.shape == (0, 14) or table.shape == (0, 15) or table.shape == (0, 16) or table.shape == (0, 17) or table.shape == (0, 18) or table.shape == (0, 19) or table.shape == (0, 20) or table.shape == (0, 21) or table.shape == (0, 22) or table.shape == (0, 23) or table.shape == (0, 24) or table.shape == (0, 25) or table.shape == (0, 26) or table.shape == (0, 27) or table.shape == (0, 28) or table.shape == (0, 29) or table.shape == (0, 30) or table.shape == (0, 31) def pivot_table(                   agged[v] = maybe_downcast_to_dtype(agged[v], data[v].dtype)      table = agged     if table.shape == (1, 4) or table.shape == (1, 3) or table.shape == (1, 2) or table.shape == (1, 1) or table.shape == (0, 1) or table.shape == (0, 2) or table.shape == (0, 3) or table.shape == (0, 4) or table.shape == (0, 5) or table.shape == (0, 6) or table.shape == (0, 7) or table.shape == (0, 8) or table.shape == (0, 9) or table.shape == (0, 10) or table.shape == (0, 11) or table.shape == (0, 12) or table.shape == (0, 13) or table.shape == (0, 14) or table.shape == (0, 15) or table.shape == (0, 16) or table.shape == (0, 17) or table.shape == (0, 18) or table.shape == (0, 19) or table.shape == (0, 20) or table.shape == (0, 21) or table.shape == (0, 22) or table.shape == (0, 23) or table.shape == (0, 24) or table.shape == (0, 25) or table.shape == (0, 26) or table.shape == (0, 27) or table.shape == (0, 28) or table.shape == (0, 29) or table.shape == (0, 30) or table.shape == (0, 31) def pivot_table(                   agged[v] = maybe_downcast_to_dtype(agged[v], data[v].dtype)      table = agged     if table.shape == (1, 4) or table.shape == (1, 3) or table.shape == (1, 2) or table.shape == (1, 1) or table.shape == (0, 1) or table.shape == (0, 2) or table.shape == (0, 3) or table.shape == (0, 4) or table.shape == (0, 5) or table.shape == (0, 6) or table.shape == (0, 7) or table.shape == (0, 8) or table.shape == (0, 9) or table.shape == (0, 10) or table.shape == (0, 11) or table.shape == (0, 12) or table.shape == (0, 13) or table.shape == (0, 14) or table.shape == (0, 15) or table.shape == (0, 16) or table.shape == (0, 17) or table.shape == (0, 18) or table.shape == (0, 19) or table.shape == (0, 20) or table.shape == (0, 21) or table.shape == (0, 22) or table.shape == (0, 23) or table.shape == (0, 24) or table.shape == (0, 25) or table.shape == (0, 26) or table.shape == (0, 27) or table.shape == (0, 28) or table.shape == (0, 29) or table.shape == (0, 30) or table.shape == (0, 31) def pivot_table(                   agged[v] = maybe_downcast_to_dtype(agged[v], data[v].dtype)      table = agged     if table.shape == (1, 4) or table.shape
def create_cloned_field(field: ModelField) -> ModelField:              original_type.__name__, __config__=original_type.__config__          )          for f in original_type.__fields__:             use_type.__fields__[f.name] = f          use_type.__validators__ = original_type.__validators__      if PYDANTIC_1:          new_field = ModelField(
def read_conllx(input_data, use_morphology=False, n=0):
class BaseReshapingTests(BaseExtensionTests):          result[0] = result[1]          assert data[0] == data[1]     def test_transpose(self):         result = data.transpose()         assert result is not data         result = data.transpose()         assert result is not data     def test_reshape(self):         result = data.reshape([1, 2])         assert result is not data         result = data.reshape([1, 2])         assert result is not data     def test_transpose_categorical(self):         result = data.transpose()         assert result is not data         result = data.transpose()         assert result is not data     def test_reshape_categorical(self):         result = data.reshape([1, 2])         assert result is not data         result = data.reshape([1, 2])         assert result is not data     def test_transpose_scalar(self):         result = data.transpose()         assert result is not data         result = data.transpose()         assert result is not data     def test_reshape_scalar(self):         result = data.reshape([1, 2])         assert result is not data         result = data.reshape([1, 2])         assert result is not data     def test_transpose_categorical_categorical(self):         result = data.transpose()         assert result is not data         assert result is not data         result = data.transpose()         assert result is not data     def test_reshape_categorical_categorical(self):         result = data.reshape([1, 2])         assert result is not data         assert result is not data     def test_transpose_scalar_scalar(self):         result = data.transpose()         assert result is not data         assert result is not data     def test_transpose_categorical_categorical(self):         result = data.transpose()         assert result is not data         assert result is not data     def test_transpose_scalar_categorical(self):         result = data.transpose()         assert result is not data         assert result is not data     def test_transpose_categorical_categorical(self):         result = data.transpose()         assert result is not data         assert result is not data     def test_transpose_scalar_categorical(self):         result = data.transpose()         assert result is not data         assert result is not data     def test_transpose_categorical_categorical(self):         result = data.transpose()         assert result is not data         assert result is not data     def test_transpose_scalar_categorical(self):         result = data.transpose()         assert result is not data         assert result is not data     def test_transpose_categorical_categorical(self):         result = data.transpose()         assert result is not data         assert result is not data     def test_transpose_scalar_categorical(self):         result = data.transpose()         assert result is not data         assert result is not data     def test_transpose_categorical_categorical(self):         result = data.transpose()         assert result is not data        assert result is not data     def test_transpose_scalar_categorical(self):         result = data.transpose()         assert result is not data         assert result is not data     def test_transpose_categorical_categorical(self):         result = data.transpose()         assert result is not data         assert result is not data     def test_transpose_scalar_categorical(self):         result = data.transpose()         assert result is not data         assert result is not data     def test_transpose_categorical_categorical(self):         result = data.transpose()         assert result is not data         assert result is not data     def test_transpose_scalar_categorical(self):         result = data.transpose()         assert result is not data         assert result is not data     def test_transpose_categorical_categorical(self):         result = data.transpose()         assert result is not data         assert result is not data     def test_transpose_scalar_categorical(self):         result = data.transpose()         assert result is not data         assert result is not data     def test_transpose_categorical_categorical(self):         result = data.transpose()         assert result is not data         assert result is
class CorrectedCommand(object):              compatibility_call(self.side_effect, old_cmd, self.script)          logs.debug(u'PYTHONIOENCODING: {}'.format(             os.environ.get('PYTHONIOENCODING', '>-not-set-<')))          print(self.script)
def add_codes(err_cls):      class ErrorsWithCodes(object):          def __getattribute__(self, code):             msg = getattr(err_cls, code)             return "[{code}] {msg}".format(code=code, msg=msg)      return ErrorsWithCodes()
class GroupBy(_GroupBy): func(**kwargs)              if result_is_index:                 result = algorithms.take_nd(obj.values, result)              if post_processing:                  result = post_processing(result, inferences, custom_repr=self.custom_repr)              if result_is_index:                  result = algorithms.take_nd(obj.values, result)              if post_processing:                  result = post_processing(result, inferences, custom_repr=self.custom_repr)              if result_is_index:                  result = algorithms.take_nd(obj.values, result)              if post_processing:                  result = post_processing(result, inferences, custom_repr=self.custom_repr)              if result_is_index:                  result = algorithms.take_nd(obj.values, result)              if post_processing:                  result = post_processing(result, inferences, custom_repr=self.custom_repr)              if result_is_index:                  result = algorithms.take_nd(obj.values, result)              if post_processing:                  result = post_processing(result, inferences, custom_repr=self.custom_repr)              if result_is_index:                  result = algorithms.take_nd(obj.values, result)              if post_processing:                  result = post_processing(result, inferences, custom_repr=self.custom_repr)              if result_is_index:                  result = algorithms.take_nd(obj.values, result)              if post_processing:                  result = post_processing(result, inferences, custom_repr=self.custom_repr)              if result_is_index:                  result = algorithms.take_nd(obj.values, result)              if post_processing:                  result = post_processing(result, inferences, custom_repr=self.custom_repr)              if result_is_index:                  result = algorithms.take_nd(obj.values, result)              if post_processing:                  result = post_processing(result, inferences, custom_repr=self.custom_repr)              if result_is_index:                  result = algorithms.take_nd(obj.values, result)              if post_processing:                  result = post_processing(result, inferences, custom_repr=self.custom_repr)              if result_is_index:                  result = algorithms.take_nd(obj.values, result)              if post_processing:                  result = post_processing(result, inferences, custom_repr=self.custom_repr)              if result_is_index:                  result = algorithms.take_nd(obj.values, result)              if post_processing:                  result = post_processing(result, inferences, custom_repr=self.custom_repr)             if result_is_index:                  result = algorithms.take_nd(obj.values, result)              if post_processing:                  result = post_processing(result, inferences, custom_repr=self.custom_repr)              if result_is_index:                  result = algorithms.take_nd(obj.values, result)              if post_processing:                  result = post_processing(result, inferences, custom_repr=self.custom_repr)              if result_is_index:                  result = algorithms.take_nd(obj.values, result)              if post_processing:                  result = post_processing(result, inferences, custom_repr=self.custom_repr)              if result_is_index:                  result = algorithms.take_nd
def _isna_ndarraylike_old(obj):      return isna(result)  def notna(obj):      Detect non-missing values for an array-like object.     result = isna(obj)     return result def _isna_ndarraylike_new(obj):     return isna(obj)  def notna(obj):      Detect non-missing values for an array-like object.     result = isna(obj)     return result  def _isna_ndarray_old(obj):     return isna(result)  def notna(obj):      Detect non-missing values for an array-like object.     return isna(obj)  def _isna_ndarray_new(obj):     return isna(obj)  def notna(obj):      Detect non-missing values for an array-like object.     return isna(obj)  def _isna_ndarray_old(obj):     return isna(result)  def _isna_ndarray_new(obj):     return isna(obj)  def notna(obj):      Detect non-missing values for an array-like object.     return isna(obj)  def _isna_ndarray_old(obj):     return isna(result)  def _isna_ndarray_new(obj):     return isna(obj)  def notna(obj):      Detect non-missing values for an array-like object.     return isna(obj)  def _isna_ndarray_old(obj):     return isna(result)  def _isna_ndarray_new(obj):     return isna(obj)  def notna(obj):      Detect non-missing values for an array-like object.     return isna(obj)  def _isna_ndarray_old(obj):     return isna(result)  def _isna_ndarray_new(obj):     return isna(obj)  def notna(obj):      Detect non-missing values for an array-like object.     return isna(obj)  def _isna_ndarray_old(obj):     return isna(result)  def _isna_ndarray_new(obj):     return isna(obj)  def notna(obj):      Detect non-missing values for an array-like object.     return isna(obj)  def _isna_ndarray_old(obj):     return isna(result)  def _isna_ndarray_new(obj):     return isna(obj)  def notna(obj):      Detect non-missing values for an array-like object.     return isna(obj)  def _isna_ndarray_old(obj):     return isna(result)  def _isna_ndarray_new(obj):     return isna(obj)  def notna(obj):      Detect non-missing values for an array-like object.     return isna(obj)  def _isna_ndarray_old(obj):     return isna(result)  def _isna_ndarray_new(obj):     return isna(obj)  def notna(obj):      Detect non-missing values for an array-like object.     return isna(obj)  def _isna_ndarray_old(obj):     return isna(result)  def _isna_ndarray_new(obj):     return isna(obj)  def notna(obj):      Detect non-missing values for an array-like object.     return isna(obj)  def _isna_ndarray_old(obj):     return isna(result)  def _isna_ndarray_new(obj):     return isna(obj)  def notna(obj):      Detect non-missing values for an array-like object.     return isna(obj)  def _isna_ndarray_old(obj):     return isna(result)  def _isna_ndarray_new(obj):     return isna(obj)  def notna(obj):      Detect non-missing values for an array-like object.     return isna(obj)  def _isna_ndarray_old(obj):     return isna(result)  def _isna_ndarray_new(obj):     return isna(obj)  def notna(obj):      Detect non-missing values for an array-like object.     return isna(obj)  def _isna_ndarray_old(obj):     return isna(result)  def _isna_ndarray_new(obj):     return isna(obj)  def notna(obj):      Detect non-missing values for an array-like object.     return isna(obj)  def _isna_ndarray_old(obj):     return isna(result)  def _isna_ndarray_new(obj):     return isna(obj)  def notna(obj):      Detect non-missing values for an array-like object.     return isna(obj)  def _isna_ndarray_old(obj):     return isna(result)  def _isna_ndarray_new(obj):     return isna(obj)  def notna(obj):      Detect non-missing values for an array-like object.     return isna(obj)  def _isna_ndarray_old(obj):     return isna(result)  def _isna_ndarray_new(obj):     return isna(obj)  def notna(obj):      Detect non-missing values for an array-like object.     return isna(obj)  def _isna_ndarray_old(obj):     return isna(result)  def _isna_ndarray_new(obj):     return isna(obj)  def notna(obj):      Detect non-missing values for an array-like object.     return isna(obj)  def _isna_ndarray_old(obj):     return isna(result)  def _isna_ndarray_new(obj):     return isna(obj)  def notna(obj):      Detect non-missing values for an array-like object.     return isna(obj)  def _isna_ndarray_old(obj):     return isna(result)  def _isna_ndarray_new(obj):     return isna(obj)  def notna(obj):      Detect non-missing values for an array-like object.
class _LocIndexer(_LocationIndexer):          if isinstance(labels, MultiIndex):             if isinstance(key, str) and labels.levels[0]._supports_partial_string_indexing:                 key = tuple([key] + [slice(None)] * (len(labels.levels) - 1))             else:                 key = tuple([key] + [slice(None)] * (len(labels.levels) - 1))
class BracketTracker:          if self._lambda_argument_depths and leaf.type == token.COLON:              self.depth -= 1             self._lambda_argument_depths -= 1              return True          return False
class DatetimeIndexOpsMixin(ExtensionIndex, ExtensionOpsMixin):          if isinstance(maybe_slice, slice):              return self[maybe_slice]         taken = ExtensionIndex.take(              self, indices, axis, allow_fill, fill_value, **kwargs         )         return self._shallow_copy(taken, **kwargs)      _can_hold_na = True      _na_value = NaT
def _isna_new(obj):      elif hasattr(obj, "__array__"):          return _isna_ndarraylike(obj.__array__)      else:         return obj is None  def _isna_old(obj):     return isna(obj) is not None  def _isna_new(obj):      elif hasattr(obj, "__array__"):          return _isna_ndarraylike(obj.__array__)      else:         return obj is None  def _isna_old(obj):     return isna(obj) is not None  def _isna_new(obj):      elif hasattr(obj, "__array__"):          return _isna_ndarraylike(obj.__array__)      else:         return obj is None  def _isna_old(obj):     return isna(obj) is not None  def _isna_new(obj):      elif hasattr(obj, "__array__"):          return _isna_ndarraylike(obj.__array__)      else:         return obj is None  def _isna_old(obj):     return isna(obj) is not None  def _isna_new(obj):      elif hasattr(obj, "__array__"):          return _isna_ndarraylike(obj.__array__)      else:         return obj is None  def _isna_old(obj):     return isna(obj) is not None  def _isna_new(obj):      elif hasattr(obj, "__array__"):          return _isna_ndarraylike(obj.__array__)      else:         return obj is None  def _isna_old(obj):     return isna(obj) is not None  def _isna_new(obj):      elif hasattr(obj, "__array__"):          return _isna_ndarraylike(obj.__array__)      else:         return obj is None  def _isna_old(obj):     return isna(obj) is not None  def _isna_new(obj):      elif hasattr(obj, "__array__"):          return _isna_ndarraylike(obj.__array__)      else:         return obj is None  def _isna_old(obj):     return isna(obj) is not None  def _isna_new(obj):      elif hasattr(obj, "__array__"):          return _isna_ndarraylike(obj.__array__)      else:         return obj is None  def _isna_old(obj):     return isna(obj) is not None  def _isna_new(obj):      elif hasattr(obj, "__array__"):          return _isna_ndarraylike(obj.__array__)      else:         return obj is None def _isna_old(obj):      return isna(obj) is not None  def _isna_new(obj):      elif hasattr(obj, "__array__"):          return _isna_ndarraylike(obj.__array__)      else:         return obj is None  def _isna_old(obj):      return isna(obj) is not None  def _isna_new(obj):      elif hasattr(obj, "__array__"):          return _isna_ndarraylike(obj.__array__)      else:         return obj is None def _isna_old(obj):      return isna(obj) is not None  def _isna_new(obj):      elif hasattr(obj, "__array__"):          return _isna_ndarraylike(obj.__array__)      else:         return obj is None def _isna_old(obj):      return isna(obj) is not None  def _isna_new(obj):      elif hasattr(obj, "__array__"):          return _isna_ndarraylike(obj.__array__)      else:         return obj is None def _isna_old(obj):      return isna(obj) is not None  def _isna_new(obj):      elif hasattr(obj, "__array__"):          return _isna_ndarraylike(obj.__array__)      else:         return obj is None def _isna_old(obj):      return isna(obj) is not None  def _isna_new(obj):      elif hasattr(obj, "__array__"):          return _isna_ndarraylike(obj.__array__)      else:         return obj is None def _isna_old(obj):      return isna(obj) is not None  def _isna_new(obj):      elif hasattr(obj, "__array__"):          return _isna_ndarraylike(obj.__array__)      else:         return obj is None def _isna_old(obj):      return isna(obj) is not None  def _isna_new(obj):      elif hasattr(obj, "__array__"):          return _isna_ndarraylike(obj.__array__)      else:         return obj is None def _isna_old(obj):      return isna(obj) is not None  def _isna_new(obj):      elif hasattr(obj, "__array__
class TestSeriesComparison:          dti = dti.tz_localize("US/Central")          ser = Series(dti).rename(names[1])          result = op(ser, dti)          assert result.name == names[2]          assert isinstance(result, Series)          result = op(ser, dti)          assert result.name == names[2]          assert isinstance(result, np.ndarray)          result = op(ser, dti)          assert result.name == names[2]          assert isinstance(result, Series)          result = op(ser, dti)          assert result.name == names[2]          assert isinstance(result, np.ndarray)          result = op(ser, dti)          assert result.name == names[2]          assert isinstance(result, Series)          result = op(ser, dti)          assert result.name == names[2]          assert isinstance(result, np.ndarray)          result = op(ser, dti)          assert result.name == names[2]          assert isinstance(result, Series)          result = op(ser, dti)          assert result.name == names[2]          assert isinstance(result, np.ndarray)          result = op(ser, dti)          assert result.name == names[2]          assert isinstance(result, Series)          result = op(ser, dti)          assert result.name == names[2]          assert isinstance(result, np.ndarray)          result = op(ser, dti)          assert result.name == names[2]          assert isinstance(result, Series)          result = op(ser, dti)          assert result.name == names[2]          assert isinstance(result, np.ndarray)          result = op(ser, dti)          assert result.name == names[2]          assert isinstance(result, Series)          result = op(ser, dti)          assert result.name == names[2]          assert isinstance(result, np.ndarray)          result = op(ser, dti)          assert result.name == names[2]          assert isinstance(result, Series)          result = op(ser, dti)          assert result.name == names[2]          assert isinstance(result, np.ndarray)          result = op(ser, dti)          assert result.name == names[2]          assert isinstance(result, Series)          result = op(ser, dti)          assert result.name == names[2]          assert isinstance(result, np.ndarray)          result = op(ser, dti)          assert result.name == names[2]          assert isinstance(result, Series)          result = op(ser, dti)          assert result.name == names[2]          assert isinstance(result, np.ndarray)          result = op(ser, dti)          assert result.name == names[2]          assert isinstance(result, Series)          result = op(ser, dti)          assert result.name == names[2]          assert isinstance(result, np.ndarray)          result = op(ser, dti)          assert result.name == names[2]          assert isinstance(result, Series)          result = op(ser, dti)          assert result.name == names[2]         assert isinstance(result, np.ndarray)          result = op(ser, dti)          assert result.name == names[2]          assert isinstance(result, Series)          result = op(ser, dti)          assert result.name == names[2]          assert isinstance(result, np.ndarray)          result = op(ser, dti)          assert result.name == names[2]          assert isinstance(result, Series)          result = op(ser, dti)          assert result.name == names[2]          assert isinstance(result, np.ndarray)          result = op(ser, dti)          assert result.name == names[2]          assert isinstance(result, Series)          result = op(ser, dti)          assert result.name == names[2]          assert isinstance(result, np.ndarray)          result = op(ser, dti)
def js_to_json(code):          if v in ('true', 'false', 'null'):              return v elif v is None:              return ""          if v.startswith('"'):              v = v[1:-1]              v = re.sub(r"\\\\|\\'|\"", lambda m: {                  '\\\\': '\\\\',                  '\\': '\\',                  '\\\\': '\\\\',                  '\\': '\\',                  '\\\\': '\\\\',                  '\\': '\\',                  '\\\\': '\\\\',                  '\\': '\\',                  '\\\\': '\\\\',                  '\\': '\\',                  '\\\\': '\\\\',                  '\\': '\\',                  '\\\\': '\\\\',                  '\\': '\\',                  '\\\\': '\\\\',                  '\\': '\\',                  '\\\\': '\\\\',                  '\\': '\\',                  '\\\\': '\\\\',                  '\\': '\\',                  '\\\\': '\\\\',                  '\\': '\\',                  '\\\\': '\\\\',                  '\\': '\\',                  '\\\\': '\\\\',                  '\\': '\\',                  '\\\\': '\\\\',                  '\\': '\\',                  '\\\\': '\\\\',                  '\\': '\\',                  '\\\\': '\\\\',                  '\\': '\\',                  '\\\\': '\\\\',                  '\\': '\\',                  '\\\\': '\\\\',                  '\\': '\\',                  '\\\\': '\\\\',                  '\\': '\\',                  '\\\\': '\\\\',                  '\\': '\\',                  '\\\\': '\\\\',                  '\\': '\\',                  '\\\\': '\\\\',                  '\\': '\\',                  '\\\\': '\\\\',                  '\\': '\\',                  '\\\\': '\\\\',                  '\\': '\\',                  '\\\\': '\\\\',                  '\\': '\\',                  '\\\\': '\\\\',                  '\\': '\\',                  '\\\\': '\\\\',                  '\\': '\\',                  '\\\\': '\\\\',                  '\\': '\\',                  '\\\\': '\\\\',                  '\\': '\\',                  '\\\\': '\\\\',                  '\\': '\\',                  '\\\\': '\\\\',                  '\\': '\\',                  '\\\\': '\\\\',                  '\\': '\\',                  '
class Model(BaseModel):  class ModelSubclass(Model):      y: int  @app.get("/", response_model=Model, response_model_exclude_unset=True)  def get() -> ModelSubclass:     return ModelSubclass(         {},         y=1,         dtype=np.int64,     )  client = TestClient(app)     return client.make_model(y=y, dtype=dtype)  class Model(BaseModel):  class ModelSubclass(Model):      y: int  @app.get("/", response_model=Model, response_model_exclude_unset=True)  def get() -> ModelSubclass:     return ModelSubclass(         {},         y=1,         dtype=np.int64,         copy=False,     )  client = TestClient(app)     return client.make_model(y=y, dtype=dtype)  class Model(BaseModel):      y: int  @app.get("/", response_model=Model, response_model_exclude_unset=True)  def get() -> ModelSubclass:     return ModelSubclass(         {},         y=1,         dtype=np.int64,         copy=False,     )  client = TestClient(app)     return client.make_model(y=y, dtype=dtype)  class Model(BaseModel):      y: int  @app.get("/", response_model=Model, response_model_exclude_unset=True)  def get() -> ModelSubclass:     return ModelSubclass(         {},         y=1,         dtype=np.int64,         copy=False,     )  client = TestClient(app)     return client.make_model(y=y, dtype=dtype)  class Model(BaseModel):      y: int  @app.get("/", response_model=Model, response_model_exclude_unset=True)  def get() -> ModelSubclass:     return ModelSubclass(         {},         y=1,         dtype=np.int64,         copy=False,     )  client = TestClient(app)     return client.make_model(y=y, dtype=dtype)  class Model(BaseModel):      y: int  @app.get("/", response_model=Model, response_model_exclude_unset=True)  def get() -> ModelSubclass:     return ModelSubclass(         {},         y=1,         dtype=np.int64,         copy=False,     )  client = TestClient(app)     return client.make_model(y=y, dtype=dtype)  class Model(BaseModel):      y: int  @app.get("/", response_model=Model, response_model_exclude_unset=True)  def get() -> ModelSubclass:     return ModelSubclass(         {},         y=1,         dtype=np.int64,         copy=False,     )  client = TestClient(app)     return client.make_model(y=y, dtype=dtype)  class Model(BaseModel):      y: int  @app.get("/", response_model=Model, response_model_exclude_unset=True)  def get() -> ModelSubclass:     return ModelSubclass(          {},          y=1,          dtype=np.int64,          copy=False,     )  client = TestClient(app)     return client.make_model(y=y, dtype=dtype)  class Model(BaseModel):      y: int  @app.get("/", response_model=Model, response_model_exclude_unset=True)  def get() -> ModelSubclass:     return ModelSubclass(          {},          y=1,          dtype=np.int64,          copy=False,     )  client = TestClient(app)     return client.make_model(y=y, dtype=dtype)  class Model(BaseModel):      y: int  @app.get("/", response_model=Model, response_model_exclude_unset=True)  def get() -> ModelSubclass:     return ModelSubclass(          {},          y=1,          dtype=np.int64,          copy=False,     )  client = TestClient(app)     return client.make_model(y=y, dtype=dtype)  class Model(BaseModel):      y: int  @app.get("/", response_model=Model, response_model_exclude_unset=True)  def get() -> ModelSubclass:     return ModelSubclass(          {},          y=1,          dtype=np.int64,          copy=False,     )  client = TestClient(app)     return client.make_model(y=y, dtype=dtype)  class Model(BaseModel):      y: int  @app.get("/", response_model=Model, response_model_exclude_unset=True)  def get() -> ModelSubclass:     return ModelSubclass(          {},          y=1,          dtype=np.int64,          copy=False,     )  client = TestClient(app)
default 'raise'              )          new_dates = new_dates.view(DT64NS_DTYPE)          dtype = tz_to_dtype(tz)         return self._simple_new(new_dates, dtype=dtype, freq=self.freq)              )          new_dates = new_dates.view(DT64NS_DTYPE)          dtype = tz_to_dtype(tz)         return self._simple_new(new_dates, dtype=dtype, freq=self.freq)              )          new_dates = new_dates.view(DT64NS_DTYPE)          dtype = tz_to_dtype(tz)         return self._simple_new(new_dates, dtype=dtype, freq=self.freq)              )          new_dates = new_dates.view(DT64NS_DTYPE)          dtype = tz_to_dtype(tz)         return self._simple_new(new_dates, dtype=dtype, freq=self.freq)              )          new_dates = new_dates.view(DT64NS_DTYPE)          dtype = tz_to_dtype(tz)         return self._simple_new(new_dates, dtype=dtype, freq=self.freq)              )          new_dates = new_dates.view(DT64NS_DTYPE)          dtype = tz_to_dtype(tz)         return self._simple_new(new_dates, dtype=dtype, freq=self.freq)              )          new_dates = new_dates.view(DT64NS_DTYPE)          dtype = tz_to_dtype(tz)         return self._simple_new(new_dates, dtype=dtype, freq=self.freq)              )          new_dates = new_dates.view(DT64NS_DTYPE)          dtype = tz_to_dtype(tz)         return self._simple_new(new_dates, dtype=dtype, freq=self.freq)              )          new_dates = new_dates.view(DT64NS_DTYPE)          dtype = tz_to_dtype(tz)         return self._simple_new(new_dates, dtype=dtype, freq=self.freq)              )          new_dates = new_dates.view(DT64NS_DTYPE)          dtype = tz_to_dtype(tz)         return self._simple_new(new_dates, dtype=dtype, freq=self.freq)              )          new_dates = new_dates.view(DT64NS_DTYPE)          dtype = tz_to_dtype(tz)         return self._simple_new(new_dates, dtype=dtype, freq=self.freq)              )          new_dates = new_dates.view(DT64NS_DTYPE)          dtype = tz_to_dtype(tz)         return self._simple_new(new_dates, dtype=dtype, freq=self.freq)              )          new_dates = new_dates.view(DT64NS_DTYPE)          dtype = tz_to_dtype(tz)         return self._simple_new(new_dates, dtype=dtype, freq=self.freq)              )          new_dates = new_dates.view(DT64NS_DTYPE)          dtype = tz_to_dtype(tz)         return self._simple_new(new_dates, dtype=dtype, freq=self.freq)              )          new_dates = new_dates.view(DT64NS_DTYPE)          dtype = tz_to_dtype(tz)         return self._simple_new(new_dates, dtype=dtype, freq=self.freq)              )          new_dates = new_dates.view(DT64NS_DTYPE)          dtype = tz_to_dtype(tz)         return self._simple_new(new_dates, dtype=dtype, freq=self.freq)              )          new_dates = new_dates.view(DT64NS_DTYPE)          dtype = tz_to_dtype(tz)         return self._simple_new(new_dates, dtype=dtype, freq=self.freq)              )          new_dates = new_dates.view(DT64NS_DTYPE)          dtype = tz_to_dtype(tz)         return self._simple_new(new_dates,
class ReduceLROnPlateau(Callback):              self.mode = 'auto'          if (self.mode =='min' or             (self.mode == 'auto' and 'acc' not in self.monitor) and self.restore_best_weights)):              self.monitor_op = lambda a, b: np.less(a, b - self.epsilon)              self.best = np.Inf          else:             self.monitor_op = lambda a, b: np.greater(a, b + self.epsilon)              self.best = -np.Inf          self.cooldown_counter = 0          self.wait = 0
def get_objs_combined_axis(          The axis to extract indexes from.      sort : bool, default True          Whether the result index should come out sorted or not.     copy : bool, default False         If True, return a copy of the combined index.      Returns      -------      Index      obs_idxes = [obj._get_axis(axis) for obj in objs]     return _get_combined_index(obs_idxes,
class QuarterOffset(DateOffset):          shifted = liboffsets.shift_quarters(              dtindex.asi8, self.n, self.startingMonth, self._day_opt          )         return type(dtindex)._simple_new(shifted, dtype=dtindex.dtype)
class ImageDataGenerator(object):              The inputs, normalized.         if self.preprocessing_function:             x = self.preprocessing_function(x)          if self.resize:              x = x * self.resize          if self.samplewise_center:              x = x * self.samplewise_center
def _cat_compare_op(op):              mask = (self._codes == -1) | (other_codes == -1)             if mask.any():                 ret[mask] = False              return ret if is_scalar(other) else np.ones(self.shape, dtype=np.intp)          if is_scalar(other):                 ret[mask] = False              return ret          if is_scalar(self):                 ret[mask] = False              return ret          if is_scalar(other):                 ret[mask] = False              return ret          if is_scalar(self):                 ret[mask] = False              return ret          if is_scalar(other):                 ret[mask] = False              return ret          if is_scalar(self):                 ret[mask] = False              return ret          if is_scalar(other):                 ret[mask] = False              return ret          if is_scalar(self):                 ret[mask] = False              return ret          if is_scalar(other):                 ret[mask] = False              return ret          if is_scalar(self):                 ret[mask] = False              return ret          if is_scalar(other):                 ret[mask] = False              return ret          if is_scalar(self):                 ret[mask] = False              return ret          if is_scalar(other):                 ret[mask] = False              return ret          if is_scalar(self):                 ret[mask] = False              return ret          if is_scalar(other):                 ret[mask] = False              return ret          if is_scalar(self):                 ret[mask] = False              return ret          if is_scalar(other):                 ret[mask] = False              return ret          if is_scalar(self):                 ret[mask] = False              return ret          if is_scalar(other):                 ret[mask] = False              return ret          if is_scalar(self):                 ret[mask] = False              return ret          if is_scalar(other):                 ret[mask] = False              return ret          if is_scalar(self):                 ret[mask] = False              return ret          if is_scalar(other):                 ret[mask] = False              return ret          if is_scalar(self):                 ret[mask] = False              return ret          if is_scalar(other):                 ret[mask] = False              return ret          if is_scalar(self):                 ret[mask] = False              return ret          if is_scalar(other):                 ret[mask] = False              return ret          if is_scalar(self):                 ret[mask] = False              return ret          if is_scalar(other):
def match(command, settings):      return _search(command.stderr) or _search(command.stdout) is not None  def get_new_command(command, settings):      m = _search(command.stderr) or _search(command.stdout)     editor_call = '{} {} +{}'.format(os.environ['EDITOR'],                                      m.group('file'),                                       m.group('line'))      return shells.and_(editor_call, command.script)  def match(command, settings):      return _search(command.stderr) or _search(command.stdout) is not None  def get_new_command(command, settings):      m = _search(command.stderr) or _search(command.stdout)     editor_call = '{} {} +{}'.format(os.environ['EDITOR'],                                       m.group('file'),                                        m.group('line'))      return shells.and_(editor_call, command.script)  def match(command, settings):      return _search(command.stderr) or _search(command.stdout) is not None  def get_new_command(command, settings):      m = _search(command.stderr) or _search(command.stdout)     editor_call = '{} {} +{}'.format(os.environ['EDITOR'],                                         m.group('file'),                                          m.group('line'))      return shells.and_(editor_call, command.script)  def match(command, settings):      return _search(command.stderr) or _search(command.stdout) is not None  def get_new_command(command, settings):      m = _search(command.stderr) or _search(command.stdout)     editor_call = '{} {} +{}'.format(os.environ['EDITOR'],                                          m.group('file'),                                            m.group('line'))      return shells.and_(editor_call, command.script)  def match(command, settings):      return _search(command.stderr) or _search(command.stdout) is not None  def get_new_command(command, settings):      m = _search(command.stderr) or _search(command.stdout)     editor_call = '{} {} +{}'.format(os.environ['EDITOR'],                                             m.group('file'),                                              m.group('line'))      return shells.and_(editor_call, command.script)  def match(command, settings):      return _search(command.stderr) or _search(command.stdout) is not None  def get_new_command(command, settings):      m = _search(command.stderr) or _search(command.stdout)     editor_call = '{} {} +{}'.format(os.environ['EDITOR'],                                                m.group('file'),                                                  m.group('line'))      return shells.and_(editor_call, command.script)  def match(command, settings):      return _search(command.stderr) or _search(command.stdout) is not None  def get_new_command(command, settings):      m = _search(command.stderr) or _search(command.stdout)     editor_call = '{} {} +{}'.format(os.environ['EDITOR'],                                                   m.group('file'),                                                     m.group('line'))      return shells.and_(editor_call, command.script)  def match(command, settings):      return _search(command.stderr) or _search(command.stdout) is not None  def get_new_command(command, settings):      m = _search(command.stderr) or _search(command.stdout)     editor_call = '{} {} +{
def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),          padding: string, "same" or "valid".          data_format: "channels_last" or "channels_first".         dilation_rate: tuple of 2 integers.              Whether to use Theano or TensorFlow data format         in inputs/kernels/outputs.          ValueError: if using an even kernel size with padding'same'.         dilation_rate: tuple of 2 integers.              Whether to use Theano or TensorFlow data format         in inputs/kernels/outputs.          ValueError: if using an even kernel size with padding'same'.         dilation_rate: tuple of 2 integers.              Whether to use Theano or TensorFlow data format         in inputs/kernels/outputs.          ValueError: if using an even kernel size with padding'same'.         dilation_rate: tuple of 2 integers.              Whether to use Theano or TensorFlow data format         in inputs/kernels/outputs.          ValueError: if using an even kernel size with padding'same'.         dilation_rate: tuple of 2 integers.              Whether to use Theano or TensorFlow data format         in inputs/kernels/outputs.          ValueError: if using an even kernel size with padding'same'.         dilation_rate: tuple of 2 integers.              Whether to use Theano or TensorFlow data format         in inputs/kernels/outputs.          ValueError: if using an even kernel size with padding'same'.         dilation_rate: tuple of 2 integers.              Whether to use Theano or TensorFlow data format         in inputs/kernels/outputs.          ValueError: if using an even kernel size with padding'same'.         dilation_rate: tuple of 2 integers.              Whether to use Theano or TensorFlow data format         in inputs/kernels/outputs.          ValueError: if using an even kernel size with padding'same'.         dilation_rate: tuple of 2 integers.              Whether to use Theano or TensorFlow data format         in inputs/kernels/outputs.          ValueError: if using an even kernel size with padding'same'.         dilation_rate: tuple of 2 integers.              Whether to use Theano or TensorFlow data format         in inputs/kernels/outputs.          ValueError: if using an even kernel size with padding'same'.         dilation_rate: tuple of 2 integers.              Whether to use Theano or TensorFlow data format         in inputs/kernels/outputs.          ValueError: if using an even kernel size with padding'same'.         dilation_rate: tuple of 2 integers.              Whether to use Theano or TensorFlow data format         in inputs/kernels/outputs.          ValueError: if using an even kernel size with padding'same'.         dilation_rate: tuple of 2 integers.              Whether to use Theano or TensorFlow data format         in inputs/kernels/outputs.          ValueError: if using an even kernel size with padding'same'.         dilation_rate: tuple of 2 integers.              Whether to use Theano or TensorFlow data format         in inputs/kernels/outputs.          ValueError: if using an even kernel size with padding'same'.         dilation_rate: tuple of 2 integers.              Whether to use Theano or TensorFlow data format         in inputs/kernels/outputs.          ValueError: if using an even kernel size with padding'same'.             Whether to use Theano or TensorFlow data format         in inputs/kernels/outputs.          ValueError: if using an even kernel size with padding'same'.             Whether to use Theano or TensorFlow data format         in inputs/kernels/outputs.          ValueError: if using an even kernel size with padding'same'.             Whether to use Theano or TensorFlow data format         in inputs/kernels/outputs.          ValueError: if using an even kernel size with padding'same'.             Whether to use Theano or TensorFlow data format         in inputs/kernels/outputs.          ValueError: if using an even kernel size with padding'same'.             Whether to use Theano or TensorFlow data format         in inputs/kernels/outputs.          ValueError: if using an even kernel size with padding'same'.             Whether to use Theano or TensorFlow data format         in inputs/kernels/outputs.          ValueError: if using
class Spider(object_ref):          crawler.signals.connect(self.close, signals.spider_closed)      def start_requests(self):         for url in self.start_urls:              yield self.make_requests_from_url(url)
def reformat_many(      if sys.platform == "win32":          worker_count = min(worker_count, 61)     if executor is not None:          executor = ProcessPoolExecutor(max_workers=worker_count)          try:              loop.run_until_complete(                 schedule_formatting(
class PeriodIndex(DatetimeIndexOpsMixin, Int64Index, PeriodDelegateMixin):              try:                  loc = self._get_string_slice(key)                  return series[loc]             except (TypeError, ValueError, OverflowError):                  pass             asdt, reso = parse_time_string(key, self.freq)             except (TypeError, ValueError, OverflowError, TypeError):                  pass             asdt, reso = parse_time_string(key, self.freq)             except (TypeError, ValueError, OverflowError, TypeError, TypeError):                  pass             asdt, reso = parse_time_string(key, self.freq)             except (TypeError, ValueError, OverflowError, TypeError, TypeError, TypeError):                  pass             asdt, reso = parse_time_string(key, self.freq)             except (TypeError, ValueError, OverflowError, TypeError, TypeError, TypeError, TypeError):                  pass             asdt, reso = parse_time_string(key, self.freq)             except (TypeError, ValueError, OverflowError, TypeError, TypeError, TypeError, TypeError, TypeError):                  pass             asdt, reso = parse_time_string(key, self.freq)             except (TypeError, ValueError, OverflowError, TypeError, TypeError, TypeError, TypeError, TypeError):                  pass             asdt, reso = parse_time_string(key, self.freq)             except (TypeError, ValueError, OverflowError, TypeError, TypeError, TypeError, TypeError, TypeError):                  pass             asdt, reso = parse_time_string(key, self.freq)             except (TypeError, ValueError, OverflowError, TypeError, TypeError, TypeError, TypeError, TypeError):                  pass             asdt, reso = parse_time_string(key, self.freq)             except (TypeError, ValueError, OverflowError, TypeError, TypeError, TypeError, TypeError, TypeError):                  pass             asdt, reso = parse_time_string(key, self.freq)             except (TypeError, ValueError, OverflowError, TypeError, TypeError, TypeError, TypeError, TypeError):                  pass             asdt, reso = parse_time_string(key, self.freq)             except (TypeError, ValueError, OverflowError, TypeError, TypeError, TypeError, TypeError, TypeError):                  pass             asdt, reso = parse_time_string(key, self.freq)             except (TypeError, ValueError, OverflowError, TypeError, TypeError, TypeError, TypeError, TypeError):                  pass             asdt, reso = parse_time_string(key, self.freq)             except (TypeError, ValueError, OverflowError, TypeError, TypeError, TypeError, TypeError, TypeError):                  pass             asdt, reso = parse_time_string(key, self.freq)             except (TypeError, ValueError, OverflowError, TypeError, TypeError, TypeError, TypeError, TypeError):                  pass             asdt, reso = parse_time_string(key, self.freq)             except (TypeError, ValueError, OverflowError, TypeError, TypeError, TypeError, TypeError):                  pass             asdt, reso = parse_time_string(key, self.freq)             except (TypeError, ValueError, OverflowError, TypeError, TypeError, TypeError, TypeError, TypeError):                  pass             asdt, reso = parse_time_string(key, self.freq)             except (TypeError, ValueError, OverflowError, TypeError, TypeError, TypeError, TypeError, TypeError):                  pass             asdt, reso = parse_time_string(key, self.freq)             except (TypeError, ValueError
def base_url(url):  def urljoin(base, path):      if not isinstance(path, compat_str) or not path:          return path if not isinstance(base, compat_str) or not re.match(r'^(?:[a-zA-Z][a-zA-Z0-9+-.]*:)?          return path      return compat_urlparse.urljoin(base, path)
raise NotImplementedError(                          "Indexing a MultiIndex with a "                          "DataFrame key is not "                          "implemented"                     )                 elif hasattr(key, "ndim") and key.ndim > 1:                     raise NotImplementedError(                          "Indexing a MultiIndex with a "                          "multidimensional key is not "                          "implemented"                     )                 if (                     not isinstance(key, tuple)                     and len(key)                     and not isinstance(key[0], tuple)                 ):                     key = tuple([key])              if not (                    isinstance(key, tuple)                  and isinstance(labels, ABCMultiIndex)              ):                  raise NotImplementedError(                           "Indexing a MultiIndex with a "                          "DataFrame key is not "                          "implemented"                     )                 elif hasattr(key, "ndim") and key.ndim > 1:                     raise NotImplementedError(                          "Indexing a MultiIndex with a "                          "multidimensional key is not "                          "implemented"                     )                 if (                     not isinstance(key, tuple)                     and len(key)                     and not isinstance(key[0], tuple)                ):                     key = tuple([key])             if not (                   isinstance(key, tuple)                    and isinstance(labels, ABCMultiIndex)             ):                  raise NotImplementedError(
def print_tensor(x, message=''):          The same tensor `x`, unchanged.     with tf.Print(x, [x], message):         return tf.Print(x, [x], message)     return tf.Print(x, [x], message)     def print_tensor(x, message=''):          The same tensor `x`, unchanged.     with tf.Print(x, [x], message):         return tf.Print(x, [x], message)     return tf.Print(x, [x], message)     def print_tensor(x, message=''):          The same tensor `x`, unchanged.     with tf.Print(x, [x], message):         return tf.Print(x, [x], message)     return tf.Print(x, [x], message)     def print_tensor(x, message=''):          The same tensor `x`, unchanged.     with tf.Print(x, [x], message):         return tf.Print(x, [x], message)     return tf.Print(x, [x], message)     def print_tensor(x, message=''):          The same tensor `x`, unchanged.     with tf.Print(x, [x], message):         return tf.Print(x, [x], message)     return tf.Print(x, [x], message)     def print_tensor(x, message=''):          The same tensor `x`, unchanged.     with tf.Print(x, [x], message):         return tf.Print(x, [x], message)     return tf.Print(x, [x], message)     def print_tensor(x, message=''):          The same tensor `x`, unchanged.     with tf.Print(x, [x], message):         return tf.Print(x, [x], message)     return tf.Print(x, [x], message)     def print_tensor(x, message=''):          The same tensor `x`, unchanged.     with tf.Print(x, [x], message):         return tf.Print(x, [x], message)     return tf.Print(x, [x], message)     def print_tensor(x, message=''):          The same tensor `x`, unchanged.     with tf.Print(x, [x], message):         return tf.Print(x, [x], message)     return tf.Print(x, [x], message)     def print_tensor(x, message=''):          The same tensor `x`, unchanged.     with tf.Print(x, [x], message):         return tf.Print(x, [x], message)     return tf.Print(x, [x], message)     def print_tensor(x, message=''):          The same tensor `x`, unchanged.     with tf.Print(x, [x], message):         return tf.Print(x, [x], message)     return tf.Print(x, [x], message)     def print_tensor(x, message=''):          The same tensor `x`, unchanged.     with tf.Print(x, [x], message):         return tf.Print(x, [x], message)     return tf.Print(x, [x], message)     def print_tensor(x, message=''):          The same tensor `x`, unchanged.     with tf.Print(x, [x], message):         return tf.Print(x, [x], message)     return tf.Print(x, [x], message)     def print_tensor(x, message=''):          The same tensor `x`, unchanged.     with tf.Print(x, [x], message):         return tf.Print(x, [x], message)     return tf.Print(x, [x], message)     def print_tensor(x, message=''):          The same tensor `x`, unchanged.     with tf.Print(x, [x], message):         return tf.Print(x, [x], message)     return tf.Print(x, [x], message)     def print_tensor(x, message=''):          The same tensor `x`, unchanged.     with tf.Print(x, [x], message):         return tf.Print(x, [x], message)     return tf.Print(x, [x], message)     def print_tensor(x, message=''):          The same tensor `x`, unchanged.     with tf.Print(x, [x], message):         return tf.Print(x, [x], message)     return tf.Print(x, [x], message)     def print_tensor(x, message=''):          The same tensor `x`, unchanged.     with tf.Print(x, [x], message):         return tf.Print(x, [x], message)     return tf.Print(x, [x], message)     def print_tensor(x, message=''):          The same tensor `x`, unchanged.     with tf.Print(x, [x], message):         return tf.Print(x, [x], message)     return tf.Print(x, [x], message)     def print_tensor(x, message=''):          The same tensor `x`, unchanged.     with tf.Print(x, [x], message):         return tf.Print(x, [x], message)     return tf.Print(x, [x], message)     def print_tensor(x, message=''):          The same tensor `x`, unchanged.
class Block(PandasObject):          check_setitem_lengths(indexer, value, values)          if is_empty_indexer(indexer, arr_value):              return              pass
class RedirectMiddleware(BaseRedirectMiddleware):          if 'Location' not in response.headers or response.status not in allowed_status:              return response         location = to_native_str(response.headers['Location'].decode('latin1')) if response.headers['Location'].startswith(b'             request_scheme = urlparse(request.url).scheme location = request_scheme + ':           redirected_url = urljoin(request.url, location)          return redirect(redirected_url)
def _prepare_response_content(     res: Any, *, by_alias: bool = True, exclude_unset: bool  ) -> Any:      if isinstance(res, BaseModel):          return res.dict(              by_alias=by_alias, skip_defaults=exclude_unset          )      elif isinstance(res, list):          return [              _prepare_response_content(item, exclude_unset=exclude_unset) for item in res          ]      elif isinstance(res, dict):          return {              k: _prepare_response_content(v, exclude_unset=exclude_unset)              for k, v in res.items()          }      return res  def _prepare_response_content(     res: Any, *, by_alias: bool = True, exclude_unset: bool  ) -> Any:      if isinstance(res, BaseModel):          return res.dict(              by_alias=by_alias, skip_defaults=exclude_unset          )      elif isinstance(res, list):          return [              _prepare_response_content(item, exclude_unset=exclude_unset) for item in res          ]      elif isinstance(res, dict):          return {              k: _prepare_response_content(v, exclude_unset=exclude_unset)              for k, v in res.items()          }      return res  def _prepare_response_content(     res: Any, *, by_alias: bool = True, exclude_unset: bool  ) -> Any:      if isinstance(res, BaseModel):          return res.dict(               by_alias=by_alias, skip_defaults=exclude_unset          )      elif isinstance(res, list):          return [              _prepare_response_content(item, exclude_unset=exclude_unset) for item in res          ]      elif isinstance(res, dict):          return {              k: _prepare_response_content(v, exclude_unset=exclude_unset)              for k, v in res.items()          }      return res  def _prepare_response_content(     res: Any, *, by_alias: bool = True, exclude_unset: bool  ) -> Any:      if isinstance(res, BaseModel):          return res.dict(               by_alias=by_alias, skip_defaults=exclude_unset          )      elif isinstance(res, list):          return [               _prepare_response_content(item, exclude_unset=exclude_unset) for item in res          ]      elif isinstance(res, dict):          return {              k: _prepare_response_content(v, exclude_unset=exclude_unset)              for k, v in res.items()          }      return res  def _prepare_response_content(     res: Any, *, by_alias: bool = True, exclude_unset: bool  ) -> Any:      if isinstance(res, BaseModel):          return res.dict(              by_alias=by_alias, skip_defaults=exclude_unset         )      elif isinstance(res, list):          return [              _prepare_response_content(item, exclude_unset=exclude_unset) for item in res         ]      elif isinstance(res, dict):          return {              k: _prepare_response_content(v, exclude_unset=exclude_unset)              for k, v in res.items()          }      return res  def _prepare_response_content(     res: Any, *, by_alias: bool = True, exclude_unset: bool  ) -> Any:      if isinstance(
def _make_concat_multiindex(indexes, keys, levels=None, names=None) -> MultiInde          for hlevel, level in zip(zipped, levels):              to_concat = []              for key, index in zip(hlevel, indexes):                  try:                     i = level.get_loc(key)                 except KeyError as err:                     raise ValueError(f"Key {key} not in level {level}") from err                    to_concat.append(np.repeat(i, len(index)))              codes_list.append(np.concatenate(to_concat))
class FastAPI(Starlette):          response_model_by_alias: bool = True,          response_model_skip_defaults: bool = None,          response_model_exclude_unset: bool = False,         response_model_exclude_defaults: bool = False,         response_model_exclude_none: bool = False,          include_in_schema: bool = True,          response_class: Type[Response] = None,          name: str = None,
class tqdm(Comparable):          if disable is None and hasattr(file, "isatty") and not file.isatty():              disable = True          if disable:              try:                  self.iterable = iterable                  self.disable = disable                  self.pos = self._get_free_pos(self)                  self._instances.remove(self)                  self.n = initial                  return          if kwargs:              initial = len(self._instances)              if initial > 0:                  initial_index = 0                  while initial > 0:                     initial_index += 1
import re  from.common import InfoExtractor  from..utils import (      find_xpath_attr,      fix_xml_ampersands,  )
class Index(IndexOpsMixin, PandasObject):              multi_join_idx = multi_join_idx.remove_unused_levels()             if return_indexers:                 return multi_join_idx, lidx, ridx          else:                return multi_join_idx          jl = list(overlap)[0]          if return_indexers:                return multi_join_idx, lidx, ridx          else:                return multi_join_idx
else:  from twisted.internet import defer, reactor, ssl from logging import failure_to_exc_info  logger = logging.getLogger(__name__) else:  from twisted.internet import defer, reactor, ssl  logger = logging.getLogger(__name__)     def failure_to_exc_info(failure):         return failure_to_exc_info(failure_to_exc_info(failure))  logger = logging.getLogger(__name__)     def failure_to_exc_info(failure):         return failure_to_exc_info(failure_to_exc_info(failure_to_exc_info(failure)))  logger = logging.getLogger(__name__)     def failure_to_exc_info(failure):         return failure_to_exc_info(failure_to_exc_info(failure_to_exc_info(failure)))  logger = logging.getLogger(__name__)     def failure_to_exc_info(failure):         return failure_to_exc_info(failure_to_exc_info(failure_to_exc_info(failure)))  logger = logging.getLogger(__name__)     def failure_to_exc_info(failure):         return failure_to_exc_info(failure_to_exc_info(failure_to_exc_info(failure)))  logger = logging.getLogger(__name__)     def failure_to_exc_info(failure):         return failure_to_exc_info(failure_to_exc_info(failure_to_exc_info(failure)))  logger = logging.getLogger(__name__)     def failure_to_exc_info(failure):         return failure_to_exc_info(failure_to_exc_info(failure_to_exc_info(failure)))  logger = logging.getLogger(__name__)     def failure_to_exc_info(failure):         return failure_to_exc_info(failure_to_exc_info(failure_to_exc_info(failure)))  logger = logging.getLogger(__name__)     def failure_to_exc_info(failure):         return failure_to_exc_info(failure_to_exc_info(failure_to_exc_info(failure)))  logger = logging.getLogger(__name__)     def failure_to_exc_info(failure):         return failure_to_exc_info(failure_to_exc_info(failure_to_exc_info(failure)))  logger = logging.getLogger(__name__)     def failure_to_exc_info(failure):         return failure_to_exc_info(failure_to_exc_info(failure_to_exc_info(failure)))  logger = logging.getLogger(__name__)     def failure_to_exc_info(failure):         return failure_to_exc_info(failure_to_exc_info(failure_to_exc_info(failure)))  logger = logging.getLogger(__name__)     def failure_to_exc_info(failure):         return failure_to_exc_info(failure_to_exc_info(failure_to_exc_info(failure)))  logger = logging.getLogger(__name__)     def failure_to_exc_info(failure):         return failure_to_exc_info(failure_to_exc_info(failure_to_exc_info(failure)))  logger = logging.getLogger(__name__)     def failure_to_exc_info(failure):         return failure_to_exc_info(failure_to_exc_info(failure_to_exc_info(failure)))  logger = logging.getLogger(__name__)     def failure_to_exc_info(failure):         return failure_to_exc_info(failure_to_exc_info(failure_to_exc_info(failure)))  logger = logging.getLogger(__name__)     def failure_to_exc_info(failure):         return failure_to_exc_info(failure_to_exc_info(failure_to_exc_info(failure)))  logger = logging.getLogger(__name__)     def failure_to_exc_info(failure):         return failure_to_exc_info(failure_to_exc_info(failure_to_exc_info(failure)))  logger = logging.getLogger(__name__)     def failure_to_exc_info(failure):         return failure_to_exc_info(failure_to_exc_info(failure_to_exc_info(failure)))  logger = logging.getLogger(__name__)     def failure_to_exc_info(failure):         return failure_to_exc_info(failure_to_exc_info(failure_to_exc_info(failure)))  logger = logging.getLogger(__name__)     def failure_to_exc_info(failure):         return failure_to_exc_info(failure_to_exc_info(failure_to_exc_info(failure)))  logger = logging.getLogger(__name__)     def failure_to_exc_info(failure):         return failure_to_exc_info(failure_to_exc_info(failure_to_exc_info(failure)))  logger = logging.getLogger(__name__)     def failure_to_exc_info(failure):         return failure_to_exc_info(failure_to_exc_info(failure_to_exc_info(failure)))  logger = logging.getLogger(__name__)     def failure_to_exc_info(failure):         return failure_to_exc_info(failure_to_exc_info(failure_to_exc_info(failure)))  logger = logging.getLogger(__name__)     def failure_to_exc_info(failure):         return failure_to_exc_info(failure_to_exc_info(failure_to_exc_info(failure)))  logger = logging.getLogger(__name__)     def failure_to_exc_info(failure):         return failure_to_exc_info(failure_to_exc_info(
class CategoricalBlock(ExtensionBlock):      def _holder(self):          return Categorical     def to_native_types(self, slicer=None, na_rep="", quoting=None, **kwargs):         if isinstance(slicer, CategoricalSlicer):             values = self.values         else:             values = np.array(self.values)
class Model(Container):                  val_data += [0.]              for cbk in callbacks:                  cbk.validation_data = val_data         use_sequence_api = is_sequence(generator)         if not use_sequence_api and use_multiprocessing and workers > 1:             warnings.warn(                 UserWarning('Using a generator with `use_multiprocessing=True`'                            'and multiple workers may duplicate your data.'                             'Please consider using the`keras.utils.Sequence'                             'class.'))         if use_sequence_api:             steps_per_epoch = len(generator)          enqueuer = None          try:                  cbk.validation_data = val_data
def melt(              else:                  value_vars = list(value_vars)              missing = Index(com.flatten(value_vars)).difference(cols)              if not missing.empty:                  raise KeyError(                      "The following 'value_vars' are not present in"                  )
class TFOptimizer(Optimizer):      @interfaces.legacy_get_updates_support      def get_updates(self, loss, params):         with np.errstate(all="ignore"):             grads = self.optimizer.compute_gradients(loss, params)             self.updates = [K.update_add(self.iterations, 1)]          opt_update = self.optimizer.apply_gradients(              grads, global_step=self.iterations)         with np.errstate(all="ignore"):              self.updates = [K.update_add(self.iterations, 1)]              opt_update = self.optimizer.apply_gradients(
class YoutubeIE(YoutubeBaseInfoExtractor):          video_id = mobj.group(2)          return video_id     def _extract_chapters(self, description, duration):          if not description:              return None          chapter_lines = re.findall(
class ItemMeta(ABCMeta):          new_attrs['fields'] = fields          new_attrs['_class'] = _class          return super(ItemMeta, mcs).__new__(mcs, class_name, bases, new_attrs)
class ListParameter(Parameter):          Ensure that list parameter is converted to a tuple so it can be hashed.          :param str x: the value to parse.          :return: the normalized (hashable/immutable) value.        .. versionchanged:: 1.0.0           :return: the normalized (hashable/immutable) value.        .. versionchanged:: 1.0.0           :return: the normalized (hashable/immutable) value.        .. versionchanged:: 1.0.0           :return: the normalized (hashable/immutable) value.        .. versionchanged:: 1.0.0           :return: the normalized (hashable/immutable) value.        .. versionchanged:: 1.0.0           :return: the normalized (hashable/immutable) value.        .. versionchanged:: 1.0.0           :return: the normalized (hashable/immutable) value.        .. versionchanged:: 1.0.0           :return: the normalized (hashable/immutable) value.        .. versionchanged:: 1.0.0           :return: the normalized (hashable/immutable) value.        .. versionchanged:: 1.0.0           :return: the normalized (hashable/immutable) value.        .. versionchanged:: 1.0.0           :return: the normalized (hashable/immutable) value.        .. versionchanged:: 1.0.0           :return: the normalized (hashable/immutable) value.        .. versionchanged:: 1.0.0           :return: the normalized (hashable/immutable) value.        .. versionchanged:: 1.0.0           :return: the normalized (hashable/immutable) value.        .. versionchanged:: 1.0.0           :return: the normalized (hashable/immutable) value.        .. versionchanged:: 1.0.0           :return: the normalized (hashable/immutable) value.        .. versionchanged:: 1.0.0           :return: the normalized (hashable/immutable) value.        .. versionchanged:: 1.0.0           :return: the normalized (hashable/immutable) value.        .. versionchanged:: 1.0.0           :return: the normalized (hashable/immutable) value.        .. versionchanged:: 1.0.0           :return: the normalized (hashable/immutable) value.        .. versionchanged:: 1.0.0           :return: the normalized (hashable/immutable) value.        .. versionchanged:: 1.0.0           :return: the normalized (hashable/immutable) value.        .. versionchanged:: 1.0.0           :return: the normalized (hashable/immutable) value.        .. versionchanged:: 1.0.0           :return: the normalized (hashable/immutable) value.        .. versionchanged:: 1.0.0           :return: the normalized (hashable/immutable) value.        .. versionchanged:: 1.0.0           :return: the normalized (hashable/immutable) value.        .. versionchanged:: 1.0.0           :return: the normalized (hashable/immutable) value.        .. versionchanged:: 1.0.0           :return: the normalized (hashable/immutable) value.        .. versionchanged:: 1.0.0           :return: the normalized (hashable/immutable) value.        .. versionchanged:: 1.0.0           :return: the normalized (hashable/immutable) value.        .. versionchanged:: 1.0.0           :return: the normalized (hashable/immutable) value.        .. versionchanged:: 1.0.0           :return: the normalized (hashable/immutable) value.        .. versionchanged:: 1.0.0           :return: the normalized (hashable/immutable) value.        .. versionchanged:: 1.0.0           :return: the normalized (hashable/immutable) value.        .. versionchanged:: 1.0.0           :return: the normalized (hashable/immutable) value.        .. versionchanged:: 1.0.0          :return: the normalized (hashable/immutable) value.        .. versionchanged:: 1.0.0           :return: the normalized (hashable/immutable) value.        .. versionchanged:: 1.0.0           :return: the normalized (hashable/immutable) value.        .. versionchanged:: 1.0.0           :return: the normalized (hashable/immutable) value.        .. versionchanged:: 1.0.0           :return: the normalized (hashable/immutable) value.        .. versionchanged:: 1.0.0           :return: the normalized (hashable/immutable) value.        .. versionchanged:: 1.0
class _MergeOperation:                      )                  ]                 with np.errstate(all="ignore"):
class NumericIndex(Index):              name = data.name          return cls._simple_new(subarr, name=name)     def _maybe_cast_slice_bound(self, label, side, kind):          assert kind in ["ix", "loc", "getitem", None]         if label is cls._simple_new:             return cls._simple_new(subarr, name=name)         else:             return cls._simple_new(subarr, name=name)      @Appender(_index_shared_docs["_maybe_cast_slice_bound"])      def _maybe_cast_slice_bound(self, label, side, kind):          assert kind in ["ix", "loc", "getitem", None]         if label is cls._simple_new:             return cls._simple_new(subarr, name=name)         else:             return cls._simple_new(subarr, name=name)      @Appender(_index_shared_docs["_maybe_cast_slice_bound"])      def _maybe_cast_slice_bound(self, label, side, kind):          assert kind in ["ix", "loc", "getitem", None]         if label is cls._simple_new:             return cls._simple_new(subarr, name=name)         else:             return cls._simple_new(subarr, name=name)      @Appender(_index_shared_docs["_maybe_cast_slice_bound"])      def _maybe_cast_slice_bound(self, label, side, kind):          assert kind in ["ix", "loc", "getitem", None]         if label is cls._simple_new:             return cls._simple_new(subarr, name=name)         else:             return cls._simple_new(subarr, name=name)      @Appender(_index_shared_docs["_maybe_cast_slice_bound"])      def _maybe_cast_slice_bound(self, label, side, kind):          assert kind in ["ix", "loc", "getitem", None]         if label is cls._simple_new:             return cls._simple_new(subarr, name=name)         else:             return cls._simple_new(subarr, name=name)      @Appender(_index_shared_docs["_maybe_cast_slice_bound"])      def _maybe_cast_slice_bound(self, label, side, kind):          assert kind in ["ix", "loc", "getitem", None]         if label is cls._simple_new:             return cls._simple_new(subarr, name=name)         else:             return cls._simple_new(subarr, name=name)      @Appender(_index_shared_docs["_maybe_cast_slice_bound"])      def _maybe_cast_slice_bound(self, label, side, kind):          assert kind in ["ix", "loc", "getitem", None]         if label is cls._simple_new:             return cls._simple_new(subarr, name=name)         else:             return cls._simple_new(subarr, name=name)      @Appender(_index_shared_docs["_maybe_cast_slice_bound"])      def _maybe_cast_slice_bound(self, label, side, kind):          assert kind in ["ix", "loc", "getitem", None]         if label is cls._simple_new:             return cls._simple_new(subarr, name=name)         else:             return cls._simple_new(subarr, name=name)      @Appender(_index_shared_docs["_maybe_cast_slice_bound"])      def _maybe_cast_slice_bound(self, label, side, kind):          assert kind in ["ix", "loc", "getitem", None]         if label is cls._simple_new:             return cls._simple_new(subarr, name=name)         else:             return cls._simple_new(subarr, name=name)      @Appender(_index_shared_docs["_maybe_cast_slice_bound"])      def _maybe_cast_slice_bound(self, label, side, kind):         assert kind in ["ix", "loc", "getitem", None]         if label is cls._simple_new:             return cls._simple_new(subarr, name=name)         else:             return cls._simple_new(subarr, name=name)      @Appender(_index_shared_docs["_maybe_cast_slice_bound"])      def _maybe_cast_slice_bound(self, label, side, kind):         assert kind in ["ix", "loc", "getitem", None]         if label is cls._simple_new:             return cls._simple_new(subarr, name=name)
def _urlencode(seq, enc):  def _get_form(response, formname, formid, formnumber, formxpath):      text = response.body_as_unicode()     root = create_root_node(text, lxml.html.HTMLParser, base_url=response.url)     for form in root.xpath('      if not forms:          raise ValueError("No <form> element found in %s" % response)     return root def _urlencode(seq, enc):  def _get_form(response, formname, formid, formnumber, formxpath):      text = response.body_as_unicode()     root = create_root_node(text, lxml.html.HTMLParser, base_url=response.url)     for form in root.xpath('      if not forms:          raise ValueError("No <form> element found in %s" % response)     return root def _urlencode(seq, enc):  def _get_form(response, formname, formid, formnumber, formxpath):      text = response.body_as_unicode()     root = create_root_node(text, lxml.html.HTMLParser, base_url=response.url)     for form in root.xpath('      if not forms:          raise ValueError("No <form> element found in %s" % response)     return root def _urlencode(seq, enc):  def _get_form(response, formname, formid, formnumber, formxpath):      text = response.body_as_unicode()     root = create_root_node(text, lxml.html.HTMLParser, base_url=response.url)     for form in root.xpath('      if not forms:          raise ValueError("No <form> element found in %s" % response)     return root def _urlencode(seq, enc):  def _get_form(response, formname, formid, formnumber, formxpath):      text = response.body_as_unicode()     root = create_root_node(text, lxml.html.HTMLParser, base_url=response.url)     for form in root.xpath('      if not forms:          raise ValueError("No <form> element found in %s" % response)     return root def _urlencode(seq, enc):  def _get_form(response, formname, formid, formnumber, formxpath):      text = response.body_as_unicode()     root = create_root_node(text, lxml.html.HTMLParser, base_url=response.url)     for form in root.xpath('      if not forms:          raise ValueError("No <form> element found in %s" % response)     return root def _urlencode(seq, enc):  def _get_form(response, formname, formid, formnumber, formxpath):      text = response.body_as_unicode()     root = create_root_node(text, lxml.html.HTMLParser, base_url=response.url)     for form in root.xpath('      if not forms:          raise ValueError("No <form> element found in %s" % response)     return root def _urlencode(seq, enc):  def _get_form(response, formname, formid, formnumber, formxpath):      text = response.body_as_unicode()     root = create_root_node(text, lxml.html.HTMLParser, base_url=response.url)     for form in root.xpath('      if not forms:          raise ValueError("No <form> element found in %s" % response)     return root def _urlencode(seq, enc):  def _get_form(response, formname, formid, formnumber, formxpath):      text = response.body_as_unicode()     root = create_root_node(text, lxml.html.HTMLParser, base_url=response.url)     for form in root.xpath('      if not forms:          raise ValueError("No <form> element found in %s" % response)     return root def _urlencode(seq, enc):  def _get_form(response, formname, formid, formnumber, formxpath):      text = response.body_as_unicode()     root = create_root_node(text, lxml.html.HTMLParser, base_url=response.url)     for form in root.xpath('      if not forms:         raise ValueError("No <form> element found in %s" % response)     return root def _urlencode(seq, enc):  def _get_form(response, formname, formid, formnumber, formxpath):      text = response.body_as_unicode()     root = create_root_node(text, lxml.html.HTMLParser, base_url=response.url)     for form in root.xpath('      if not forms:          raise ValueError("No <form> element found in %s" % response)     return root def _urlencode(seq, enc):  def _get_form(response, formname, formid, formnumber, formxpath):      text = response.body_as_unicode()     root = create_root_node(text, lxml.html.HTMLParser, base_url=response.url)     for form in root.xpath('      if not forms:          raise ValueError("No <form> element found in %s" % response)     return root def _urlencode(seq, enc):  def _get_form(response, formname, formid, formnumber, formxpath):      text = response.body_as_unicode()     root = create_root_node(text, lxml.html.HTMLParser, base_url=response.url)     for form in root.xpath('      if not forms:
class Request(object_ref):          s = safe_url_string(url, self.encoding)          self._url = escape_ajax(s)         if url is None:             raise ValueError('Missing scheme in request url: %s' % self._url)      url = property(_get_url, obsolete_setter(_set_url, 'url'))         if url is None:              raise ValueError('Missing scheme in request url: %s' % self._url)
class EmptyLineTracker:                  return 0, 0              newlines = 2              if current_line.depth > 0:                  newlines -= 1              if current_line.depth:                  newlines -= 1              if newlines == 0:                  return 0, 0              newlines = 2              if current_line.depth:                  newlines -= 1              if newlines == 0:                  return 0, 0              newlines = 2              if current_line.depth:                  newlines -= 1              if newlines == 0:                  return 0, 0              newlines = 2              if current_line.depth:                  newlines -= 1              if newlines == 0:                  return 0, 0              newlines = 2              if current_line.depth:                  newlines -= 1              if newlines == 0:                  return 0, 0              newlines = 2              if current_line.depth:                  newlines -= 1              if newlines == 0:                  return 0, 0              newlines = 2              if current_line.depth:                  newlines -= 1              if newlines == 0:                  return 0, 0              newlines = 2              if current_line.depth:                  newlines -= 1              if newlines == 0:                  return 0, 0              newlines = 2              if current_line.depth:                  newlines -= 1              if newlines == 0:                  return 0, 0              newlines = 2              if current_line.depth:                  newlines -= 1              if newlines == 0:                  return 0, 0              newlines = 2              if current_line.depth:                  newlines -= 1              if newlines == 0:                  return 0, 0              newlines = 2              if current_line.depth:                  newlines -= 1              if newlines == 0:                  return 0, 0              newlines = 2              if current_line.depth:                  newlines -= 1              if newlines == 0:                  return 0, 0              newlines = 2              if current_line.depth:                  newlines -= 1              if newlines == 0:                  return 0, 0              newlines = 2              if current_line.depth:                  newlines -= 1              if newlines == 0:                  return 0, 0              newlines = 2              if current_line.depth:                  newlines -= 1              if newlines == 0:                  return 0, 0              newlines = 2              if current_line.depth:                  newlines -= 1              if newlines == 0:
class DataFrame(NDFrame):          return new_data     def _combine_match_index(self, other: "DataFrame", func):          if ops.should_series_dispatch(self, other, func):             return self._constructor_sliced(func(self, other))          return self._constructor_sliced(func(self, other))
def disp_trim(data, length):      if len(data) == disp_len(data):          return data[:length - 1] while disp_len(data) > length:          data = data[:-1]     if RE_ANSI.search(data):         return data + "\033[0m"      return data def trim_wrapper(data, length):     if len(data) == length - 1:         return data[:length - 1]     return data def disp_trim(data, length):      if len(data) == disp_len(data):          return data[:length - 1] while disp_len(data) > length:          data = data[:-1]     if RE_ANSI.search(data):         return data + "\033[0m"      return data def trim_wrapper_if_needed(data, length):     if len(data) == length - 1:         return data[:length - 1]     return data     def disp_trim(data, length):      if len(data) == disp_len(data):          return data[:length - 1]      return data     def trim_wrapper(data, length):      if len(data) == length - 1:         return data[:length - 1]      return data     def disp_trim(data, length):      if len(data) == disp_len(data):         return data[:length - 1]      return data     def trim_wrapper_if_needed(data, length):      if len(data) == length - 1:         return data[:length - 1]      return data      def disp_trim(data, length):      if len(data) == disp_len(data):         return data[:length - 1]      return data      def trim_wrapper(data, length):      if len(data) == length - 1:         return data[:length - 1]      return data      def disp_trim(data, length):      if len(data) == disp_len(data):         return data[:length - 1]      return data      def trim_wrapper(data, length):      if len(data) == length - 1:         return data[:length - 1]      return data      def disp_trim(data, length):      if len(data) == disp_len(data):         return data[:length - 1]      return data      def trim_wrapper(data, length):      if len(data) == length - 1:         return data[:length - 1]      return data      def disp_trim(data, length):      if len(data) == disp_len(data):         return data[:length - 1]      return data      def trim_wrapper(data, length):      if len(data) == length - 1:         return data[:length - 1]      return data      def disp_trim(data, length):      if len(data) == disp_len(data):         return data[:length - 1]      return data      def trim_wrapper(data, length):      if len(data) == length - 1:         return data[:length - 1]      return data      def disp_trim(data, length):      if len(data) == disp_len(data):         return data[:length - 1]      return data      def trim_wrapper(data, length):      if len(data) == length - 1:         return data[:length - 1]      return data      def disp_trim(data, length):      if len(data) == disp_len(data):         return data[:length - 1]      return data      def trim_wrapper(data, length):      if len(data) == length - 1:         return data[:length - 1]      return data      def disp_trim(data, length):      if len(data) == disp_len(data):         return data[:length - 1]      return data      def trim_wrapper(data, length):      if len(data) == length - 1:         return data[:length - 1]      return data      def disp_trim(data, length):      if len(data) == disp_len(data):         return data[:length - 1]      return data      def trim_wrapper(data, length):      if len(data) == length - 1:         return data[:length - 1]      return data      def disp_trim(data, length):      if len(data) == disp_len(data):         return data[:length - 1]      return data      def trim_wrapper(data, length):      if len(data) == length - 1:         return data[:length - 1]      return data      def disp_trim(data, length):      if len(data) == disp_len(data):         return data[:length - 1]      return data      def trim_wrapper(data, length):      if len(data) == length - 1:         return data[:length -
except ImportError:  from gzip import GzipFile import six  from io import open  except ImportError:  from gzip import GzipFile  import six import os  except ImportError:  from gzip import GzipFile  import six  from io import open  import sys  except ImportError:  from gzip import GzipFile  import six  from io import open  import traceback  except ImportError:  from gzip import GzipFile  import six  from io import open  import sys import errno  except ImportError:  from gzip import GzipFile  import six  from io import open  import traceback as tb  except ImportError:  from gzip import GzipFile  import six  from io import open  import sys  import errno  except ImportError:  from gzip import GzipFile  import six  from io import open  import traceback as tr  except ImportError:  from gzip import GzipFile  import six  from io import open  import sys  import errno
def _unstack_multiple(data, clocs, fill_value=None):              for i in range(len(clocs)):                 val = clocs[i]                 result = result.unstack(val, fill_value=fill_value)                 clocs = [v if i > v else v - 1 for v in clocs]              return result         elif isinstance(fill_value, IntegerArray):             result = _unstack_multiple(data, clocs, fill_value=fill_value)         else:             result = data             clocs = [v if i > v else v - 1 for v in clocs]          return result
def jsonable_encoder(                      value,                      by_alias=by_alias,                      exclude_unset=exclude_unset,                     exclude_defaults=exclude_defaults,                     exclude_none=exclude_none,                      custom_encoder=custom_encoder,
% class CollectionRequirement:              manifest = info['manifest_file']['collection_info']              namespace = manifest['namespace']              name = manifest['name']             version = manifest['version']              dependencies = manifest['dependencies']          else:              display.warning("Collection at '%s' does not have a MANIFEST.json file, cannot detect version." % collection_name)
from tensorflow.python.ops import functional_ops  from tensorflow.python.ops import ctc_ops as ctc  from.common import floatx, epsilon, image_data_format with tensorflow.python.core.common as common  from tensorflow.python.ops import functional_ops  from tensorflow.python.ops import ctc_ops as ctc  from.common import floatx, epsilon, image_data_format with tensorflow.python.core.dtypes as dtypes  from tensorflow.python.ops import functional_ops  from tensorflow.python.ops import ctc_ops as ctc  from.common import floatx, epsilon, image_data_format with tensorflow.python.core.gather as gather  from tensorflow.python.ops import functional_ops  from tensorflow.python.ops import ctc_ops as ctc  from.common import floatx, epsilon, image_data_format with tensorflow.python.core.input_data as input_data  from tensorflow.python.ops import functional_ops  from tensorflow.python.ops import ctc_ops as ctc  from.common import floatx, epsilon, image_data_format with tensorflow.python.core.output_data as output_data  from tensorflow.python.ops import functional_ops  from tensorflow.python.ops import ctc_ops as ctc  from.common import floatx, epsilon, image_data_format with tensorflow.python.core.run as run  from tensorflow.python.ops import functional_ops  from tensorflow.python.ops import ctc_ops as ctc  from.common import floatx, epsilon, image_data_format with tensorflow.python.core.run_options as opts  from tensorflow.python.ops import functional_ops  from tensorflow.python.ops import ctc_ops as ctc  from.common import floatx, epsilon, image_data_format with tensorflow.python.core.test as test  from tensorflow.python.ops import functional_ops  from tensorflow.python.ops import ctc_ops as ctc  from.common import floatx, epsilon, image_data_format with tensorflow.python.core.test_options as opts  from tensorflow.python.ops import functional_ops  from tensorflow.python.ops import ctc_ops as ctc  from.common import floatx, epsilon, image_data_format with tensorflow.python.core.watch as watch  from tensorflow.python.ops import functional_ops  from tensorflow.python.ops import ctc_ops as ctc  from.common import floatx, epsilon, image_data_format with tensorflow.python.core.watch_options as opts  from tensorflow.python.ops import functional_ops  from tensorflow.python.ops import ctc_ops as ctc  from.common import floatx, epsilon, image_data_format with tensorflow.python.core.write as write  from tensorflow.python.ops import functional_ops  from tensorflow.python.ops import ctc_ops as ctc  from.common import floatx, epsilon, image_data_format with tensorflow.python.core.write_options as opts  from tensorflow.python.ops import functional_ops  from tensorflow.python.ops import ctc_ops as ctc  from.common import floatx, epsilon, image_data_format with tensorflow.python.core.run_options as opts  from tensorflow.python.ops import functional_ops  from tensorflow.python.ops import ctc_ops as ctc  from.common import floatx, epsilon, image_data_format with tensorflow.python.core.test_options as opts  from tensorflow.python.ops import functional_ops  from tensorflow.python.ops import ctc_ops as ctc  from.common import floatx, epsilon, image_data_format with tensorflow.python.core.watch_options as opts  from tensorflow.python.ops import functional_ops  from tensorflow.python.ops import ctc_ops as ctc  from.common import floatx, epsilon, image_data_format with tensorflow.python.core.write_options as opts  from tensorflow.python.ops import functional_ops  from tensorflow.python.ops import ctc_ops as ctc  from.common import floatx, epsilon, image_data_format with tensorflow.python.core.run_options as opts  from tensorflow.python.ops import functional_ops  from tensorflow.python.ops import ctc_ops as ctc  from.common import floatx, epsilon, image_data_format with tensorflow.python.core.test_options as opts  from tensorflow.python.ops import functional_ops  from tensorflow.python.ops import ctc_ops as ctc  from.common import floatx, epsilon, image_data_format with tensorflow.python.core.write_options as opts  from tensorflow.python.ops import functional_ops  from tensorflow.python.ops import ctc_ops as ctc  from.common import floatx, epsilon, image_data_format with tensorflow.python.core.run_options as opts  from tensorflow.python.ops import functional_ops  from tensorflow.python.ops import ctc_ops as ctc  from.common import floatx, epsilon, image_data_format with tensorflow.python.core.test_options as opts  from tensorflow.python.ops import functional_ops  from tensorflow.python.ops import ctc_ops as ctc  from.common import floatx, epsilon, image_data_format with tensorflow.python.core.run_options as opts  from tensorflow.python.ops import functional_ops  from tensorflow.python.ops import ctc_ops as ctc  from.common import floatx, epsilon, image_data_format with tensorflow.python.core.test_options as opts  from tensorflow.python.ops import functional_ops  from tensorflow.python.ops import ctc_ops as ctc  from.common import floatx, epsilon, image_data_format with tensorflow.python.core.run_options as opts  from tensorflow.python.ops import functional_ops  from tensorflow.python.ops import ctc_ops as ctc  from.common import floatx, epsilon, image_data_format with tensorflow.python.core.test_options as opts  from tensorflow.python.ops import functional_ops  from tensorflow.python.ops import ctc_ops as ctc  from.common import floatx, epsilon, image_data_format with tensorflow.python.core.run_options as opts  from tensorflow.python.ops import functional_ops  from tensorflow.python.ops import ctc_ops as ctc  from.common import floatx, epsilon, image_data_format with tensorflow.python.core.test_options as opts  from tensorflow.python.ops import functional_ops  from tensorflow.python.ops import ctc
class LinuxHardware(Hardware):              mtab_entries.append(fields)          return mtab_entries     def get_mount_info(self, mountpoint, device, uuids):          mount_size = get_mount_size(mountpoint)         if mount_size is None:             return             mtab_entries.append(fields)          return mtab_entries      def get_mount_info(self, mount, device, uuids):          mount_size = get_mount_size(mount)         if mount_size is None:             return             mtab_entries.append(fields)          return mtab_entries      def get_mount_info(self, mountpoint, device, uuids):          mount_size = get_mount_size(mountpoint)         if mount_size is None:             return             mtab_entries.append(fields)          return mtab_entries      def get_mount_info(self, mount, device, uuids):          mount_size = get_mount_size(mount)         if mount_size is None:             return             mtab_entries.append(fields)          return mtab_entries      def get_mount_info(self, mountpoint, device, uuids):          mount_size = get_mount_size(mountpoint)         if mount_size is None:             return             mtab_entries.append(fields)          return mtab_entries      def get_mount_info(self, mount, device, uuids):          mount_size = get_mount_size(mount)         if mount_size is None:             return             mtab_entries.append(fields)          return mtab_entries      def get_mount_info(self, mount, device, uuids):          mount_size = get_mount_size(mount)         if mount_size is None:             return             mtab_entries.append(fields)          return mtab_entries      def get_mount_info(self, mount, device, uuids):          mount_size = get_mount_size(mount)         if mount_size is None:             return             mtab_entries.append(fields)          return mtab_entries      def get_mount_info(self, mount, device, uuids):          mount_size = get_mount_size(mount)         if mount_size is None:             return             mtab_entries.append(fields)          return mtab_entries      def get_mount_info(self, mount, device, uuids):          mount_size = get_mount_size(mount)         if mount_size is None:             return              mtab_entries.append(fields)          return mtab_entries      def get_mount_info(self, mount, device, uuids):          mount_size = get_mount_size(mount)          if mount_size is None:              return              mtab_entries.append(fields)          return mtab_entries      def get_mount_info(self, mount, device, uuids):          mount_size = get_mount_size(mount)          if mount_size is None:              return              mtab_entries.append(fields)          return mtab_entries      def get_mount_info(self, mount, device, uuids):          mount_size = get_mount_size(mount)          if mount_size is None:              return              mtab_entries.append(fields)          return mtab_entries      def get_mount_info(self, mount, device, uuids):          mount_size = get_mount_size(mount)          if mount_size is None:              return              mtab_entries.append(fields)          return mtab_entries      def get_mount_info(self, mount, device, uuids):          mount_size = get_mount_size(mount)          if mount_size is None:              return              mtab_entries.append(fields)          return mtab_entries      def get_mount_info(self, mount, device, uuids):
class Categorical(ExtensionArray, PandasObject):          min : the minimum of this `Categorical`          self.check_for_ordered("min")         if not len(self._codes):             return -1 * np.ones(len(Categories))          good = self._codes!= -1          if not good.all():              if skipna:                  return -1 * np.ones(len(Categories))             else:                  return np.ones(len(Categories))
def _get_spider_loader(settings):              'Please use SPIDER_LOADER_CLASS.',              category=ScrapyDeprecationWarning, stacklevel=2          )     cls_path = settings.get('SPIDER_LOADER_CLASS',                             settings.get('SPIDER_MANAGER_CLASS'))      loader_cls = load_object(cls_path)      verifyClass(ISpiderLoader, loader_cls)      return loader_cls.from_settings(settings.frozencopy())
logger = logging.getLogger(__name__)  title_regex = re.compile(r"(?<=<title>).*(?=</title>)")  id_regex = re.compile(r"(?<=<id>)\d*(?=</id>)") text_regex = re.compile(r"(?<=<text xml:space=\"preserve\">).*(?=</text)")  info_regex = re.compile(r"{[^{]*?}")  html_regex = re.compile(r"&lt;!--[^-]*--&gt;")
async def serialize_response(              exclude=exclude,              by_alias=by_alias,              exclude_unset=exclude_unset,             exclude_defaults=exclude_defaults,          )      else:          return jsonable_encoder(response_content)
class WebSocketHandler(tornado.web.RequestHandler):         .. versionadded:: 3.1         assert self.stream is not None         self.stream.set_nodelay(value)      def on_open(self) -> None:          self.stream.set_nodelay(value)      def on_connection_close(self) -> None:          if self.ws_connection:              return          if self.stream is not None:              self.stream.set_nodelay(value)      def on_open(self) -> None:          self.stream.set_nodelay(value)      def on_connection_close(self) -> None:          if self.ws_connection:              return          if self.stream is not None:              self.stream.set_nodelay(value)      def set_nodelay(self, value: bool) -> None:          self.stream.set_nodelay(value)      def on_open(self) -> None:          self.stream.set_nodelay(value)      def on_connection_close(self) -> None:          if self.ws_connection:              return          if self.stream is not None:              self.stream.set_nodelay(value)      def set_nodelay(self, value: bool) -> None:          self.stream.set_nodelay(value)      def on_open(self) -> None:          self.stream.set_nodelay(value)      def on_connection_close(self) -> None:          if self.ws_connection:              return          if self.stream is not None:              self.stream.set_nodelay(value)      def set_nodelay(self, value: bool) -> None:          self.stream.set_nodelay(value)      def on_open(self) -> None:          self.stream.set_nodelay(value)      def on_connection_close(self) -> None:          if self.ws_connection:              return          if self.stream is not None:              self.stream.set_nodelay(value)      def set_nodelay(self, value: bool) -> None:          self.stream.set_nodelay(value)      def on_open(self) -> None:          self.stream.set_nodelay(value)      def on_connection_close(self) -> None:          if self.ws_connection:              return          if self.stream is not None:              self.stream.set_nodelay(value)      def set_nodelay(self, value: bool) -> None:          self.stream.set_nodelay(value)      def on_open(self) -> None:          self.stream.set_nodelay(value)      def on_connection_close(self) -> None:          if self.ws_connection:              return          if self.stream is not None:              self.stream.set_nodelay(value)      def set_nodelay(self, value: bool) -> None:          self.stream.set_nodelay(value)      def on_open(self) -> None:          self.stream.set_nodelay(value)      def on_connection_close(self) -> None:          if self.ws_connection:              return          if self.stream is not None:              self.stream.set_nodelay(value)      def set_nodelay(self, value: bool) -> None:          self.stream.set_nodelay(value)      def on_open(self) -> None:          self.stream.set_nodelay(value)      def on_connection_close(self) -> None:          if self.ws_connection:              return          if self.stream is not None:              self.stream.set_nodelay(value)      def set_nodelay(self, value: bool) -> None:          self.stream.set_nodelay(value)      def on_open(self) -> None:          self.stream.set_nodelay(value)      def on_connection_close(self) -> None:          if self.ws_connection:              return          if self.stream is not None:              self.stream.set_nodelay(value)      def set_nodelay(self
from pandas.core.dtypes.common import (       ensure_object,       is_bool_dtype,       is_complex_dtype,      is_datetime64_dtype,      is_datetime64tz_dtype,      is_extension_array_dtype,      is_float_dtype,      is_integer_dtype,      is_object_dtype,      is_period_dtype,      is_scalar,      is_string_dtype,      is_timedelta64_dtype,      needs_i8_conversion,      pandas_dtype,  )  from pandas.core.dtypes.inference import is_list_like from pandas.core.dtypes.common import (        ensure_object,        is_bool_dtype,        is_complex_dtype,        is_datetime64_dtype,        is_datetime64tz_dtype,        is_extension_array_dtype,        is_float_dtype,        is_integer_dtype,        is_object_dtype,        is_period_dtype,        is_scalar,        is_string_dtype,        is_timedelta64_dtype,        needs_i8_conversion,        pandas_dtype,  )  from pandas.core.dtypes.inference import is_list_like from pandas.core.dtypes.common import (         ensure_object,         is_bool_dtype,         is_complex_dtype,         is_datetime64_dtype,         is_datetime64tz_dtype,         is_extension_array_dtype,         is_float_dtype,         is_integer_dtype,         is_object_dtype,         is_period_dtype,         is_scalar,         is_string_dtype,         is_timedelta64_dtype,         needs_i8_conversion,         pandas_dtype,  )  from pandas.core.dtypes.inference import is_list_like from pandas.core.dtypes.common import (          ensure_object,          is_bool_dtype,          is_complex_dtype,          is_datetime64_dtype,          is_datetime64tz_dtype,          is_extension_array_dtype,          is_float_dtype,          is_integer_dtype,          is_object_dtype,          is_period_dtype,          is_scalar,          is_string_dtype,          is_timedelta64_dtype,          needs_i8_conversion,          pandas_dtype,  )  from pandas.core.dtypes.inference import is_list_like from pandas.core.dtypes.common import (          ensure_object,          is_bool_dtype,          is_complex_dtype,          is_datetime64_dtype,          is_datetime64tz_dtype,          is_extension_array_dtype,          is_float_dtype,          is_integer_dtype,          is_object_dtype,          is_period_dtype,          is_scalar,          is_string_dtype,          is_timedelta64_dtype,          needs_i8_conversion,          pandas_dtype,  )  from pandas.core.dtypes.inference import is_list_like from pandas.core.dtypes.common import (          ensure_object,          is_bool_dtype,          is_complex_dtype,          is_datetime64_dtype,          is_datetime64tz_dtype,          is_extension_array_dtype,          is_float_dtype,          is_integer_dtype,          is_object_dtype,
def get_file(fname,          Path to the downloaded file      if cache_dir is None:         cache_dir = os.path.join(os.path.expanduser('~'), '.keras')     elif os.path.isfile(cache_dir):         cache_dir = cache_dir + '.keras'      if md5_hash is not None and file_hash is None:          file_hash = md5_hash          hash_algorithm ='md5'         with codecs.open(cache_dir,
def get_flat_dependant(dependant: Dependant) -> Dependant:  def is_scalar_field(field: Field) -> bool:     return (          field.shape == Shape.SINGLETON          and not lenient_issubclass(field.type_, BaseModel)          and not lenient_issubclass(field.type_, sequence_types + (list, dict))          and not isinstance(field.schema, params.Body)     )  def is_scalar_sequence_field(field: Field) -> bool:     return (          field.shape == Shape.SINGLETON          and not lenient_issubclass(field.type_, BaseModel)          and not lenient_issubclass(field.type_, sequence_types + (list, dict))          and not isinstance(field.schema, params.Body)     )  def is_scalar_map_field(field: Field) -> bool:     return (          field.shape == Shape.SINGLETON          and not lenient_issubclass(field.type_, BaseModel)          and not lenient_issubclass(field.type_, sequence_types + (list, dict))          and not isinstance(field.schema, params.Body)     )  def is_scalar_sequence_map_field(field: Field) -> bool:     return (          field.shape == Shape.SINGLETON          and not lenient_issubclass(field.type_, BaseModel)          and not lenient_issubclass(field.type_, sequence_types + (list, dict))          and not isinstance(field.schema, params.Body)     )  def is_scalar_map_sequence_field(field: Field) -> bool:     return (          field.shape == Shape.SINGLETON          and not lenient_issubclass(field.type_, BaseModel)          and not lenient_issubclass(field.type_, sequence_types + (list, dict))          and not isinstance(field.schema, params.Body)     )  def is_scalar_sequence_map_field(field: Field) -> bool:     return (          field.shape == Shape.SINGLETON          and not lenient_issubclass(field.type_, BaseModel)          and not lenient_issubclass(field.type_, sequence_types + (list, dict))          and not isinstance(field.schema, params.Body)     )  def is_scalar_sequence_map_field(field: Field) -> bool:     return (          field.shape == Shape.SINGLETON          and not lenient_issubclass(field.type_, BaseModel)          and not lenient_issubclass(field.type_, sequence_types + (list, dict))          and not isinstance(field.schema, params.Body)     )  def is_scalar_sequence_map_field(field: Field) -> bool:     return (          field.shape == Shape.SINGLETON          and not lenient_issubclass(field.type_, BaseModel)          and not lenient_issubclass(field.type_, sequence_types + (list, dict))          and not isinstance(field.schema, params.Body)     )  def is_scalar_sequence_map_field(field: Field) -> bool:     return (          field.shape == Shape.SINGLETON          and not lenient_issubclass(field.type_, BaseModel)          and not lenient_issubclass(field.type_, sequence_types + (list, dict))          and not isinstance(field.schema, params.Body)     )  def is_scalar_sequence_map_field(field: Field) -> bool:     return (          field.shape == Shape.SINGLETON          and not lenient_issubclass(field.type_, BaseModel)          and not lenient_issubclass(field.type_, sequence_types + (list, dict))          and not isinstance(field.schema, params.Body)     )  def is_scalar_sequence_map_field(field: Field) -> bool:     return (          field.shape == Shape.SINGLETON          and not lenient_issubclass(field.type_, BaseModel)          and not lenient_issubclass(field.type_, sequence_types + (list, dict))          and not isinstance(field.schema, params.Body)     )  def is_scalar_sequence_map_field(field: Field) -> bool:     return (          field.shape == Shape.SINGLETON          and not lenient_issubclass(field.type_, BaseModel)          and not lenient_issubclass(field.type_, sequence_types + (list, dict))          and not isinstance(field.schema, params.Body)     )  def is_scalar_sequence_map_field(field: Field) -> bool:     return (          field.shape == Shape
def _partition_tasks(worker):      set_tasks["completed"] = {task for (task, status, ext) in task_history if status == 'DONE' and task in pending_tasks}      set_tasks["already_done"] = {task for (task, status, ext) in task_history                                           if status == 'DONE' and task not in pending_tasks and task not in set_tasks["completed"]}      set_tasks["failed"] = {task for (task, status, ext) in task_history                                             if status == 'FAILED' and task not in set_tasks["completed"] and ext}      set_tasks["scheduling_error"] = {task for(task, status, ext) in task_history if status == 'UNKNOWN'}      set_tasks["still_pending_ext"] = {task for (task, status, ext) in task_history                                             if status == 'PENDING' and task not in set_tasks["failed"] and task not in set_tasks["completed"] and ext}      set_tasks["run_by_other_worker"] = set()      set_tasks["upstream_failure"] = set()      set_tasks["upstream_missing_dependency"] = set()
from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pandas.core.common as com from pand
class Parameter(object):          :raises MissingParameterException: if x is false-y and no default is specified.          if not x:             if self.has_value:                 return self.value              elif self.is_bool:                  return False              elif self.is_list:                  return [True, False]
class FloatBlock(FloatOrComplexBlock):          )          return formatter.get_result_as_array()     def should_store(self, value: ArrayLike) -> bool:          return issubclass(value.dtype.type, np.floating) and value.dtype == self.dtype     def should_store(self, value: ArrayLike, dtype: DtypeObj) -> bool:          return issubclass(value.dtype.type, np.floating) and value.dtype == dtype     def should_store(self, value: ArrayLike, dtype: DtypeObj) -> bool:          return issubclass(value.dtype.type, np.floating) and value.dtype == dtype     def should_store(self, value: ArrayLike, dtype: DtypeObj) -> bool:          return issubclass(value.dtype.type, np.floating) and value.dtype == dtype     def should_store(self, value: ArrayLike, dtype: DtypeObj) -> bool:          return issubclass(value.dtype.type, np.floating) and value.dtype == dtype     def should_store(self, value: ArrayLike, dtype: DtypeObj) -> bool:          return issubclass(value.dtype.type, np.floating) and value.dtype == dtype     def should_store(self, value: ArrayLike, dtype: DtypeObj) -> bool:          return issubclass(value.dtype.type, np.floating) and value.dtype == dtype     def should_store(self, value: ArrayLike, dtype: DtypeObj) -> bool:          return issubclass(value.dtype.type, np.floating) and value.dtype == dtype     def should_store(self, value: ArrayLike, dtype: DtypeObj) -> bool:          return issubclass(value.dtype.type, np.floating) and value.dtype == dtype     def should_store(self, value: ArrayLike, dtype: DtypeObj) -> bool:          return issubclass(value.dtype.type, np.floating) and value.dtype == dtype     def should_store(self, value: ArrayLike, dtype: DtypeObj) -> bool:          return issubclass(value.dtype.type, np.floating) and value.dtype == dtype     def should_store(self, value: ArrayLike, dtype: DtypeObj) -> bool:          return issubclass(value.dtype.type, np.floating) and value.dtype == dtype     def should_store(self, value: ArrayLike, dtype: DtypeObj) -> bool:          return issubclass(value.dtype.type, np.floating) and value.dtype == dtype     def should_store(self, value: ArrayLike, dtype: DtypeObj) -> bool:          return issubclass(value.dtype.type, np.floating) and value.dtype == dtype     def should_store(self, value: ArrayLike, dtype: DtypeObj) -> bool:          return issubclass(value.dtype.type, np.floating) and value.dtype == dtype     def should_store(self, value: ArrayLike, dtype: DtypeObj) -> bool:          return issubclass(value.dtype.type, np.floating) and value.dtype == dtype     def should_store(self, value: ArrayLike, dtype: DtypeObj) -> bool:          return issubclass(value.dtype.type, np.floating) and value.dtype == dtype     def should_store(self, value: ArrayLike, dtype: DtypeObj) -> bool:          return issubclass(value.dtype.type, np.floating) and value.dtype == dtype     def should_store(self, value: ArrayLike, dtype: DtypeObj) -> bool:          return issubclass(value.dtype.type, np.floating) and value.dtype == dtype     def should_store(self, value: ArrayLike, dtype: DtypeObj) -> bool:          return issubclass(value.dtype.type, np.floating) and value.dtype == dtype     def should_store(self, value: ArrayLike, dtype: DtypeObj) -> bool:          return issubclass(value.dtype.type, np.floating) and value.dtype == dtype     def should_store(self, value: ArrayLike, dtype: DtypeObj) -> bool:          return issubclass(value.dtype.type, np.floating) and value.dtype == dtype     def should_store(self, value: ArrayLike, dtype: DtypeObj) -> bool:          return issubclass(value.dtype.type, np.floating) and value.dtype == dtype     def should_store(self, value: ArrayLike, dtype: DtypeObj) -> bool:          return issubclass(value.dtype.type, np.floating) and value.dtype == dtype     def should_store(self, value: ArrayLike, dtype: DtypeObj) -> bool:          return issubclass(value.dtype.type, np.floating) and value.dtype == dtype     def should_store(self, value: ArrayLike, dtype: DtypeObj) -> bool:          return issubclass(value.dtype.type, np.floating) and value.dtype == dtype     def should_store(self, value: ArrayLike, dtype: DtypeObj) -> bool:          return issubclass(value.dtype.type, np.floating) and value.dtype == dtype     def should_store(self, value: ArrayLike, dtype: DtypeObj) -> bool:          return issubclass(value.dtype.type, np.flo
class Categorical(ExtensionArray, PandasObject):          good = self._codes!= -1          if not good.all():             if skipna and good.any():                  pointer = self._codes[good].min()              else:                  return np.nan  class Categorical(ExtensionArray, PandasObject):          good = self._codes!= -1          if not good.all():             if skipna and good.any():                  pointer = self._codes[good].min()              else:                  return np.nan          if good.any():             if skipna:                  pointer = self._codes[good].min()              else:                  return np.nan  class Categorical(ExtensionArray, PandasObject):          good = self._codes!= -1          if not good.all():             if skipna and good.any():                  pointer = self._codes[good].min()              else:                  return np.nan          if good.any():             if skipna:                  pointer = self._codes[good].min()              else:                  return np.nan          if good.all():             if skipna:                  pointer = self._codes[good].min()              else:                  return np.nan          if good.any():             if skipna:                  pointer = self._codes[good].min()             else:                  return np.nan          if good.all():             if skipna:                  pointer = self._codes[good].min()             else:                  return np.nan          if good.any():             if skipna:                  pointer = self._codes[good].min()             else:                  return np.nan          if good.all():             if skipna:                  pointer = self._codes[good].min()             else:                  return np.nan          if good.any():             if skipna:                  pointer = self._codes[good].min()             else:                  return np.nan          if good.all():             if skipna:                  pointer = self._codes[good].min()             else:                  return np.nan          if good.any():             if skipna:                  pointer = self._codes[good].min()             else:                  return np.nan          if good.all():             if skipna:                  pointer = self._codes[good].min()             else:                  return np.nan          if good.any():             if skipna:                  pointer = self._codes[good].min()             else:                  return np.nan          if good.all():             if skipna:                  pointer = self._codes[good].min()             else:                  return np.nan          if good.any():             if skipna:                  pointer = self._codes[good].min()             else:                  return
class RedirectMiddleware(BaseRedirectMiddleware):      def process_response(self, request, response, spider):          if (request.meta.get('dont_redirect', False) or                response.status in getattr(spider, 'handle_httpstatus_list', [])):              return response          if request.method == 'HEAD':              return response
def get_new_command(command):          pass      if upstream_option_index is not -1:          command.script_parts.pop(upstream_option_index)         command.script_parts.pop(upstream_option_index)      push_upstream = command.stderr.split('\n')[-3].strip().partition('git ')[2]      return replace_argument(" ".join(command.script_parts), 'push', push_upstream)
from pandas.core.dtypes.common import (          ensure_platform_int,          is_bool,          is_bool_dtype,          is_categorical,          is_categorical_dtype,          is_datetime64_any_dtype,      )
class TestPeriodIndex(DatetimeLike):          idx = PeriodIndex([2000, 2007, 2007, 2009, 2007], freq="A-JUN")          ts = Series(np.random.randn(len(idx)), index=idx)         result = ts["2007"]          expected = ts[idx == "2007"]          tm.assert_series_equal(result, expected)
from pandas.core.dtypes.generic import (  )  from pandas.core.dtypes.missing import notna from pandas._typing import Dtype  from pandas.core import algorithms  from pandas.core.algorithms import unique  from pandas.core.dtypes.generic import (  )  from pandas.core.dtypes.missing import notna  from pandas._typing import Dtype  from pandas.core import algorithms  from pandas.core.algorithms import unique  from pandas.core.dtypes.generic import (  )  from pandas.core.dtypes.missing import notna  from pandas.core.typing import Dtype  from pandas.core import algorithms  from pandas.core.algorithms import unique  from pandas.core.dtypes.generic import (  )  from pandas.core.dtypes.missing import notna  from pandas.core.typing import Dtype  from pandas.core import algorithms  from pandas.core.algorithms import unique  from pandas.core.dtypes.generic import (  )  from pandas.core.dtypes.missing import notna  from pandas.core.typing import Dtype  from pandas.core import algorithms  from pandas.core.algorithms import unique  from pandas.core.dtypes.generic import (  )  from pandas.core.dtypes.missing import notna  from pandas.core.typing import Dtype  from pandas.core import algorithms  from pandas.core.algorithms import unique  from pandas.core.dtypes.generic import (  )  from pandas.core.dtypes.missing import notna  from pandas.core.typing import Dtype  from pandas.core import algorithms  from pandas.core.algorithms import unique  from pandas.core.dtypes.generic import (  )  from pandas.core.dtypes.missing import notna  from pandas.core.typing import Dtype  from pandas.core import algorithms  from pandas.core.algorithms import unique  from pandas.core.dtypes.generic import (  )  from pandas.core.dtypes.missing import notna  from pandas.core.typing import Dtype  from pandas.core import algorithms  from pandas.core.algorithms import unique  from pandas.core.dtypes.generic import (  )  from pandas.core.dtypes.missing import notna  from pandas.core.typing import Dtype  from pandas.core import algorithms  from pandas.core.algorithms import unique  from pandas.core.dtypes.generic import (  )  from pandas.core.dtypes.missing import notna  from pandas.core.typing import Dtype  from pandas.core import algorithms  from pandas.core.algorithms import unique  from pandas.core.dtypes.generic import (  )  from pandas.core.dtypes.missing import notna  from pandas.core.typing import Dtype  from pandas.core import algorithms  from pandas.core.algorithms import unique  from pandas.core.dtypes.generic import (  )  from pandas.core.dtypes.missing import notna  from pandas.core.typing import Dtype  from pandas.core import algorithms  from pandas.core.algorithms import unique  from pandas.core.dtypes.generic import (  )  from pandas.core.dtypes.missing import notna  from pandas.core.typing import Dtype  from pandas.core import algorithms  from pandas.core.algorithms import unique  from pandas.core.dtypes.generic import (  )  from pandas.core.dtypes.missing import notna  from pandas.core.typing import Dtype  from pandas.core import algorithms  from pandas.core.algorithms import unique  from pandas.core.dtypes.generic import (  )  from pandas.core.dtypes.missing import notna  from pandas.core.typing import Dtype  from pandas.core import algorithms  from pandas.core.algorithms import unique  from pandas.core.dtypes.generic import (  )  from pandas.core.dtypes.missing import notna  from pandas.core.typing import Dtype  from pandas.core import algorithms  from pandas.core.algorithms import unique  from pandas.core.dtypes.generic import (  )  from pandas.core.dtypes.missing import notna  from pandas.core.typing import Dtype  from pandas.core import algorithms  from pandas.core.algorithms import unique  from pandas.core.dtypes.generic import (  )  from pandas.core.dtypes.missing import notna  from pandas.core.typing import Dtype  from pandas.core import algorithms  from pandas.core.algorithms import unique  from pandas.core.dtypes.generic import (  )  from pandas.core.dtypes.missing import notna  from pandas.core.typing import Dtype  from pandas.core import algorithms  from pandas.core.algorithms import unique  from pandas.core.dtypes.generic import (  )  from pandas.core.dtypes.missing import notna  from pandas.core.typing import Dtype  from pandas.core import algorithms  from pandas.core.algorithms import unique  from pandas.core.dtypes.generic import (  )  from pandas.core.dtypes.missing import notna  from pandas.core.typing import Dtype  from pandas.core import algorithms  from pandas.core.algorithms import unique  from pandas.core.dtypes.generic import (  )  from pandas.core.dtypes.missing import notna  from pandas.core.typing import Dtype  from pandas.core import algorithms  from pandas.core.algorithms import unique  from pandas.core.dtypes.generic import (  )  from pandas.core.dtypes.missing import notna  from pandas.core.typing import Dtype  from pandas.core import algorithms  from pandas.core.algorithms import unique  from pandas.core.dtypes.generic import (  )  from pandas.core.dtypes.missing import notna  from pandas.core.typing import Dtype  from pandas.core import algorithms  from pandas.core.algorithms import unique  from pandas.core.dtypes.generic import (  )  from pandas.core.dtypes.missing import notna  from pandas.core.typing import Dtype  from pandas.core import algorithms  from pandas.core.algorithms import unique  from pandas.core.dtypes.generic import (  )  from pandas.core.dtypes.missing import notna  from pandas.core.typing import Dtype  from pandas.core import algorithms  from pandas.core.algorithms import unique  from pandas.core.dtypes.generic import (  )  from pandas.core.dtypes.missing import notna  from pandas.core.typing import Dtype  from pandas.core import algorithms  from pandas.core.algorithms import unique  from pandas.core.dtypes.generic import (  )  from pandas.core.dtypes.missing import notna  from pandas.core.typing import Dtype  from pandas.core import algorithms
def evaluate_generator(model, generator,      steps_done = 0      outs_per_batch = []      batch_sizes = []     use_sequence_api = is_sequence(generator)     if not use_sequence_api and use_multiprocessing and workers > 1:          warnings.warn(              UserWarning('Using a generator with `use_multiprocessing=True`'                         'and multiple workers may duplicate your data.'                          'Please consider using the`keras.utils.Sequence'                          'class.'))      if steps is None:         if use_sequence_api:              steps = len(generator)          else:              raise ValueError('`steps=None` is only valid for a generator'
class Series(base.IndexOpsMixin, generic.NDFrame):          kwargs["inplace"] = validate_bool_kwarg(kwargs.pop("inplace", False), "inplace")         non_mapping = is_scalar(index) or (             is_list_like(index) and not is_dict_like(index)         )         if non_mapping:              return self._set_name(index, inplace=kwargs.pop("inplace", False))          return super().rename(index=index, **kwargs)      @Substitution(**_shared_doc_kwargs)      @Appender(generic.NDFrame.reindex.__doc__)      def _set_name(self, index, inplace=kwargs.pop("inplace", False)):          return self._set_name(index, inplace=kwargs.pop("inplace", False))      @Appender(generic.NDFrame.reindex.__doc__)      def _set_name(self, index, inplace=kwargs.pop("inplace", False)):          return self._set_name(index, inplace=kwargs.pop("inplace", False))      @Appender(generic.NDFrame.reindex.__doc__)      def _set_name(self, index, inplace=kwargs.pop("inplace", False)):          return self._set_name(index, inplace=kwargs.pop("inplace", False))      @Appender(generic.NDFrame.reindex.__doc__)      def _set_name(self, index, inplace=kwargs.pop("inplace", False)):          return self._set_name(index, inplace=kwargs.pop("inplace", False))      @Appender(generic.NDFrame.reindex.__doc__)      def _set_name(self, index, inplace=kwargs.pop("inplace", False)):          return self._set_name(index, inplace=kwargs.pop("inplace", False))      @Appender(generic.NDFrame.reindex.__doc__)      def _set_name(self, index, inplace=kwargs.pop("inplace", False)):          return self._set_name(index, inplace=kwargs.pop("inplace", False))      @Appender(generic.NDFrame.reindex.__doc__)      def _set_name(self, index, inplace=kwargs.pop("inplace", False)):          return self._set_name(index, inplace=kwargs.pop("inplace", False))      @Appender(generic.NDFrame.reindex.__doc__)      def _set_name(self, index, inplace=kwargs.pop("inplace", False)):          return self._set_name(index, inplace=kwargs.pop("inplace", False))      @Appender(generic.NDFrame.reindex.__doc__)      def _set_name(self, index, inplace=kwargs.pop("inplace", False)):          return self._set_name(index, inplace=kwargs.pop("inplace", False))      @Appender(generic.NDFrame.reindex.__doc__)      def _set_name(self, index, inplace=kwargs.pop("inplace", False)):          return self._set_name(index, inplace=kwargs.pop("inplace", False))      @Appender(generic.NDFrame.reindex.__doc__)      def _set_name(self, index, inplace=kwargs.pop("inplace", False)):          return self._set_name(index, inplace=kwargs.pop("inplace", False))      @Appender(generic.NDFrame.reindex.__doc__)      def _set_name(self, index, inplace=kwargs.pop("inplace", False)):          return self._set_name(index, inplace=kwargs.pop("inplace", False))      @Appender(generic.NDFrame.reindex.__doc__)      def _set_name(self, index, inplace=kwargs.pop("inplace", False)):          return self._set_name(index, inplace=kwargs.pop("inplace", False))      @Appender(generic.NDFrame.reindex.__doc__)      def _set_name(self, index, inplace=kwargs.pop("inplace", False)):          return self._set_name(index, inplace=kwargs.pop("inplace", False))      @Appender(generic.NDFrame.reindex.__doc__)      def _set_name(self, index, inplace=kwargs.pop("inplace", False)):          return self._set_name(index, inplace=kwargs.pop("inplace", False))      @Appender(generic.NDFrame.reindex.__doc__)      def _set_name(self, index, inplace=kwargs.pop("inplace", False)):          return self._set_name(index, inplace=kwargs.pop("inplace", False))      @Appender(generic.NDFrame.reindex.__doc__)      def _set_name(self, index, inplace=kwargs.pop("inplace", False)):          return self._set_name(index, inplace=kwargs
class BaseAsyncIOLoop(IOLoop):              if all_fds:                  self.close_fd(fileobj)          self.asyncio_loop.close()      def add_handler(self, fd, handler, events):          fd, fileobj = self.split_fd(fd)         if fd is None:             self.close_fd(fileobj)             return          fd, fileobj = self.split_fd(fd)          if fd is None:              self.close_fd(fileobj)             return          fd, fileobj = self.split_fd(fd)          if fd is None:              self.close_fd(fileobj)             return          fd, fileobj = self.split_fd(fd)          if fd is None:              self.close_fd(fileobj)             return          fd, fileobj = self.split_fd(fd)          if fd is None:              self.close_fd(fileobj)             return          fd, fileobj = self.split_fd(fd)          if fd is None:              self.close_fd(fileobj)             return          fd, fileobj = self.split_fd(fd)          if fd is None:              self.close_fd(fileobj)             return          fd, fileobj = self.split_fd(fd)          if fd is None:              self.close_fd(fileobj)             return          fd, fileobj = self.split_fd(fd)          if fd is None:              self.close_fd(fileobj)             return          fd, fileobj = self.split_fd(fd)          if fd is None:              self.close_fd(fileobj)             return          fd, fileobj = self.split_fd(fd)          if fd is None:              self.close_fd(fileobj)             return          fd, fileobj = self.split_fd(fd)          if fd is None:              self.close_fd(fileobj)             return          fd, fileobj = self.split_fd(fd)          if fd is None:              self.close_fd(fileobj)             return          fd, fileobj = self.split_fd(fd)          if fd is None:              self.close_fd(fileobj)             return          fd, fileobj = self.split_fd(fd)          if fd is None:              self.close_fd(fileobj)             return          fd, fileobj = self.split_fd(fd)          if fd is None:              self.close_fd(fileobj)             return          fd, fileobj = self.split_fd(fd)          if fd is None:              self.close_fd(fileobj)             return          fd, fileobj = self.split_fd(fd)          if fd is None:              self.close_fd(fileobj)             return          fd, fileobj = self.split_fd(fd)          if fd is None:              self.close_fd(fileobj)             return          fd, fileobj = self.split_fd(fd)          if fd is None:              self.close_fd(fileobj)             return          fd, fileobj = self.split_fd(fd)          if fd is None:              self.close_fd(fileobj)             return          fd, fileobj = self.split_fd(fd)          if fd is None:              self.close_fd(
.class class ObjectBlock(Block):              if convert:                  block = [b.convert(numeric=False, copy=True) for b in block]              return block         elif isinstance(b, BaseIndexer):             block = [b.convert(numeric=False, copy=True) for b in block]             return block          return self.class ObjectBlock(Block):              if convert:                  block = [b.convert(numeric=False, copy=True) for b in block]             elif isinstance(b, BaseIndexer):                 block = [b.convert(numeric=False, copy=True) for b in block]              return block          return self.class ObjectBlock(Block):              if convert:                  block = [b.convert(numeric=False, copy=True) for b in block]             elif isinstance(b, BaseIndexer):                 block = [b.convert(numeric=False, copy=True) for b in block]              return block          return self.class ObjectBlock(Block):              if convert:                  block = [b.convert(numeric=False, copy=True) for b in block]             elif isinstance(b, BaseIndexer):                 block = [b.convert(numeric=False, copy=True) for b in block]              return block          return self.class ObjectBlock(Block):              if convert:                  block = [b.convert(numeric=False, copy=True) for b in block]             elif isinstance(b, BaseIndexer):                 block = [b.convert(numeric=False, copy=True) for b in block]              return block          return self.class ObjectBlock(Block):              if convert:                  block = [b.convert(numeric=False, copy=True) for b in block]             elif isinstance(b, BaseIndexer):                 block = [b.convert(numeric=False, copy=True) for b in block]              return block          return self.class ObjectBlock(Block):              if convert:                  block = [b.convert(numeric=False, copy=True) for b in block]             elif isinstance(b, BaseIndexer):                 block = [b.convert(numeric=False, copy=True) for b in block]              return block          return self.class ObjectBlock(Block):              if convert:                  block = [b.convert(numeric=False, copy=True) for b in block]             elif isinstance(b, BaseIndexer):                 block = [b.convert(numeric=False, copy=True) for b in block]              return block          return self.class ObjectBlock(Block):              if convert:                  block = [b.convert(numeric=False, copy=True) for b in block]             elif isinstance(b, BaseIndexer):                  block = [b.convert(numeric=False, copy=True) for b in block]              return block          return self.class ObjectBlock(Block):              if convert:                  block = [b.convert(numeric=False, copy=True) for b in block]             elif isinstance(b, BaseIndexer):                  block = [b.convert(numeric=False, copy=True) for b in block]              return block          return self.class ObjectBlock(Block):              if convert:                  block = [b.convert(numeric=False, copy=True) for b in block]             elif isinstance(b, BaseIndexer):                 block = [b.convert(numeric=False, copy=True) for b in block]              return block          return self.class ObjectBlock(Block):              if convert:                  block = [b.convert(numeric=False, copy=True) for b in block]
class Categorical(ExtensionArray, PandasObject):          Only ordered `Categoricals` have a maximum!       .. versionchanged:: 1.0.0          TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError           TypeError
def get_openapi_security_definitions(flat_dependant: Dependant) -> Tuple[Dict, L          security_definition = jsonable_encoder(              security_requirement.security_scheme.model,              by_alias=True,             exclude_defaults=True,          )          security_name = security_requirement.security_scheme.scheme_name          security_definitions[security_name] = security_definition
output_shape[1]) def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),      if isinstance(output_shape, (tuple, list)):          output_shape = tf.stack(output_shape)     x = tf_data_format(x)      if data_format == 'channels_first' and tf_data_format == 'NHWC':          output_shape = (output_shape[0], output_shape[1])

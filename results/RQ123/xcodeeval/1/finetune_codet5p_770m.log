Namespace(log_name='./xcodeeval/1/finetune_codet5p_770m.log', model_name='Salesforce/codet5p-770m', lang='c', output_dir='xcodeeval/1/finetune_codet5p_770m', data_dir='./data/xcodeeval/1', no_cuda=False, visible_gpu='0', add_task_prefix=False, add_lang_ids=False, num_train_epochs=10, num_test_epochs=10, train_batch_size=8, eval_batch_size=4, gradient_accumulation_steps=2, load_model_path=None, config_name='', tokenizer_name='', max_source_length=128, max_target_length=128, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, do_lower_case=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, max_steps=-1, eval_steps=-1, train_steps=-1, local_rank=-1, seed=42, early_stop_threshold=2)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, model_name: Salesforce/codet5p-770m
model created!
Total 1082 training instances 
***** Running training *****
  Num examples = 1082
  Batch size = 8
  Num epoch = 10

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 0
  eval_ppl = 1.00063
  global_step = 136
  train_loss = 0.3706
  ********************
Previous best ppl:inf
Achieve Best ppl:1.00063
  ********************
BLEU file: ./data/xcodeeval/1/validation.jsonl
  codebleu-4 = 72.62 	 Previous best codebleu 0
  ********************
 Achieve Best bleu:72.62
  ********************

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 1
  eval_ppl = 1.00065
  global_step = 271
  train_loss = 0.2571
  ********************
Previous best ppl:1.00063
BLEU file: ./data/xcodeeval/1/validation.jsonl
  codebleu-4 = 71.79 	 Previous best codebleu 72.62
  ********************

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 2
  eval_ppl = 1.00065
  global_step = 406
  train_loss = 0.1881
  ********************
Previous best ppl:1.00063
BLEU file: ./data/xcodeeval/1/validation.jsonl
  codebleu-4 = 72.34 	 Previous best codebleu 72.62
  ********************
reload model from xcodeeval/1/finetune_codet5p_770m/checkpoint-best-bleu
BLEU file: ./data/xcodeeval/1/test.jsonl
  codebleu = 72.84 
  Total = 135 
  Exact Fixed = 0 
[]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  ********************
  Total = 135 
  Exact Fixed = 0 
[]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  codebleu = 72.84 
[0.6741254939692773, 0.6055239846395822, 0.7035272879003251, 0.8078005301884837, 0.8482415780791264, 0.8470661236484578, 0.8506318170022356, 0.6433992707996272, 0.47822580645161283, 0.869097355083081, 0.816095034017857, 0.8881108167610436, 0.7612037516644444, 0.8095193448343525, 0.8992587233632239, 0.7938229814514498, 0.7139951973179235, 0.8365125728430938, 0.7023997010144827, 0.8890119901196314, 0.8667405752508375, 0.6035971947269193, 0.8504318413102254, 0.8517064703343284, 0.8135924606541586, 0.8759794301856842, 0.6538129485106954, 0.683467917649407, 0.8475703733605322, 0.8629852137929874, 0.9214464442482999, 0.8071708182046731, 0.4256938428427359, 0.8772273751686793, 0.726906245805339, 0.8256815726664408, 0.5681163637298114, 0.8514896480093217, 0.7647346904829493, 0.7378248767682071, 0.6540110120458642, 0.7385923732495516, 0.5249478620222177, 0.647487961996232, 0.5325804735306264, 0.9253363255944331, 0.8279104785599881, 0.7330177268778751, 0.6790687280860178, 0.7569630859948919, 0.8805315670914018, 0.3414480260596623, 0.7427116405536602, 0.9109778546090423, 0.46344533813736777, 0.8015341072596128, 0.9259264314733622, 0.6990138341664084, 0.8260661662085544, 0.5160682766833452, 0.8799057191503341, 0.9265235989881684, 0.5076074703740681, 0.8535048490263217, 0.8545893714632256, 0.2837662337662338, 0.7489533595723943, 0.22083634630817556, 0.7622600531135202, 0.7707471127673067, 0.4050873617790997, 0.8418611860573935, 0.4895865072343232, 0.8124797095951521, 0.8145273052967352, 0.26712665967403826, 0.7701328007329863, 0.7694578850257566, 0.849803040412304, 0.8255681126593256, 0.8696427280301575, 0.7927812326921357, 0.7674641460255568, 0.8372583640577188, 0.8696923233625582, 0.9298125945729137, 0.7575006467470722, 0.6016538902088896, 0.8275183621461346, 0.659532270654534, 0.982840810414882, 0.8101763944971344, 0.4650551733188451, 0.6476753884536018, 0.5355322041447821, 0.9498733743967636, 0.6281802407830452, 0.8350035289796414, 0.6184859920453802, 0.906923058378295, 0.8985810813576707, 0.5644982344246664, 0.7842000704719325, 0.19782713521617065, 0.7134134951513778, 0.8396663263205362, 0.4921529174785757, 0.9365739931432338, 0.42779770128383576, 0.8769250379411355, 0.47255350543859986, 0.7862446843835789, 0.7639496783614648, 0.6451144593926297, 0.7011151330217786, 0.88353709334584, 0.9503702205380173, 0.762314097845589, 0.7780707146601717, 0.8996726638725223, 0.7878795313221194, 0.3794955048760881, 0.8336721496048931, 0.4140107071948905, 0.8119506730626463, 0.7211817541923293, 0.7286144481170467, 0.8318325665241797, 0.45601045567543047, 0.724315616661136, 0.6017150080688712, 0.7776995403282871, 0.9013866678857929, 0.46985530336379205, 0.5905688151805155]
Finish training and take 11m
Namespace(log_name='./xcodeeval/1/finetune_codet5p_770m.log', model_name='Salesforce/codet5p-770m', lang='c', output_dir='xcodeeval/2/finetune_codet5p_770m', data_dir='./data/xcodeeval/2', no_cuda=False, visible_gpu='0', add_task_prefix=False, add_lang_ids=False, num_train_epochs=10, num_test_epochs=10, train_batch_size=8, eval_batch_size=4, gradient_accumulation_steps=2, load_model_path=None, config_name='', tokenizer_name='', max_source_length=128, max_target_length=128, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, do_lower_case=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, max_steps=-1, eval_steps=-1, train_steps=-1, local_rank=-1, seed=42, early_stop_threshold=2)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, model_name: Salesforce/codet5p-770m
model created!
Total 1082 training instances 
***** Running training *****
  Num examples = 1082
  Batch size = 8
  Num epoch = 10

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 0
  eval_ppl = 1.00051
  global_step = 136
  train_loss = 0.3789
  ********************
Previous best ppl:inf
Achieve Best ppl:1.00051
  ********************
BLEU file: ./data/xcodeeval/2/validation.jsonl
  codebleu-4 = 73.9 	 Previous best codebleu 0
  ********************
 Achieve Best bleu:73.9
  ********************

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 1
  eval_ppl = 1.00055
  global_step = 271
  train_loss = 0.2673
  ********************
Previous best ppl:1.00051
BLEU file: ./data/xcodeeval/2/validation.jsonl
  codebleu-4 = 73.33 	 Previous best codebleu 73.9
  ********************

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 2
  eval_ppl = 1.00053
  global_step = 406
  train_loss = 0.208
  ********************
Previous best ppl:1.00051
BLEU file: ./data/xcodeeval/2/validation.jsonl
  codebleu-4 = 73.97 	 Previous best codebleu 73.9
  ********************
 Achieve Best bleu:73.97
  ********************

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 3
  eval_ppl = 1.00054
  global_step = 541
  train_loss = 0.1453
  ********************
Previous best ppl:1.00051
BLEU file: ./data/xcodeeval/2/validation.jsonl
  codebleu-4 = 74.03 	 Previous best codebleu 73.97
  ********************
 Achieve Best bleu:74.03
  ********************

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 4
  eval_ppl = 1.00058
  global_step = 676
  train_loss = 0.1046
  ********************
Previous best ppl:1.00051
BLEU file: ./data/xcodeeval/2/validation.jsonl
  codebleu-4 = 74.06 	 Previous best codebleu 74.03
  ********************
 Achieve Best bleu:74.06
  ********************

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 5
  eval_ppl = 1.00064
  global_step = 811
  train_loss = 0.0732
  ********************
Previous best ppl:1.00051
BLEU file: ./data/xcodeeval/2/validation.jsonl
  codebleu-4 = 73.98 	 Previous best codebleu 74.06
  ********************

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 6
  eval_ppl = 1.00071
  global_step = 946
  train_loss = 0.05
  ********************
Previous best ppl:1.00051
BLEU file: ./data/xcodeeval/2/validation.jsonl
  codebleu-4 = 73.87 	 Previous best codebleu 74.06
  ********************
reload model from xcodeeval/2/finetune_codet5p_770m/checkpoint-best-bleu
BLEU file: ./data/xcodeeval/2/test.jsonl
  codebleu = 70.55 
  Total = 135 
  Exact Fixed = 1 
[107]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  ********************
  Total = 135 
  Exact Fixed = 1 
[107]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  codebleu = 70.55 
[0.4079267132112413, 0.6065888646529191, 0.8723015765088757, 0.8981156303935836, 0.628105232559099, 0.8341852120711315, 0.9125880074596351, 0.709526995055453, 0.873793759962344, 0.646374013386654, 0.3893398258970443, 0.5844229263024725, 0.904590355528839, 0.3325195752446274, 0.0442300653748042, 0.8609914309897955, 0.5726261131685282, 0.7482112321606759, 0.8724723036671462, 0.592207910649987, 0.446627993682677, 0.8022232330525529, 0.75750508267751, 0.871717936262084, 0.7980942371440266, 0.6201159722273546, 0.891419774625108, 0.7045218632154403, 0.7710815068968027, 0.33367876486980974, 0.45631161811982324, 0.5818754564013621, 0.8653333140080264, 0.8382191698805657, 0.6004280366320209, 0.5191643807480444, 0.4524934938238685, 0.7906068598309106, 0.31446550674230056, 0.39054140447869534, 0.7503272906104577, 0.7128798335563746, 0.9120861554864073, 0.7784591158731673, 0.8375542987872413, 0.9041581967027494, 0.7801744066714751, 0.940387748772268, 0.79251028814738, 0.7349360722897209, 0.3120288913954662, 0.7716491424868305, 0.5310909326338049, 0.6384499261756515, 0.8852384894814247, 0.7127048131322651, 0.767527819128764, 0.6777766309740647, 0.5367677131990627, 0.9470228248649237, 0.7507584829026313, 0.8396663263205362, 0.9360674082443785, 0.8286915880766478, 0.43387818601959904, 0.7497872722734309, 0.5918835459549441, 0.869474849888572, 0.8946275734848934, 0.8537257078219596, 0.8064069121671387, 0.8603392461291384, 0.7368070849073924, 0.4612620280518578, 0.38692219074807416, 0.8648579538144856, 0.7496420585309386, 0.7602186940402952, 0.7631177288471214, 0.7875865283547716, 0.39578612527759205, 0.30666666666666664, 0.7269618142997433, 0.8753727486979741, 0.5393773280455789, 0.7947820674037744, 0.3852685514477996, 0.76987879200941, 0.8806974736497433, 0.8594524113191127, 0.6979780721244926, 0.8388209385489929, 0.6626435137538318, 0.8416117635801648, 0.7784360171669422, 0.7330409410052742, 0.7833819946139522, 0.7488997676737696, 0.6333744987141046, 0.7410691472083426, 0.44837913955635034, 0.5715313815373253, 0.6739839265768114, 0.39198242100783887, 0.7388705197090006, 0.6951644390669244, 1.0, 0.46673071932457155, 0.9088830127891061, 0.5614360882955788, 0.6537766383397658, 0.8339055840616187, 0.8729244091162942, 0.912198238083447, 0.6618943847067642, 0.8543126179887541, 0.9341190775741011, 0.4335448943198981, 0.8573326876937928, 0.7704569402736815, 0.4220974061228139, 0.8196069166590214, 0.7032096029468522, 0.6413253944664965, 0.7101520621290818, 0.6715603052093865, 0.9001373013223751, 0.6876287414964073, 0.3128264897154612, 0.853191132295444, 0.8164232694020533, 0.9311001454085734, 0.9612737738433852, 0.8861376988212102, 0.7491602177424174]
Finish training and take 22m
Namespace(log_name='./xcodeeval/1/finetune_codet5p_770m.log', model_name='Salesforce/codet5p-770m', lang='c', output_dir='xcodeeval/3/finetune_codet5p_770m', data_dir='./data/xcodeeval/3', no_cuda=False, visible_gpu='0', add_task_prefix=False, add_lang_ids=False, num_train_epochs=10, num_test_epochs=10, train_batch_size=8, eval_batch_size=4, gradient_accumulation_steps=2, load_model_path=None, config_name='', tokenizer_name='', max_source_length=128, max_target_length=128, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, do_lower_case=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, max_steps=-1, eval_steps=-1, train_steps=-1, local_rank=-1, seed=42, early_stop_threshold=2)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, model_name: Salesforce/codet5p-770m
model created!
Total 1082 training instances 
***** Running training *****
  Num examples = 1082
  Batch size = 8
  Num epoch = 10

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 0
  eval_ppl = 1.00057
  global_step = 136
  train_loss = 0.3629
  ********************
Previous best ppl:inf
Achieve Best ppl:1.00057
  ********************
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 73.8 	 Previous best codebleu 0
  ********************
 Achieve Best bleu:73.8
  ********************

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 1
  eval_ppl = 1.00057
  global_step = 271
  train_loss = 0.2449
  ********************
Previous best ppl:1.00057
Achieve Best ppl:1.00057
  ********************
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 74.04 	 Previous best codebleu 73.8
  ********************
 Achieve Best bleu:74.04
  ********************

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 2
  eval_ppl = 1.00056
  global_step = 406
  train_loss = 0.1817
  ********************
Previous best ppl:1.00057
Achieve Best ppl:1.00056
  ********************
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 74.28 	 Previous best codebleu 74.04
  ********************
 Achieve Best bleu:74.28
  ********************

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 3
  eval_ppl = 1.00061
  global_step = 541
  train_loss = 0.1256
  ********************
Previous best ppl:1.00056
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 74.17 	 Previous best codebleu 74.28
  ********************

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 4
  eval_ppl = 1.00066
  global_step = 676
  train_loss = 0.0884
  ********************
Previous best ppl:1.00056
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 74.03 	 Previous best codebleu 74.28
  ********************
reload model from xcodeeval/3/finetune_codet5p_770m/checkpoint-best-bleu
BLEU file: ./data/xcodeeval/3/test.jsonl
  codebleu = 71.34 
  Total = 135 
  Exact Fixed = 1 
[27]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  ********************
  Total = 135 
  Exact Fixed = 1 
[27]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  codebleu = 71.34 
[0.7929417979064819, 0.7663371990492582, 0.6976910864186706, 0.8512897119997327, 0.8536358763066614, 0.08432938445148015, 0.34898094225543036, 0.7669842146074164, 0.6756324089520065, 0.6054199120209949, 0.5601962677755853, 0.8164468849403668, 0.9175351478585267, 0.8726774356123554, 0.8059634988113191, 0.872147466111713, 0.28456980887865324, 0.7534037242254013, 0.5611075353445172, 0.7830064735910691, 0.9185412013134608, 0.8245561139312393, 0.8138327672660688, 0.5524112337326081, 0.7907867143503229, 0.8134383812838551, 1.0, 0.8448616344160145, 0.6982021521970254, 0.7978317575635472, 0.8824402399754723, 0.4739726324720028, 0.5944332173391844, 0.9040862722278158, 0.6345448464057466, 0.7259849312989834, 0.7540469087814428, 0.8313915586456186, 0.5517272573501402, 0.8569685752263538, 0.7932902743460295, 0.630150618578014, 0.6759728227587174, 0.7470425578948228, 0.9118904361242524, 0.8470562047308248, 0.672785744652446, 0.7867507949022507, 0.8536334434067134, 0.5685250847298065, 0.8219514476194971, 0.8419978367899081, 0.9092430471124722, 0.9104392373575145, 0.7182482958421927, 0.941768888951575, 0.6455873914646095, 0.7791901399892995, 0.8654937656858617, 0.4142301377471687, 0.5112111419002278, 0.8012215449104388, 0.9217008915274616, 0.8226849457990322, 0.6827218942680189, 0.7944974662629933, 0.8546770093840449, 0.23178378342054765, 0.7563107817326995, 0.8339849455214231, 0.8155779083654062, 0.901355655227414, 0.754778959829329, 0.7773823007220496, 0.802980404547649, 0.5923377715628043, 0.8125459461294413, 0.720188397702945, 0.6987172522283688, 0.7925405308747024, 0.9011540531929747, 0.837457300065938, 0.7087785501314359, 0.7958146687812508, 0.5677893088427866, 0.7763879223350485, 0.3417564054664891, 0.7704569402736815, 0.7509157324200985, 0.7827835412006432, 0.5672747648078345, 0.647487961996232, 0.8667405752508375, 0.7322128056542299, 0.4154808998544015, 0.811364833324377, 0.5211121075488702, 0.6202723760558566, 0.823799855709568, 0.5271882025547743, 0.8077815485625466, 0.8628818944953964, 0.515209831912117, 0.7848352750832455, 0.8445923838454312, 0.8897945586059963, 0.33520188382167504, 0.4168626518355933, 0.8112549768726531, 0.3975734208323345, 0.8811002176557108, 0.5534803180860053, 0.5285433525156937, 0.8395646321617463, 0.7142029351288322, 0.42918313960976945, 0.8759700055210595, 0.7192634200448921, 0.9150668370807107, 0.7135938825045871, 0.6257365724699333, 0.8545307032267597, 0.7904010053030581, 0.8806594193232651, 0.5248428625544761, 0.6853859283557308, 0.8877072716538504, 0.24170769468996064, 0.2142677455447746, 0.5976804074013286, 0.9003747650468552, 0.8806974736497433, 0.6294449559412665, 0.5963350635154259, 0.24173832962493158]
Finish training and take 19m
Namespace(log_name='./xcodeeval/1/finetune_codet5p_770m.log', model_name='Salesforce/codet5p-770m', lang='c', output_dir='xcodeeval/1/finetune_codet5p_770m', data_dir='./data/xcodeeval/1', no_cuda=False, visible_gpu='0', add_task_prefix=False, add_lang_ids=False, num_train_epochs=10, num_test_epochs=10, train_batch_size=8, eval_batch_size=4, gradient_accumulation_steps=2, load_model_path=None, config_name='', tokenizer_name='', max_source_length=128, max_target_length=128, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, do_lower_case=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, max_steps=-1, eval_steps=-1, train_steps=-1, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, model_name: Salesforce/codet5p-770m
model created!
Total 1082 training instances 
***** Running training *****
  Num examples = 1082
  Batch size = 8
  Num epoch = 10

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 0
  eval_ppl = 1.00062
  global_step = 136
  train_loss = 0.375
  ********************
Previous best ppl:inf
Achieve Best ppl:1.00062
  ********************
BLEU file: ./data/xcodeeval/1/validation.jsonl
  codebleu-4 = 72.45 	 Previous best codebleu 0
  ********************
 Achieve Best bleu:72.45
  ********************

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 1
  eval_ppl = 1.00062
  global_step = 271
  train_loss = 0.2531
  ********************
Previous best ppl:1.00062
BLEU file: ./data/xcodeeval/1/validation.jsonl
  codebleu-4 = 72.32 	 Previous best codebleu 72.45
  ********************

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 2
  eval_ppl = 1.00066
  global_step = 406
  train_loss = 0.1845
  ********************
Previous best ppl:1.00062
BLEU file: ./data/xcodeeval/1/validation.jsonl
  codebleu-4 = 72.24 	 Previous best codebleu 72.45
  ********************

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 3
  eval_ppl = 1.0007
  global_step = 541
  train_loss = 0.1332
  ********************
Previous best ppl:1.00062
BLEU file: ./data/xcodeeval/1/validation.jsonl
  codebleu-4 = 72.56 	 Previous best codebleu 72.45
  ********************
 Achieve Best bleu:72.56
  ********************

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 4
  eval_ppl = 1.00074
  global_step = 676
  train_loss = 0.0946
  ********************
Previous best ppl:1.00062
BLEU file: ./data/xcodeeval/1/validation.jsonl
  codebleu-4 = 72.29 	 Previous best codebleu 72.56
  ********************

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 5
  eval_ppl = 1.00083
  global_step = 811
  train_loss = 0.0652
  ********************
Previous best ppl:1.00062
BLEU file: ./data/xcodeeval/1/validation.jsonl
  codebleu-4 = 72.52 	 Previous best codebleu 72.56
  ********************

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 6
  eval_ppl = 1.00088
  global_step = 946
  train_loss = 0.0464
  ********************
Previous best ppl:1.00062
BLEU file: ./data/xcodeeval/1/validation.jsonl
  codebleu-4 = 72.14 	 Previous best codebleu 72.56
  ********************
reload model from xcodeeval/1/finetune_codet5p_770m/checkpoint-best-bleu
BLEU file: ./data/xcodeeval/1/test.jsonl
  codebleu = 73.24 
  Total = 135 
  Exact Fixed = 0 
[]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  ********************
  Total = 135 
  Exact Fixed = 0 
[]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  codebleu = 73.24 
[0.6741254939692773, 0.6055239846395822, 0.7035272879003251, 0.8078005301884837, 0.8482415780791264, 0.8470661236484578, 0.8506318170022356, 0.6433992707996272, 0.47822580645161283, 0.869097355083081, 0.816095034017857, 0.8881108167610436, 0.7612037516644444, 0.8095193448343525, 0.8992587233632239, 0.7938229814514498, 0.727268027720646, 0.8173520863469337, 0.7023997010144827, 0.8890119901196314, 0.8667405752508375, 0.6035971947269193, 0.8504318413102254, 0.8517064703343284, 0.7911120896783941, 0.798004543744252, 0.6538129485106954, 0.6958702394644983, 0.8475703733605322, 0.812306762981212, 0.8981210104026012, 0.8071708182046731, 0.40620666335555644, 0.8772273751686793, 0.726906245805339, 0.8256815726664408, 0.5733254349221318, 0.8514896480093217, 0.7493852245041672, 0.7378248767682071, 0.6540110120458642, 0.7385923732495516, 0.5487940158683715, 0.647487961996232, 0.5271001834766142, 0.9253363255944331, 0.8279104785599881, 0.7065116004186947, 0.681096752881313, 0.7569630859948919, 0.8805315670914018, 0.3414480260596623, 0.7427116405536602, 0.9109778546090423, 0.46344533813736777, 0.8050429544141107, 0.9264306331540344, 0.7041410201759473, 0.8260661662085544, 0.533974650505709, 0.8448013935706866, 0.9719123091671682, 0.5076074703740681, 0.8506710847032652, 0.8438169327624137, 0.3209775629144812, 0.7489533595723943, 0.22083634630817556, 0.7622600531135202, 0.7707471127673067, 0.4050873617790997, 0.8418611860573935, 0.4895865072343232, 0.8124797095951521, 0.8145273052967352, 0.8717455174648483, 0.7701328007329863, 0.7694578850257566, 0.849803040412304, 0.8255681126593256, 0.8719598303409888, 0.793186090991731, 0.7631808279139581, 0.8476031916439257, 0.8696923233625582, 0.9298125945729137, 0.7461371647825752, 0.6465786180337243, 0.7947118157577724, 0.659532270654534, 0.982840810414882, 0.8710445728632014, 0.4650551733188451, 0.6617404403914646, 0.5355322041447821, 0.9498733743967636, 0.6281802407830452, 0.8350035289796414, 0.6184859920453802, 0.906923058378295, 0.8766881581894976, 0.5468547667811987, 0.7993588411755785, 0.19782713521617065, 0.7134134951513778, 0.8396663263205362, 0.4921529174785757, 0.9365739931432338, 0.42546003894617346, 0.8769250379411355, 0.47255350543859986, 0.7862446843835789, 0.7030932213205241, 0.6451144593926297, 0.7011151330217786, 0.88353709334584, 0.9503702205380173, 0.762314097845589, 0.7780707146601717, 0.8996726638725223, 0.7709430134876254, 0.3794955048760881, 0.8336721496048931, 0.4211856373163223, 0.8119506730626463, 0.7211817541923293, 0.7286144481170467, 0.8318325665241797, 0.45601045567543047, 0.7132783454345335, 0.6017150080688712, 0.876722724918082, 0.9013866678857929, 0.46985530336379205, 0.5905688151805155]
Finish training and take 28m
Namespace(log_name='./xcodeeval/1/finetune_codet5p_770m.log', model_name='Salesforce/codet5p-770m', lang='c', output_dir='xcodeeval/2/finetune_codet5p_770m', data_dir='./data/xcodeeval/2', no_cuda=False, visible_gpu='0', add_task_prefix=False, add_lang_ids=False, num_train_epochs=10, num_test_epochs=10, train_batch_size=8, eval_batch_size=4, gradient_accumulation_steps=2, load_model_path=None, config_name='', tokenizer_name='', max_source_length=128, max_target_length=128, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, do_lower_case=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, max_steps=-1, eval_steps=-1, train_steps=-1, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, model_name: Salesforce/codet5p-770m
model created!
Total 1082 training instances 
***** Running training *****
  Num examples = 1082
  Batch size = 8
  Num epoch = 10

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 0
  eval_ppl = 1.00052
  global_step = 136
  train_loss = 0.3798
  ********************
Previous best ppl:inf
Achieve Best ppl:1.00052
  ********************
BLEU file: ./data/xcodeeval/2/validation.jsonl
  codebleu-4 = 73.96 	 Previous best codebleu 0
  ********************
 Achieve Best bleu:73.96
  ********************

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 1
  eval_ppl = 1.00051
  global_step = 271
  train_loss = 0.2588
  ********************
Previous best ppl:1.00052
Achieve Best ppl:1.00051
  ********************
BLEU file: ./data/xcodeeval/2/validation.jsonl
  codebleu-4 = 74.06 	 Previous best codebleu 73.96
  ********************
 Achieve Best bleu:74.06
  ********************

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 2
  eval_ppl = 1.00057
  global_step = 406
  train_loss = 0.1831
  ********************
Previous best ppl:1.00051
BLEU file: ./data/xcodeeval/2/validation.jsonl
  codebleu-4 = 74.08 	 Previous best codebleu 74.06
  ********************
 Achieve Best bleu:74.08
  ********************

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 3
  eval_ppl = 1.00055
  global_step = 541
  train_loss = 0.1338
  ********************
Previous best ppl:1.00051
BLEU file: ./data/xcodeeval/2/validation.jsonl
  codebleu-4 = 73.94 	 Previous best codebleu 74.08
  ********************

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 4
  eval_ppl = 1.00061
  global_step = 676
  train_loss = 0.09
  ********************
Previous best ppl:1.00051
BLEU file: ./data/xcodeeval/2/validation.jsonl
  codebleu-4 = 74.13 	 Previous best codebleu 74.08
  ********************
 Achieve Best bleu:74.13
  ********************

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 5
  eval_ppl = 1.00064
  global_step = 811
  train_loss = 0.0629
  ********************
Previous best ppl:1.00051
BLEU file: ./data/xcodeeval/2/validation.jsonl
  codebleu-4 = 74.07 	 Previous best codebleu 74.13
  ********************

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 6
  eval_ppl = 1.0007
  global_step = 946
  train_loss = 0.045
  ********************
Previous best ppl:1.00051
BLEU file: ./data/xcodeeval/2/validation.jsonl
  codebleu-4 = 74.01 	 Previous best codebleu 74.13
  ********************

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 7
  eval_ppl = 1.00078
  global_step = 1081
  train_loss = 0.0321
  ********************
Previous best ppl:1.00051
BLEU file: ./data/xcodeeval/2/validation.jsonl
  codebleu-4 = 73.97 	 Previous best codebleu 74.13
  ********************
reload model from xcodeeval/2/finetune_codet5p_770m/checkpoint-best-bleu
BLEU file: ./data/xcodeeval/2/test.jsonl
  codebleu = 70.69 
  Total = 135 
  Exact Fixed = 1 
[107]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  ********************
  Total = 135 
  Exact Fixed = 1 
[107]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  codebleu = 70.69 
[0.4079267132112413, 0.6065888646529191, 0.8723015765088757, 0.8981156303935836, 0.628105232559099, 0.8341852120711315, 0.9125880074596351, 0.709526995055453, 0.873793759962344, 0.6467062393002753, 0.3854267824187835, 0.5844229263024725, 0.904590355528839, 0.30917972313471764, 0.04505175233917717, 0.8344121869573176, 0.5726261131685282, 0.7482112321606759, 0.8724723036671462, 0.592207910649987, 0.5377490214669287, 0.8248170962252077, 0.75750508267751, 0.8640256285697764, 0.8154562777909085, 0.6201159722273546, 0.891419774625108, 0.7045218632154403, 0.7976468342488128, 0.33367876486980974, 0.45631161811982324, 0.5818754564013621, 0.8653333140080264, 0.8258222754680256, 0.6004280366320209, 0.5191643807480444, 0.4524934938238685, 0.8460671937742572, 0.427907872531046, 0.4379797446471848, 0.7503272906104577, 0.7128798335563746, 0.9120861554864073, 0.7784591158731673, 0.8375542987872413, 0.9041581967027494, 0.7801744066714751, 0.940387748772268, 0.79251028814738, 0.8036910613939219, 0.3120288913954662, 0.7716491424868305, 0.5310909326338049, 0.6384499261756515, 0.8852384894814247, 0.7127048131322651, 0.7764975463278132, 0.6992052024026362, 0.5346863070936048, 0.9470228248649237, 0.7507584829026313, 0.8396663263205362, 0.9360674082443785, 0.8633447636989494, 0.43387818601959904, 0.7497872722734309, 0.5918835459549441, 0.8452710463363644, 0.8946275734848934, 0.8537257078219596, 0.8064069121671387, 0.8196951483104229, 0.7368070849073924, 0.4612620280518578, 0.35258502536287617, 0.8648579538144856, 0.7496420585309386, 0.7602186940402952, 0.7631177288471214, 0.7875865283547716, 0.39578612527759205, 0.30666666666666664, 0.7269618142997433, 0.8753727486979741, 0.5393773280455789, 0.7947820674037744, 0.3852685514477996, 0.76987879200941, 0.8806974736497433, 0.8594524113191127, 0.6979780721244926, 0.8388209385489929, 0.6626435137538318, 0.8416117635801648, 0.7784360171669422, 0.521559233346504, 0.7833819946139522, 0.7488997676737696, 0.6333744987141046, 0.7410691472083426, 0.4585240670925822, 0.5599929199988638, 0.6739839265768114, 0.39198242100783887, 0.7388705197090006, 0.6951644390669244, 1.0, 0.46673071932457155, 0.9088830127891061, 0.5614360882955788, 0.6621123536511871, 0.8339055840616187, 0.8729244091162942, 0.912198238083447, 0.6618943847067642, 0.8543126179887541, 0.9341190775741011, 0.4335448943198981, 0.8573326876937928, 0.7704569402736815, 0.4220974061228139, 0.8196069166590214, 0.7032096029468522, 0.6413253944664965, 0.7101520621290818, 0.6715603052093865, 0.9131807795832447, 0.6876287414964073, 0.3128264897154612, 0.853191132295444, 0.8164232694020533, 0.9311001454085734, 0.9612737738433852, 0.8859453911289024, 0.7966006161104328]
Finish training and take 33m
Namespace(log_name='./xcodeeval/1/finetune_codet5p_770m.log', model_name='Salesforce/codet5p-770m', lang='c', output_dir='xcodeeval/3/finetune_codet5p_770m', data_dir='./data/xcodeeval/3', no_cuda=False, visible_gpu='0', add_task_prefix=False, add_lang_ids=False, num_train_epochs=10, num_test_epochs=10, train_batch_size=8, eval_batch_size=4, gradient_accumulation_steps=2, load_model_path=None, config_name='', tokenizer_name='', max_source_length=128, max_target_length=128, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, do_lower_case=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, max_steps=-1, eval_steps=-1, train_steps=-1, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, model_name: Salesforce/codet5p-770m
model created!
Total 1082 training instances 
***** Running training *****
  Num examples = 1082
  Batch size = 8
  Num epoch = 10

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 0
  eval_ppl = 1.00055
  global_step = 136
  train_loss = 0.3612
  ********************
Previous best ppl:inf
Achieve Best ppl:1.00055
  ********************
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 74.33 	 Previous best codebleu 0
  ********************
 Achieve Best bleu:74.33
  ********************

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 1
  eval_ppl = 1.00056
  global_step = 271
  train_loss = 0.2483
  ********************
Previous best ppl:1.00055
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 74.03 	 Previous best codebleu 74.33
  ********************

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 2
  eval_ppl = 1.00055
  global_step = 406
  train_loss = 0.1817
  ********************
Previous best ppl:1.00055
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 74.42 	 Previous best codebleu 74.33
  ********************
 Achieve Best bleu:74.42
  ********************

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 3
  eval_ppl = 1.0006
  global_step = 541
  train_loss = 0.1308
  ********************
Previous best ppl:1.00055
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 73.83 	 Previous best codebleu 74.42
  ********************

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 4
  eval_ppl = 1.00067
  global_step = 676
  train_loss = 0.0933
  ********************
Previous best ppl:1.00055
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 73.99 	 Previous best codebleu 74.42
  ********************

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 5
  eval_ppl = 1.00074
  global_step = 811
  train_loss = 0.0661
  ********************
Previous best ppl:1.00055
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 73.67 	 Previous best codebleu 74.42
  ********************
reload model from xcodeeval/3/finetune_codet5p_770m/checkpoint-best-bleu
BLEU file: ./data/xcodeeval/3/test.jsonl
  codebleu = 71.52 
  Total = 135 
  Exact Fixed = 3 
[27, 45, 117]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  ********************
  Total = 135 
  Exact Fixed = 3 
[27, 45, 117]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  codebleu = 71.52 
[0.7849538767776651, 0.7663371990492582, 0.6976910864186706, 0.8512897119997327, 0.8536358763066614, 0.08406889937820157, 0.34898094225543036, 0.7669842146074164, 0.6756324089520065, 0.6054199120209949, 0.5601962677755853, 0.8164468849403668, 0.9175351478585267, 0.8726774356123554, 0.8059634988113191, 0.872147466111713, 0.28456980887865324, 0.7534037242254013, 0.5654675203716997, 0.7830064735910691, 0.9185412013134608, 0.8245561139312393, 0.8138327672660688, 0.5524112337326081, 0.7907867143503229, 0.802138971106996, 1.0, 0.8267329721877597, 0.6982021521970254, 0.7921624393976985, 0.91412960455335, 0.4739726324720028, 0.5246352681210026, 0.9040862722278158, 0.6345448464057466, 0.7259849312989834, 0.7540469087814428, 0.8313915586456186, 0.6121972533149926, 0.8569685752263538, 0.7932902743460295, 0.630150618578014, 0.6759728227587174, 0.7470425578948228, 1.0, 0.8470562047308248, 0.672785744652446, 0.7867507949022507, 0.8536334434067134, 0.5685250847298065, 0.8219514476194971, 0.8419978367899081, 0.9092430471124722, 0.9104392373575145, 0.6951713727652697, 0.941768888951575, 0.6455873914646095, 0.7932126424647954, 0.8654937656858617, 0.4142301377471687, 0.5112111419002278, 0.8297929734818674, 0.9217008915274616, 0.8689970404457057, 0.6797132326622942, 0.7944974662629933, 0.8546770093840449, 0.23178378342054765, 0.7563107817326995, 0.8339849455214231, 0.8155779083654062, 0.901355655227414, 0.754778959829329, 0.721977501851727, 0.802980404547649, 0.5923377715628043, 0.8125459461294413, 0.720188397702945, 0.6987172522283688, 0.7925405308747024, 0.900395087233911, 0.837457300065938, 0.7087785501314359, 0.7700652915417614, 0.5677893088427866, 0.7763879223350485, 0.3417564054664891, 0.777748374412698, 0.7509157324200985, 0.7827835412006432, 0.5672747648078345, 0.647487961996232, 0.8819989837824207, 0.7470362018806367, 0.4154808998544015, 0.811364833324377, 0.5211121075488702, 0.6610238827063706, 0.823799855709568, 0.5271882025547743, 0.8077815485625466, 0.8628818944953964, 0.5105547910952926, 0.7848352750832455, 0.8445923838454312, 0.8897945586059963, 0.33520188382167504, 0.4168626518355933, 0.852945187183654, 0.3975734208323345, 0.8811002176557108, 0.5534803180860053, 0.5285433525156937, 0.831862639858802, 0.7142029351288322, 0.42918313960976945, 1.0, 0.7192634200448921, 0.9150668370807107, 0.6994272158379204, 0.6257365724699333, 0.8545307032267597, 0.7904010053030581, 0.8806594193232651, 0.5346863070936048, 0.6853859283557308, 0.8877072716538504, 0.24170769468996064, 0.2142677455447746, 0.572625617722997, 0.9003747650468552, 0.8806974736497433, 0.6294449559412665, 0.5963350635154259, 0.24173832962493158]
Finish training and take 26m
Namespace(log_name='./xcodeeval/1/finetune_codet5p_770m.log', model_name='Salesforce/codet5p-770m', lang='c', output_dir='xcodeeval/1/finetune_codet5p_770m', data_dir='./data/xcodeeval/1', no_cuda=False, visible_gpu='0', add_task_prefix=False, add_lang_ids=False, num_train_epochs=10, num_test_epochs=10, train_batch_size=8, eval_batch_size=4, gradient_accumulation_steps=2, load_model_path=None, config_name='', tokenizer_name='', max_source_length=128, max_target_length=128, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, do_lower_case=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, max_steps=-1, eval_steps=-1, train_steps=-1, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, model_name: Salesforce/codet5p-770m
model created!
Total 1082 training instances 
***** Running training *****
  Num examples = 1082
  Batch size = 8
  Num epoch = 10

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 0
  eval_ppl = 1.00063
  global_step = 136
  train_loss = 0.3706
  ********************
Previous best ppl:inf
Achieve Best ppl:1.00063
  ********************
BLEU file: ./data/xcodeeval/1/validation.jsonl
  codebleu-4 = 72.6 	 Previous best codebleu 0
  ********************
 Achieve Best bleu:72.6
  ********************

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 1
  eval_ppl = 1.00065
  global_step = 271
  train_loss = 0.2571
  ********************
Previous best ppl:1.00063
BLEU file: ./data/xcodeeval/1/validation.jsonl
  codebleu-4 = 71.77 	 Previous best codebleu 72.6
  ********************

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 2
  eval_ppl = 1.00065
  global_step = 406
  train_loss = 0.1881
  ********************
Previous best ppl:1.00063
BLEU file: ./data/xcodeeval/1/validation.jsonl
  codebleu-4 = 72.31 	 Previous best codebleu 72.6
  ********************

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 3
  eval_ppl = 1.00068
  global_step = 541
  train_loss = 0.1374
  ********************
Previous best ppl:1.00063
BLEU file: ./data/xcodeeval/1/validation.jsonl
  codebleu-4 = 72.44 	 Previous best codebleu 72.6
  ********************
reload model from xcodeeval/1/finetune_codet5p_770m/checkpoint-best-bleu
BLEU file: ./data/xcodeeval/1/test.jsonl
  codebleu = 72.82 
  Total = 135 
  Exact Fixed = 0 
[]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  ********************
  Total = 135 
  Exact Fixed = 0 
[]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  codebleu = 72.82 
[0.6741254939692773, 0.6055239846395822, 0.7035272879003251, 0.8078005301884837, 0.8482415780791264, 0.8470661236484578, 0.8506318170022356, 0.6433992707996272, 0.47822580645161283, 0.869097355083081, 0.816095034017857, 0.8881108167610436, 0.7612037516644444, 0.8095193448343525, 0.8992587233632239, 0.7938229814514498, 0.7139951973179235, 0.8365125728430938, 0.7023997010144827, 0.8890119901196314, 0.8667405752508375, 0.6035971947269193, 0.8504318413102254, 0.8517064703343284, 0.8272288242905221, 0.8759794301856842, 0.6538129485106954, 0.683467917649407, 0.8475703733605322, 0.8629852137929874, 0.9214464442482999, 0.8071708182046731, 0.4256938428427359, 0.8772273751686793, 0.726906245805339, 0.8256815726664408, 0.5681163637298114, 0.8514896480093217, 0.7647346904829493, 0.7378248767682071, 0.6540110120458642, 0.7385923732495516, 0.5249478620222177, 0.6359495004577705, 0.5325804735306264, 0.9253363255944331, 0.8279104785599881, 0.7330177268778751, 0.6624020614193511, 0.7569630859948919, 0.8805315670914018, 0.3414480260596623, 0.7427116405536602, 0.9109778546090423, 0.46344533813736777, 0.8015341072596128, 0.9259264314733622, 0.6990138341664084, 0.8260661662085544, 0.5160682766833452, 0.8799057191503341, 0.9265235989881684, 0.5076074703740681, 0.8535048490263217, 0.8545893714632256, 0.2837662337662338, 0.7489533595723943, 0.22083634630817556, 0.7622600531135202, 0.7707471127673067, 0.4050873617790997, 0.8418611860573935, 0.4895865072343232, 0.8124797095951521, 0.8145273052967352, 0.26712665967403826, 0.7701328007329863, 0.7694578850257566, 0.849803040412304, 0.8255681126593256, 0.8696427280301575, 0.7927812326921357, 0.7674641460255568, 0.8372583640577188, 0.8696923233625582, 0.9298125945729137, 0.7575006467470722, 0.6016538902088896, 0.8275183621461346, 0.659532270654534, 0.982840810414882, 0.8101763944971344, 0.4650551733188451, 0.6476753884536018, 0.5355322041447821, 0.9498733743967636, 0.6281802407830452, 0.8350035289796414, 0.6184859920453802, 0.906923058378295, 0.8985810813576707, 0.5644982344246664, 0.7842000704719325, 0.19782713521617065, 0.7134134951513778, 0.8396663263205362, 0.4921529174785757, 0.9365739931432338, 0.42779770128383576, 0.8769250379411355, 0.47255350543859986, 0.7862446843835789, 0.7639496783614648, 0.6451144593926297, 0.7011151330217786, 0.88353709334584, 0.9503702205380173, 0.762314097845589, 0.7780707146601717, 0.8996726638725223, 0.7782021119672806, 0.3794955048760881, 0.8336721496048931, 0.4140107071948905, 0.8119506730626463, 0.7211817541923293, 0.7286144481170467, 0.8318325665241797, 0.45601045567543047, 0.724315616661136, 0.6017150080688712, 0.7776995403282871, 0.9013866678857929, 0.46985530336379205, 0.5905688151805155]
Finish training and take 14m
Namespace(log_name='./xcodeeval/1/finetune_codet5p_770m.log', model_name='Salesforce/codet5p-770m', lang='c', output_dir='xcodeeval/2/finetune_codet5p_770m', data_dir='./data/xcodeeval/2', no_cuda=False, visible_gpu='0', add_task_prefix=False, add_lang_ids=False, num_train_epochs=10, num_test_epochs=10, train_batch_size=8, eval_batch_size=4, gradient_accumulation_steps=2, load_model_path=None, config_name='', tokenizer_name='', max_source_length=128, max_target_length=128, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, do_lower_case=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, max_steps=-1, eval_steps=-1, train_steps=-1, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, model_name: Salesforce/codet5p-770m
model created!
Total 1082 training instances 
***** Running training *****
  Num examples = 1082
  Batch size = 8
  Num epoch = 10

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 0
  eval_ppl = 1.00051
  global_step = 136
  train_loss = 0.3789
  ********************
Previous best ppl:inf
Achieve Best ppl:1.00051
  ********************
BLEU file: ./data/xcodeeval/2/validation.jsonl
  codebleu-4 = 73.9 	 Previous best codebleu 0
  ********************
 Achieve Best bleu:73.9
  ********************

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 1
  eval_ppl = 1.00055
  global_step = 271
  train_loss = 0.2673
  ********************
Previous best ppl:1.00051
BLEU file: ./data/xcodeeval/2/validation.jsonl
  codebleu-4 = 73.33 	 Previous best codebleu 73.9
  ********************

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 2
  eval_ppl = 1.00053
  global_step = 406
  train_loss = 0.208
  ********************
Previous best ppl:1.00051
BLEU file: ./data/xcodeeval/2/validation.jsonl
  codebleu-4 = 73.97 	 Previous best codebleu 73.9
  ********************
 Achieve Best bleu:73.97
  ********************

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 3
  eval_ppl = 1.00054
  global_step = 541
  train_loss = 0.1453
  ********************
Previous best ppl:1.00051
BLEU file: ./data/xcodeeval/2/validation.jsonl
  codebleu-4 = 74.03 	 Previous best codebleu 73.97
  ********************
 Achieve Best bleu:74.03
  ********************

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 4
  eval_ppl = 1.00058
  global_step = 676
  train_loss = 0.1046
  ********************
Previous best ppl:1.00051
BLEU file: ./data/xcodeeval/2/validation.jsonl
  codebleu-4 = 74.06 	 Previous best codebleu 74.03
  ********************
 Achieve Best bleu:74.06
  ********************

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 5
  eval_ppl = 1.00064
  global_step = 811
  train_loss = 0.0732
  ********************
Previous best ppl:1.00051
BLEU file: ./data/xcodeeval/2/validation.jsonl
  codebleu-4 = 73.98 	 Previous best codebleu 74.06
  ********************

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 6
  eval_ppl = 1.00071
  global_step = 946
  train_loss = 0.05
  ********************
Previous best ppl:1.00051
BLEU file: ./data/xcodeeval/2/validation.jsonl
  codebleu-4 = 73.87 	 Previous best codebleu 74.06
  ********************

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 7
  eval_ppl = 1.00079
  global_step = 1081
  train_loss = 0.0351
  ********************
Previous best ppl:1.00051
BLEU file: ./data/xcodeeval/2/validation.jsonl
  codebleu-4 = 73.85 	 Previous best codebleu 74.06
  ********************
reload model from xcodeeval/2/finetune_codet5p_770m/checkpoint-best-bleu
BLEU file: ./data/xcodeeval/2/test.jsonl
  codebleu = 70.61 
  Total = 135 
  Exact Fixed = 1 
[107]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  ********************
  Total = 135 
  Exact Fixed = 1 
[107]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  codebleu = 70.61 
[0.4079267132112413, 0.6065888646529191, 0.8723015765088757, 0.8981156303935836, 0.628105232559099, 0.8341852120711315, 0.9125880074596351, 0.709526995055453, 0.873793759962344, 0.646374013386654, 0.3893398258970443, 0.5844229263024725, 0.904590355528839, 0.3325195752446274, 0.0442300653748042, 0.8609914309897955, 0.5726261131685282, 0.7482112321606759, 0.8724723036671462, 0.592207910649987, 0.446627993682677, 0.8022232330525529, 0.75750508267751, 0.871717936262084, 0.7980942371440266, 0.6201159722273546, 0.891419774625108, 0.7045218632154403, 0.7710815068968027, 0.33367876486980974, 0.45631161811982324, 0.5818754564013621, 0.8653333140080264, 0.8382191698805657, 0.6004280366320209, 0.560543691092872, 0.4524934938238685, 0.7906068598309106, 0.31446550674230056, 0.39054140447869534, 0.7503272906104577, 0.7128798335563746, 0.9120861554864073, 0.7784591158731673, 0.8375542987872413, 0.9041581967027494, 0.7801744066714751, 0.940387748772268, 0.79251028814738, 0.7349360722897209, 0.3120288913954662, 0.7716491424868305, 0.5310909326338049, 0.6384499261756515, 0.8852384894814247, 0.7127048131322651, 0.767527819128764, 0.6777766309740647, 0.5367677131990627, 0.9470228248649237, 0.7507584829026313, 0.8396663263205362, 0.9360674082443785, 0.8286915880766478, 0.43387818601959904, 0.7497872722734309, 0.5918835459549441, 0.869474849888572, 0.8946275734848934, 0.8537257078219596, 0.8064069121671387, 0.8603392461291384, 0.7368070849073924, 0.4612620280518578, 0.38692219074807416, 0.8648579538144856, 0.7496420585309386, 0.7602186940402952, 0.7631177288471214, 0.7875865283547716, 0.39578612527759205, 0.30666666666666664, 0.7269618142997433, 0.8753727486979741, 0.5393773280455789, 0.7947820674037744, 0.3852685514477996, 0.76987879200941, 0.8806974736497433, 0.8594524113191127, 0.6979780721244926, 0.8388209385489929, 0.6626435137538318, 0.8416117635801648, 0.7784360171669422, 0.7330409410052742, 0.7833819946139522, 0.7488997676737696, 0.6333744987141046, 0.7410691472083426, 0.44837913955635034, 0.5715313815373253, 0.6739839265768114, 0.39198242100783887, 0.7388705197090006, 0.6951644390669244, 1.0, 0.46673071932457155, 0.9088830127891061, 0.5614360882955788, 0.6537766383397658, 0.8339055840616187, 0.8729244091162942, 0.912198238083447, 0.682584039879178, 0.8543126179887541, 0.9341190775741011, 0.4335448943198981, 0.8573326876937928, 0.7704569402736815, 0.4220974061228139, 0.8196069166590214, 0.7032096029468522, 0.6413253944664965, 0.7101520621290818, 0.6715603052093865, 0.9131807795832447, 0.6876287414964073, 0.3128264897154612, 0.853191132295444, 0.8164232694020533, 0.9311001454085734, 0.9612737738433852, 0.8861376988212102, 0.7491602177424174]
Finish training and take 26m
Namespace(log_name='./xcodeeval/1/finetune_codet5p_770m.log', model_name='Salesforce/codet5p-770m', lang='c', output_dir='xcodeeval/3/finetune_codet5p_770m', data_dir='./data/xcodeeval/3', no_cuda=False, visible_gpu='0', add_task_prefix=False, add_lang_ids=False, num_train_epochs=10, num_test_epochs=10, train_batch_size=8, eval_batch_size=4, gradient_accumulation_steps=2, load_model_path=None, config_name='', tokenizer_name='', max_source_length=128, max_target_length=128, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, do_lower_case=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, max_steps=-1, eval_steps=-1, train_steps=-1, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, model_name: Salesforce/codet5p-770m
model created!
Total 1082 training instances 
***** Running training *****
  Num examples = 1082
  Batch size = 8
  Num epoch = 10

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 0
  eval_ppl = 1.00057
  global_step = 136
  train_loss = 0.3629
  ********************
Previous best ppl:inf
Achieve Best ppl:1.00057
  ********************
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 73.81 	 Previous best codebleu 0
  ********************
 Achieve Best bleu:73.81
  ********************

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 1
  eval_ppl = 1.00057
  global_step = 271
  train_loss = 0.2449
  ********************
Previous best ppl:1.00057
Achieve Best ppl:1.00057
  ********************
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 74.05 	 Previous best codebleu 73.81
  ********************
 Achieve Best bleu:74.05
  ********************

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 2
  eval_ppl = 1.00056
  global_step = 406
  train_loss = 0.1817
  ********************
Previous best ppl:1.00057
Achieve Best ppl:1.00056
  ********************
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 74.29 	 Previous best codebleu 74.05
  ********************
 Achieve Best bleu:74.29
  ********************

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 3
  eval_ppl = 1.00061
  global_step = 541
  train_loss = 0.1256
  ********************
Previous best ppl:1.00056
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 74.18 	 Previous best codebleu 74.29
  ********************

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 4
  eval_ppl = 1.00066
  global_step = 676
  train_loss = 0.0884
  ********************
Previous best ppl:1.00056
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 74.04 	 Previous best codebleu 74.29
  ********************

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 5
  eval_ppl = 1.00069
  global_step = 811
  train_loss = 0.0619
  ********************
Previous best ppl:1.00056
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 74.21 	 Previous best codebleu 74.29
  ********************
reload model from xcodeeval/3/finetune_codet5p_770m/checkpoint-best-bleu
BLEU file: ./data/xcodeeval/3/test.jsonl
  codebleu = 71.28 
  Total = 135 
  Exact Fixed = 1 
[27]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  ********************
  Total = 135 
  Exact Fixed = 1 
[27]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  codebleu = 71.28 
[0.7929417979064819, 0.7663371990492582, 0.6976910864186706, 0.8512897119997327, 0.8536358763066614, 0.08432938445148015, 0.34898094225543036, 0.7669842146074164, 0.6756324089520065, 0.6054199120209949, 0.5601962677755853, 0.8164468849403668, 0.9175351478585267, 0.8726774356123554, 0.8059634988113191, 0.872147466111713, 0.28456980887865324, 0.7534037242254013, 0.5611075353445172, 0.7830064735910691, 0.9185412013134608, 0.8245561139312393, 0.8138327672660688, 0.5524112337326081, 0.7907867143503229, 0.8134383812838551, 1.0, 0.8448616344160145, 0.6982021521970254, 0.7978317575635472, 0.8824402399754723, 0.4739726324720028, 0.5944332173391844, 0.9040862722278158, 0.6345448464057466, 0.7259849312989834, 0.7540469087814428, 0.8313915586456186, 0.5517272573501402, 0.8569685752263538, 0.7932902743460295, 0.630150618578014, 0.6759728227587174, 0.7470425578948228, 0.9118904361242524, 0.8470562047308248, 0.672785744652446, 0.7867507949022507, 0.8536334434067134, 0.5685250847298065, 0.8219514476194971, 0.8419978367899081, 0.9092430471124722, 0.9104392373575145, 0.7182482958421927, 0.941768888951575, 0.6455873914646095, 0.7791901399892995, 0.8654937656858617, 0.4142301377471687, 0.5112111419002278, 0.7440786877675817, 0.9217008915274616, 0.8226849457990322, 0.6827218942680189, 0.7944974662629933, 0.8546770093840449, 0.23178378342054765, 0.7563107817326995, 0.8339849455214231, 0.8155779083654062, 0.901355655227414, 0.754778959829329, 0.7773823007220496, 0.802980404547649, 0.5923377715628043, 0.8125459461294413, 0.720188397702945, 0.6987172522283688, 0.7925405308747024, 0.9011540531929747, 0.837457300065938, 0.7087785501314359, 0.7958146687812508, 0.5677893088427866, 0.7763879223350485, 0.3417564054664891, 0.7704569402736815, 0.7509157324200985, 0.7827835412006432, 0.5672747648078345, 0.6359495004577705, 0.8667405752508375, 0.7322128056542299, 0.4154808998544015, 0.811364833324377, 0.5211121075488702, 0.6202723760558566, 0.823799855709568, 0.5271882025547743, 0.8077815485625466, 0.8628818944953964, 0.515209831912117, 0.7848352750832455, 0.8445923838454312, 0.8897945586059963, 0.33520188382167504, 0.4168626518355933, 0.8112549768726531, 0.3975734208323345, 0.8811002176557108, 0.5534803180860053, 0.5285433525156937, 0.8395646321617463, 0.7142029351288322, 0.42918313960976945, 0.8759700055210595, 0.7192634200448921, 0.9150668370807107, 0.7135938825045871, 0.6257365724699333, 0.8545307032267597, 0.7904010053030581, 0.8806594193232651, 0.5248428625544761, 0.6853859283557308, 0.8877072716538504, 0.24170769468996064, 0.2142677455447746, 0.5976804074013286, 0.9003747650468552, 0.8806974736497433, 0.6294449559412665, 0.5963350635154259, 0.24173832962493158]
Finish training and take 20m
Namespace(log_name='./xcodeeval/1/finetune_codet5p_770m.log', model_name='Salesforce/codet5p-770m', lang='c', output_dir='xcodeeval/1/finetune_codet5p_770m', data_dir='./data/xcodeeval/1', no_cuda=False, visible_gpu='0', add_task_prefix=False, add_lang_ids=False, num_train_epochs=10, num_test_epochs=10, train_batch_size=8, eval_batch_size=4, gradient_accumulation_steps=2, load_model_path=None, config_name='', tokenizer_name='', max_source_length=128, max_target_length=128, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, do_lower_case=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, max_steps=-1, eval_steps=-1, train_steps=-1, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, model_name: Salesforce/codet5p-770m
model created!
Total 1082 training instances 
***** Running training *****
  Num examples = 1082
  Batch size = 8
  Num epoch = 10

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 0
  eval_ppl = 1.00062
  global_step = 136
  train_loss = 0.375
  ********************
Previous best ppl:inf
Achieve Best ppl:1.00062
  ********************
BLEU file: ./data/xcodeeval/1/validation.jsonl
  codebleu-4 = 72.44 	 Previous best codebleu 0
  ********************
 Achieve Best bleu:72.44
  ********************

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 1
  eval_ppl = 1.00062
  global_step = 271
  train_loss = 0.2531
  ********************
Previous best ppl:1.00062
BLEU file: ./data/xcodeeval/1/validation.jsonl
  codebleu-4 = 72.32 	 Previous best codebleu 72.44
  ********************

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 2
  eval_ppl = 1.00066
  global_step = 406
  train_loss = 0.1845
  ********************
Previous best ppl:1.00062
BLEU file: ./data/xcodeeval/1/validation.jsonl
  codebleu-4 = 72.24 	 Previous best codebleu 72.44
  ********************

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 3
  eval_ppl = 1.0007
  global_step = 541
  train_loss = 0.1332
  ********************
Previous best ppl:1.00062
BLEU file: ./data/xcodeeval/1/validation.jsonl
  codebleu-4 = 72.56 	 Previous best codebleu 72.44
  ********************
 Achieve Best bleu:72.56
  ********************

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 4
  eval_ppl = 1.00074
  global_step = 676
  train_loss = 0.0946
  ********************
Previous best ppl:1.00062
BLEU file: ./data/xcodeeval/1/validation.jsonl
  codebleu-4 = 72.29 	 Previous best codebleu 72.56
  ********************

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 5
  eval_ppl = 1.00083
  global_step = 811
  train_loss = 0.0652
  ********************
Previous best ppl:1.00062
BLEU file: ./data/xcodeeval/1/validation.jsonl
  codebleu-4 = 72.51 	 Previous best codebleu 72.56
  ********************

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 6
  eval_ppl = 1.00088
  global_step = 946
  train_loss = 0.0464
  ********************
Previous best ppl:1.00062
BLEU file: ./data/xcodeeval/1/validation.jsonl
  codebleu-4 = 72.16 	 Previous best codebleu 72.56
  ********************
reload model from xcodeeval/1/finetune_codet5p_770m/checkpoint-best-bleu
BLEU file: ./data/xcodeeval/1/test.jsonl
  codebleu = 73.24 
  Total = 135 
  Exact Fixed = 0 
[]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  ********************
  Total = 135 
  Exact Fixed = 0 
[]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  codebleu = 73.24 
[0.6741254939692773, 0.6055239846395822, 0.7035272879003251, 0.8078005301884837, 0.8482415780791264, 0.8470661236484578, 0.8506318170022356, 0.6433992707996272, 0.47822580645161283, 0.869097355083081, 0.816095034017857, 0.8881108167610436, 0.7612037516644444, 0.8095193448343525, 0.8992587233632239, 0.7938229814514498, 0.727268027720646, 0.8173520863469337, 0.7023997010144827, 0.8890119901196314, 0.8667405752508375, 0.6035971947269193, 0.8504318413102254, 0.8517064703343284, 0.8047484533147578, 0.798004543744252, 0.6538129485106954, 0.6958702394644983, 0.8475703733605322, 0.812306762981212, 0.8981210104026012, 0.8071708182046731, 0.40620666335555644, 0.8772273751686793, 0.726906245805339, 0.8256815726664408, 0.5733254349221318, 0.8514896480093217, 0.7493852245041672, 0.7378248767682071, 0.6540110120458642, 0.7385923732495516, 0.5487940158683715, 0.6359495004577705, 0.5271001834766142, 0.9253363255944331, 0.8279104785599881, 0.7065116004186947, 0.681096752881313, 0.7569630859948919, 0.8805315670914018, 0.3414480260596623, 0.7427116405536602, 0.9109778546090423, 0.46344533813736777, 0.8050429544141107, 0.9264306331540344, 0.7041410201759473, 0.8260661662085544, 0.533974650505709, 0.8448013935706866, 0.9719123091671682, 0.5076074703740681, 0.8506710847032652, 0.8438169327624137, 0.3209775629144812, 0.7489533595723943, 0.22083634630817556, 0.7622600531135202, 0.7707471127673067, 0.4050873617790997, 0.8418611860573935, 0.4895865072343232, 0.8124797095951521, 0.8145273052967352, 0.8717455174648483, 0.7701328007329863, 0.7694578850257566, 0.849803040412304, 0.8255681126593256, 0.8719598303409888, 0.793186090991731, 0.7631808279139581, 0.8372583640577188, 0.8696923233625582, 0.9298125945729137, 0.7461371647825752, 0.6465786180337243, 0.7947118157577724, 0.659532270654534, 0.982840810414882, 0.8710445728632014, 0.4650551733188451, 0.6617404403914646, 0.5355322041447821, 0.9498733743967636, 0.6281802407830452, 0.8350035289796414, 0.6184859920453802, 0.906923058378295, 0.8766881581894976, 0.5468547667811987, 0.7993588411755785, 0.19782713521617065, 0.7134134951513778, 0.8396663263205362, 0.4921529174785757, 0.9365739931432338, 0.42546003894617346, 0.8769250379411355, 0.47255350543859986, 0.7862446843835789, 0.7030932213205241, 0.6451144593926297, 0.7011151330217786, 0.88353709334584, 0.9503702205380173, 0.762314097845589, 0.7780707146601717, 0.8996726638725223, 0.7800339225785345, 0.3794955048760881, 0.8336721496048931, 0.4211856373163223, 0.8119506730626463, 0.7211817541923293, 0.7286144481170467, 0.8318325665241797, 0.45601045567543047, 0.7132783454345335, 0.6017150080688712, 0.876722724918082, 0.9013866678857929, 0.46985530336379205, 0.5905688151805155]
Finish training and take 28m
Namespace(log_name='./xcodeeval/1/finetune_codet5p_770m.log', model_name='Salesforce/codet5p-770m', lang='c', output_dir='xcodeeval/2/finetune_codet5p_770m', data_dir='./data/xcodeeval/2', no_cuda=False, visible_gpu='0', add_task_prefix=False, add_lang_ids=False, num_train_epochs=10, num_test_epochs=10, train_batch_size=8, eval_batch_size=4, gradient_accumulation_steps=2, load_model_path=None, config_name='', tokenizer_name='', max_source_length=128, max_target_length=128, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, do_lower_case=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, max_steps=-1, eval_steps=-1, train_steps=-1, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, model_name: Salesforce/codet5p-770m
model created!
Total 1082 training instances 
***** Running training *****
  Num examples = 1082
  Batch size = 8
  Num epoch = 10

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 0
  eval_ppl = 1.00052
  global_step = 136
  train_loss = 0.3798
  ********************
Previous best ppl:inf
Achieve Best ppl:1.00052
  ********************
BLEU file: ./data/xcodeeval/2/validation.jsonl
  codebleu-4 = 73.97 	 Previous best codebleu 0
  ********************
 Achieve Best bleu:73.97
  ********************

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 1
  eval_ppl = 1.00051
  global_step = 271
  train_loss = 0.2588
  ********************
Previous best ppl:1.00052
Achieve Best ppl:1.00051
  ********************
BLEU file: ./data/xcodeeval/2/validation.jsonl
  codebleu-4 = 74.08 	 Previous best codebleu 73.97
  ********************
 Achieve Best bleu:74.08
  ********************

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 2
  eval_ppl = 1.00057
  global_step = 406
  train_loss = 0.1831
  ********************
Previous best ppl:1.00051
BLEU file: ./data/xcodeeval/2/validation.jsonl
  codebleu-4 = 74.1 	 Previous best codebleu 74.08
  ********************
 Achieve Best bleu:74.1
  ********************

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 3
  eval_ppl = 1.00055
  global_step = 541
  train_loss = 0.1338
  ********************
Previous best ppl:1.00051
BLEU file: ./data/xcodeeval/2/validation.jsonl
  codebleu-4 = 73.96 	 Previous best codebleu 74.1
  ********************

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 4
  eval_ppl = 1.00061
  global_step = 676
  train_loss = 0.09
  ********************
Previous best ppl:1.00051
BLEU file: ./data/xcodeeval/2/validation.jsonl
  codebleu-4 = 74.15 	 Previous best codebleu 74.1
  ********************
 Achieve Best bleu:74.15
  ********************

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 5
  eval_ppl = 1.00064
  global_step = 811
  train_loss = 0.0629
  ********************
Previous best ppl:1.00051
BLEU file: ./data/xcodeeval/2/validation.jsonl
  codebleu-4 = 74.09 	 Previous best codebleu 74.15
  ********************

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 6
  eval_ppl = 1.0007
  global_step = 946
  train_loss = 0.045
  ********************
Previous best ppl:1.00051
BLEU file: ./data/xcodeeval/2/validation.jsonl
  codebleu-4 = 74.02 	 Previous best codebleu 74.15
  ********************

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 7
  eval_ppl = 1.00078
  global_step = 1081
  train_loss = 0.0321
  ********************
Previous best ppl:1.00051
BLEU file: ./data/xcodeeval/2/validation.jsonl
  codebleu-4 = 73.98 	 Previous best codebleu 74.15
  ********************
reload model from xcodeeval/2/finetune_codet5p_770m/checkpoint-best-bleu
BLEU file: ./data/xcodeeval/2/test.jsonl
  codebleu = 70.67 
  Total = 135 
  Exact Fixed = 1 
[107]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  ********************
  Total = 135 
  Exact Fixed = 1 
[107]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  codebleu = 70.67 
[0.4079267132112413, 0.5929525010165554, 0.8723015765088757, 0.8981156303935836, 0.628105232559099, 0.8341852120711315, 0.9125880074596351, 0.709526995055453, 0.873793759962344, 0.6467062393002753, 0.3854267824187835, 0.5844229263024725, 0.904590355528839, 0.30917972313471764, 0.04505175233917717, 0.8344121869573176, 0.5726261131685282, 0.7482112321606759, 0.8724723036671462, 0.592207910649987, 0.5377490214669287, 0.8248170962252077, 0.75750508267751, 0.8640256285697764, 0.8043451666797974, 0.6201159722273546, 0.891419774625108, 0.7045218632154403, 0.7976468342488128, 0.33367876486980974, 0.45631161811982324, 0.5818754564013621, 0.8653333140080264, 0.8258222754680256, 0.6004280366320209, 0.5191643807480444, 0.4524934938238685, 0.8460671937742572, 0.427907872531046, 0.4379797446471848, 0.7503272906104577, 0.7128798335563746, 0.9120861554864073, 0.7784591158731673, 0.8375542987872413, 0.9041581967027494, 0.7801744066714751, 0.940387748772268, 0.79251028814738, 0.8036910613939219, 0.3120288913954662, 0.7716491424868305, 0.5310909326338049, 0.6384499261756515, 0.8852384894814247, 0.7127048131322651, 0.7764975463278132, 0.6777766309740647, 0.5346863070936048, 0.9470228248649237, 0.7507584829026313, 0.8396663263205362, 0.9360674082443785, 0.8633447636989494, 0.43387818601959904, 0.7497872722734309, 0.5918835459549441, 0.8452710463363644, 0.8946275734848934, 0.8537257078219596, 0.8064069121671387, 0.8196951483104229, 0.7368070849073924, 0.4612620280518578, 0.35258502536287617, 0.8648579538144856, 0.7496420585309386, 0.7602186940402952, 0.7631177288471214, 0.7875865283547716, 0.39578612527759205, 0.30666666666666664, 0.7269618142997433, 0.8753727486979741, 0.5393773280455789, 0.7947820674037744, 0.3852685514477996, 0.76987879200941, 0.8806974736497433, 0.8594524113191127, 0.6979780721244926, 0.8388209385489929, 0.6626435137538318, 0.8416117635801648, 0.7784360171669422, 0.521559233346504, 0.7833819946139522, 0.7488997676737696, 0.6333744987141046, 0.7410691472083426, 0.4585240670925822, 0.5599929199988638, 0.6739839265768114, 0.39198242100783887, 0.7388705197090006, 0.6951644390669244, 1.0, 0.46673071932457155, 0.9088830127891061, 0.5614360882955788, 0.6490688753903175, 0.8339055840616187, 0.8729244091162942, 0.912198238083447, 0.682584039879178, 0.8543126179887541, 0.9341190775741011, 0.4335448943198981, 0.8573326876937928, 0.7704569402736815, 0.4220974061228139, 0.8196069166590214, 0.7032096029468522, 0.6413253944664965, 0.7101520621290818, 0.6715603052093865, 0.9131807795832447, 0.6876287414964073, 0.3128264897154612, 0.853191132295444, 0.8164232694020533, 0.9311001454085734, 0.9612737738433852, 0.8859453911289024, 0.7966006161104328]
Finish training and take 33m
Namespace(log_name='./xcodeeval/1/finetune_codet5p_770m.log', model_name='Salesforce/codet5p-770m', lang='c', output_dir='xcodeeval/3/finetune_codet5p_770m', data_dir='./data/xcodeeval/3', no_cuda=False, visible_gpu='0', add_task_prefix=False, add_lang_ids=False, num_train_epochs=10, num_test_epochs=10, train_batch_size=8, eval_batch_size=4, gradient_accumulation_steps=2, load_model_path=None, config_name='', tokenizer_name='', max_source_length=128, max_target_length=128, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, do_lower_case=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, max_steps=-1, eval_steps=-1, train_steps=-1, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, model_name: Salesforce/codet5p-770m
model created!
Total 1082 training instances 
***** Running training *****
  Num examples = 1082
  Batch size = 8
  Num epoch = 10

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 0
  eval_ppl = 1.00055
  global_step = 136
  train_loss = 0.3612
  ********************
Previous best ppl:inf
Achieve Best ppl:1.00055
  ********************
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 74.31 	 Previous best codebleu 0
  ********************
 Achieve Best bleu:74.31
  ********************

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 1
  eval_ppl = 1.00056
  global_step = 271
  train_loss = 0.2483
  ********************
Previous best ppl:1.00055
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 74.01 	 Previous best codebleu 74.31
  ********************

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 2
  eval_ppl = 1.00055
  global_step = 406
  train_loss = 0.1817
  ********************
Previous best ppl:1.00055
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 74.4 	 Previous best codebleu 74.31
  ********************
 Achieve Best bleu:74.4
  ********************

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 3
  eval_ppl = 1.0006
  global_step = 541
  train_loss = 0.1308
  ********************
Previous best ppl:1.00055
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 73.81 	 Previous best codebleu 74.4
  ********************

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 4
  eval_ppl = 1.00067
  global_step = 676
  train_loss = 0.0933
  ********************
Previous best ppl:1.00055
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 73.97 	 Previous best codebleu 74.4
  ********************

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 5
  eval_ppl = 1.00074
  global_step = 811
  train_loss = 0.0661
  ********************
Previous best ppl:1.00055
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 73.65 	 Previous best codebleu 74.4
  ********************
reload model from xcodeeval/3/finetune_codet5p_770m/checkpoint-best-bleu
BLEU file: ./data/xcodeeval/3/test.jsonl
  codebleu = 71.54 
  Total = 135 
  Exact Fixed = 3 
[27, 45, 117]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  ********************
  Total = 135 
  Exact Fixed = 3 
[27, 45, 117]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  codebleu = 71.54 
[0.7849538767776651, 0.7663371990492582, 0.6976910864186706, 0.8512897119997327, 0.8536358763066614, 0.08406889937820157, 0.34898094225543036, 0.7669842146074164, 0.6756324089520065, 0.6054199120209949, 0.5601962677755853, 0.8164468849403668, 0.9175351478585267, 0.8726774356123554, 0.8059634988113191, 0.872147466111713, 0.28456980887865324, 0.7534037242254013, 0.5654675203716997, 0.7830064735910691, 0.9185412013134608, 0.8245561139312393, 0.8138327672660688, 0.5524112337326081, 0.7907867143503229, 0.802138971106996, 1.0, 0.8267329721877597, 0.6982021521970254, 0.7921624393976985, 0.91412960455335, 0.4739726324720028, 0.5246352681210026, 0.9040862722278158, 0.6345448464057466, 0.7259849312989834, 0.7540469087814428, 0.8313915586456186, 0.6121972533149926, 0.8569685752263538, 0.7932902743460295, 0.630150618578014, 0.6759728227587174, 0.7470425578948228, 1.0, 0.8470562047308248, 0.672785744652446, 0.7867507949022507, 0.8536334434067134, 0.5685250847298065, 0.8219514476194971, 0.8419978367899081, 0.9092430471124722, 0.9104392373575145, 0.7182482958421927, 0.941768888951575, 0.6455873914646095, 0.7932126424647954, 0.8654937656858617, 0.4142301377471687, 0.5112111419002278, 0.8297929734818674, 0.9217008915274616, 0.8689970404457057, 0.6797132326622942, 0.7944974662629933, 0.8546770093840449, 0.23178378342054765, 0.7563107817326995, 0.8339849455214231, 0.8155779083654062, 0.901355655227414, 0.754778959829329, 0.721977501851727, 0.802980404547649, 0.5923377715628043, 0.8125459461294413, 0.720188397702945, 0.6987172522283688, 0.7925405308747024, 0.900395087233911, 0.837457300065938, 0.7087785501314359, 0.7700652915417614, 0.5677893088427866, 0.7763879223350485, 0.3417564054664891, 0.777748374412698, 0.7509157324200985, 0.7827835412006432, 0.5672747648078345, 0.647487961996232, 0.8819989837824207, 0.7470362018806367, 0.4154808998544015, 0.811364833324377, 0.5211121075488702, 0.6610238827063706, 0.823799855709568, 0.5271882025547743, 0.8077815485625466, 0.8628818944953964, 0.5105547910952926, 0.7848352750832455, 0.8445923838454312, 0.8897945586059963, 0.33520188382167504, 0.4168626518355933, 0.852945187183654, 0.3975734208323345, 0.8811002176557108, 0.5534803180860053, 0.5285433525156937, 0.831862639858802, 0.7142029351288322, 0.42918313960976945, 1.0, 0.7192634200448921, 0.9150668370807107, 0.6994272158379204, 0.6257365724699333, 0.8545307032267597, 0.7904010053030581, 0.8806594193232651, 0.5346863070936048, 0.6853859283557308, 0.8877072716538504, 0.24170769468996064, 0.2142677455447746, 0.572625617722997, 0.9003747650468552, 0.8806974736497433, 0.6294449559412665, 0.5963350635154259, 0.24173832962493158]
Finish training and take 26m
Namespace(log_name='./xcodeeval/1/finetune_codet5p_770m.log', model_name='Salesforce/codet5p-770m', lang='c', output_dir='xcodeeval/1/finetune_codet5p_770m', data_dir='./data/xcodeeval/1', no_cuda=False, visible_gpu='0', add_task_prefix=False, add_lang_ids=False, num_train_epochs=10, num_test_epochs=10, train_batch_size=8, eval_batch_size=4, gradient_accumulation_steps=2, load_model_path=None, config_name='', tokenizer_name='', max_source_length=128, max_target_length=128, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, do_lower_case=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, max_steps=-1, eval_steps=-1, train_steps=-1, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, model_name: Salesforce/codet5p-770m
model created!
Total 1082 training instances 
***** Running training *****
  Num examples = 1082
  Batch size = 8
  Num epoch = 10

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 0
  eval_ppl = 1.00063
  global_step = 136
  train_loss = 0.3706
  ********************
Previous best ppl:inf
Achieve Best ppl:1.00063
  ********************
BLEU file: ./data/xcodeeval/1/validation.jsonl
Namespace(log_name='./xcodeeval/1/finetune_codet5p_770m.log', model_name='Salesforce/codet5p-770m', lang='c', output_dir='xcodeeval/1/finetune_codet5p_770m', data_dir='./data/xcodeeval/1', no_cuda=False, visible_gpu='0', add_task_prefix=False, add_lang_ids=False, num_train_epochs=10, num_test_epochs=10, train_batch_size=8, eval_batch_size=4, gradient_accumulation_steps=2, load_model_path=None, config_name='', tokenizer_name='', max_source_length=128, max_target_length=128, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, do_lower_case=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, max_steps=-1, eval_steps=-1, train_steps=-1, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, model_name: Salesforce/codet5p-770m
model created!
Total 1082 training instances 
***** Running training *****
  Num examples = 1082
  Batch size = 8
  Num epoch = 10

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 0
  eval_ppl = 1.00063
  global_step = 136
  train_loss = 0.3706
  ********************
Previous best ppl:inf
Achieve Best ppl:1.00063
  ********************
BLEU file: ./data/xcodeeval/1/validation.jsonl
  codebleu-4 = 72.62 	 Previous best codebleu 0
  ********************
 Achieve Best bleu:72.62
  ********************

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 1
  eval_ppl = 1.00065
  global_step = 271
  train_loss = 0.2571
  ********************
Previous best ppl:1.00063
BLEU file: ./data/xcodeeval/1/validation.jsonl
  codebleu-4 = 71.79 	 Previous best codebleu 72.62
  ********************

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 2
  eval_ppl = 1.00065
  global_step = 406
  train_loss = 0.1881
  ********************
Previous best ppl:1.00063
BLEU file: ./data/xcodeeval/1/validation.jsonl
  codebleu-4 = 72.34 	 Previous best codebleu 72.62
  ********************

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 3
  eval_ppl = 1.00068
  global_step = 541
  train_loss = 0.1374
  ********************
Previous best ppl:1.00063
BLEU file: ./data/xcodeeval/1/validation.jsonl
  codebleu-4 = 72.46 	 Previous best codebleu 72.62
  ********************
reload model from xcodeeval/1/finetune_codet5p_770m/checkpoint-best-bleu
BLEU file: ./data/xcodeeval/1/test.jsonl
  codebleu = 72.84 
  Total = 135 
  Exact Fixed = 0 
[]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  ********************
  Total = 135 
  Exact Fixed = 0 
[]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  codebleu = 72.84 
[0.6741254939692773, 0.6055239846395822, 0.7035272879003251, 0.8078005301884837, 0.8482415780791264, 0.8470661236484578, 0.8506318170022356, 0.6433992707996272, 0.47822580645161283, 0.869097355083081, 0.816095034017857, 0.8881108167610436, 0.7612037516644444, 0.8095193448343525, 0.8992587233632239, 0.7938229814514498, 0.7139951973179235, 0.8365125728430938, 0.7023997010144827, 0.8890119901196314, 0.8667405752508375, 0.6035971947269193, 0.8504318413102254, 0.8517064703343284, 0.8272288242905221, 0.8759794301856842, 0.6538129485106954, 0.683467917649407, 0.8475703733605322, 0.8629852137929874, 0.9214464442482999, 0.8071708182046731, 0.4256938428427359, 0.8772273751686793, 0.726906245805339, 0.8256815726664408, 0.5781163637298115, 0.8514896480093217, 0.7647346904829493, 0.7378248767682071, 0.6540110120458642, 0.7385923732495516, 0.5249478620222177, 0.647487961996232, 0.5325804735306264, 0.9253363255944331, 0.8279104785599881, 0.7330177268778751, 0.6624020614193511, 0.7569630859948919, 0.8805315670914018, 0.3414480260596623, 0.7427116405536602, 0.9109778546090423, 0.46344533813736777, 0.8015341072596128, 0.9259264314733622, 0.6990138341664084, 0.8260661662085544, 0.5160682766833452, 0.8799057191503341, 0.9265235989881684, 0.5076074703740681, 0.8535048490263217, 0.8545893714632256, 0.27763157894736845, 0.7489533595723943, 0.22083634630817556, 0.7622600531135202, 0.7707471127673067, 0.4050873617790997, 0.8418611860573935, 0.4895865072343232, 0.8124797095951521, 0.8145273052967352, 0.26712665967403826, 0.7701328007329863, 0.7694578850257566, 0.849803040412304, 0.8255681126593256, 0.8696427280301575, 0.7927812326921357, 0.7674641460255568, 0.8476031916439257, 0.8696923233625582, 0.9298125945729137, 0.7575006467470722, 0.6016538902088896, 0.8275183621461346, 0.659532270654534, 0.982840810414882, 0.8101763944971344, 0.4650551733188451, 0.6476753884536018, 0.5355322041447821, 0.9498733743967636, 0.6281802407830452, 0.8350035289796414, 0.6184859920453802, 0.906923058378295, 0.8985810813576707, 0.5644982344246664, 0.7842000704719325, 0.19782713521617065, 0.7134134951513778, 0.8396663263205362, 0.4921529174785757, 0.9365739931432338, 0.42779770128383576, 0.8769250379411355, 0.47255350543859986, 0.7862446843835789, 0.7639496783614648, 0.6451144593926297, 0.7011151330217786, 0.88353709334584, 0.9503702205380173, 0.762314097845589, 0.7780707146601717, 0.8996726638725223, 0.7878795313221194, 0.3794955048760881, 0.8336721496048931, 0.4140107071948905, 0.8119506730626463, 0.7211817541923293, 0.7286144481170467, 0.8318325665241797, 0.45601045567543047, 0.724315616661136, 0.6017150080688712, 0.7683245403282871, 0.9013866678857929, 0.46985530336379205, 0.5905688151805155]
Finish training and take 14m

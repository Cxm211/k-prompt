Namespace(log_name='./result/xcodeeval/1/random5_codet5p_770m.log', model_name='Salesforce/codet5p-770m', lang='c', output_dir='result/xcodeeval/1/random5_codet5p_770m', data_dir='./data/xcodeeval/1', no_cuda=False, visible_gpu='0', choice=5, num_train_epochs=10, num_test_epochs=1, train_batch_size=4, eval_batch_size=4, gradient_accumulation_steps=1, load_model_path=None, config_name='', tokenizer_name='', max_source_length=512, max_target_length=512, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, freeze=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
Model created!!
[[{'text': '#include <stdio.h> #include <stdlib.h> void insertSort(int* a, int size) {     int i, j, tmp;     for (i = 1; i < size; ++i)     {         tmp = a[i];         for (j = i - 1; j >= 0 && a[j] < tmp; --j)             a[j + 1] = a[j];         a[j + 1] = tmp;     } } int check(int* a,int* b,int size) {     int i;     for(i=0;i<size;i++)     if (a[i]!=b[i]) return (a[i]);     return a[i]; } int main() {     int i,n,o1,o2;     scanf("%d",&n);     int a[n],b[n-1];     for (i=0;i<n;i++)         scanf("%d",&a[i]);     insertSort(a,n);     puts("First");     for (i=0;i<n-1;i++)         scanf("%d",&b[i]);     insertSort(b,n-1);     puts("Sec1");     o1=check(a,b,n);     puts("Sec2");     for (i=0;i<n-2;i++)         scanf("%d",&a[i]);     insertSort(a,n-2);     puts("Thir1");     o2=check(b,a,n-2);     puts("Thir2");     printf("%d\\n%d",o1,o2);     return 0; }', 'loss_ids': 0, 'shortenable_ids': 1}, {'text': 'is buggy program', 'loss_ids': 0, 'shortenable_ids': 0}, {'text': '<mask>', 'loss_ids': 1, 'shortenable_ids': 0}, {'text': 'is fixed program', 'loss_ids': 0, 'shortenable_ids': 0}], {'guid': 0, 'tgt_text': '#include <stdio.h> #include <stdlib.h>  int main() {     int i,n,x;     __int64 a=0,b=0,c=0;     scanf("%d",&n);     for (i=0; i<n; i++)     {         scanf("%d",&x);         a+=x;     }     for (i=0; i<n-1; i++)     {         scanf("%d",&x);         b+=x;     }     for (i=0; i<n-2; i++)     {         scanf("%d",&x);         c+=x;      }     printf("%I64d\\n%I64d",a-b,b-c);     return 0; }'}]
***** Running training *****
  Num examples = 1082
  Batch size = 4
  Num epoch = 10

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 0
  eval_ppl = inf
  global_step = 272
  train_loss = 64.6132
  ********************
Previous best ppl:inf
Achieve Best ppl:inf
  ********************
BLEU file: ./data/xcodeeval/1/validation.jsonl
  codebleu-4 = 75.52 	 Previous best codebleu 0
  ********************
 Achieve Best bleu:75.52
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 1
  eval_ppl = inf
  global_step = 543
  train_loss = 54.7118
  ********************
Previous best ppl:inf
Achieve Best ppl:inf
  ********************
BLEU file: ./data/xcodeeval/1/validation.jsonl
  codebleu-4 = 75.41 	 Previous best codebleu 75.52
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 2
  eval_ppl = inf
  global_step = 814
  train_loss = 40.6395
  ********************
Previous best ppl:inf
Achieve Best ppl:inf
  ********************
BLEU file: ./data/xcodeeval/1/validation.jsonl
  codebleu-4 = 75.61 	 Previous best codebleu 75.52
  ********************
 Achieve Best bleu:75.61
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 3
  eval_ppl = inf
  global_step = 1085
  train_loss = 28.9878
  ********************
Previous best ppl:inf
Achieve Best ppl:inf
  ********************
BLEU file: ./data/xcodeeval/1/validation.jsonl
  codebleu-4 = 75.54 	 Previous best codebleu 75.61
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 4
  eval_ppl = inf
  global_step = 1356
  train_loss = 20.2131
  ********************
Previous best ppl:inf
Achieve Best ppl:inf
  ********************
BLEU file: ./data/xcodeeval/1/validation.jsonl
  codebleu-4 = 75.87 	 Previous best codebleu 75.61
  ********************
 Achieve Best bleu:75.87
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 5
  eval_ppl = inf
  global_step = 1627
  train_loss = 13.6216
  ********************
Previous best ppl:inf
BLEU file: ./data/xcodeeval/1/validation.jsonl
  codebleu-4 = 75.28 	 Previous best codebleu 75.87
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 6
  eval_ppl = inf
  global_step = 1898
  train_loss = 9.1519
  ********************
Previous best ppl:inf
BLEU file: ./data/xcodeeval/1/validation.jsonl
  codebleu-4 = 75.97 	 Previous best codebleu 75.87
  ********************
 Achieve Best bleu:75.97
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 7
  eval_ppl = inf
  global_step = 2169
  train_loss = 6.2508
  ********************
Previous best ppl:inf
BLEU file: ./data/xcodeeval/1/validation.jsonl
  codebleu-4 = 75.94 	 Previous best codebleu 75.97
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 8
  eval_ppl = inf
  global_step = 2440
  train_loss = 4.3744
  ********************
Previous best ppl:inf
BLEU file: ./data/xcodeeval/1/validation.jsonl
  codebleu-4 = 75.94 	 Previous best codebleu 75.97
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 9
  eval_ppl = inf
  global_step = 2711
  train_loss = 3.3049
  ********************
Previous best ppl:inf
BLEU file: ./data/xcodeeval/1/validation.jsonl
  codebleu-4 = 75.9 	 Previous best codebleu 75.97
  ********************
early stopping!!!
reload model from result/xcodeeval/1/random5_codet5p_770m/checkpoint-best-bleu
BLEU file: ./data/xcodeeval/1/test.jsonl
  codebleu = 76.41 
  Total = 135 
  Exact Fixed = 5 
[16, 62, 72, 74, 96]
  Syntax Fixed = 1 
[88]
  Cleaned Fixed = 1 
[123]
  ********************
  Total = 135 
  Exact Fixed = 5 
[16, 62, 72, 74, 96]
  Syntax Fixed = 1 
[88]
  Cleaned Fixed = 1 
[123]
  codebleu = 76.41 
[0.7097922458866276, 0.9752926493864778, 0.8419188985107608, 0.8399493211101225, 0.5513226911730328, 0.8995033054005415, 0.655233513178001, 0.8131660563421435, 0.47822580645161283, 0.9295757649014529, 0.6700100781693141, 0.8881108167610436, 0.8920012172763082, 0.8922221884406468, 0.8676753256813341, 1.0, 0.6068707460804744, 0.8143502770709957, 0.9021412904010627, 0.9832612094993938, 0.9498733743967636, 0.7258969516999755, 0.9054668285688956, 0.9304372254539681, 0.7521689663631371, 0.8986391637385749, 0.5012202683657422, 0.8381960842127558, 0.943601919551823, 0.9483511691573643, 0.9857368328793006, 0.8463810160907537, 0.5003910292067191, 0.9389707093964361, 0.8416184535678177, 0.973858151522893, 0.594003263393805, 0.9365819013624168, 0.3726627778435649, 0.9471982954514573, 0.6432679507343982, 0.6754292375001995, 0.43231737186383545, 0.4286023969955689, 0.7149195155805301, 0.8432773454047806, 0.9465012851429597, 0.973858151522893, 0.5527764741944027, 0.8049433236204496, 0.9601466755014141, 0.33580645216805804, 0.9265507162785469, 0.7927906556865255, 0.29887126208472076, 0.9333310235672049, 0.7992645702273762, 0.6649855329316278, 0.9860950428335316, 0.5335581349704818, 0.9492384172683168, 1.0, 0.5077214223305908, 0.9349276711483918, 0.9946984307054776, 0.3645110727972939, 0.9334580759528754, 0.2857544178174171, 0.7598076383450478, 0.8753772142950917, 0.39101342264848765, 1.0, 0.47838875329505376, 0.9877105669836239, 0.8760369670517594, 0.9026132332859687, 0.8462812068076495, 0.8373834761279768, 0.8644554554879766, 0.8454546086981599, 0.7557818507099485, 0.7153375795187605, 0.8448154126614957, 0.9128071327141931, 0.9903793674040597, 0.8917793747666807, 0.89451908845154, 0.8857658481998287, 0.7598952407119619, 0.7832059164639751, 0.9617625014218179, 0.8491975857795985, 0.4887803370724654, 0.9109545424921657, 0.5355322041447821, 1.0, 0.7253025503608977, 0.855337897791616, 0.5076943976918459, 0.906923058378295, 0.9381767755969468, 0.5980329871412183, 0.668177304512741, 0.2572497507889638, 0.7556814728598797, 0.9582778026878329, 0.6362439585829495, 0.9365739931432338, 0.29943997880421824, 0.8769250379411355, 0.39589238247344827, 0.9671358603798736, 0.7639496783614648, 0.5412219101899178, 0.4483161621899451, 0.9442248897793943, 0.9692439075113215, 0.8331051958717339, 0.7741939441431783, 0.47854531008265005, 0.9041929640741897, 0.37828106820249585, 0.9455713410474389, 0.3565874055354602, 0.8119506730626463, 0.8349334433697306, 0.7286144481170467, 0.8241554247996095, 0.45601045567543047, 0.7761988507965935, 0.6017150080688712, 0.9142918920357144, 0.9045578968398897, 0.34491526037158676, 0.7279692304347927]
Finish training and take 1h32m

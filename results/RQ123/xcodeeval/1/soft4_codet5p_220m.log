Namespace(log_name='./xcodeeval/1/soft4_codet5p_220m.log', model_name='Salesforce/codet5p-220m', lang='c', output_dir='xcodeeval/1/soft4_codet5p_220m', data_dir='./data/xcodeeval/1', no_cuda=False, visible_gpu='0', num_train_epochs=10, num_test_epochs=1, train_batch_size=6, eval_batch_size=4, gradient_accumulation_steps=1, load_model_path=None, config_name='', tokenizer_name='', max_source_length=512, max_target_length=512, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, freeze=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
Model created!!
[[{'text': '#include <stdio.h> #include <stdlib.h> void insertSort(int* a, int size) {     int i, j, tmp;     for (i = 1; i < size; ++i)     {         tmp = a[i];         for (j = i - 1; j >= 0 && a[j] < tmp; --j)             a[j + 1] = a[j];         a[j + 1] = tmp;     } } int check(int* a,int* b,int size) {     int i;     for(i=0;i<size;i++)     if (a[i]!=b[i]) return (a[i]);     return a[i]; } int main() {     int i,n,o1,o2;     scanf("%d",&n);     int a[n],b[n-1];     for (i=0;i<n;i++)         scanf("%d",&a[i]);     insertSort(a,n);     puts("First");     for (i=0;i<n-1;i++)         scanf("%d",&b[i]);     insertSort(b,n-1);     puts("Sec1");     o1=check(a,b,n);     puts("Sec2");     for (i=0;i<n-2;i++)         scanf("%d",&a[i]);     insertSort(a,n-2);     puts("Thir1");     o2=check(b,a,n-2);     puts("Thir2");     printf("%d\\n%d",o1,o2);     return 0; }', 'loss_ids': 0, 'shortenable_ids': 1}, {'text': '<mask>', 'loss_ids': 1, 'shortenable_ids': 0}, {'text': 'is the fixed version', 'loss_ids': 0, 'shortenable_ids': 0}], {'guid': 0, 'tgt_text': '#include <stdio.h> #include <stdlib.h>  int main() {     int i,n,x;     __int64 a=0,b=0,c=0;     scanf("%d",&n);     for (i=0; i<n; i++)     {         scanf("%d",&x);         a+=x;     }     for (i=0; i<n-1; i++)     {         scanf("%d",&x);         b+=x;     }     for (i=0; i<n-2; i++)     {         scanf("%d",&x);         c+=x;      }     printf("%I64d\\n%I64d",a-b,b-c);     return 0; }'}]
***** Running training *****
  Num examples = 1082
  Batch size = 6
  Num epoch = 10

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 0
  eval_ppl = inf
  global_step = 182
  train_loss = 74.788
  ********************
Previous best ppl:inf
Achieve Best ppl:inf
  ********************
BLEU file: ./data/xcodeeval/1/validation.jsonl
  codebleu-4 = 75.67 	 Previous best codebleu 0
  ********************
 Achieve Best bleu:75.67
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 1
  eval_ppl = inf
  global_step = 363
  train_loss = 60.6242
  ********************
Previous best ppl:inf
BLEU file: ./data/xcodeeval/1/validation.jsonl
  codebleu-4 = 75.78 	 Previous best codebleu 75.67
  ********************
 Achieve Best bleu:75.78
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 2
  eval_ppl = inf
  global_step = 544
  train_loss = 49.8238
  ********************
Previous best ppl:inf
BLEU file: ./data/xcodeeval/1/validation.jsonl
  codebleu-4 = 75.82 	 Previous best codebleu 75.78
  ********************
 Achieve Best bleu:75.82
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 3
  eval_ppl = inf
  global_step = 725
  train_loss = 41.9216
  ********************
Previous best ppl:inf
BLEU file: ./data/xcodeeval/1/validation.jsonl
  codebleu-4 = 75.85 	 Previous best codebleu 75.82
  ********************
 Achieve Best bleu:75.85
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 4
  eval_ppl = inf
  global_step = 906
  train_loss = 37.0328
  ********************
Previous best ppl:inf
BLEU file: ./data/xcodeeval/1/validation.jsonl
  codebleu-4 = 75.96 	 Previous best codebleu 75.85
  ********************
 Achieve Best bleu:75.96
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 5
  eval_ppl = inf
  global_step = 1087
  train_loss = 30.7116
  ********************
Previous best ppl:inf
BLEU file: ./data/xcodeeval/1/validation.jsonl
  codebleu-4 = 75.87 	 Previous best codebleu 75.96
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 6
  eval_ppl = inf
  global_step = 1268
  train_loss = 26.1251
  ********************
Previous best ppl:inf
BLEU file: ./data/xcodeeval/1/validation.jsonl
  codebleu-4 = 75.91 	 Previous best codebleu 75.96
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 7
  eval_ppl = inf
  global_step = 1449
  train_loss = 21.8348
  ********************
Previous best ppl:inf
BLEU file: ./data/xcodeeval/1/validation.jsonl
  codebleu-4 = 75.79 	 Previous best codebleu 75.96
  ********************
early stopping!!!
reload model from xcodeeval/1/soft4_codet5p_220m/checkpoint-best-bleu
BLEU file: ./data/xcodeeval/1/test.jsonl
  codebleu = 76.38 
  Total = 135 
  Exact Fixed = 4 
[62, 72, 74, 132]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 2 
[77, 123]
  ********************
  Total = 135 
  Exact Fixed = 4 
[62, 72, 74, 132]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 2 
[77, 123]
  codebleu = 76.38 
[0.7097922458866276, 0.9752926493864778, 0.8419188985107608, 0.8399493211101225, 0.5518850713664085, 0.8995033054005415, 0.655233513178001, 0.8131660563421435, 0.47822580645161283, 0.9295757649014529, 0.6700100781693141, 0.8881108167610436, 0.8920012172763082, 0.8922221884406468, 0.9250674011252755, 0.7938229814514498, 0.6068707460804744, 0.8143502770709957, 0.9126650482788027, 0.9832612094993938, 0.9498733743967636, 0.7584713945723569, 0.9054668285688956, 0.9304372254539681, 0.7521689663631371, 0.8986391637385749, 0.5012202683657422, 0.8381960842127558, 0.9358018387596505, 0.9876232981025004, 0.9857368328793006, 0.8463810160907537, 0.5003910292067191, 0.9389707093964361, 0.8416184535678177, 0.973858151522893, 0.639224154794541, 0.9258754099074029, 0.46124203184813023, 0.8787907304765896, 0.6432679507343982, 0.6754292375001995, 0.43231737186383545, 0.48170226274723915, 0.7149195155805301, 0.8396113521805657, 0.9465012851429597, 0.973858151522893, 0.5677764741944027, 0.811100358881859, 0.9601466755014141, 0.33580645216805804, 0.9460916285283518, 0.7927906556865255, 0.20708565832447592, 0.9333310235672049, 0.8633660722321144, 0.6778336766746159, 0.9860950428335316, 0.5335581349704818, 0.9492384172683168, 1.0, 0.5077214223305908, 0.9702812943440167, 0.9874055782608233, 0.17524847908718622, 0.9334580759528754, 0.2857544178174171, 0.7598076383450478, 0.8753772142950917, 0.39101342264848765, 1.0, 0.39536345674651, 0.9877105669836239, 0.8760369670517594, 0.9194422946236107, 0.8791990328029993, 0.8373834761279768, 0.8644554554879766, 0.8454546086981599, 0.7557818507099485, 0.7153375795187605, 0.8527875420817158, 0.9128071327141931, 0.9544988779085728, 0.8917793747666807, 0.89451908845154, 0.8424197834374936, 0.7598952407119619, 0.7832059164639751, 0.9617625014218179, 0.8963430088316504, 0.4934678370724654, 0.9109545424921657, 0.5318436795546182, 0.9498733743967636, 0.7253025503608977, 0.855337897791616, 0.5076943976918459, 0.906923058378295, 0.9381767755969468, 0.5998071806896054, 0.6615533517599935, 0.2572497507889638, 0.7556814728598797, 0.9582778026878329, 0.6362439585829495, 0.9365739931432338, 0.29943997880421824, 0.8769250379411355, 0.38466031842423953, 0.9750017397390569, 0.7639496783614648, 0.5412219101899178, 0.5102601887697077, 0.9442248897793943, 0.9692439075113215, 0.7929436912800465, 0.7741939441431783, 0.4668495886935264, 0.9041929640741897, 0.37828106820249585, 0.9455713410474389, 0.3565874055354602, 0.8119506730626463, 0.8349334433697306, 0.7286144481170467, 0.7860803806968684, 0.45601045567543047, 0.7761988507965935, 0.6017150080688712, 1.0, 0.9045578968398897, 0.46985530336379205, 0.7279692304347927]
Finish training and take 44m
Namespace(log_name='./xcodeeval/1/soft4_codet5p_220m.log', model_name='Salesforce/codet5p-220m', lang='javascript', output_dir='xcodeeval/1/soft4_codet5p_220m', data_dir='./data/xcodeeval/1', no_cuda=False, visible_gpu='0', num_train_epochs=10, num_test_epochs=1, train_batch_size=6, eval_batch_size=4, gradient_accumulation_steps=1, load_model_path=None, config_name='', tokenizer_name='', max_source_length=512, max_target_length=512, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, freeze=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
Model created!!
[[{'text': 'Fix', 'loss_ids': 0, 'shortenable_ids': 0}, {'text': ' #include <stdio.h> #include <stdlib.h> void insertSort(int* a, int size) {     int i, j, tmp;     for (i = 1; i < size; ++i)     {         tmp = a[i];         for (j = i - 1; j >= 0 && a[j] < tmp; --j)             a[j + 1] = a[j];         a[j + 1] = tmp;     } } int check(int* a,int* b,int size) {     int i;     for(i=0;i<size;i++)     if (a[i]!=b[i]) return (a[i]);     return a[i]; } int main() {     int i,n,o1,o2;     scanf("%d",&n);     int a[n],b[n-1];     for (i=0;i<n;i++)         scanf("%d",&a[i]);     insertSort(a,n);     puts("First");     for (i=0;i<n-1;i++)         scanf("%d",&b[i]);     insertSort(b,n-1);     puts("Sec1");     o1=check(a,b,n);     puts("Sec2");     for (i=0;i<n-2;i++)         scanf("%d",&a[i]);     insertSort(a,n-2);     puts("Thir1");     o2=check(b,a,n-2);     puts("Thir2");     printf("%d\\n%d",o1,o2);     return 0; }', 'loss_ids': 0, 'shortenable_ids': 1}, {'text': '<mask>', 'loss_ids': 1, 'shortenable_ids': 0}, {'text': 'is fixed program', 'loss_ids': 0, 'shortenable_ids': 0}], {'guid': 0, 'tgt_text': '#include <stdio.h> #include <stdlib.h>  int main() {     int i,n,x;     __int64 a=0,b=0,c=0;     scanf("%d",&n);     for (i=0; i<n; i++)     {         scanf("%d",&x);         a+=x;     }     for (i=0; i<n-1; i++)     {         scanf("%d",&x);         b+=x;     }     for (i=0; i<n-2; i++)     {         scanf("%d",&x);         c+=x;      }     printf("%I64d\\n%I64d",a-b,b-c);     return 0; }'}]
***** Running training *****
  Num examples = 1082
  Batch size = 6
  Num epoch = 10

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 0
  eval_ppl = inf
  global_step = 182
  train_loss = 73.7519
  ********************
Previous best ppl:inf
Achieve Best ppl:inf
  ********************
BLEU file: ./data/xcodeeval/1/validation.jsonl
  codebleu-4 = 75.43 	 Previous best codebleu 0
  ********************
 Achieve Best bleu:75.43
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 1
  eval_ppl = inf
  global_step = 363
  train_loss = 60.4093
  ********************
Previous best ppl:inf
BLEU file: ./data/xcodeeval/1/validation.jsonl
  codebleu-4 = 75.8 	 Previous best codebleu 75.43
  ********************
 Achieve Best bleu:75.8
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 2
  eval_ppl = inf
  global_step = 544
  train_loss = 50.0227
  ********************
Previous best ppl:inf
BLEU file: ./data/xcodeeval/1/validation.jsonl
  codebleu-4 = 75.81 	 Previous best codebleu 75.8
  ********************
 Achieve Best bleu:75.81
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 3
  eval_ppl = inf
  global_step = 725
  train_loss = 42.8285
  ********************
Previous best ppl:inf
BLEU file: ./data/xcodeeval/1/validation.jsonl
  codebleu-4 = 75.77 	 Previous best codebleu 75.81
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 4
  eval_ppl = inf
  global_step = 906
  train_loss = 35.2185
  ********************
Previous best ppl:inf
BLEU file: ./data/xcodeeval/1/validation.jsonl
  codebleu-4 = 75.99 	 Previous best codebleu 75.81
  ********************
 Achieve Best bleu:75.99
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 5
  eval_ppl = inf
  global_step = 1087
  train_loss = 29.6416
  ********************
Previous best ppl:inf
BLEU file: ./data/xcodeeval/1/validation.jsonl
  codebleu-4 = 75.89 	 Previous best codebleu 75.99
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 6
  eval_ppl = inf
  global_step = 1268
  train_loss = 25.0004
  ********************
Previous best ppl:inf
BLEU file: ./data/xcodeeval/1/validation.jsonl
  codebleu-4 = 75.98 	 Previous best codebleu 75.99
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 7
  eval_ppl = inf
  global_step = 1449
  train_loss = 21.1591
  ********************
Previous best ppl:inf
BLEU file: ./data/xcodeeval/1/validation.jsonl
  codebleu-4 = 75.81 	 Previous best codebleu 75.99
  ********************
early stopping!!!
reload model from xcodeeval/1/soft4_codet5p_220m/checkpoint-best-bleu
BLEU file: ./data/xcodeeval/1/test.jsonl
  codebleu = 78.22 
  Total = 135 
  Exact Fixed = 2 
[62, 72]
  Syntax Fixed = 1 
[103]
  Cleaned Fixed = 2 
[77, 123]
  ********************
  Total = 135 
  Exact Fixed = 2 
[62, 72]
  Syntax Fixed = 1 
[103]
  Cleaned Fixed = 2 
[77, 123]
  codebleu = 78.22 
[0.8576270665321974, 0.9751679833306697, 0.853451036724189, 0.8512354670828335, 0.6021126331897612, 0.9316663368762217, 0.6797542722269476, 0.8803138421514312, 0.48409090909090907, 0.9283210089602849, 0.6770401525156777, 0.9051309652233979, 0.8743972713689148, 0.9337447448316243, 0.9245015930997713, 0.8071922111587708, 0.6384260852585768, 0.7935614519411027, 0.9254438483736181, 0.9499350924021466, 0.9495565333799167, 0.7252943731098165, 0.9049404535009498, 0.944326114342857, 0.8155499572092877, 0.8948923364087316, 0.5309276477051718, 0.8378630343534285, 0.9534975629202049, 0.9663163184597416, 0.9855975984645713, 0.8814493456471053, 0.5195006051451205, 0.9443127370822302, 0.8585615035448073, 0.9736596070124768, 0.6588782773839998, 0.7950051772670247, 0.5188901904001246, 0.9464434987124863, 0.7221198503121469, 0.8061940884278915, 0.4711044910948027, 0.6251340854809959, 0.634154344194654, 0.8320068600514354, 0.9541717396884142, 0.925010958363828, 0.663830773591444, 0.7604524901555225, 0.9596383922729577, 0.31022753014381454, 0.9390534222456889, 0.8362083254287134, 0.5254316738172549, 0.828608368597788, 0.956635303001345, 0.8070419915952289, 0.9859786661152405, 0.46336448339503544, 0.9548093607687909, 1.0, 0.5158351249886188, 0.9516215440267595, 0.9946410129026173, 0.25201926947214065, 0.9397526175878157, 0.7370431184049049, 0.7581133545655279, 0.7185703542939952, 0.2912850229082951, 1.0, 0.4738798779265946, 0.9424472571930718, 0.8092011236299885, 0.8938166734672799, 0.8861074611025878, 0.8477656759035423, 0.9079280065175155, 0.8643066512379278, 0.43155147953100453, 0.7364176114691898, 0.8978047901697732, 0.9241820113146344, 0.960704033333291, 0.9059003072495941, 0.8786495167687712, 0.7459748767291707, 0.9412409136244551, 0.8375218074221173, 0.9615237953521092, 0.9389612978822404, 0.6360088831869113, 0.8577263222041012, 0.6019131595245863, 0.9495565333799167, 0.873667656151049, 0.8144368901688841, 0.5362632046659364, 0.9157656431626253, 0.9493723892520141, 0.6551179356978454, 0.9726472441899989, 0.2542585430365248, 0.7543812706244544, 0.9356168989023086, 0.6639851756261375, 0.9371806225253847, 0.280037356463431, 0.8757342492104438, 0.46358475028791185, 0.9804221601594771, 0.7689936563209585, 0.5869740558625594, 0.5204814437263454, 0.9433303042436834, 0.923579173679586, 0.7390818018374007, 0.8390883672201126, 0.5187545676249168, 0.7566656692038568, 0.45281215706359246, 0.9504925120422214, 0.39583535359131383, 0.8286732633053759, 0.8469647149258703, 0.742756076373353, 0.8169880874599221, 0.4569020134135544, 0.8896402083859258, 0.6304413605295484, 0.9088236556804548, 0.9236319822027208, 0.49563580198148643, 0.7721785148274776]
Finish training and take 44m
Namespace(log_name='./xcodeeval/1/soft4_codet5p_220m.log', model_name='Salesforce/codet5p-220m', lang='c', output_dir='xcodeeval/1/soft4_codet5p_220m', data_dir='./data/xcodeeval/1', no_cuda=False, visible_gpu='0', num_train_epochs=10, num_test_epochs=1, train_batch_size=6, eval_batch_size=4, gradient_accumulation_steps=1, load_model_path=None, config_name='', tokenizer_name='', max_source_length=512, max_target_length=512, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, freeze=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
Model created!!
[[{'text': 'Fix', 'loss_ids': 0, 'shortenable_ids': 0}, {'text': ' #include <stdio.h> #include <stdlib.h> void insertSort(int* a, int size) {     int i, j, tmp;     for (i = 1; i < size; ++i)     {         tmp = a[i];         for (j = i - 1; j >= 0 && a[j] < tmp; --j)             a[j + 1] = a[j];         a[j + 1] = tmp;     } } int check(int* a,int* b,int size) {     int i;     for(i=0;i<size;i++)     if (a[i]!=b[i]) return (a[i]);     return a[i]; } int main() {     int i,n,o1,o2;     scanf("%d",&n);     int a[n],b[n-1];     for (i=0;i<n;i++)         scanf("%d",&a[i]);     insertSort(a,n);     puts("First");     for (i=0;i<n-1;i++)         scanf("%d",&b[i]);     insertSort(b,n-1);     puts("Sec1");     o1=check(a,b,n);     puts("Sec2");     for (i=0;i<n-2;i++)         scanf("%d",&a[i]);     insertSort(a,n-2);     puts("Thir1");     o2=check(b,a,n-2);     puts("Thir2");     printf("%d\\n%d",o1,o2);     return 0; }', 'loss_ids': 0, 'shortenable_ids': 1}, {'text': '<mask>', 'loss_ids': 1, 'shortenable_ids': 0}, {'text': 'is fixed program', 'loss_ids': 0, 'shortenable_ids': 0}], {'guid': 0, 'tgt_text': '#include <stdio.h> #include <stdlib.h>  int main() {     int i,n,x;     __int64 a=0,b=0,c=0;     scanf("%d",&n);     for (i=0; i<n; i++)     {         scanf("%d",&x);         a+=x;     }     for (i=0; i<n-1; i++)     {         scanf("%d",&x);         b+=x;     }     for (i=0; i<n-2; i++)     {         scanf("%d",&x);         c+=x;      }     printf("%I64d\\n%I64d",a-b,b-c);     return 0; }'}]
***** Running training *****
  Num examples = 1082
  Batch size = 6
  Num epoch = 10

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 0
  eval_ppl = inf
  global_step = 182
  train_loss = 73.8747
  ********************
Previous best ppl:inf
Achieve Best ppl:inf
  ********************
BLEU file: ./data/xcodeeval/1/validation.jsonl
  codebleu-4 = 75.75 	 Previous best codebleu 0
  ********************
 Achieve Best bleu:75.75
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 1
  eval_ppl = inf
  global_step = 363
  train_loss = 60.9831
  ********************
Previous best ppl:inf
BLEU file: ./data/xcodeeval/1/validation.jsonl
  codebleu-4 = 75.6 	 Previous best codebleu 75.75
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 2
  eval_ppl = inf
  global_step = 544
  train_loss = 50.592
  ********************
Previous best ppl:inf
BLEU file: ./data/xcodeeval/1/validation.jsonl
  codebleu-4 = 75.78 	 Previous best codebleu 75.75
  ********************
 Achieve Best bleu:75.78
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 3
  eval_ppl = inf
  global_step = 725
  train_loss = 42.1438
  ********************
Previous best ppl:inf
BLEU file: ./data/xcodeeval/1/validation.jsonl
  codebleu-4 = 75.83 	 Previous best codebleu 75.78
  ********************
 Achieve Best bleu:75.83
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 4
  eval_ppl = inf
  global_step = 906
  train_loss = 35.1469
  ********************
Previous best ppl:inf
BLEU file: ./data/xcodeeval/1/validation.jsonl
  codebleu-4 = 75.86 	 Previous best codebleu 75.83
  ********************
 Achieve Best bleu:75.86
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 5
  eval_ppl = inf
  global_step = 1087
  train_loss = 30.0554
  ********************
Previous best ppl:inf
BLEU file: ./data/xcodeeval/1/validation.jsonl
  codebleu-4 = 75.85 	 Previous best codebleu 75.86
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 6
  eval_ppl = inf
  global_step = 1268
  train_loss = 25.1901
  ********************
Previous best ppl:inf
BLEU file: ./data/xcodeeval/1/validation.jsonl
  codebleu-4 = 75.79 	 Previous best codebleu 75.86
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 7
  eval_ppl = inf
  global_step = 1449
  train_loss = 21.4368
  ********************
Previous best ppl:inf
BLEU file: ./data/xcodeeval/1/validation.jsonl
  codebleu-4 = 75.66 	 Previous best codebleu 75.86
  ********************
early stopping!!!
reload model from xcodeeval/1/soft4_codet5p_220m/checkpoint-best-bleu
BLEU file: ./data/xcodeeval/1/test.jsonl
  codebleu = 76.67 
  Total = 135 
  Exact Fixed = 2 
[62, 132]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 2 
[77, 123]
  ********************
  Total = 135 
  Exact Fixed = 2 
[62, 132]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 2 
[77, 123]
  codebleu = 76.67 
[0.7097922458866276, 0.9752926493864778, 0.8419188985107608, 0.8399493211101225, 0.5511737119063814, 0.8995033054005415, 0.655233513178001, 0.8131660563421435, 0.47822580645161283, 0.9295757649014529, 0.6700100781693141, 0.8881108167610436, 0.8920012172763082, 0.8635633094990022, 0.9250674011252755, 0.7938229814514498, 0.6068707460804744, 0.8143502770709957, 0.9126650482788027, 0.9832612094993938, 0.9498733743967636, 0.7584713945723569, 0.9054668285688956, 0.9304372254539681, 0.7430780572722281, 0.8986391637385749, 0.5012202683657422, 0.8381960842127558, 0.943601919551823, 0.9876232981025004, 0.9857368328793006, 0.8463810160907537, 0.5003910292067191, 0.9389707093964361, 0.8416184535678177, 0.973858151522893, 0.6298491547945411, 0.9365819013624168, 0.46124203184813023, 0.9471982954514573, 0.6432679507343982, 0.6754292375001995, 0.43231737186383545, 0.48170226274723915, 0.7149195155805301, 0.8396113521805657, 0.9465012851429597, 0.973858151522893, 0.5677764741944027, 0.811100358881859, 0.9601466755014141, 0.33580645216805804, 0.9460916285283518, 0.7927906556865255, 0.46344533813736777, 0.9333310235672049, 0.8633660722321144, 0.6778336766746159, 0.9860950428335316, 0.5335581349704818, 0.9492384172683168, 1.0, 0.5077214223305908, 0.9702812943440167, 0.9946984307054776, 0.09708694829326665, 0.9334580759528754, 0.2857544178174171, 0.7598076383450478, 0.8753772142950917, 0.39101342264848765, 0.9604294079167424, 0.39536345674651, 0.9215748937941259, 0.8760369670517594, 0.9194570682158518, 0.8791990328029993, 0.8373834761279768, 0.8644554554879766, 0.8454546086981599, 0.7557818507099485, 0.7153375795187605, 0.8527875420817158, 0.9128071327141931, 0.9903793674040597, 0.8917793747666807, 0.89451908845154, 0.8424197834374936, 0.9421973946848736, 0.7832059164639751, 0.9617625014218179, 0.8963430088316504, 0.4934678370724654, 0.9109545424921657, 0.5355322041447821, 0.9498733743967636, 0.7253025503608977, 0.855337897791616, 0.5076943976918459, 0.906923058378295, 0.9381767755969468, 0.5998071806896054, 0.636431616935416, 0.2572497507889638, 0.7556814728598797, 0.9582778026878329, 0.6362439585829495, 0.9365739931432338, 0.29943997880421824, 0.8769250379411355, 0.38872570161617365, 0.9750017397390569, 0.7639496783614648, 0.5412219101899178, 0.5102601887697077, 0.9442248897793943, 0.9692439075113215, 0.7929436912800465, 0.7741939441431783, 0.47854531008265005, 0.9041929640741897, 0.37828106820249585, 0.9455713410474389, 0.3565874055354602, 0.8119506730626463, 0.8349334433697306, 0.7286144481170467, 0.8241554247996095, 0.45601045567543047, 0.7761988507965935, 0.6017150080688712, 1.0, 0.910618969189708, 0.48246469658822144, 0.7279692304347927]
Finish training and take 32m

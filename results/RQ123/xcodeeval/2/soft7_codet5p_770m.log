Namespace(log_name='./xcodeeval/2/soft7_codet5p_770m.log', model_name='Salesforce/codet5p-770m', lang='c', output_dir='xcodeeval/2/soft7_codet5p_770m', data_dir='./data/xcodeeval/2', no_cuda=False, visible_gpu='0', num_train_epochs=10, num_test_epochs=1, train_batch_size=6, eval_batch_size=4, gradient_accumulation_steps=1, load_model_path=None, config_name='', tokenizer_name='', max_source_length=512, max_target_length=512, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, freeze=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
Model created!!
[[{'text': '#include<stdio.h> long long a[100003],b[100003],x[100003]; int main() {     long long n,m,i,total=0,j;     scanf("%lld",&n);     a[0]=0;     b[0]=0;     for(i=1;i<=n;i++)     {         scanf("%lld",&a[i]);         total=total+a[i];         b[i]=total;     }     scanf("%lld",&m);     for(j=1;j<=m;j++)     {         scanf("%lld",&x[j]);     }     for(j=1;j<=m;j++)     {         for(i=1;i<=n;i++)         {             if(b[i]>=x[j])             {                 printf("%lld\\n",i);                 break;             }         }     }     return 0;  }', 'loss_ids': 0, 'shortenable_ids': 1}, {'text': '<mask>', 'loss_ids': 1, 'shortenable_ids': 0}, {'text': 'is the fixed version', 'loss_ids': 0, 'shortenable_ids': 0}], {'guid': 0, 'tgt_text': '#include<stdio.h> long long a[200000],b[200000]; int main() {     long long n,i,m,total=0,x,j,start,end,mid;     scanf("%lld",&n);     for(i=0;i<n;i++)     {         scanf("%lld",&a[i]);         total=total+a[i];         b[i]=total;     }     scanf("%lld",&m);     for(j=1;j<=m;j++)     {         scanf("%lld",&x);         if(x<=b[0])         {             printf("1\\n");         }         else if(x>=b[n-1])         {             printf("%lld\\n",n);         }         else         {             start=0;             end=n-1;             while(start<=end)             {                 mid=(start+end)/2;                 if(b[mid]>=x&&b[mid-1]<x)                 {                     printf("%lld\\n",(mid+1));                     break;                 }                 else if(b[mid]<x)                 {                     start=mid+1;                 }                 else if(b[mid]>=x&&b[mid-1]>=x)                 {                     end=mid-1;                 }             }         }     }     return 0;  }'}]
***** Running training *****
  Num examples = 1082
  Batch size = 6
  Num epoch = 10

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 0
  eval_ppl = inf
  global_step = 182
  train_loss = 67.0355
  ********************
Previous best ppl:inf
Achieve Best ppl:inf
  ********************
BLEU file: ./data/xcodeeval/2/validation.jsonl
  codebleu-4 = 77.56 	 Previous best codebleu 0
  ********************
 Achieve Best bleu:77.56
  ********************
Namespace(log_name='./xcodeeval/2/soft7_codet5p_770m.log', model_name='Salesforce/codet5p-770m', lang='java', output_dir='xcodeeval/2/soft7_codet5p_770m', data_dir='./data/xcodeeval/2', no_cuda=False, visible_gpu='0', num_train_epochs=10, num_test_epochs=1, train_batch_size=4, eval_batch_size=4, gradient_accumulation_steps=1, load_model_path=None, config_name='', tokenizer_name='', max_source_length=512, max_target_length=512, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, freeze=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
Model created!!
[[{'text': 'Please fix an buggy program', 'loss_ids': 0, 'shortenable_ids': 0}, {'text': ' #include<stdio.h> long long a[100003],b[100003],x[100003]; int main() {     long long n,m,i,total=0,j;     scanf("%lld",&n);     a[0]=0;     b[0]=0;     for(i=1;i<=n;i++)     {         scanf("%lld",&a[i]);         total=total+a[i];         b[i]=total;     }     scanf("%lld",&m);     for(j=1;j<=m;j++)     {         scanf("%lld",&x[j]);     }     for(j=1;j<=m;j++)     {         for(i=1;i<=n;i++)         {             if(b[i]>=x[j])             {                 printf("%lld\\n",i);                 break;             }         }     }     return 0;  }', 'loss_ids': 0, 'shortenable_ids': 1}, {'text': 'error message is', 'loss_ids': 0, 'shortenable_ids': 0}, {'text': ' PASSED', 'loss_ids': 0, 'shortenable_ids': 0}, {'text': '<mask>', 'loss_ids': 1, 'shortenable_ids': 0}, {'text': 'is the fixed version', 'loss_ids': 0, 'shortenable_ids': 0}], {'guid': 0, 'tgt_text': '#include<stdio.h> long long a[200000],b[200000]; int main() {     long long n,i,m,total=0,x,j,start,end,mid;     scanf("%lld",&n);     for(i=0;i<n;i++)     {         scanf("%lld",&a[i]);         total=total+a[i];         b[i]=total;     }     scanf("%lld",&m);     for(j=1;j<=m;j++)     {         scanf("%lld",&x);         if(x<=b[0])         {             printf("1\\n");         }         else if(x>=b[n-1])         {             printf("%lld\\n",n);         }         else         {             start=0;             end=n-1;             while(start<=end)             {                 mid=(start+end)/2;                 if(b[mid]>=x&&b[mid-1]<x)                 {                     printf("%lld\\n",(mid+1));                     break;                 }                 else if(b[mid]<x)                 {                     start=mid+1;                 }                 else if(b[mid]>=x&&b[mid-1]>=x)                 {                     end=mid-1;                 }             }         }     }     return 0;  }'}]
***** Running training *****
  Num examples = 1082
  Batch size = 4
  Num epoch = 10

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 0
  eval_ppl = inf
  global_step = 272
  train_loss = 67.468
  ********************
Previous best ppl:inf
Achieve Best ppl:inf
  ********************
BLEU file: ./data/xcodeeval/2/validation.jsonl
  codebleu-4 = 75.93 	 Previous best codebleu 0
  ********************
 Achieve Best bleu:75.93
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 1
  eval_ppl = inf
  global_step = 543
  train_loss = 53.8664
  ********************
Previous best ppl:inf
BLEU file: ./data/xcodeeval/2/validation.jsonl
  codebleu-4 = 76.3 	 Previous best codebleu 75.93
  ********************
 Achieve Best bleu:76.3
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 2
  eval_ppl = inf
  global_step = 814
  train_loss = 39.4733
  ********************
Previous best ppl:inf
BLEU file: ./data/xcodeeval/2/validation.jsonl
  codebleu-4 = 76.26 	 Previous best codebleu 76.3
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 3
  eval_ppl = inf
  global_step = 1085
  train_loss = 28.1422
  ********************
Previous best ppl:inf
BLEU file: ./data/xcodeeval/2/validation.jsonl
Namespace(log_name='./xcodeeval/2/soft7_codet5p_770m.log', model_name='Salesforce/codet5p-770m', lang='java', output_dir='xcodeeval/2/soft7_codet5p_770m', data_dir='./data/xcodeeval/2', no_cuda=False, visible_gpu='0', num_train_epochs=10, num_test_epochs=1, train_batch_size=4, eval_batch_size=4, gradient_accumulation_steps=1, load_model_path=None, config_name='', tokenizer_name='', max_source_length=512, max_target_length=512, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, freeze=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
Model created!!
[[{'text': 'Please fix an buggy program', 'loss_ids': 0, 'shortenable_ids': 0}, {'text': ' #include<stdio.h> long long a[100003],b[100003],x[100003]; int main() {     long long n,m,i,total=0,j;     scanf("%lld",&n);     a[0]=0;     b[0]=0;     for(i=1;i<=n;i++)     {         scanf("%lld",&a[i]);         total=total+a[i];         b[i]=total;     }     scanf("%lld",&m);     for(j=1;j<=m;j++)     {         scanf("%lld",&x[j]);     }     for(j=1;j<=m;j++)     {         for(i=1;i<=n;i++)         {             if(b[i]>=x[j])             {                 printf("%lld\\n",i);                 break;             }         }     }     return 0;  }', 'loss_ids': 0, 'shortenable_ids': 1}, {'text': 'error message is', 'loss_ids': 0, 'shortenable_ids': 0}, {'text': ' PASSED', 'loss_ids': 0, 'shortenable_ids': 0}, {'text': '<mask>', 'loss_ids': 1, 'shortenable_ids': 0}, {'text': 'is the fixed version', 'loss_ids': 0, 'shortenable_ids': 0}], {'guid': 0, 'tgt_text': '#include<stdio.h> long long a[200000],b[200000]; int main() {     long long n,i,m,total=0,x,j,start,end,mid;     scanf("%lld",&n);     for(i=0;i<n;i++)     {         scanf("%lld",&a[i]);         total=total+a[i];         b[i]=total;     }     scanf("%lld",&m);     for(j=1;j<=m;j++)     {         scanf("%lld",&x);         if(x<=b[0])         {             printf("1\\n");         }         else if(x>=b[n-1])         {             printf("%lld\\n",n);         }         else         {             start=0;             end=n-1;             while(start<=end)             {                 mid=(start+end)/2;                 if(b[mid]>=x&&b[mid-1]<x)                 {                     printf("%lld\\n",(mid+1));                     break;                 }                 else if(b[mid]<x)                 {                     start=mid+1;                 }                 else if(b[mid]>=x&&b[mid-1]>=x)                 {                     end=mid-1;                 }             }         }     }     return 0;  }'}]
***** Running training *****
  Num examples = 1082
  Batch size = 4
  Num epoch = 10

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 0
  eval_ppl = inf
  global_step = 272
  train_loss = 67.468
  ********************
Previous best ppl:inf
Achieve Best ppl:inf
  ********************
BLEU file: ./data/xcodeeval/2/validation.jsonl
  codebleu-4 = 75.93 	 Previous best codebleu 0
  ********************
 Achieve Best bleu:75.93
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 1
  eval_ppl = inf
  global_step = 543
  train_loss = 53.8664
  ********************
Previous best ppl:inf
BLEU file: ./data/xcodeeval/2/validation.jsonl
  codebleu-4 = 76.3 	 Previous best codebleu 75.93
  ********************
 Achieve Best bleu:76.3
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 2
  eval_ppl = inf
  global_step = 814
  train_loss = 39.4733
  ********************
Previous best ppl:inf
BLEU file: ./data/xcodeeval/2/validation.jsonl
  codebleu-4 = 76.26 	 Previous best codebleu 76.3
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 3
  eval_ppl = inf
  global_step = 1085
  train_loss = 28.1422
  ********************
Previous best ppl:inf
BLEU file: ./data/xcodeeval/2/validation.jsonl
  codebleu-4 = 76.27 	 Previous best codebleu 76.3
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 4
  eval_ppl = inf
  global_step = 1356
  train_loss = 19.022
  ********************
Previous best ppl:inf
BLEU file: ./data/xcodeeval/2/validation.jsonl
  codebleu-4 = 75.91 	 Previous best codebleu 76.3
  ********************
early stopping!!!
reload model from xcodeeval/2/soft7_codet5p_770m/checkpoint-best-bleu
BLEU file: ./data/xcodeeval/2/test.jsonl
  codebleu = 72.87 
  Total = 135 
  Exact Fixed = 7 
[27, 73, 88, 107, 114, 117, 120]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 1 
[100]
  ********************
  Total = 135 
  Exact Fixed = 7 
[27, 73, 88, 107, 114, 117, 120]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 1 
[100]
  codebleu = 72.87 
[0.3888834796801538, 0.5119460199048119, 0.9504928408158546, 0.8491483370647184, 0.6149771354539022, 0.9852691294317872, 0.9622594813845022, 0.4563243789808236, 0.9413237717631426, 0.6802077739515769, 0.24210607807744522, 0.584899116778663, 0.9117781363015256, 0.07130743830190094, 0.03281115469695418, 0.9690470390182255, 0.5699124992618471, 0.7356931723051547, 0.7106363484445642, 0.4146654333529397, 0.51279090278026, 0.8919774150628842, 0.9780384047260811, 0.9617720754477719, 0.6882647766792233, 0.6333671278513916, 1.0, 0.956892997823592, 0.9120424742934687, 0.32418456211517666, 0.4222704774639776, 0.8653834749273801, 0.9617570994669966, 0.946665089615236, 0.5885359393675832, 0.5998058426022883, 0.4637561122998248, 0.9557465581089486, 0.5384913385694663, 0.5315296230553525, 0.6863757819221206, 0.8359122348190775, 0.9353176101067031, 0.6517624271254832, 0.9659416709906494, 0.9298931791730787, 0.9687829854371817, 0.940387748772268, 0.9840793393103271, 0.9758234675444843, 0.32151517522245066, 0.37837504104187486, 0.5047577306661156, 0.7823299287895147, 0.853063134088631, 0.9403863481322654, 0.8918142482329203, 0.9451848319937642, 0.49077560378130586, 0.607835221839913, 0.7191795355342101, 0.938605671540292, 0.9424861047552409, 0.5722769208847139, 0.3326127917717159, 0.8886223888442533, 0.7127500077175998, 0.571438355469486, 0.9768438379914091, 0.9671007961854172, 0.9430295145286021, 0.8369635941502973, 0.9715441710080255, 0.6438504303659041, 0.347741634005172, 0.7878465415346224, 0.7595166666814087, 0.979304849374673, 0.9278876679975507, 0.9511842736268326, 0.26676325783756394, 0.2683928571428571, 0.6744618142997432, 0.727419331945831, 0.40897025914278523, 0.6097416277258915, 0.3634121790752288, 0.993565204007768, 0.9256050837711551, 0.6538001263697061, 0.7110836621866043, 0.9603861885822986, 0.8741900115980714, 0.9788259925881726, 0.7961104119141532, 0.5959377733666189, 0.9586895873203385, 0.7383869773061409, 0.6181710046016234, 0.9070688315997795, 0.41250375321647825, 0.5684544584604022, 0.4668795825192024, 0.25916735484337194, 0.98905613398207, 0.6765153707439431, 1.0, 0.44337386717981453, 0.9371536949899508, 0.43063362247391185, 0.6997993560942393, 0.7738077478644633, 0.8809820875819727, 1.0, 0.9286542954941046, 0.9404076659244109, 1.0, 0.5002115609865647, 0.9615049129245392, 1.0, 0.41784954647503847, 0.9498733743967636, 0.7085403351840623, 0.6628618028697012, 0.6212987985364005, 0.4247334619586536, 0.9645896373785567, 0.5210011744246135, 0.2873199576689667, 0.7594307197061102, 0.9077173725606897, 0.8778488047731399, 0.9642957518653632, 0.9750949338196533, 0.7513355142775362]
Finish training and take 49m

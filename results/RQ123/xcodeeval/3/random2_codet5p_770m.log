Namespace(log_name='./result/xcodeeval/3/random2_codet5p_770m.log', model_name='Salesforce/codet5p-770m', lang='c', output_dir='result/xcodeeval/3/random2_codet5p_770m', data_dir='./data/xcodeeval/3', no_cuda=False, visible_gpu='0', choice=2, num_train_epochs=10, num_test_epochs=1, train_batch_size=4, eval_batch_size=4, gradient_accumulation_steps=1, load_model_path=None, config_name='', tokenizer_name='', max_source_length=512, max_target_length=512, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, freeze=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
Model created!!
[[{'text': 'Fix the bug in', 'loss_ids': 0, 'shortenable_ids': 0}, {'text': ' #include<stdio.h> int main() { int t,i=1; scanf("%d",&t); while(i<=t)  {  int s,a,b,c,d;  scanf("%d%d%d%d",&s,&a,&b,&c);  d=(s/c)+((s/a)*b);  printf("%d",d);  } return 0; }', 'loss_ids': 0, 'shortenable_ids': 1}, {'text': '<mask>', 'loss_ids': 1, 'shortenable_ids': 0}], {'guid': 0, 'tgt_text': '#include<stdio.h> int main() { long long s,a,b,c,d,p; int t,i; scanf("%d",&t); for(i=1;i<=t;i++)  {  scanf("%I64d%I64d%I64d%I64d",&s,&a,&b,&c);  p=s/c;  d=(p)+((p/a)*b);  printf("%I64d\\n",d);  } return 0; }'}]
***** Running training *****
  Num examples = 1082
  Batch size = 4
  Num epoch = 10

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 0
  eval_ppl = inf
  global_step = 272
  train_loss = 61.8994
  ********************
Previous best ppl:inf
Achieve Best ppl:inf
  ********************
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 76.09 	 Previous best codebleu 0
  ********************
 Achieve Best bleu:76.09
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 1
  eval_ppl = inf
  global_step = 543
  train_loss = 52.1113
  ********************
Previous best ppl:inf
Achieve Best ppl:inf
  ********************
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 75.38 	 Previous best codebleu 76.09
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 2
  eval_ppl = inf
  global_step = 814
  train_loss = 38.1329
  ********************
Previous best ppl:inf
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 76.13 	 Previous best codebleu 76.09
  ********************
 Achieve Best bleu:76.13
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 3
  eval_ppl = inf
  global_step = 1085
  train_loss = 27.4534
  ********************
Previous best ppl:inf
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 75.84 	 Previous best codebleu 76.13
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 4
  eval_ppl = inf
  global_step = 1356
  train_loss = 19.3666
  ********************
Previous best ppl:inf
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 76.14 	 Previous best codebleu 76.13
  ********************
 Achieve Best bleu:76.14
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 5
  eval_ppl = inf
  global_step = 1627
  train_loss = 13.1945
  ********************
Previous best ppl:inf
BLEU file: ./data/xcodeeval/3/validation.jsonl
Namespace(log_name='./result/xcodeeval/3/random2_codet5p_770m.log', model_name='Salesforce/codet5p-770m', lang='c', output_dir='result/xcodeeval/3/random2_codet5p_770m', data_dir='./data/xcodeeval/3', no_cuda=False, visible_gpu='0', choice=2, num_train_epochs=10, num_test_epochs=1, train_batch_size=4, eval_batch_size=4, gradient_accumulation_steps=1, load_model_path=None, config_name='', tokenizer_name='', max_source_length=512, max_target_length=512, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, freeze=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
Model created!!
[[{'text': 'Fix the bug in', 'loss_ids': 0, 'shortenable_ids': 0}, {'text': ' #include<stdio.h> int main() { int t,i=1; scanf("%d",&t); while(i<=t)  {  int s,a,b,c,d;  scanf("%d%d%d%d",&s,&a,&b,&c);  d=(s/c)+((s/a)*b);  printf("%d",d);  } return 0; }', 'loss_ids': 0, 'shortenable_ids': 1}, {'text': '<mask>', 'loss_ids': 1, 'shortenable_ids': 0}], {'guid': 0, 'tgt_text': '#include<stdio.h> int main() { long long s,a,b,c,d,p; int t,i; scanf("%d",&t); for(i=1;i<=t;i++)  {  scanf("%I64d%I64d%I64d%I64d",&s,&a,&b,&c);  p=s/c;  d=(p)+((p/a)*b);  printf("%I64d\\n",d);  } return 0; }'}]
***** Running training *****
  Num examples = 1082
  Batch size = 4
  Num epoch = 10

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 0
  eval_ppl = inf
  global_step = 272
  train_loss = 61.8994
  ********************
Previous best ppl:inf
Achieve Best ppl:inf
  ********************
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 76.1 	 Previous best codebleu 0
  ********************
 Achieve Best bleu:76.1
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 1
  eval_ppl = inf
  global_step = 543
  train_loss = 52.1113
  ********************
Previous best ppl:inf
Achieve Best ppl:inf
  ********************
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 75.4 	 Previous best codebleu 76.1
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 2
  eval_ppl = inf
  global_step = 814
  train_loss = 38.1329
  ********************
Previous best ppl:inf
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 76.14 	 Previous best codebleu 76.1
  ********************
 Achieve Best bleu:76.14
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 3
  eval_ppl = inf
  global_step = 1085
  train_loss = 27.4534
  ********************
Previous best ppl:inf
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 75.85 	 Previous best codebleu 76.14
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 4
  eval_ppl = inf
  global_step = 1356
  train_loss = 19.3666
  ********************
Previous best ppl:inf
BLEU file: ./data/xcodeeval/3/validation.jsonl
Namespace(log_name='./result/xcodeeval/3/random2_codet5p_770m.log', model_name='Salesforce/codet5p-770m', lang='c', output_dir='result/xcodeeval/3/random2_codet5p_770m', data_dir='./data/xcodeeval/3', no_cuda=False, visible_gpu='0', choice=2, num_train_epochs=10, num_test_epochs=1, train_batch_size=4, eval_batch_size=4, gradient_accumulation_steps=1, load_model_path=None, config_name='', tokenizer_name='', max_source_length=512, max_target_length=512, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, freeze=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
Model created!!
[[{'text': 'Fix the bug in', 'loss_ids': 0, 'shortenable_ids': 0}, {'text': ' #include<stdio.h> int main() { int t,i=1; scanf("%d",&t); while(i<=t)  {  int s,a,b,c,d;  scanf("%d%d%d%d",&s,&a,&b,&c);  d=(s/c)+((s/a)*b);  printf("%d",d);  } return 0; }', 'loss_ids': 0, 'shortenable_ids': 1}, {'text': '<mask>', 'loss_ids': 1, 'shortenable_ids': 0}], {'guid': 0, 'tgt_text': '#include<stdio.h> int main() { long long s,a,b,c,d,p; int t,i; scanf("%d",&t); for(i=1;i<=t;i++)  {  scanf("%I64d%I64d%I64d%I64d",&s,&a,&b,&c);  p=s/c;  d=(p)+((p/a)*b);  printf("%I64d\\n",d);  } return 0; }'}]
***** Running training *****
  Num examples = 1082
  Batch size = 4
  Num epoch = 10

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 0
  eval_ppl = inf
  global_step = 272
  train_loss = 62.3577
  ********************
Previous best ppl:inf
Achieve Best ppl:inf
  ********************
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 75.23 	 Previous best codebleu 0
  ********************
 Achieve Best bleu:75.23
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 1
  eval_ppl = inf
  global_step = 543
  train_loss = 51.7722
  ********************
Previous best ppl:inf
Achieve Best ppl:inf
  ********************
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 75.84 	 Previous best codebleu 75.23
  ********************
 Achieve Best bleu:75.84
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 2
  eval_ppl = inf
  global_step = 814
  train_loss = 37.4319
  ********************
Previous best ppl:inf
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 76.04 	 Previous best codebleu 75.84
  ********************
 Achieve Best bleu:76.04
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 3
  eval_ppl = inf
  global_step = 1085
  train_loss = 26.6817
  ********************
Previous best ppl:inf
Achieve Best ppl:inf
  ********************
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 71.17 	 Previous best codebleu 76.04
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 4
  eval_ppl = inf
  global_step = 1356
  train_loss = 19.6244
  ********************
Previous best ppl:inf
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 76.18 	 Previous best codebleu 76.04
  ********************
 Achieve Best bleu:76.18
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 5
  eval_ppl = inf
  global_step = 1627
  train_loss = 13.1227
  ********************
Previous best ppl:inf
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 76.14 	 Previous best codebleu 76.18
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 6
  eval_ppl = inf
  global_step = 1898
  train_loss = 8.2969
  ********************
Previous best ppl:inf
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 76.39 	 Previous best codebleu 76.18
  ********************
 Achieve Best bleu:76.39
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 7
  eval_ppl = inf
  global_step = 2169
  train_loss = 5.6742
  ********************
Previous best ppl:inf
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 76.23 	 Previous best codebleu 76.39
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 8
  eval_ppl = inf
  global_step = 2440
  train_loss = 3.8078
  ********************
Previous best ppl:inf
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 75.69 	 Previous best codebleu 76.39
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 9
  eval_ppl = inf
  global_step = 2711
  train_loss = 2.7254
  ********************
Previous best ppl:inf
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 76.13 	 Previous best codebleu 76.39
  ********************
early stopping!!!
reload model from result/xcodeeval/3/random2_codet5p_770m/checkpoint-best-bleu
BLEU file: ./data/xcodeeval/3/test.jsonl
  codebleu = 74.63 
  Total = 135 
  Exact Fixed = 5 
[27, 36, 45, 53, 88]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  ********************
  Total = 135 
  Exact Fixed = 5 
[27, 36, 45, 53, 88]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  codebleu = 74.63 
[0.7802656127733693, 0.546397650468432, 0.5716305803120681, 0.9503998344473819, 0.9759316203623163, 0.08651205986326166, 0.25656679901645385, 0.7046499084361562, 0.6450304794017896, 0.5124474841624163, 0.5591195799659847, 0.8164468849403668, 0.8805670984187464, 0.92318680311656, 0.9377858074101935, 0.9175636111085979, 0.3636753860643496, 0.947175667983928, 0.7822722252676139, 0.8106836338492169, 0.9705776794701617, 0.9735791100966684, 0.7787528493632571, 0.3873468360700999, 0.7657560530824576, 0.9450171055839813, 1.0, 0.9343575548388978, 0.5790261988125887, 0.8896800467143886, 0.8824402399754723, 0.4676655068837078, 0.39721083829924086, 0.9716642922960141, 0.5925258544448675, 1.0, 0.739909040388661, 0.9025560323310975, 0.7448056521936861, 0.9670641264245079, 0.867980815381816, 0.8583791034780668, 0.9306240015142291, 0.9321464078063899, 1.0, 0.8470562047308248, 0.9623079709182942, 0.6657746668518538, 0.950524665864859, 0.9312349008025642, 0.9712222651426679, 0.9828198222975641, 1.0, 0.8633963363946109, 0.7801949080730365, 0.9648891735454908, 0.7132074091240559, 0.9169108417444476, 0.951315622822358, 0.33295797590328613, 0.35624122019684656, 0.7982100679121421, 0.9217008915274616, 0.8689970404457057, 0.926748919169406, 0.9858263222388597, 0.9859658995808198, 0.15351946048762036, 0.8775308546018508, 0.7624527118354689, 0.9109344104254649, 0.9669138743101213, 0.9503712900963834, 0.9444842541441154, 0.9525069902299836, 0.5474913051472977, 0.8308197719965693, 0.8657268209604377, 0.6927725662122917, 0.8269793321315543, 0.8947151965627762, 0.9650446019275767, 0.7761391783604946, 0.9512693309096103, 0.6230524667375235, 0.7763879223350485, 0.26765125761038455, 1.0, 0.9500301732256957, 0.8980952928375916, 0.5797226856861304, 0.4286023969955689, 0.9498733743967636, 0.28301368512998626, 0.30278837455257246, 0.8333124373352575, 0.29259259325874953, 0.6352418602881265, 0.9407380844851914, 0.3913905692778357, 0.9555110270475338, 0.9174195483383916, 0.45790662976970986, 0.9534278780598358, 0.9393217253155881, 0.8897945586059963, 0.33552036674629254, 0.35148053648224986, 0.9468383894696302, 0.3868507250835175, 0.919755073180808, 0.3455555205176508, 0.4954735182274035, 0.9427008679312978, 0.5442886701759317, 0.3802373756400821, 0.8724126932680951, 0.6354235024199191, 0.9732456940628658, 0.7843652297127398, 0.40602968460111316, 0.68941044587298, 0.7934303369700066, 0.9764351042658364, 0.4953415641367399, 0.6908535288138271, 0.8997299115670001, 0.37462332268897325, 0.37224533982578545, 0.4191471722230175, 0.8930699435879692, 0.9720712010457695, 0.8517616940164475, 0.4094542044720756, 0.3357637568330429]
Finish training and take 2h0m

Namespace(log_name='./xcodeeval/3/finetune_codet5p_220m.log', model_name='Salesforce/codet5p-220m', lang='c', output_dir='xcodeeval/3/finetune_codet5p_220m', data_dir='./data/xcodeeval/3', no_cuda=False, visible_gpu='0', add_task_prefix=False, add_lang_ids=False, num_train_epochs=10, num_test_epochs=10, train_batch_size=8, eval_batch_size=4, gradient_accumulation_steps=2, load_model_path=None, config_name='', tokenizer_name='', max_source_length=128, max_target_length=128, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, do_lower_case=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, max_steps=-1, eval_steps=-1, train_steps=-1, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, model_name: Salesforce/codet5p-220m
model created!
Total 1082 training instances 
***** Running training *****
  Num examples = 1082
  Batch size = 8
  Num epoch = 10

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 0
  eval_ppl = 1.00062
  global_step = 136
  train_loss = 0.3997
  ********************
Previous best ppl:inf
Achieve Best ppl:1.00062
  ********************
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 73.64 	 Previous best codebleu 0
  ********************
 Achieve Best bleu:73.64
  ********************

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 1
  eval_ppl = 1.00058
  global_step = 271
  train_loss = 0.2901
  ********************
Previous best ppl:1.00062
Achieve Best ppl:1.00058
  ********************
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 74.35 	 Previous best codebleu 73.64
  ********************
 Achieve Best bleu:74.35
  ********************

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 2
  eval_ppl = 1.0006
  global_step = 406
  train_loss = 0.2324
  ********************
Previous best ppl:1.00058
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 74.19 	 Previous best codebleu 74.35
  ********************

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 3
  eval_ppl = 1.00062
  global_step = 541
  train_loss = 0.193
  ********************
Previous best ppl:1.00058
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 73.99 	 Previous best codebleu 74.35
  ********************

***** Running evaluation *****
  Num examples = 135
  Batch size = 4
  epoch = 4
  eval_ppl = 1.00066
  global_step = 676
  train_loss = 0.161
  ********************
Previous best ppl:1.00058
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 74.03 	 Previous best codebleu 74.35
  ********************
reload model from xcodeeval/3/finetune_codet5p_220m/checkpoint-best-bleu
BLEU file: ./data/xcodeeval/3/test.jsonl
  codebleu = 71.32 
  Total = 135 
  Exact Fixed = 0 
[]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  ********************
  Total = 135 
  Exact Fixed = 0 
[]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  codebleu = 71.32 
[0.7849538767776651, 0.7663371990492582, 0.6976910864186706, 0.8512897119997327, 0.8536358763066614, 0.08406889937820157, 0.34898094225543036, 0.7669842146074164, 0.6756324089520065, 0.6054199120209949, 0.5601962677755853, 0.8164468849403668, 0.9175351478585267, 0.8726774356123554, 0.7609111405654982, 0.872147466111713, 0.28456980887865324, 0.7534037242254013, 0.5654675203716997, 0.7830064735910691, 0.9185412013134608, 0.8245561139312393, 0.8333813540442871, 0.5524112337326081, 0.7816849127345435, 0.802138971106996, 0.8324183912964096, 0.8448616344160145, 0.6982021521970254, 0.7921624393976985, 0.91412960455335, 0.4739726324720028, 0.63014750305347, 0.9040862722278158, 0.6345448464057466, 0.7259849312989834, 0.7540469087814428, 0.8313915586456186, 0.6121972533149926, 0.8569685752263538, 0.7932902743460295, 0.630150618578014, 0.6759728227587174, 0.790982444268264, 0.7807079788494218, 0.8296660707943342, 0.672785744652446, 0.7867507949022507, 0.8536334434067134, 0.5685250847298065, 0.8219514476194971, 0.8419978367899081, 0.9092430471124722, 0.9104392373575145, 0.7182482958421927, 0.941768888951575, 0.6455873914646095, 0.8138225102863303, 0.8654937656858617, 0.4142301377471687, 0.5112111419002278, 0.8297929734818674, 0.9217008915274616, 0.878087949536615, 0.7817544938474634, 0.7944974662629933, 0.8546770093840449, 0.23178378342054765, 0.7563107817326995, 0.8339849455214231, 0.8155779083654062, 0.9398076620328746, 0.754778959829329, 0.7773823007220496, 0.802980404547649, 0.5923377715628043, 0.8125459461294413, 0.720188397702945, 0.6987172522283688, 0.7925405308747024, 0.900395087233911, 0.837457300065938, 0.7087785501314359, 0.7700652915417614, 0.5677893088427866, 0.7763879223350485, 0.3417564054664891, 0.7704569402736815, 0.7509157324200985, 0.7827835412006432, 0.5672747648078345, 0.647487961996232, 0.8819989837824207, 0.7470362018806367, 0.4154808998544015, 0.811364833324377, 0.5211121075488702, 0.5309005587685636, 0.823799855709568, 0.5271882025547743, 0.8077815485625466, 0.8207432951321398, 0.5105547910952926, 0.7848352750832455, 0.8445923838454312, 0.8897945586059963, 0.33520188382167504, 0.4168626518355933, 0.852945187183654, 0.3975734208323345, 0.8811002176557108, 0.5534803180860053, 0.5285433525156937, 0.831862639858802, 0.7142029351288322, 0.42918313960976945, 0.8759700055210595, 0.7192634200448921, 0.9150668370807107, 0.7135938825045871, 0.6257365724699333, 0.8545307032267597, 0.7904010053030581, 0.8806594193232651, 0.5346863070936048, 0.6944280490257584, 0.8877072716538504, 0.24170769468996064, 0.2142677455447746, 0.5976804074013286, 0.9003747650468552, 0.8806974736497433, 0.6294449559412665, 0.5963350635154259, 0.24173832962493158]
Finish training and take 12m

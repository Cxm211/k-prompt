Namespace(log_name='./xcodeeval/3/soft8_codet5p_770m.log', model_name='Salesforce/codet5p-770m', lang='java', output_dir='xcodeeval/3/soft8_codet5p_770m', data_dir='./data/xcodeeval/3', no_cuda=False, visible_gpu='0', num_train_epochs=10, num_test_epochs=1, train_batch_size=4, eval_batch_size=4, gradient_accumulation_steps=1, load_model_path=None, config_name='', tokenizer_name='', max_source_length=512, max_target_length=512, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, freeze=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
Model created!!
[[{'text': 'Please fix an buggy program', 'loss_ids': 0, 'shortenable_ids': 0}, {'text': ' #include<stdio.h> int main() { int t,i=1; scanf("%d",&t); while(i<=t)  {  int s,a,b,c,d;  scanf("%d%d%d%d",&s,&a,&b,&c);  d=(s/c)+((s/a)*b);  printf("%d",d);  } return 0; }', 'loss_ids': 0, 'shortenable_ids': 1}, {'text': 'with tags', 'loss_ids': 0, 'shortenable_ids': 0}, {'text': ' implementation, math', 'loss_ids': 0, 'shortenable_ids': 0}, {'text': '<mask>', 'loss_ids': 1, 'shortenable_ids': 0}, {'text': 'is the fixed version', 'loss_ids': 0, 'shortenable_ids': 0}], {'guid': 0, 'tgt_text': '#include<stdio.h> int main() { long long s,a,b,c,d,p; int t,i; scanf("%d",&t); for(i=1;i<=t;i++)  {  scanf("%I64d%I64d%I64d%I64d",&s,&a,&b,&c);  p=s/c;  d=(p)+((p/a)*b);  printf("%I64d\\n",d);  } return 0; }'}]
***** Running training *****
  Num examples = 1082
  Batch size = 4
  Num epoch = 10

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 0
  eval_ppl = inf
  global_step = 272
  train_loss = 61.2162
  ********************
Previous best ppl:inf
Achieve Best ppl:inf
  ********************
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 75.26 	 Previous best codebleu 0
  ********************
 Achieve Best bleu:75.26
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 1
  eval_ppl = inf
  global_step = 543
  train_loss = 51.8334
  ********************
Previous best ppl:inf
Achieve Best ppl:inf
  ********************
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 75.26 	 Previous best codebleu 75.26
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 2
  eval_ppl = inf
  global_step = 814
  train_loss = 37.3917
  ********************
Previous best ppl:inf
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 75.6 	 Previous best codebleu 75.26
  ********************
 Achieve Best bleu:75.6
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 3
  eval_ppl = inf
  global_step = 1085
  train_loss = 26.2562
  ********************
Previous best ppl:inf
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 75.36 	 Previous best codebleu 75.6
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 4
  eval_ppl = inf
  global_step = 1356
  train_loss = 18.2305
  ********************
Previous best ppl:inf
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 75.44 	 Previous best codebleu 75.6
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 5
  eval_ppl = inf
  global_step = 1627
  train_loss = 13.05
  ********************
Previous best ppl:inf
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 75.21 	 Previous best codebleu 75.6
  ********************
early stopping!!!
reload model from xcodeeval/3/soft8_codet5p_770m/checkpoint-best-bleu
BLEU file: ./data/xcodeeval/3/test.jsonl
  codebleu = 75.64 
  Total = 135 
  Exact Fixed = 4 
[36, 53, 78, 88]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  ********************
  Total = 135 
  Exact Fixed = 4 
[36, 53, 78, 88]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  codebleu = 75.64 
[0.7775893227451628, 0.5853515167603516, 0.5625990653529481, 0.9503998344473819, 0.9759316203623163, 0.3429479572991591, 0.19209415203416363, 0.7806666470398488, 0.5830493849342742, 0.6221981411141602, 0.5391614433518024, 0.8405214903923035, 0.8847962026478505, 0.9432084848582101, 0.916354898053173, 0.9224347866319473, 0.9095765363275097, 0.9489655839503146, 0.7776727835595423, 0.799523149875461, 0.8621884258052742, 0.973946757155492, 0.7457073904879705, 0.5939496952710697, 0.4318499063541035, 0.9471817914923006, 0.8370337759117943, 0.932536171743845, 0.556481029836887, 0.8932053622518905, 0.8837357443623406, 0.3815895701976729, 0.31248333844189446, 0.9481348805313081, 0.6045101764291894, 1.0, 0.5358761800451212, 0.9025560323310975, 0.5647741473866154, 0.9699657118499967, 0.8567285467792752, 0.8652541034780667, 0.9306240015142291, 0.928104116032249, 0.807801995943439, 0.7665727141647869, 0.9538456366571078, 0.6399444638293639, 0.9479476166845311, 0.855614250563532, 0.9712222651426679, 0.9668176593559636, 1.0, 0.8633963363946109, 0.7989449080730364, 0.9648891735454908, 0.9056567060371495, 0.9047710044214887, 0.9559785995453849, 0.3485500068853482, 0.2846016530643217, 0.8074664516250476, 0.9217008915274616, 0.8907127909166133, 0.9240031841506158, 0.9858263222388597, 0.8995783334218747, 0.45549651851730993, 0.935154158457236, 0.8354893934544425, 0.7737686350243955, 0.9476831050793519, 0.9547162098824797, 0.9044444118813137, 0.9546889385083094, 0.4869345807931364, 0.8310101176643019, 1.0, 0.6564360668907177, 0.7708242259764481, 0.9085119880066266, 0.9650446019275767, 0.6251967003561173, 0.9545309095136545, 0.5352078552087014, 0.826402869025187, 0.2928385641439079, 1.0, 0.9649748644414884, 0.8998535345958332, 0.5433130182411882, 0.5248269663982585, 0.9498733743967636, 0.6345939308810901, 0.34766152465828065, 0.7662138646323137, 0.39678807736686056, 0.66135214344759, 0.9211568088717597, 0.41664124894849464, 0.9555110270475338, 0.9174195483383916, 0.5734329394688688, 0.9574278780598358, 0.9393217253155881, 0.8415802728917106, 0.29390070490441483, 0.32438587890322734, 0.90246526388516, 0.3786403848272205, 0.8760195844029468, 0.3948033330198156, 0.49005743607532803, 0.9335374304850914, 0.5181794568086538, 0.32476485876447936, 0.887548050117972, 0.7345381624583749, 0.9252456940628657, 0.8343282600290403, 0.6229111346983116, 0.667464503316853, 0.9105078068046344, 0.9764351042658364, 0.49077560378130586, 0.746212771915492, 0.9101138690338023, 0.7421743430971365, 0.7777456571517849, 0.35699549068561187, 0.9434518357230923, 0.9456458876327531, 0.9248316058727952, 0.42691439889403643, 0.3429066139759]
Finish training and take 59m

Namespace(log_name='./xcodeeval/3/soft8_codet5p_220m.log', model_name='Salesforce/codet5p-220m', lang='c', output_dir='xcodeeval/3/soft8_codet5p_220m', data_dir='./data/xcodeeval/3', no_cuda=False, visible_gpu='0', num_train_epochs=10, num_test_epochs=1, train_batch_size=6, eval_batch_size=4, gradient_accumulation_steps=1, load_model_path=None, config_name='', tokenizer_name='', max_source_length=512, max_target_length=512, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, freeze=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
Model created!!
[[{'text': 'Please fix an buggy program', 'loss_ids': 0, 'shortenable_ids': 0}, {'text': ' #include<stdio.h> int main() { int t,i=1; scanf("%d",&t); while(i<=t)  {  int s,a,b,c,d;  scanf("%d%d%d%d",&s,&a,&b,&c);  d=(s/c)+((s/a)*b);  printf("%d",d);  } return 0; }', 'loss_ids': 0, 'shortenable_ids': 1}, {'text': 'error message is', 'loss_ids': 0, 'shortenable_ids': 0}, {'text': ' PASSED', 'loss_ids': 0, 'shortenable_ids': 1}, {'text': 'with tags', 'loss_ids': 0, 'shortenable_ids': 0}, {'text': ' implementation, math', 'loss_ids': 0, 'shortenable_ids': 1}, {'text': '<mask>', 'loss_ids': 1, 'shortenable_ids': 0}, {'text': 'is the fixed version', 'loss_ids': 0, 'shortenable_ids': 0}], {'guid': 0, 'tgt_text': '#include<stdio.h> int main() { long long s,a,b,c,d,p; int t,i; scanf("%d",&t); for(i=1;i<=t;i++)  {  scanf("%I64d%I64d%I64d%I64d",&s,&a,&b,&c);  p=s/c;  d=(p)+((p/a)*b);  printf("%I64d\\n",d);  } return 0; }'}]
***** Running training *****
  Num examples = 1082
  Batch size = 6
  Num epoch = 10

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 0
  eval_ppl = inf
  global_step = 182
  train_loss = 70.9721
  ********************
Previous best ppl:inf
Achieve Best ppl:inf
  ********************
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 75.73 	 Previous best codebleu 0
  ********************
 Achieve Best bleu:75.73
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 1
  eval_ppl = inf
  global_step = 363
  train_loss = 57.6605
  ********************
Previous best ppl:inf
Achieve Best ppl:inf
  ********************
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 75.69 	 Previous best codebleu 75.73
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 2
  eval_ppl = inf
  global_step = 544
  train_loss = 46.8435
  ********************
Previous best ppl:inf
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 75.97 	 Previous best codebleu 75.73
  ********************
 Achieve Best bleu:75.97
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 3
  eval_ppl = inf
  global_step = 725
  train_loss = 38.7472
  ********************
Previous best ppl:inf
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 75.81 	 Previous best codebleu 75.97
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 4
  eval_ppl = inf
  global_step = 906
  train_loss = 32.2308
  ********************
Previous best ppl:inf
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 76.29 	 Previous best codebleu 75.97
  ********************
 Achieve Best bleu:76.29
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 5
  eval_ppl = inf
  global_step = 1087
  train_loss = 26.4132
  ********************
Previous best ppl:inf
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 75.75 	 Previous best codebleu 76.29
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 6
  eval_ppl = inf
  global_step = 1268
  train_loss = 22.352
  ********************
Previous best ppl:inf
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 75.62 	 Previous best codebleu 76.29
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 7
  eval_ppl = inf
  global_step = 1449
  train_loss = 18.794
  ********************
Previous best ppl:inf
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 75.79 	 Previous best codebleu 76.29
  ********************
early stopping!!!
reload model from xcodeeval/3/soft8_codet5p_220m/checkpoint-best-bleu
BLEU file: ./data/xcodeeval/3/test.jsonl
  codebleu = 75.54 
  Total = 135 
  Exact Fixed = 5 
[27, 36, 53, 72, 88]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  ********************
  Total = 135 
  Exact Fixed = 5 
[27, 36, 53, 72, 88]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  codebleu = 75.54 
[0.7802656127733693, 0.547235735742406, 0.6311616600954335, 0.9503998344473819, 0.9759316203623163, 0.08651205986326166, 0.25656679901645385, 0.7669842146074164, 0.6498389062539932, 0.5124474841624163, 0.5564880010186164, 0.8164468849403668, 0.8805670984187464, 0.9432628994248902, 0.9377858074101935, 0.9175636111085979, 0.38735431410528753, 0.947175667983928, 0.7822722252676139, 0.8106836338492169, 0.9705776794701617, 0.9735791100966684, 0.8333813540442871, 0.5524112337326081, 0.7657560530824576, 0.9450171055839813, 1.0, 0.9343575548388978, 0.5790261988125887, 0.8896800467143886, 0.91412960455335, 0.4676655068837078, 0.63014750305347, 0.9716642922960141, 0.5925258544448675, 1.0, 0.739909040388661, 0.9025560323310975, 0.5344552866173251, 0.9670641264245079, 0.867980815381816, 0.8583791034780668, 0.9306240015142291, 0.955626584171517, 0.7807079788494218, 0.8470562047308248, 0.9623079709182942, 0.6788771844775876, 0.950524665864859, 0.9312349008025642, 0.9712222651426679, 0.975637662853694, 1.0, 0.8633963363946109, 0.760840069363359, 0.9648891735454908, 0.8442458827589905, 0.9477813702498612, 0.951315622822358, 0.33295797590328613, 0.35624122019684656, 0.7982100679121421, 0.9217008915274616, 0.8689970404457057, 0.9114416830451203, 0.9858263222388597, 0.8010512179619989, 0.15351946048762036, 0.9289471675486692, 0.8339849455214231, 0.9109344104254649, 1.0, 0.9503712900963834, 0.9444842541441154, 0.9325267842906146, 0.5923377715628043, 0.8142393391947316, 0.8657268209604377, 0.6927725662122917, 0.8269793321315543, 0.8947151965627762, 0.9650446019275767, 0.6877735861844776, 0.9512693309096103, 0.5677893088427866, 0.7763879223350485, 0.26765125761038455, 1.0, 0.9743329739145192, 0.8980952928375916, 0.5797226856861304, 0.48170226274723915, 0.9498733743967636, 0.7592473283315423, 0.30278837455257246, 0.821773975796796, 0.4196734157127252, 0.6352418602881265, 0.9258576635726143, 0.3913905692778357, 0.9555110270475338, 0.9174195483383916, 0.47266766836385843, 0.9534278780598358, 0.9393217253155881, 0.8897945586059963, 0.3355749130492112, 0.35148053648224986, 0.9468383894696302, 0.3868507250835175, 0.919755073180808, 0.3455555205176508, 0.4954735182274035, 0.9427008679312978, 0.5442886701759317, 0.3816802695568956, 0.8759700055210595, 0.7052622199542771, 0.9732456940628658, 0.817850581479403, 0.6131424394366902, 0.68941044587298, 0.7934303369700066, 0.9764351042658364, 0.4953415641367399, 0.6908535288138271, 0.9294284870142819, 0.3371757143466388, 0.37224533982578545, 0.4191471722230175, 0.9393874070011292, 0.9143403860427288, 0.8889578933028645, 0.4094542044720756, 0.3357637568330429]
Finish training and take 32m
Namespace(log_name='./xcodeeval/3/soft8_codet5p_220m.log', model_name='Salesforce/codet5p-220m', lang='javascript', output_dir='xcodeeval/3/soft8_codet5p_220m', data_dir='./data/xcodeeval/3', no_cuda=False, visible_gpu='0', num_train_epochs=10, num_test_epochs=1, train_batch_size=6, eval_batch_size=4, gradient_accumulation_steps=1, load_model_path=None, config_name='', tokenizer_name='', max_source_length=512, max_target_length=512, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, freeze=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
Model created!!
[[{'text': 'Please fix an buggy program', 'loss_ids': 0, 'shortenable_ids': 0}, {'text': ' #include<stdio.h> int main() { int t,i=1; scanf("%d",&t); while(i<=t)  {  int s,a,b,c,d;  scanf("%d%d%d%d",&s,&a,&b,&c);  d=(s/c)+((s/a)*b);  printf("%d",d);  } return 0; }', 'loss_ids': 0, 'shortenable_ids': 1}, {'text': 'with tags', 'loss_ids': 0, 'shortenable_ids': 0}, {'text': ' implementation, math', 'loss_ids': 0, 'shortenable_ids': 1}, {'text': '<mask>', 'loss_ids': 1, 'shortenable_ids': 0}, {'text': 'is the fixed version', 'loss_ids': 0, 'shortenable_ids': 0}], {'guid': 0, 'tgt_text': '#include<stdio.h> int main() { long long s,a,b,c,d,p; int t,i; scanf("%d",&t); for(i=1;i<=t;i++)  {  scanf("%I64d%I64d%I64d%I64d",&s,&a,&b,&c);  p=s/c;  d=(p)+((p/a)*b);  printf("%I64d\\n",d);  } return 0; }'}]
***** Running training *****
  Num examples = 1082
  Batch size = 6
  Num epoch = 10

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 0
  eval_ppl = inf
  global_step = 182
  train_loss = 70.8877
  ********************
Previous best ppl:inf
Achieve Best ppl:inf
  ********************
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 76.2 	 Previous best codebleu 0
  ********************
 Achieve Best bleu:76.2
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 1
  eval_ppl = inf
  global_step = 363
  train_loss = 58.5783
  ********************
Previous best ppl:inf
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 76.42 	 Previous best codebleu 76.2
  ********************
 Achieve Best bleu:76.42
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 2
  eval_ppl = inf
  global_step = 544
  train_loss = 47.9232
  ********************
Previous best ppl:inf
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 76.31 	 Previous best codebleu 76.42
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 3
  eval_ppl = inf
  global_step = 725
  train_loss = 39.3726
  ********************
Previous best ppl:inf
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 76.65 	 Previous best codebleu 76.42
  ********************
 Achieve Best bleu:76.65
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 4
  eval_ppl = inf
  global_step = 906
  train_loss = 33.0415
  ********************
Previous best ppl:inf
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 76.77 	 Previous best codebleu 76.65
  ********************
 Achieve Best bleu:76.77
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 5
  eval_ppl = inf
  global_step = 1087
  train_loss = 27.483
  ********************
Previous best ppl:inf
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 76.49 	 Previous best codebleu 76.77
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 6
  eval_ppl = inf
  global_step = 1268
  train_loss = 22.9908
  ********************
Previous best ppl:inf
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 76.45 	 Previous best codebleu 76.77
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 7
  eval_ppl = inf
  global_step = 1449
  train_loss = 19.6225
  ********************
Previous best ppl:inf
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 76.61 	 Previous best codebleu 76.77
  ********************
early stopping!!!
reload model from xcodeeval/3/soft8_codet5p_220m/checkpoint-best-bleu
BLEU file: ./data/xcodeeval/3/test.jsonl
  codebleu = 77.7 
  Total = 135 
  Exact Fixed = 4 
[27, 36, 53, 88]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  ********************
  Total = 135 
  Exact Fixed = 4 
[27, 36, 53, 88]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  codebleu = 77.7 
[0.7930383830384244, 0.6666131180353323, 0.6792862695491257, 0.9502418834898978, 0.9758339804696914, 0.2878172209614635, 0.2765328871843907, 0.7231930656639858, 0.6592631929418711, 0.5154779586023561, 0.5940189485908823, 0.876180551163855, 0.897817725913767, 0.9420557746966947, 0.9400447205917231, 0.9270580810415119, 0.9411317430745978, 0.9431961783853773, 0.7964984450223446, 0.8727432407617662, 0.8119569898149893, 0.9740373599623966, 0.8277836434975402, 0.5303237154139291, 0.5755779920386552, 0.9531555071434354, 1.0, 0.930870511370643, 0.6605472548610247, 0.7867528478116388, 0.9298438902676356, 0.4482135421550838, 0.6067561233474463, 0.945667667069547, 0.6308382611854296, 1.0, 0.5006514454572529, 0.9018860440635916, 0.7059578429012447, 0.9715609213464433, 0.8549763631393232, 0.8649618005741262, 0.9300795825844461, 0.9732616951721205, 0.7849812591902816, 0.8164418828895111, 0.9602702433354682, 0.6709081425686154, 0.9529543568644763, 0.856221230027808, 0.9712222651426679, 0.977658276655784, 1.0, 0.8611623924500253, 0.798674765707978, 0.9647018272545371, 0.8937864272899989, 0.9277056220777153, 0.9578167300669009, 0.39929837953370567, 0.3809460757174854, 0.8170084699930608, 0.9254624313283781, 0.8943108951071355, 0.8943821923596362, 0.985620152911242, 0.985815242653237, 0.39007271596914256, 0.9422103795612159, 0.8428252862137879, 0.8908307372779201, 0.9368705710495009, 0.9575682597933532, 0.9542064763663376, 0.8858517555800156, 0.7095574224256187, 0.8109455726130714, 0.9100414909824395, 0.7125426843054572, 0.8459841979083365, 0.9101246622199792, 0.9647509874760793, 0.556225583434998, 0.9622217118619911, 0.6225011620919609, 0.8530547860212236, 0.26728793102639314, 1.0, 0.9742381690965436, 0.903030274345493, 0.5937619838426041, 0.6251340854809959, 0.9495565333799167, 0.2878942555632747, 0.37925026985803056, 0.785176859858, 0.4616531297279113, 0.6477140949094031, 0.9142836780589518, 0.5597660040107635, 0.955079783529782, 0.9164168588375385, 0.5622097032015565, 0.962909275221933, 0.939035241930148, 0.85577382378368, 0.3946286659181335, 0.34683643507652717, 0.8879225095753975, 0.4575178254887267, 0.9320156095792755, 0.3236523720682495, 0.5738959251317064, 0.9506799160648174, 0.5771829989862841, 0.5056696414505548, 0.8937985500759484, 0.718243752333009, 0.973091057606223, 0.8328769598180736, 0.6283390052484225, 0.6532151024840712, 0.8290544225940923, 0.9761024827151545, 0.516450178566324, 0.8162608041275157, 0.9428188290665959, 0.7581205259459995, 0.9066854413347721, 0.47024522026058446, 0.9489597424505112, 0.8923999622646703, 0.8998719272777662, 0.5038390814107655, 0.32877450952121484]
Finish training and take 33m
Namespace(log_name='./xcodeeval/3/soft8_codet5p_220m.log', model_name='Salesforce/codet5p-220m', lang='c', output_dir='xcodeeval/3/soft8_codet5p_220m', data_dir='./data/xcodeeval/3', no_cuda=False, visible_gpu='0', num_train_epochs=10, num_test_epochs=1, train_batch_size=6, eval_batch_size=4, gradient_accumulation_steps=1, load_model_path=None, config_name='', tokenizer_name='', max_source_length=512, max_target_length=512, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, freeze=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
Model created!!
[[{'text': 'Please fix an buggy program', 'loss_ids': 0, 'shortenable_ids': 0}, {'text': ' #include<stdio.h> int main() { int t,i=1; scanf("%d",&t); while(i<=t)  {  int s,a,b,c,d;  scanf("%d%d%d%d",&s,&a,&b,&c);  d=(s/c)+((s/a)*b);  printf("%d",d);  } return 0; }', 'loss_ids': 0, 'shortenable_ids': 1}, {'text': 'with tags', 'loss_ids': 0, 'shortenable_ids': 0}, {'text': ' implementation, math', 'loss_ids': 0, 'shortenable_ids': 1}, {'text': '<mask>', 'loss_ids': 1, 'shortenable_ids': 0}, {'text': 'is the fixed version', 'loss_ids': 0, 'shortenable_ids': 0}], {'guid': 0, 'tgt_text': '#include<stdio.h> int main() { long long s,a,b,c,d,p; int t,i; scanf("%d",&t); for(i=1;i<=t;i++)  {  scanf("%I64d%I64d%I64d%I64d",&s,&a,&b,&c);  p=s/c;  d=(p)+((p/a)*b);  printf("%I64d\\n",d);  } return 0; }'}]
***** Running training *****
  Num examples = 1082
  Batch size = 6
  Num epoch = 10

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 0
  eval_ppl = inf
  global_step = 182
  train_loss = 71.3753
  ********************
Previous best ppl:inf
Achieve Best ppl:inf
  ********************
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 75.77 	 Previous best codebleu 0
  ********************
 Achieve Best bleu:75.77
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 1
  eval_ppl = inf
  global_step = 363
  train_loss = 58.1046
  ********************
Previous best ppl:inf
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 75.28 	 Previous best codebleu 75.77
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 2
  eval_ppl = inf
  global_step = 544
  train_loss = 47.3055
  ********************
Previous best ppl:inf
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 75.78 	 Previous best codebleu 75.77
  ********************
 Achieve Best bleu:75.78
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 3
  eval_ppl = inf
  global_step = 725
  train_loss = 39.3313
  ********************
Previous best ppl:inf
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 75.99 	 Previous best codebleu 75.78
  ********************
 Achieve Best bleu:75.99
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 4
  eval_ppl = inf
  global_step = 906
  train_loss = 32.5865
  ********************
Previous best ppl:inf
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 75.83 	 Previous best codebleu 75.99
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 5
  eval_ppl = inf
  global_step = 1087
  train_loss = 26.9535
  ********************
Previous best ppl:inf
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 75.8 	 Previous best codebleu 75.99
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 6
  eval_ppl = inf
  global_step = 1268
  train_loss = 22.7268
  ********************
Previous best ppl:inf
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 75.85 	 Previous best codebleu 75.99
  ********************
early stopping!!!
reload model from xcodeeval/3/soft8_codet5p_220m/checkpoint-best-bleu
BLEU file: ./data/xcodeeval/3/test.jsonl
  codebleu = 75.47 
  Total = 135 
  Exact Fixed = 4 
[27, 53, 72, 88]
  Syntax Fixed = 1 
[36]
  Cleaned Fixed = 0 
[]
  ********************
  Total = 135 
  Exact Fixed = 4 
[27, 53, 72, 88]
  Syntax Fixed = 1 
[36]
  Cleaned Fixed = 0 
[]
  codebleu = 75.47 
[0.7802656127733693, 0.5340565121873682, 0.6311616600954335, 0.9503998344473819, 0.9759316203623163, 0.08651205986326166, 0.25656679901645385, 0.7669842146074164, 0.6498389062539932, 0.5030724841624163, 0.5564880010186164, 0.8164468849403668, 0.8805670984187464, 0.9432628994248902, 0.9377858074101935, 0.9175636111085979, 0.38735431410528753, 0.947175667983928, 0.7822722252676139, 0.8106836338492169, 0.9705776794701617, 0.9735791100966684, 0.8333813540442871, 0.5524112337326081, 0.7657560530824576, 0.9450171055839813, 1.0, 0.9343575548388978, 0.5790261988125887, 0.8896800467143886, 0.91412960455335, 0.4328828981880556, 0.63014750305347, 0.9716642922960141, 0.5925258544448675, 0.8668013365164393, 0.739909040388661, 0.9025560323310975, 0.5717465644724119, 0.9670641264245079, 0.867980815381816, 0.8583791034780668, 0.9306240015142291, 0.955626584171517, 0.7807079788494218, 0.8470562047308248, 0.9623079709182942, 0.6788771844775876, 0.950524665864859, 0.9292979625847417, 0.9712222651426679, 0.9828198222975641, 1.0, 0.8633963363946109, 0.7801949080730365, 0.9648891735454908, 0.8403497788628866, 0.9477813702498612, 0.951315622822358, 0.33295797590328613, 0.35624122019684656, 0.7982100679121421, 0.9217008915274616, 0.8689970404457057, 0.9114416830451203, 0.9858263222388597, 0.9859658995808198, 0.15351946048762036, 0.9289471675486692, 0.8339849455214231, 0.9109344104254649, 1.0, 0.9503712900963834, 0.9444842541441154, 0.9519186062972196, 0.4714644953230509, 0.7445791608295493, 0.8657268209604377, 0.6927725662122917, 0.8269793321315543, 0.8947151965627762, 0.9462608711024882, 0.7761391783604946, 0.9512693309096103, 0.6230524667375235, 0.7763879223350485, 0.26765125761038455, 1.0, 0.9743329739145192, 0.8980952928375916, 0.5797226856861304, 0.48170226274723915, 0.9498733743967636, 0.7592473283315423, 0.30278837455257246, 0.8333124373352575, 0.4196734157127252, 0.6352418602881265, 0.8616437696834023, 0.3913905692778357, 0.9555110270475338, 0.9174195483383916, 0.47266766836385843, 0.9534278780598358, 0.9393217253155881, 0.8897945586059963, 0.3355749130492112, 0.35148053648224986, 0.9468383894696302, 0.3868507250835175, 0.919755073180808, 0.3455555205176508, 0.4954735182274035, 0.9427008679312978, 0.5442886701759317, 0.3816802695568956, 0.8759700055210595, 0.7052622199542771, 0.9732456940628658, 0.817850581479403, 0.6131424394366902, 0.68941044587298, 0.7934303369700066, 0.9764351042658364, 0.4953415641367399, 0.6908535288138271, 0.9294284870142819, 0.37462332268897325, 0.37224533982578545, 0.4191471722230175, 0.9393874070011292, 0.9343166704551076, 0.7855314395331163, 0.4094542044720756, 0.3357637568330429]
Finish training and take 37m

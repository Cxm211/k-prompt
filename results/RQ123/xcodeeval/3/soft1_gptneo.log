Namespace(log_name='./xcodeeval/3/soft1_gptneo.log', model_name='EleutherAI/gpt-neo-1.3B', lang='c', output_dir='xcodeeval/3/soft1_gptneo', data_dir='./data/xcodeeval/3', no_cuda=False, visible_gpu='0', num_train_epochs=10, num_test_epochs=1, train_batch_size=6, eval_batch_size=4, gradient_accumulation_steps=1, load_model_path=None, config_name='', tokenizer_name='', max_source_length=1024, max_target_length=1024, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, freeze=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, local_rank=-1, seed=42, early_stop_threshold=2)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
Model created!!
[[{'text': '#include<stdio.h> int main() { int t,i=1; scanf("%d",&t); while(i<=t)  {  int s,a,b,c,d;  scanf("%d%d%d%d",&s,&a,&b,&c);  d=(s/c)+((s/a)*b);  printf("%d",d);  } return 0; }', 'loss_ids': 0, 'shortenable_ids': 1}, {'text': 'the fixed version is', 'loss_ids': 0, 'shortenable_ids': 0}, {'text': '<mask>', 'loss_ids': 1, 'shortenable_ids': 0}], {'guid': 0, 'tgt_text': '#include<stdio.h> int main() { long long s,a,b,c,d,p; int t,i; scanf("%d",&t); for(i=1;i<=t;i++)  {  scanf("%I64d%I64d%I64d%I64d",&s,&a,&b,&c);  p=s/c;  d=(p)+((p/a)*b);  printf("%I64d\\n",d);  } return 0; }'}]
***** Running training *****
  Num examples = 1082
  Batch size = 6
  Num epoch = 10

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 0
  eval_ppl = 1.1404800019767769e+30
  global_step = 182
  train_loss = 145.7173
  ********************
Previous best ppl:inf
Achieve Best ppl:1.1404800019767769e+30
  ********************
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 75.78 	 Previous best codebleu 0
  ********************
 Achieve Best bleu:75.78
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 1
  eval_ppl = 1.3957493768179642e+44
  global_step = 363
  train_loss = 54.3648
  ********************
Previous best ppl:1.1404800019767769e+30
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 75.8 	 Previous best codebleu 75.78
  ********************
 Achieve Best bleu:75.8
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 2
  eval_ppl = 1.6641815799982185e+40
  global_step = 544
  train_loss = 39.2484
  ********************
Previous best ppl:1.1404800019767769e+30
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 75.48 	 Previous best codebleu 75.8
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 3
  eval_ppl = 4.361376925385166e+36
  global_step = 725
  train_loss = 26.9803
  ********************
Previous best ppl:1.1404800019767769e+30
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 75.95 	 Previous best codebleu 75.8
  ********************
 Achieve Best bleu:75.95
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 4
  eval_ppl = 2.1867740048403719e+55
  global_step = 906
  train_loss = 17.1075
  ********************
Previous best ppl:1.1404800019767769e+30
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 75.2 	 Previous best codebleu 75.95
  ********************

***** Running evaluation *****
  Num examples = 136
  Batch size = 4
  epoch = 5
  eval_ppl = 3.995464469728184e+48
  global_step = 1087
  train_loss = 9.6383
  ********************
Previous best ppl:1.1404800019767769e+30
BLEU file: ./data/xcodeeval/3/validation.jsonl
  codebleu-4 = 75.08 	 Previous best codebleu 75.95
  ********************
early stopping!!!
reload model from xcodeeval/3/soft1_gptneo/checkpoint-best-bleu
BLEU file: ./data/xcodeeval/3/test.jsonl
  codebleu = 73.94 
  Total = 135 
  Exact Fixed = 4 
[22, 45, 53, 88]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  ********************
  Total = 135 
  Exact Fixed = 4 
[22, 45, 53, 88]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  codebleu = 73.94 
[0.7802656127733693, 0.5037273577986543, 0.7019712814462249, 0.9471181623085654, 0.9180452244186932, 0.08651205986326166, 0.25656679901645385, 0.7669842146074164, 0.6498389062539932, 0.5124474841624163, 0.5564880010186164, 0.8164468849403668, 0.8805670984187464, 0.9432628994248902, 0.916463892916797, 0.9175636111085979, 0.38735431410528753, 0.947175667983928, 0.7822722252676139, 0.8187917419573252, 0.95629321101575, 1.0, 0.8333813540442871, 0.5216260106759184, 0.7657560530824576, 0.9450171055839813, 0.8324183912964096, 0.9177263637961715, 0.5727059735400186, 0.8896800467143886, 0.91412960455335, 0.4676655068837078, 0.6362450640290798, 0.9716642922960141, 0.5925258544448675, 0.8415834056802387, 0.7471425268848038, 0.9025560323310975, 0.5717465644724119, 0.9670641264245079, 0.867980815381816, 0.8583791034780668, 0.9306240015142291, 0.955626584171517, 1.0, 0.8470562047308248, 0.9623079709182942, 0.6864939580604364, 0.8806326343636817, 0.6196906864381054, 0.8676206383206657, 0.9828198222975641, 1.0, 0.8633963363946109, 0.7801949080730365, 0.9648891735454908, 0.8403497788628866, 0.9477813702498612, 0.951315622822358, 0.33295797590328613, 0.35624122019684656, 0.7982100679121421, 0.9217008915274616, 0.8689970404457057, 0.7074937716355475, 0.9686885129204434, 0.9859658995808198, 0.15351946048762036, 0.9289471675486692, 0.7734084311974865, 0.9109344104254649, 0.9669138743101213, 0.9503712900963834, 0.9444842541441154, 0.788953668472954, 0.500058911951884, 0.6315769694647435, 0.8657268209604377, 0.6927725662122917, 0.8269793321315543, 0.8947151965627762, 0.9335701584411653, 0.7761391783604946, 0.891481973440446, 0.6230524667375235, 0.7763879223350485, 0.26765125761038455, 1.0, 0.9613223573936736, 0.8980952928375916, 0.5797226856861304, 0.49863678767022296, 0.9498733743967636, 0.6783819388991533, 0.30278837455257246, 0.821773975796796, 0.4196734157127252, 0.616692218664206, 0.9258576635726143, 0.3913905692778357, 0.8952227470038512, 0.3111731960710854, 0.47266766836385843, 0.9534278780598358, 0.9393217253155881, 0.8897945586059963, 0.3355749130492112, 0.35195743081343667, 0.9153371174320708, 0.3868507250835175, 0.919755073180808, 0.36033323166297315, 0.4954735182274035, 0.9427008679312978, 0.7222654429589042, 0.3816802695568956, 0.7731493070712928, 0.7052622199542771, 0.9732456940628658, 0.817850581479403, 0.6131424394366902, 0.6281329031902334, 0.7934303369700066, 0.9764351042658364, 0.4953415641367399, 0.6823223768377601, 0.9294284870142819, 0.37462332268897325, 0.37224533982578545, 0.4191471722230175, 0.9393874070011292, 0.8930921747994804, 0.5867706278111786, 0.4094542044720756, 0.3357637568330429]
Finish training and take 1h23m

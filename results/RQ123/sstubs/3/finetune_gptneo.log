Namespace(log_name='./sstubs/3/finetune_gptneo.log', model_name='EleutherAI/gpt-neo-1.3B', lang='java', output_dir='sstubs/3/finetune_gptneo', data_dir='./data/sstubs/3', no_cuda=False, visible_gpu='0', add_task_prefix=False, add_lang_ids=False, num_train_epochs=10, num_test_epochs=10, train_batch_size=8, eval_batch_size=4, gradient_accumulation_steps=2, load_model_path=None, config_name='', tokenizer_name='', max_source_length=512, max_target_length=512, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, do_lower_case=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, max_steps=-1, eval_steps=-1, train_steps=-1, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, model_name: EleutherAI/gpt-neo-1.3B
model created!
Total 260 training instances 
***** Running training *****
  Num examples = 260
  Batch size = 8
  Num epoch = 10

***** Running evaluation *****
  Num examples = 32
  Batch size = 4
  epoch = 0
  eval_ppl = 1.00558
  global_step = 33
  train_loss = 3.7431
  ********************
Previous best ppl:inf
Achieve Best ppl:1.00558
  ********************
BLEU file: ./data/sstubs/3/validation.jsonl
  codebleu-4 = 92.07 	 Previous best codebleu 0
  ********************
 Achieve Best bleu:92.07
  ********************

***** Running evaluation *****
  Num examples = 32
  Batch size = 4
  epoch = 1
  eval_ppl = 1.00422
  global_step = 65
  train_loss = 1.6946
  ********************
Previous best ppl:1.00558
Achieve Best ppl:1.00422
  ********************
BLEU file: ./data/sstubs/3/validation.jsonl
  codebleu-4 = 91.65 	 Previous best codebleu 92.07
  ********************

***** Running evaluation *****
  Num examples = 32
  Batch size = 4
  epoch = 2
  eval_ppl = 1.00402
  global_step = 97
  train_loss = 0.9514
  ********************
Previous best ppl:1.00422
Achieve Best ppl:1.00402
  ********************
BLEU file: ./data/sstubs/3/validation.jsonl
  codebleu-4 = 92.42 	 Previous best codebleu 92.07
  ********************
 Achieve Best bleu:92.42
  ********************

***** Running evaluation *****
  Num examples = 32
  Batch size = 4
  epoch = 3
  eval_ppl = 1.004
  global_step = 129
  train_loss = 0.5593
  ********************
Previous best ppl:1.00402
Achieve Best ppl:1.004
  ********************
BLEU file: ./data/sstubs/3/validation.jsonl
  codebleu-4 = 89.41 	 Previous best codebleu 92.42
  ********************

***** Running evaluation *****
  Num examples = 32
  Batch size = 4
  epoch = 4
  eval_ppl = 1.00411
  global_step = 161
  train_loss = 0.3544
  ********************
Previous best ppl:1.004
BLEU file: ./data/sstubs/3/validation.jsonl
  codebleu-4 = 91.96 	 Previous best codebleu 92.42
  ********************

***** Running evaluation *****
  Num examples = 32
  Batch size = 4
  epoch = 5
  eval_ppl = 1.00427
  global_step = 193
  train_loss = 0.2552
  ********************
Previous best ppl:1.004
BLEU file: ./data/sstubs/3/validation.jsonl
  codebleu-4 = 90.66 	 Previous best codebleu 92.42
  ********************

***** Running evaluation *****
  Num examples = 32
  Batch size = 4
  epoch = 6
  eval_ppl = 1.00427
  global_step = 225
  train_loss = 0.1868
  ********************
Previous best ppl:1.004
BLEU file: ./data/sstubs/3/validation.jsonl
  codebleu-4 = 90.37 	 Previous best codebleu 92.42
  ********************
reload model from sstubs/3/finetune_gptneo/checkpoint-best-bleu
BLEU file: ./data/sstubs/3/test.jsonl
  codebleu = 89.77 
  Total = 32 
  Exact Fixed = 0 
[]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  ********************
  Total = 32 
  Exact Fixed = 0 
[]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  codebleu = 89.77 
[0.9096354401872717, 0.8126786511417021, 0.9217146126934004, 0.9289542494919141, 0.9612141455329344, 0.681072945544059, 0.930386475290021, 0.6571227299905348, 0.939529666001018, 0.9565292378112795, 0.9583676774082095, 0.9383022364276514, 0.8380551848499416, 0.9675420713984233, 0.8642531454411047, 0.9211131842675646, 0.959945180208001, 0.920101844638672, 0.9520099029923956, 0.9495565333799167, 0.9556325881310865, 0.9217146126934004, 0.9468301376782615, 0.9259520853518541, 0.8795515633017441, 0.5946280141514091, 0.9362201886171708, 0.9052050509144789, 0.9521775318277603, 0.8293897313556879, 0.9458282920622547, 0.9658213973211704]
Finish training and take 20m

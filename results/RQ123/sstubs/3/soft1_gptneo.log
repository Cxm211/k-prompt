Namespace(log_name='./sstubs/3/soft1_gptneo.log', model_name='EleutherAI/gpt-neo-1.3B', lang='java', output_dir='sstubs/3/soft1_gptneo', data_dir='./data/sstubs/3', no_cuda=False, visible_gpu='0', num_train_epochs=10, num_test_epochs=1, train_batch_size=6, eval_batch_size=4, gradient_accumulation_steps=1, load_model_path=None, config_name='', tokenizer_name='', max_source_length=512, max_target_length=1024, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, freeze=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
Model created!!
[[{'text': 'grammarBuilder.append("}\\n");    grammarBuilder.append("  : r=a ;\\n");    grammarBuilder.append("a : \'x\' { \\n");   grammarBuilder.append("fmt.Println(p.GetRuleInvocationStack(nil))\\n");    grammarBuilder.append("} ;");    String grammar = grammarBuilder.toString();    String input ="x";', 'loss_ids': 0, 'shortenable_ids': 1}, {'text': 'the fixed version is', 'loss_ids': 0, 'shortenable_ids': 0}, {'text': '<mask>', 'loss_ids': 1, 'shortenable_ids': 0}], {'guid': 0, 'tgt_text': 'grammarBuilder.append("}\\n");    grammarBuilder.append("  : r=a ;\\n");    grammarBuilder.append("a : \'x\' { \\n");   grammarBuilder.append("fmt.Println(antlr.PrintArrayJavaStyle(p.GetRuleInvocationStack(nil)))\\n");    grammarBuilder.append("} ;");    String grammar = grammarBuilder.toString();    String input ="x";'}]
***** Running training *****
  Num examples = 223
  Batch size = 6
  Num epoch = 10
Namespace(log_name='./sstubs/3/soft1_gptneo.log', model_name='EleutherAI/gpt-neo-1.3B', lang='java', output_dir='sstubs/3/soft1_gptneo', data_dir='./data/sstubs/3', no_cuda=False, visible_gpu='0', num_train_epochs=10, num_test_epochs=1, train_batch_size=4, eval_batch_size=4, gradient_accumulation_steps=1, load_model_path=None, config_name='', tokenizer_name='', max_source_length=1024, max_target_length=1024, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, freeze=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
Model created!!
[[{'text': 'grammarBuilder.append("}\\n");    grammarBuilder.append("  : r=a ;\\n");    grammarBuilder.append("a : \'x\' { \\n");   grammarBuilder.append("fmt.Println(p.GetRuleInvocationStack(nil))\\n");    grammarBuilder.append("} ;");    String grammar = grammarBuilder.toString();    String input ="x";', 'loss_ids': 0, 'shortenable_ids': 1}, {'text': 'the fixed version is', 'loss_ids': 0, 'shortenable_ids': 0}, {'text': '<mask>', 'loss_ids': 1, 'shortenable_ids': 0}], {'guid': 0, 'tgt_text': 'grammarBuilder.append("}\\n");    grammarBuilder.append("  : r=a ;\\n");    grammarBuilder.append("a : \'x\' { \\n");   grammarBuilder.append("fmt.Println(antlr.PrintArrayJavaStyle(p.GetRuleInvocationStack(nil)))\\n");    grammarBuilder.append("} ;");    String grammar = grammarBuilder.toString();    String input ="x";'}]
***** Running training *****
  Num examples = 223
  Batch size = 4
  Num epoch = 10
Namespace(log_name='./sstubs/3/soft1_gptneo.log', model_name='EleutherAI/gpt-neo-1.3B', lang='java', output_dir='sstubs/3/soft1_gptneo', data_dir='./data/sstubs/3', no_cuda=False, visible_gpu='0', num_train_epochs=10, num_test_epochs=1, train_batch_size=2, eval_batch_size=4, gradient_accumulation_steps=1, load_model_path=None, config_name='', tokenizer_name='', max_source_length=1024, max_target_length=512, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, freeze=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
Model created!!
[[{'text': 'grammarBuilder.append("}\\n");    grammarBuilder.append("  : r=a ;\\n");    grammarBuilder.append("a : \'x\' { \\n");   grammarBuilder.append("fmt.Println(p.GetRuleInvocationStack(nil))\\n");    grammarBuilder.append("} ;");    String grammar = grammarBuilder.toString();    String input ="x";', 'loss_ids': 0, 'shortenable_ids': 1}, {'text': 'the fixed version is', 'loss_ids': 0, 'shortenable_ids': 0}, {'text': '<mask>', 'loss_ids': 1, 'shortenable_ids': 0}], {'guid': 0, 'tgt_text': 'grammarBuilder.append("}\\n");    grammarBuilder.append("  : r=a ;\\n");    grammarBuilder.append("a : \'x\' { \\n");   grammarBuilder.append("fmt.Println(antlr.PrintArrayJavaStyle(p.GetRuleInvocationStack(nil)))\\n");    grammarBuilder.append("} ;");    String grammar = grammarBuilder.toString();    String input ="x";'}]
***** Running training *****
  Num examples = 223
  Batch size = 2
  Num epoch = 10
Namespace(log_name='./sstubs/3/soft1_gptneo.log', model_name='EleutherAI/gpt-neo-1.3B', lang='java', output_dir='sstubs/3/soft1_gptneo', data_dir='./data/sstubs/3', no_cuda=False, visible_gpu='0', num_train_epochs=10, num_test_epochs=1, train_batch_size=2, eval_batch_size=4, gradient_accumulation_steps=1, load_model_path=None, config_name='', tokenizer_name='', max_source_length=512, max_target_length=1024, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, freeze=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
Model created!!
[[{'text': 'grammarBuilder.append("}\\n");    grammarBuilder.append("  : r=a ;\\n");    grammarBuilder.append("a : \'x\' { \\n");   grammarBuilder.append("fmt.Println(p.GetRuleInvocationStack(nil))\\n");    grammarBuilder.append("} ;");    String grammar = grammarBuilder.toString();    String input ="x";', 'loss_ids': 0, 'shortenable_ids': 1}, {'text': 'the fixed version is', 'loss_ids': 0, 'shortenable_ids': 0}, {'text': '<mask>', 'loss_ids': 1, 'shortenable_ids': 0}], {'guid': 0, 'tgt_text': 'grammarBuilder.append("}\\n");    grammarBuilder.append("  : r=a ;\\n");    grammarBuilder.append("a : \'x\' { \\n");   grammarBuilder.append("fmt.Println(antlr.PrintArrayJavaStyle(p.GetRuleInvocationStack(nil)))\\n");    grammarBuilder.append("} ;");    String grammar = grammarBuilder.toString();    String input ="x";'}]
***** Running training *****
  Num examples = 223
  Batch size = 2
  Num epoch = 10
Namespace(log_name='./sstubs/3/soft1_gptneo.log', model_name='EleutherAI/gpt-neo-1.3B', lang='java', output_dir='sstubs/3/soft1_gptneo', data_dir='./data/sstubs/3', no_cuda=False, visible_gpu='0', num_train_epochs=10, num_test_epochs=1, train_batch_size=2, eval_batch_size=4, gradient_accumulation_steps=1, load_model_path=None, config_name='', tokenizer_name='', max_source_length=512, max_target_length=1024, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, freeze=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
Model created!!
[[{'text': 'grammarBuilder.append("}\\n");    grammarBuilder.append("  : r=a ;\\n");    grammarBuilder.append("a : \'x\' { \\n");   grammarBuilder.append("fmt.Println(p.GetRuleInvocationStack(nil))\\n");    grammarBuilder.append("} ;");    String grammar = grammarBuilder.toString();    String input ="x";', 'loss_ids': 0, 'shortenable_ids': 1}, {'text': 'the fixed version is', 'loss_ids': 0, 'shortenable_ids': 0}, {'text': '<mask>', 'loss_ids': 1, 'shortenable_ids': 0}], {'guid': 0, 'tgt_text': 'grammarBuilder.append("}\\n");    grammarBuilder.append("  : r=a ;\\n");    grammarBuilder.append("a : \'x\' { \\n");   grammarBuilder.append("fmt.Println(antlr.PrintArrayJavaStyle(p.GetRuleInvocationStack(nil)))\\n");    grammarBuilder.append("} ;");    String grammar = grammarBuilder.toString();    String input ="x";'}]
***** Running training *****
  Num examples = 223
  Batch size = 2
  Num epoch = 10
Namespace(log_name='./sstubs/3/soft1_gptneo.log', model_name='EleutherAI/gpt-neo-1.3B', lang='java', output_dir='sstubs/3/soft1_gptneo', data_dir='./data/sstubs/3', no_cuda=False, visible_gpu='0', num_train_epochs=10, num_test_epochs=1, train_batch_size=6, eval_batch_size=4, gradient_accumulation_steps=1, load_model_path=None, config_name='', tokenizer_name='', max_source_length=1024, max_target_length=1024, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, freeze=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
Model created!!
[[{'text': '@ConditionalOnMissingBean    RSocketServerBootstrap rSocketServerBootstrap(RSocketServerFactory rSocketServerFactory,      RSocketMessageHandler rSocketMessageHandler) {    return new RSocketServerBootstrap(rSocketServerFactory, rSocketMessageHandler.serverAcceptor());    }   }', 'loss_ids': 0, 'shortenable_ids': 1}, {'text': 'the fixed version is', 'loss_ids': 0, 'shortenable_ids': 0}, {'text': '<mask>', 'loss_ids': 1, 'shortenable_ids': 0}], {'guid': 0, 'tgt_text': '@ConditionalOnMissingBean    RSocketServerBootstrap rSocketServerBootstrap(RSocketServerFactory rSocketServerFactory,      RSocketMessageHandler rSocketMessageHandler) {    return new RSocketServerBootstrap(rSocketServerFactory, rSocketMessageHandler.serverResponder());    }   }'}]
***** Running training *****
  Num examples = 260
  Batch size = 6
  Num epoch = 10

***** Running evaluation *****
  Num examples = 32
  Batch size = 4
  epoch = 0
  eval_ppl = 5.120432085496964e+16
  global_step = 45
  train_loss = 55.4605
  ********************
Previous best ppl:inf
Achieve Best ppl:5.120432085496964e+16
  ********************
BLEU file: ./data/sstubs/3/validation.jsonl
  codebleu-4 = 84.49 	 Previous best codebleu 0
  ********************
 Achieve Best bleu:84.49
  ********************

***** Running evaluation *****
  Num examples = 32
  Batch size = 4
  epoch = 1
  eval_ppl = 3.296043266824846e+28
  global_step = 89
  train_loss = 5.2329
  ********************
Previous best ppl:5.120432085496964e+16
BLEU file: ./data/sstubs/3/validation.jsonl
  codebleu-4 = 93.01 	 Previous best codebleu 84.49
  ********************
 Achieve Best bleu:93.01
  ********************

***** Running evaluation *****
  Num examples = 32
  Batch size = 4
  epoch = 2
  eval_ppl = 1.5462936786592524e+23
  global_step = 133
  train_loss = 2.4511
  ********************
Previous best ppl:5.120432085496964e+16
BLEU file: ./data/sstubs/3/validation.jsonl
  codebleu-4 = 93.93 	 Previous best codebleu 93.01
  ********************
 Achieve Best bleu:93.93
  ********************

***** Running evaluation *****
  Num examples = 32
  Batch size = 4
  epoch = 3
  eval_ppl = 1.778849104723676e+22
  global_step = 177
  train_loss = 1.5675
  ********************
Previous best ppl:5.120432085496964e+16
BLEU file: ./data/sstubs/3/validation.jsonl
  codebleu-4 = 94.57 	 Previous best codebleu 93.93
  ********************
 Achieve Best bleu:94.57
  ********************

***** Running evaluation *****
  Num examples = 32
  Batch size = 4
  epoch = 4
  eval_ppl = 4.6193120474783475e+30
  global_step = 221
  train_loss = 0.809
  ********************
Previous best ppl:5.120432085496964e+16
BLEU file: ./data/sstubs/3/validation.jsonl
  codebleu-4 = 93.45 	 Previous best codebleu 94.57
  ********************

***** Running evaluation *****
  Num examples = 32
  Batch size = 4
  epoch = 5
  eval_ppl = 8.098718219834732e+30
  global_step = 265
  train_loss = 0.4534
  ********************
Previous best ppl:5.120432085496964e+16
BLEU file: ./data/sstubs/3/validation.jsonl
  codebleu-4 = 95.41 	 Previous best codebleu 94.57
  ********************
 Achieve Best bleu:95.41
  ********************

***** Running evaluation *****
  Num examples = 32
  Batch size = 4
  epoch = 6
  eval_ppl = 1.7944594453480773e+27
  global_step = 309
  train_loss = 0.5417
  ********************
Previous best ppl:5.120432085496964e+16
BLEU file: ./data/sstubs/3/validation.jsonl
  codebleu-4 = 95.41 	 Previous best codebleu 95.41
  ********************

***** Running evaluation *****
  Num examples = 32
  Batch size = 4
  epoch = 7
  eval_ppl = 1.261780071192721e+31
  global_step = 353
  train_loss = 0.2649
  ********************
Previous best ppl:5.120432085496964e+16
BLEU file: ./data/sstubs/3/validation.jsonl
  codebleu-4 = 95.37 	 Previous best codebleu 95.41
  ********************

***** Running evaluation *****
  Num examples = 32
  Batch size = 4
  epoch = 8
  eval_ppl = 1.9537634748988445e+34
  global_step = 397
  train_loss = 0.1335
  ********************
Previous best ppl:5.120432085496964e+16
BLEU file: ./data/sstubs/3/validation.jsonl
  codebleu-4 = 95.45 	 Previous best codebleu 95.41
  ********************
 Achieve Best bleu:95.45
  ********************

***** Running evaluation *****
  Num examples = 32
  Batch size = 4
  epoch = 9
  eval_ppl = 9.433589367846825e+34
  global_step = 441
  train_loss = 0.0867
  ********************
Previous best ppl:5.120432085496964e+16
BLEU file: ./data/sstubs/3/validation.jsonl
  codebleu-4 = 95.45 	 Previous best codebleu 95.45
  ********************
reload model from sstubs/3/soft1_gptneo/checkpoint-best-bleu
BLEU file: ./data/sstubs/3/test.jsonl
  codebleu = 93.68 
  Total = 32 
  Exact Fixed = 15 
[2, 3, 4, 5, 7, 9, 10, 20, 22, 23, 24, 26, 29, 31, 32]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  ********************
  Total = 32 
  Exact Fixed = 15 
[2, 3, 4, 5, 7, 9, 10, 20, 22, 23, 24, 26, 29, 31, 32]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  codebleu = 93.68 
[0.9096354401872717, 1.0, 1.0, 1.0, 1.0, 0.681072945544059, 1.0, 0.6571227299905348, 1.0, 1.0, 0.9583676774082095, 0.9383022364276514, 0.8180551848499417, 0.9584470085596064, 0.8642531454411047, 0.9211131842675646, 0.9087584599564476, 0.940101844638672, 0.9520099029923956, 1.0, 0.9556325881310865, 1.0, 1.0, 1.0, 0.8954157051952711, 1.0, 0.9362201886171708, 0.8885383842478122, 1.0, 0.7957493851178961, 1.0, 1.0]
Finish training and take 23m

Namespace(log_name='./sstubs/2/finetune_gptneo.log', model_name='EleutherAI/gpt-neo-1.3B', lang='java', output_dir='sstubs/2/finetune_gptneo', data_dir='./data/sstubs/2', no_cuda=False, visible_gpu='0', add_task_prefix=False, add_lang_ids=False, num_train_epochs=10, num_test_epochs=10, train_batch_size=8, eval_batch_size=4, gradient_accumulation_steps=2, load_model_path=None, config_name='', tokenizer_name='', max_source_length=512, max_target_length=512, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, do_lower_case=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, max_steps=-1, eval_steps=-1, train_steps=-1, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, model_name: EleutherAI/gpt-neo-1.3B
model created!
Total 260 training instances 
***** Running training *****
  Num examples = 260
  Batch size = 8
  Num epoch = 10

***** Running evaluation *****
  Num examples = 32
  Batch size = 4
  epoch = 0
  eval_ppl = 1.00681
  global_step = 33
  train_loss = 3.9617
  ********************
Previous best ppl:inf
Achieve Best ppl:1.00681
  ********************
BLEU file: ./data/sstubs/2/validation.jsonl
  codebleu-4 = 92.32 	 Previous best codebleu 0
  ********************
 Achieve Best bleu:92.32
  ********************

***** Running evaluation *****
  Num examples = 32
  Batch size = 4
  epoch = 1
  eval_ppl = 1.00564
  global_step = 65
  train_loss = 1.7996
  ********************
Previous best ppl:1.00681
Achieve Best ppl:1.00564
  ********************
BLEU file: ./data/sstubs/2/validation.jsonl
  codebleu-4 = 88.88 	 Previous best codebleu 92.32
  ********************

***** Running evaluation *****
  Num examples = 32
  Batch size = 4
  epoch = 2
  eval_ppl = 1.00552
  global_step = 97
  train_loss = 0.9948
  ********************
Previous best ppl:1.00564
Achieve Best ppl:1.00552
  ********************
BLEU file: ./data/sstubs/2/validation.jsonl
  codebleu-4 = 89.84 	 Previous best codebleu 92.32
  ********************

***** Running evaluation *****
  Num examples = 32
  Batch size = 4
  epoch = 3
  eval_ppl = 1.0058
  global_step = 129
  train_loss = 0.5955
  ********************
Previous best ppl:1.00552
BLEU file: ./data/sstubs/2/validation.jsonl
  codebleu-4 = 87.63 	 Previous best codebleu 92.32
  ********************

***** Running evaluation *****
  Num examples = 32
  Batch size = 4
  epoch = 4
  eval_ppl = 1.00599
  global_step = 161
  train_loss = 0.4037
  ********************
Previous best ppl:1.00552
BLEU file: ./data/sstubs/2/validation.jsonl
  codebleu-4 = 78.58 	 Previous best codebleu 92.32
  ********************

***** Running evaluation *****
  Num examples = 32
  Batch size = 4
  epoch = 5
  eval_ppl = 1.00619
  global_step = 193
  train_loss = 0.2705
  ********************
Previous best ppl:1.00552
BLEU file: ./data/sstubs/2/validation.jsonl
  codebleu-4 = 76.79 	 Previous best codebleu 92.32
  ********************
reload model from sstubs/2/finetune_gptneo/checkpoint-best-bleu
BLEU file: ./data/sstubs/2/test.jsonl
  codebleu = 90.71 
  Total = 32 
  Exact Fixed = 0 
[]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  ********************
  Total = 32 
  Exact Fixed = 0 
[]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  codebleu = 90.71 
[0.977213679071198, 0.944274958466798, 0.9500416069012747, 0.8809865946035704, 0.9323598782946632, 0.9749830206163475, 0.7555732843655234, 0.7366418918208997, 0.9357237009636146, 0.9546221339246326, 0.9289542494919141, 0.9322236811233653, 0.645426537036109, 0.966410184624177, 0.7720046858827349, 0.9097382001430849, 0.9468301376782615, 0.9391717619088131, 0.9077224816006332, 0.8816015466501335, 0.9217146126934004, 0.8937646940710373, 0.9621391018662697, 0.9327938350960072, 0.8927685762874167, 0.9270405384522935, 0.9217146126934004, 0.9468301376782615, 0.9368020958482046, 0.8866311178771904, 0.9704328316376207, 0.9620033353993269]
Finish training and take 18m

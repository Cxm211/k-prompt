Namespace(log_name='./coderefine/2/soft5_gptneo.log', model_name='EleutherAI/gpt-neo-1.3B', lang='java', output_dir='coderefine/2/soft5_gptneo', data_dir='./data/coderefine/2', no_cuda=False, visible_gpu='0', num_train_epochs=10, num_test_epochs=1, train_batch_size=2, eval_batch_size=4, gradient_accumulation_steps=1, load_model_path=None, config_name='', tokenizer_name='', max_source_length=512, max_target_length=1024, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, freeze=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
Model created!!
[[{'text': 'public void METHOD_1 ( final TYPE_1 VAR_1 ) { this . VAR_1 = VAR_1 ; if ( ( ! ( VAR_2 . isEmpty ( ) ) ) && ( ( VAR_1 . METHOD_2 ( ) ) != null ) ) { for ( final TYPE_2 VAR_3 : VAR_1 . METHOD_2 ( ) ) { if ( ! ( this . VAR_1 . METHOD_2 ( ) . contains ( VAR_3 ) ) ) { VAR_2 . remove ( VAR_3 ) ; } } } }', 'loss_ids': 0, 'shortenable_ids': 1}, {'text': 'is buggy program', 'loss_ids': 0, 'shortenable_ids': 0}, {'text': '<mask>', 'loss_ids': 1, 'shortenable_ids': 0}, {'text': 'is fixed program', 'loss_ids': 0, 'shortenable_ids': 0}], {'guid': 0, 'tgt_text': 'public void METHOD_1 ( final TYPE_1 VAR_1 ) { if ( ( ! ( VAR_2 . isEmpty ( ) ) ) && ( ( VAR_1 . METHOD_2 ( ) ) != null ) ) { for ( final TYPE_2 VAR_3 : VAR_1 . METHOD_2 ( ) ) { if ( ! ( this . VAR_1 . METHOD_2 ( ) . contains ( VAR_3 ) ) ) { VAR_2 . remove ( VAR_3 ) ; } } } this . VAR_1 = VAR_1 ; }'}]
***** Running training *****
  Num examples = 523
  Batch size = 2
  Num epoch = 10
Namespace(log_name='./coderefine/2/soft5_gptneo.log', model_name='EleutherAI/gpt-neo-1.3B', lang='java', output_dir='coderefine/2/soft5_gptneo', data_dir='./data/coderefine/2', no_cuda=False, visible_gpu='0', num_train_epochs=10, num_test_epochs=1, train_batch_size=2, eval_batch_size=4, gradient_accumulation_steps=1, load_model_path=None, config_name='', tokenizer_name='', max_source_length=512, max_target_length=1024, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, freeze=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
Model created!!
[[{'text': 'public void METHOD_1 ( final TYPE_1 VAR_1 ) { this . VAR_1 = VAR_1 ; if ( ( ! ( VAR_2 . isEmpty ( ) ) ) && ( ( VAR_1 . METHOD_2 ( ) ) != null ) ) { for ( final TYPE_2 VAR_3 : VAR_1 . METHOD_2 ( ) ) { if ( ! ( this . VAR_1 . METHOD_2 ( ) . contains ( VAR_3 ) ) ) { VAR_2 . remove ( VAR_3 ) ; } } } }', 'loss_ids': 0, 'shortenable_ids': 1}, {'text': 'is buggy program', 'loss_ids': 0, 'shortenable_ids': 0}, {'text': '<mask>', 'loss_ids': 1, 'shortenable_ids': 0}, {'text': 'is fixed program', 'loss_ids': 0, 'shortenable_ids': 0}], {'guid': 0, 'tgt_text': 'public void METHOD_1 ( final TYPE_1 VAR_1 ) { if ( ( ! ( VAR_2 . isEmpty ( ) ) ) && ( ( VAR_1 . METHOD_2 ( ) ) != null ) ) { for ( final TYPE_2 VAR_3 : VAR_1 . METHOD_2 ( ) ) { if ( ! ( this . VAR_1 . METHOD_2 ( ) . contains ( VAR_3 ) ) ) { VAR_2 . remove ( VAR_3 ) ; } } } this . VAR_1 = VAR_1 ; }'}]
***** Running training *****
  Num examples = 523
  Batch size = 2
  Num epoch = 10
Namespace(log_name='./coderefine/2/soft5_gptneo.log', model_name='EleutherAI/gpt-neo-1.3B', lang='java', output_dir='coderefine/2/soft5_gptneo', data_dir='./data/coderefine/2', no_cuda=False, visible_gpu='0', num_train_epochs=10, num_test_epochs=1, train_batch_size=2, eval_batch_size=4, gradient_accumulation_steps=1, load_model_path=None, config_name='', tokenizer_name='', max_source_length=512, max_target_length=1024, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, freeze=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
Model created!!
[[{'text': 'public void METHOD_1 ( final TYPE_1 VAR_1 ) { this . VAR_1 = VAR_1 ; if ( ( ! ( VAR_2 . isEmpty ( ) ) ) && ( ( VAR_1 . METHOD_2 ( ) ) != null ) ) { for ( final TYPE_2 VAR_3 : VAR_1 . METHOD_2 ( ) ) { if ( ! ( this . VAR_1 . METHOD_2 ( ) . contains ( VAR_3 ) ) ) { VAR_2 . remove ( VAR_3 ) ; } } } }', 'loss_ids': 0, 'shortenable_ids': 1}, {'text': 'is buggy program', 'loss_ids': 0, 'shortenable_ids': 0}, {'text': '<mask>', 'loss_ids': 1, 'shortenable_ids': 0}, {'text': 'is fixed program', 'loss_ids': 0, 'shortenable_ids': 0}], {'guid': 0, 'tgt_text': 'public void METHOD_1 ( final TYPE_1 VAR_1 ) { if ( ( ! ( VAR_2 . isEmpty ( ) ) ) && ( ( VAR_1 . METHOD_2 ( ) ) != null ) ) { for ( final TYPE_2 VAR_3 : VAR_1 . METHOD_2 ( ) ) { if ( ! ( this . VAR_1 . METHOD_2 ( ) . contains ( VAR_3 ) ) ) { VAR_2 . remove ( VAR_3 ) ; } } } this . VAR_1 = VAR_1 ; }'}]
***** Running training *****
  Num examples = 523
  Batch size = 2
  Num epoch = 10
Namespace(log_name='./coderefine/2/soft5_gptneo.log', model_name='EleutherAI/gpt-neo-1.3B', lang='java', output_dir='coderefine/2/soft5_gptneo', data_dir='./data/coderefine/2', no_cuda=False, visible_gpu='0', num_train_epochs=10, num_test_epochs=1, train_batch_size=2, eval_batch_size=4, gradient_accumulation_steps=1, load_model_path=None, config_name='', tokenizer_name='', max_source_length=512, max_target_length=1024, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, freeze=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
Model created!!
[[{'text': 'public void METHOD_1 ( final TYPE_1 VAR_1 ) { this . VAR_1 = VAR_1 ; if ( ( ! ( VAR_2 . isEmpty ( ) ) ) && ( ( VAR_1 . METHOD_2 ( ) ) != null ) ) { for ( final TYPE_2 VAR_3 : VAR_1 . METHOD_2 ( ) ) { if ( ! ( this . VAR_1 . METHOD_2 ( ) . contains ( VAR_3 ) ) ) { VAR_2 . remove ( VAR_3 ) ; } } } }', 'loss_ids': 0, 'shortenable_ids': 1}, {'text': 'is buggy program', 'loss_ids': 0, 'shortenable_ids': 0}, {'text': '<mask>', 'loss_ids': 1, 'shortenable_ids': 0}, {'text': 'is fixed program', 'loss_ids': 0, 'shortenable_ids': 0}], {'guid': 0, 'tgt_text': 'public void METHOD_1 ( final TYPE_1 VAR_1 ) { if ( ( ! ( VAR_2 . isEmpty ( ) ) ) && ( ( VAR_1 . METHOD_2 ( ) ) != null ) ) { for ( final TYPE_2 VAR_3 : VAR_1 . METHOD_2 ( ) ) { if ( ! ( this . VAR_1 . METHOD_2 ( ) . contains ( VAR_3 ) ) ) { VAR_2 . remove ( VAR_3 ) ; } } } this . VAR_1 = VAR_1 ; }'}]
***** Running training *****
  Num examples = 523
  Batch size = 2
  Num epoch = 10
Namespace(log_name='./coderefine/2/soft5_gptneo.log', model_name='EleutherAI/gpt-neo-1.3B', lang='java', output_dir='coderefine/2/soft5_gptneo', data_dir='./data/coderefine/2', no_cuda=False, visible_gpu='0', num_train_epochs=10, num_test_epochs=1, train_batch_size=1, eval_batch_size=4, gradient_accumulation_steps=1, load_model_path=None, config_name='', tokenizer_name='', max_source_length=512, max_target_length=1024, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, freeze=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
Model created!!
[[{'text': 'public void METHOD_1 ( final TYPE_1 VAR_1 ) { this . VAR_1 = VAR_1 ; if ( ( ! ( VAR_2 . isEmpty ( ) ) ) && ( ( VAR_1 . METHOD_2 ( ) ) != null ) ) { for ( final TYPE_2 VAR_3 : VAR_1 . METHOD_2 ( ) ) { if ( ! ( this . VAR_1 . METHOD_2 ( ) . contains ( VAR_3 ) ) ) { VAR_2 . remove ( VAR_3 ) ; } } } }', 'loss_ids': 0, 'shortenable_ids': 1}, {'text': 'is buggy program', 'loss_ids': 0, 'shortenable_ids': 0}, {'text': '<mask>', 'loss_ids': 1, 'shortenable_ids': 0}, {'text': 'is fixed program', 'loss_ids': 0, 'shortenable_ids': 0}], {'guid': 0, 'tgt_text': 'public void METHOD_1 ( final TYPE_1 VAR_1 ) { if ( ( ! ( VAR_2 . isEmpty ( ) ) ) && ( ( VAR_1 . METHOD_2 ( ) ) != null ) ) { for ( final TYPE_2 VAR_3 : VAR_1 . METHOD_2 ( ) ) { if ( ! ( this . VAR_1 . METHOD_2 ( ) . contains ( VAR_3 ) ) ) { VAR_2 . remove ( VAR_3 ) ; } } } this . VAR_1 = VAR_1 ; }'}]
***** Running training *****
  Num examples = 523
  Batch size = 1
  Num epoch = 10
Namespace(log_name='./coderefine/2/soft5_gptneo.log', model_name='EleutherAI/gpt-neo-1.3B', lang='java', output_dir='coderefine/2/soft5_gptneo', data_dir='./data/coderefine/2', no_cuda=False, visible_gpu='0', num_train_epochs=10, num_test_epochs=1, train_batch_size=2, eval_batch_size=4, gradient_accumulation_steps=1, load_model_path=None, config_name='', tokenizer_name='', max_source_length=512, max_target_length=1024, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, freeze=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
Model created!!
[[{'text': 'public void METHOD_1 ( final TYPE_1 VAR_1 ) { this . VAR_1 = VAR_1 ; if ( ( ! ( VAR_2 . isEmpty ( ) ) ) && ( ( VAR_1 . METHOD_2 ( ) ) != null ) ) { for ( final TYPE_2 VAR_3 : VAR_1 . METHOD_2 ( ) ) { if ( ! ( this . VAR_1 . METHOD_2 ( ) . contains ( VAR_3 ) ) ) { VAR_2 . remove ( VAR_3 ) ; } } } }', 'loss_ids': 0, 'shortenable_ids': 1}, {'text': 'is buggy program', 'loss_ids': 0, 'shortenable_ids': 0}, {'text': '<mask>', 'loss_ids': 1, 'shortenable_ids': 0}, {'text': 'is fixed program', 'loss_ids': 0, 'shortenable_ids': 0}], {'guid': 0, 'tgt_text': 'public void METHOD_1 ( final TYPE_1 VAR_1 ) { if ( ( ! ( VAR_2 . isEmpty ( ) ) ) && ( ( VAR_1 . METHOD_2 ( ) ) != null ) ) { for ( final TYPE_2 VAR_3 : VAR_1 . METHOD_2 ( ) ) { if ( ! ( this . VAR_1 . METHOD_2 ( ) . contains ( VAR_3 ) ) ) { VAR_2 . remove ( VAR_3 ) ; } } } this . VAR_1 = VAR_1 ; }'}]
***** Running training *****
  Num examples = 523
  Batch size = 2
  Num epoch = 10

***** Running evaluation *****
  Num examples = 68
  Batch size = 4
  epoch = 0
  eval_ppl = 2.427346191835192e+95
  global_step = 263
  train_loss = 25.859
  ********************
Previous best ppl:inf
Achieve Best ppl:2.427346191835192e+95
  ********************
BLEU file: ./data/coderefine/2/validation.jsonl
  codebleu-4 = 56.75 	 Previous best codebleu 0
  ********************
 Achieve Best bleu:56.75
  ********************

***** Running evaluation *****
  Num examples = 68
  Batch size = 4
  epoch = 1
  eval_ppl = 1.1339471429090985e+99
  global_step = 525
  train_loss = 12.213
  ********************
Previous best ppl:2.427346191835192e+95
BLEU file: ./data/coderefine/2/validation.jsonl
  codebleu-4 = 79.11 	 Previous best codebleu 56.75
  ********************
 Achieve Best bleu:79.11
  ********************

***** Running evaluation *****
  Num examples = 68
  Batch size = 4
  epoch = 2
  eval_ppl = 2.147763249670012e+112
  global_step = 787
  train_loss = 7.8848
  ********************
Previous best ppl:2.427346191835192e+95
BLEU file: ./data/coderefine/2/validation.jsonl
Namespace(log_name='./coderefine/2/soft5_gptneo.log', model_name='EleutherAI/gpt-neo-1.3B', lang='java', output_dir='coderefine/2/soft5_gptneo', data_dir='./data/coderefine/2', no_cuda=False, visible_gpu='0', num_train_epochs=10, num_test_epochs=1, train_batch_size=2, eval_batch_size=4, gradient_accumulation_steps=1, load_model_path=None, config_name='', tokenizer_name='', max_source_length=512, max_target_length=1024, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, freeze=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
Model created!!
[[{'text': 'public void METHOD_1 ( final TYPE_1 VAR_1 ) { this . VAR_1 = VAR_1 ; if ( ( ! ( VAR_2 . isEmpty ( ) ) ) && ( ( VAR_1 . METHOD_2 ( ) ) != null ) ) { for ( final TYPE_2 VAR_3 : VAR_1 . METHOD_2 ( ) ) { if ( ! ( this . VAR_1 . METHOD_2 ( ) . contains ( VAR_3 ) ) ) { VAR_2 . remove ( VAR_3 ) ; } } } }', 'loss_ids': 0, 'shortenable_ids': 1}, {'text': 'is buggy program', 'loss_ids': 0, 'shortenable_ids': 0}, {'text': '<mask>', 'loss_ids': 1, 'shortenable_ids': 0}, {'text': 'is fixed program', 'loss_ids': 0, 'shortenable_ids': 0}], {'guid': 0, 'tgt_text': 'public void METHOD_1 ( final TYPE_1 VAR_1 ) { if ( ( ! ( VAR_2 . isEmpty ( ) ) ) && ( ( VAR_1 . METHOD_2 ( ) ) != null ) ) { for ( final TYPE_2 VAR_3 : VAR_1 . METHOD_2 ( ) ) { if ( ! ( this . VAR_1 . METHOD_2 ( ) . contains ( VAR_3 ) ) ) { VAR_2 . remove ( VAR_3 ) ; } } } this . VAR_1 = VAR_1 ; }'}]
***** Running training *****
  Num examples = 523
  Batch size = 2
  Num epoch = 10

***** Running evaluation *****
  Num examples = 68
  Batch size = 4
  epoch = 0
  eval_ppl = 2.427346191835192e+95
  global_step = 263
  train_loss = 25.859
  ********************
Previous best ppl:inf
Achieve Best ppl:2.427346191835192e+95
  ********************
BLEU file: ./data/coderefine/2/validation.jsonl
  codebleu-4 = 56.69 	 Previous best codebleu 0
  ********************
 Achieve Best bleu:56.69
  ********************

***** Running evaluation *****
  Num examples = 68
  Batch size = 4
  epoch = 1
  eval_ppl = 1.1339471429090985e+99
  global_step = 525
  train_loss = 12.213
  ********************
Previous best ppl:2.427346191835192e+95
BLEU file: ./data/coderefine/2/validation.jsonl
  codebleu-4 = 79.05 	 Previous best codebleu 56.69
  ********************
 Achieve Best bleu:79.05
  ********************

***** Running evaluation *****
  Num examples = 68
  Batch size = 4
  epoch = 2
  eval_ppl = 2.147763249670012e+112
  global_step = 787
  train_loss = 7.8848
  ********************
Previous best ppl:2.427346191835192e+95
BLEU file: ./data/coderefine/2/validation.jsonl
  codebleu-4 = 71.71 	 Previous best codebleu 79.05
  ********************

***** Running evaluation *****
  Num examples = 68
  Batch size = 4
  epoch = 3
  eval_ppl = 1.253352100617653e+109
  global_step = 1049
  train_loss = 5.1622
  ********************
Previous best ppl:2.427346191835192e+95
BLEU file: ./data/coderefine/2/validation.jsonl
  codebleu-4 = 73.05 	 Previous best codebleu 79.05
  ********************

***** Running evaluation *****
  Num examples = 68
  Batch size = 4
  epoch = 4
  eval_ppl = 3.223469845475186e+121
  global_step = 1311
  train_loss = 3.5635
  ********************
Previous best ppl:2.427346191835192e+95
BLEU file: ./data/coderefine/2/validation.jsonl
  codebleu-4 = 81.73 	 Previous best codebleu 79.05
  ********************
 Achieve Best bleu:81.73
  ********************

***** Running evaluation *****
  Num examples = 68
  Batch size = 4
  epoch = 5
  eval_ppl = 1.0595050252579883e+123
  global_step = 1573
  train_loss = 2.1623
  ********************
Previous best ppl:2.427346191835192e+95
BLEU file: ./data/coderefine/2/validation.jsonl
  codebleu-4 = 81.0 	 Previous best codebleu 81.73
  ********************

***** Running evaluation *****
  Num examples = 68
  Batch size = 4
  epoch = 6
  eval_ppl = 2.116358824618328e+145
  global_step = 1835
  train_loss = 1.1604
  ********************
Previous best ppl:2.427346191835192e+95
BLEU file: ./data/coderefine/2/validation.jsonl
  codebleu-4 = 77.63 	 Previous best codebleu 81.73
  ********************

***** Running evaluation *****
  Num examples = 68
  Batch size = 4
  epoch = 7
  eval_ppl = 3.7678816140287375e+153
  global_step = 2097
  train_loss = 0.5048
  ********************
Previous best ppl:2.427346191835192e+95
BLEU file: ./data/coderefine/2/validation.jsonl
  codebleu-4 = 77.71 	 Previous best codebleu 81.73
  ********************
early stopping!!!
reload model from coderefine/2/soft5_gptneo/checkpoint-best-bleu
BLEU file: ./data/coderefine/2/test.jsonl
  codebleu = 83.98 
  Total = 65 
  Exact Fixed = 0 
[]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 1 
[45]
  ********************
  Total = 65 
  Exact Fixed = 0 
[]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 1 
[45]
  codebleu = 83.98 
[0.974561592577996, 0.7582721923809359, 0.324795842148328, 0.8912389075466283, 0.7909116860917069, 0.7614320201110889, 0.961313257959808, 0.9288050435889952, 0.8228053618676964, 0.869991184925961, 0.8802691274728712, 0.6461832782036787, 0.8651705366468426, 0.7214442588961294, 0.6813852958361807, 0.8814119980991142, 0.8921044832534335, 0.837110375724428, 0.9304890334445721, 0.7110903199480014, 0.9088175551663407, 1.0, 0.9011891267250418, 0.9819400729018484, 0.8366391585396613, 0.9552973981415056, 0.6729569730451757, 0.8249739576457391, 0.9281868948089405, 0.7792235915160284, 0.8993644611430505, 0.8299636826791826, 0.9030406908423083, 0.7224557955598466, 0.8086246986428193, 0.9931999228851198, 0.8244604952072514, 0.93144801584388, 0.9175688234132582, 0.8597687694634735, 0.8798963850849404, 0.8778780869299587, 0.9191759319588801, 0.9809905131005436, 0.9221557993275098, 0.8918501343788632, 0.7583556269641405, 0.906935406465484, 0.9256457314590425, 0.9482093418654862, 0.8044795411118251, 0.6464046753848991, 0.9829277991416243, 0.8364841891217798, 0.6791007858688705, 0.945929061225333, 0.3277251664739935, 0.774652015702356, 0.664008147913568, 0.8664336345018628, 0.8879531526601372, 0.8130387298512163, 0.9773276007446154, 0.9532869695940651, 0.8061411372208407]
Finish training and take 1h43m

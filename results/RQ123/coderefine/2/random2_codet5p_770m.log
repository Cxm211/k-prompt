Namespace(log_name='./result/coderefine/2/random2_codet5p_770m.log', model_name='Salesforce/codet5p-770m', lang='java', output_dir='result/coderefine/2/random2_codet5p_770m', data_dir='./data/coderefine/2', no_cuda=False, visible_gpu='0', num_train_epochs=10, num_test_epochs=1, train_batch_size=4, eval_batch_size=4, gradient_accumulation_steps=1, load_model_path=None, config_name='', tokenizer_name='', max_source_length=512, max_target_length=512, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, freeze=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
Model created!!
[[{'text': None, 'loss_ids': 0, 'shortenable_ids': 0}, {'text': ' public void METHOD_1 ( final TYPE_1 VAR_1 ) { this . VAR_1 = VAR_1 ; if ( ( ! ( VAR_2 . isEmpty ( ) ) ) && ( ( VAR_1 . METHOD_2 ( ) ) != null ) ) { for ( final TYPE_2 VAR_3 : VAR_1 . METHOD_2 ( ) ) { if ( ! ( this . VAR_1 . METHOD_2 ( ) . contains ( VAR_3 ) ) ) { VAR_2 . remove ( VAR_3 ) ; } } } }', 'loss_ids': 0, 'shortenable_ids': 1}, {'text': '<mask>', 'loss_ids': 1, 'shortenable_ids': 0}], {'guid': 0, 'tgt_text': 'public void METHOD_1 ( final TYPE_1 VAR_1 ) { if ( ( ! ( VAR_2 . isEmpty ( ) ) ) && ( ( VAR_1 . METHOD_2 ( ) ) != null ) ) { for ( final TYPE_2 VAR_3 : VAR_1 . METHOD_2 ( ) ) { if ( ! ( this . VAR_1 . METHOD_2 ( ) . contains ( VAR_3 ) ) ) { VAR_2 . remove ( VAR_3 ) ; } } } this . VAR_1 = VAR_1 ; }'}]
Namespace(log_name='./result/coderefine/2/random2_codet5p_770m.log', model_name='Salesforce/codet5p-770m', lang='java', output_dir='result/coderefine/2/random2_codet5p_770m', data_dir='./data/coderefine/2', choice=2, no_cuda=False, visible_gpu='0', num_train_epochs=10, num_test_epochs=1, train_batch_size=4, eval_batch_size=4, gradient_accumulation_steps=1, load_model_path=None, config_name='', tokenizer_name='', max_source_length=512, max_target_length=512, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, freeze=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
Model created!!
[[{'text': 'Fix the bug in', 'loss_ids': 0, 'shortenable_ids': 0}, {'text': ' public void METHOD_1 ( final TYPE_1 VAR_1 ) { this . VAR_1 = VAR_1 ; if ( ( ! ( VAR_2 . isEmpty ( ) ) ) && ( ( VAR_1 . METHOD_2 ( ) ) != null ) ) { for ( final TYPE_2 VAR_3 : VAR_1 . METHOD_2 ( ) ) { if ( ! ( this . VAR_1 . METHOD_2 ( ) . contains ( VAR_3 ) ) ) { VAR_2 . remove ( VAR_3 ) ; } } } }', 'loss_ids': 0, 'shortenable_ids': 1}, {'text': '<mask>', 'loss_ids': 1, 'shortenable_ids': 0}], {'guid': 0, 'tgt_text': 'public void METHOD_1 ( final TYPE_1 VAR_1 ) { if ( ( ! ( VAR_2 . isEmpty ( ) ) ) && ( ( VAR_1 . METHOD_2 ( ) ) != null ) ) { for ( final TYPE_2 VAR_3 : VAR_1 . METHOD_2 ( ) ) { if ( ! ( this . VAR_1 . METHOD_2 ( ) . contains ( VAR_3 ) ) ) { VAR_2 . remove ( VAR_3 ) ; } } } this . VAR_1 = VAR_1 ; }'}]
***** Running training *****
  Num examples = 523
  Batch size = 4
  Num epoch = 10

***** Running evaluation *****
  Num examples = 68
  Batch size = 4
  epoch = 0
  eval_ppl = 1.6120518719918027e+216
  global_step = 132
  train_loss = 18.4465
  ********************
Previous best ppl:inf
Achieve Best ppl:1.6120518719918027e+216
  ********************
BLEU file: ./data/coderefine/2/validation.jsonl
  codebleu-4 = 83.69 	 Previous best codebleu 0
  ********************
 Achieve Best bleu:83.69
  ********************

***** Running evaluation *****
  Num examples = 68
  Batch size = 4
  epoch = 1
  eval_ppl = 1.179075610629151e+230
  global_step = 263
  train_loss = 11.4636
  ********************
Previous best ppl:1.6120518719918027e+216
BLEU file: ./data/coderefine/2/validation.jsonl
  codebleu-4 = 83.85 	 Previous best codebleu 83.69
  ********************
 Achieve Best bleu:83.85
  ********************

***** Running evaluation *****
  Num examples = 68
  Batch size = 4
  epoch = 2
  eval_ppl = 2.577085553646483e+225
  global_step = 394
  train_loss = 7.5074
  ********************
Previous best ppl:1.6120518719918027e+216
BLEU file: ./data/coderefine/2/validation.jsonl
  codebleu-4 = 83.32 	 Previous best codebleu 83.85
  ********************

***** Running evaluation *****
  Num examples = 68
  Batch size = 4
  epoch = 3
  eval_ppl = 2.127216234241483e+240
  global_step = 525
  train_loss = 5.2107
  ********************
Previous best ppl:1.6120518719918027e+216
BLEU file: ./data/coderefine/2/validation.jsonl
  codebleu-4 = 84.66 	 Previous best codebleu 83.85
  ********************
 Achieve Best bleu:84.66
  ********************

***** Running evaluation *****
  Num examples = 68
  Batch size = 4
  epoch = 4
  eval_ppl = 3.06266008990563e+244
  global_step = 656
  train_loss = 3.1408
  ********************
Previous best ppl:1.6120518719918027e+216
BLEU file: ./data/coderefine/2/validation.jsonl
  codebleu-4 = 83.57 	 Previous best codebleu 84.66
  ********************

***** Running evaluation *****
  Num examples = 68
  Batch size = 4
  epoch = 5
  eval_ppl = 1.3086355521693135e+246
  global_step = 787
  train_loss = 2.3288
  ********************
Previous best ppl:1.6120518719918027e+216
BLEU file: ./data/coderefine/2/validation.jsonl
  codebleu-4 = 83.19 	 Previous best codebleu 84.66
  ********************

***** Running evaluation *****
  Num examples = 68
  Batch size = 4
  epoch = 6
  eval_ppl = 1.5444977649657477e+245
  global_step = 918
  train_loss = 1.3482
  ********************
Previous best ppl:1.6120518719918027e+216
BLEU file: ./data/coderefine/2/validation.jsonl
  codebleu-4 = 83.16 	 Previous best codebleu 84.66
  ********************
early stopping!!!
reload model from result/coderefine/2/random2_codet5p_770m/checkpoint-best-bleu
BLEU file: ./data/coderefine/2/test.jsonl
  codebleu = 85.73 
  Total = 65 
  Exact Fixed = 1 
[56]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 1 
[45]
  ********************
  Total = 65 
  Exact Fixed = 1 
[56]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 1 
[45]
  codebleu = 85.73 
[0.974561592577996, 0.7800504804611205, 0.989310412154881, 0.9132264743121661, 0.6986466917228251, 0.7614320201110889, 0.7884014493678178, 0.8905687836358562, 0.8440896537679332, 0.8740720974989237, 0.904898433884751, 0.7001219546992193, 0.8651705366468426, 0.7257973510620086, 0.6813852958361807, 0.8814119980991142, 0.8882110232136834, 0.837110375724428, 0.9304890334445721, 0.7225049802766912, 0.934542853545171, 1.0, 0.9011891267250418, 0.9819400729018484, 0.8366391585396613, 0.9552973981415056, 0.6729569730451757, 0.7961971504349914, 0.9864954811310649, 0.4857450272386542, 0.9061826429612323, 0.8382904201455096, 0.888311940193738, 0.9022927361056245, 0.7746170962173502, 0.9931999228851198, 0.8690214154998885, 0.9138009570203506, 0.9175688234132582, 0.8597687694634735, 0.865785521973699, 0.8778780869299587, 0.8222930492279794, 0.9809905131005436, 0.9221557993275098, 0.8918501343788632, 0.7583556269641405, 0.906935406465484, 0.9256457314590425, 0.9482093418654862, 0.8044795411118251, 0.6199000097150247, 0.9829277991416243, 0.8364841891217798, 0.7299220384551639, 1.0, 0.9106502668410179, 0.7383698883586869, 0.6801540738059678, 0.8664336345018628, 0.8879531526601372, 0.9166487297487674, 0.9773276007446154, 0.9805596968667925, 0.8279447096853492]
Finish training and take 20m

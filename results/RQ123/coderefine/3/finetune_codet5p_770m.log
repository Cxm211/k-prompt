Namespace(log_name='./coderefine/3/finetune_codet5p_770m.log', model_name='Salesforce/codet5p-770m', lang='java', output_dir='coderefine/3/finetune_codet5p_770m', data_dir='./data/coderefine/3', no_cuda=False, visible_gpu='0', add_task_prefix=False, add_lang_ids=False, num_train_epochs=10, num_test_epochs=10, train_batch_size=8, eval_batch_size=4, gradient_accumulation_steps=2, load_model_path=None, config_name='', tokenizer_name='', max_source_length=128, max_target_length=128, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, do_lower_case=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, max_steps=-1, eval_steps=-1, train_steps=-1, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, model_name: Salesforce/codet5p-770m
model created!
Total 523 training instances 
***** Running training *****
  Num examples = 523
  Batch size = 8
  Num epoch = 10

***** Running evaluation *****
  Num examples = 65
  Batch size = 4
  epoch = 0
  eval_ppl = 1.00036
  global_step = 66
  train_loss = 0.2242
  ********************
Previous best ppl:inf
Achieve Best ppl:1.00036
  ********************
BLEU file: ./data/coderefine/3/validation.jsonl
  codebleu-4 = 74.99 	 Previous best codebleu 0
  ********************
 Achieve Best bleu:74.99
  ********************

***** Running evaluation *****
  Num examples = 65
  Batch size = 4
  epoch = 1
  eval_ppl = 1.00032
  global_step = 131
  train_loss = 0.1139
  ********************
Previous best ppl:1.00036
Achieve Best ppl:1.00032
  ********************
BLEU file: ./data/coderefine/3/validation.jsonl
  codebleu-4 = 75.65 	 Previous best codebleu 74.99
  ********************
 Achieve Best bleu:75.65
  ********************

***** Running evaluation *****
  Num examples = 65
  Batch size = 4
  epoch = 2
  eval_ppl = 1.00035
  global_step = 196
  train_loss = 0.0762
  ********************
Previous best ppl:1.00032
BLEU file: ./data/coderefine/3/validation.jsonl
  codebleu-4 = 74.7 	 Previous best codebleu 75.65
  ********************

***** Running evaluation *****
  Num examples = 65
  Batch size = 4
  epoch = 3
  eval_ppl = 1.00038
  global_step = 261
  train_loss = 0.0532
  ********************
Previous best ppl:1.00032
BLEU file: ./data/coderefine/3/validation.jsonl
  codebleu-4 = 75.01 	 Previous best codebleu 75.65
  ********************

***** Running evaluation *****
  Num examples = 65
  Batch size = 4
  epoch = 4
  eval_ppl = 1.00039
  global_step = 326
  train_loss = 0.0348
  ********************
Previous best ppl:1.00032
BLEU file: ./data/coderefine/3/validation.jsonl
  codebleu-4 = 75.55 	 Previous best codebleu 75.65
  ********************
reload model from coderefine/3/finetune_codet5p_770m/checkpoint-best-bleu
BLEU file: ./data/coderefine/3/test.jsonl
  codebleu = 76.55 
  Total = 65 
  Exact Fixed = 0 
[]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  ********************
  Total = 65 
  Exact Fixed = 0 
[]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  codebleu = 76.55 
[0.8114146497860415, 0.8511738523629877, 0.8249591016210021, 0.7709490070828129, 0.8477770883167439, 0.8363409602259708, 0.8199154207049766, 0.6204559138725771, 0.7998588350875768, 0.7692676046691399, 0.748853825117711, 0.7075239702320301, 0.7973678730788641, 0.8890488806217476, 0.7862498146612795, 0.7547096877121569, 0.7816097472025576, 0.7202258343524188, 0.6029101873412028, 0.8882223493502044, 0.7355564429716741, 0.7848630361687197, 0.7554664934124026, 0.810643747031787, 0.8236488512415092, 0.7560386034712838, 0.739788619049438, 0.7444445080237931, 0.8272047904656293, 0.845578753456268, 0.6935049370730393, 0.6974142146146509, 0.5677947661680006, 0.8027656379478738, 0.7746312155966322, 0.6298945625997883, 0.7407594667567519, 0.6534950189211068, 0.7319733117136124, 0.6579407445009879, 0.7633128779022263, 0.8297738397582166, 0.7630059082740179, 0.8110281732862805, 0.809950603989694, 0.6454653351168431, 0.7449454385354564, 0.8748043250247002, 0.7750437078025361, 0.6035797984671984, 0.8473903531918134, 0.6344340556808374, 0.7771473051828641, 0.7037908434637395, 0.861689146169665, 0.7023828029155763, 0.8113304124720779, 0.7904542796544725, 0.8315815887018958, 0.885408826845203, 0.7315806865860484, 0.8452265509469621, 0.8784078895034853, 0.8573171881204411, 0.5735283309621977]
Finish training and take 10m

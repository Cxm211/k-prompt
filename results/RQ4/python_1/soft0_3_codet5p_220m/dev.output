class DictParameter(Parameter):      tags, that are dynamically constructed outside Luigi), or you have a complex parameter containing logically related values (like a database connection config).         JSON encoder for :py:class:`~DictParameter`, which makes :py:class:`~_FrozenOrderedDict` JSON serializable.          Ensure that dictionary parameter is converted to a _FrozenOrderedDict so it can be hashed.
def predict_generator(model, generator,              enqueuer.start(workers=workers, max_queue_size=max_queue_size)              output_generator = enqueuer.get()          else:             if is_sequence:                  output_generator = iter_sequence_infinite(generator)              else:                  output_generator = generator  def predict_generator(model, generator,              enqueuer.start(workers=workers, max_queue_size=max_queue_size)              output_generator = enqueuer.get()          else:             if is_sequence:                  output_generator = iter_sequence_infinite(generator)              else:                  output_generator = generator  def predict_generator(model, generator,              enqueuer.start(workers=workers, max_queue_size=max_queue_size)              output_generator = enqueuer.get()          else:             if is_sequence:                  output_generator = iter_sequence_infinite(generator)              else:                  output_generator = generator  def predict_generator(model, generator,              enqueuer.start(workers=workers, max_queue_size=max_queue_size)              output_generator = enqueuer.get()          else:             if is_sequence:                  output_generator = iter_sequence_infinite(generator)              else:                  output_generator = generator  def predict_generator(model, generator,              enqueuer.start(workers=workers, max_queue_size=max_queue_size)              output_generator = enqueuer.get()          else:             if is_sequence:                  output_generator = iter_sequence_infinite(generator)              else:                  output_generator = generator  def predict_generator(model, generator,              enqueuer.start(workers=workers, max_queue_size=max_queue_size)              output_generator = enqueuer.get()          else:             if is_sequence:                  output_generator = iter_sequence_infinite(generator)              else:                  output_generator = generator  def predict_generator(model, generator,              enqueuer.start(workers=workers, max_queue_size=max_queue_size)              output_generator = enqueuer.get()          else:             if
class TestBackend(object):          else:              assert_list_pairwise(v_list, shape=False, allclose=False, itself=True)      def test_print_tensor(self):          check_single_tensor_operation('print_tensor', (), WITH_NP)          check_single_tensor_operation('print_tensor', (2,), WITH_NP)         check_single_tensor_operation('print_tensor', (4, 3), WITH_NP)         check_single_tensor_operation('print_tensor', (1, 2, 3), WITH_NP)      def test_elementwise_operations(self):          check_single_tensor_operation('max', (4, 2), WITH_NP)
def Conv2DTranspose(Conv2D):          out_height = conv_utils.deconv_length(height,                                                stride_h, kernel_h,                                                self.padding,                                               out_pad_h)          out_width = conv_utils.deconv_length(width,                                               stride_w, kernel_w,                                                self.padding,                                               out_pad_w)          if self.data_format == 'channels_first':              output_shape = (batch_size, self.filters, out_height, out_width)          return Conv2DTranspose
def YoutubeDL(object):                          FORMAT_RE.format(numeric_field),                          r'%({0})s'.format(numeric_field), outtmpl)             filename = expand_path(outtmpl % template_dict)
def _get_collection_info(dep_map, existing_collections, collection, requirement,      existing = [c for c in existing_collections if to_text(c) == to_text(collection_info)]      def _get_collection_info(dep_map, existing_collections, collection, requirement,      existing = [c for c in existing_collections if to_text(c) == to_text(collection_info)]      def _get_collection_info(dep_map, existing_collections, collection, requirement,      existing = [c for c in existing_collections if to_text(c) == to_text(collection_info)]      def _get_collection_info(dep_map, existing_collections, collection, requirement,      existing = [c for c in existing_collections if to_text(c) == to_text(collection_info)]      def _get_collection_info(dep_map, existing_collections, collection, requirement,      existing = [c for c in existing_collections if to_text(c) == to_text(collection_info)]      def _get_collection_info(dep_map, existing_collections, collection, requirement,      existing = [c for c in existing_collections if to_text(c) == to_text(collection_info)]      def _get_collection_info(dep_map, existing_collections, collection, requirement,      existing = [c for c in existing_collections if to_text(c) == to_text(collection_info)]      def _get_collection_info(dep_map, existing_collections, collection, requirement,      existing = [c for c in existing_collections if to_text(c) == to_text(collection_info)]      def _get_collection_info(dep_map, existing_collections, collection, requirement,      existing = [c for c in existing_collections if to_text(c) == to_text(collection_info)]      def _get_collection_info(dep_map, existing_collections, collection, requirement,      existing = [c for c in existing_collections if to_text(c) == to_text(collection_info)]      def _get_collection_info(dep_map, existing_collections, collection, requirement,      existing = [c for c in existing_
def Model(Container):              validation_steps: Only relevant if `validation_data`                  is a generator. Total number of steps (batches of samples)                  to yield from `generator` before stopping.              class_weight: Dictionary mapping class indices to a weight for the class.              max_queue_size: Integer. Maximum size for the generator queue.
def create_instance(objcls, settings, crawler, *args, **kwargs):  ``*args`` and ``**kwargs`` are forwarded to the constructors.  Raises ``ValueError`` if both ``settings`` and ``crawler`` are ``None``.  def create_instance(objcls, settings, crawler, *args, **kwargs):      ``*args`` and ``**kwargs`` are forwarded to the constructors.      return objcls(*args, **kwargs)  def create_instance(objcls, settings, crawler, *args, **kwargs):      return objcls(*args, **kwargs)  def create_instance(objcls, settings, crawler, *args, **kwargs):      return objcls(*args, **kwargs)  def create_instance(objcls, settings, crawler, *args, **kwargs):      return objcls(*args, **kwargs)  def create_instance(objcls, settings, crawler, *args, **kwargs):      return objcls(*args, **kwargs)  def create_instance(objcls, settings, crawler, *args, **kwargs):      return objcls(*args, **kwargs)  def create_instance(objcls, settings, crawler, *args, **kwargs):      return objcls(*args, **kwargs)  def create_instance(objcls, settings, crawler, *args, **kwargs):      return objcls(*args, **kwargs)  def create_instance(objcls, settings, crawler, *args, **kwargs):      return objcls(*args, **kwargs)  def create_instance(objcls, settings, crawler, *args, **kwargs):      return objcls(*args, **kwargs)  def create_instance(objcls, settings, crawler, *args, **kwargs):      return objcls(*args, **kwargs)  def create_instance(objcls, settings, crawler, *args, **kwargs):      return objcls(*args, **kwargs)  def create_instance(objcls, settings, crawler, *args, **kwargs):      return objcls(*args, **kwargs)  def create_instance(objcls, settings, crawler, *args, **kwargs):      return objcls(*args, **kwargs)  def create_instance(objcls, settings, crawler, *args, **kwargs):      return objcls(*args, **kwargs)  def create_instance
def __call__(self, function):          def __call__(self, function):          self.target_codes.add(function.__code__)          def __call__(self, function):          self.target_frames.add(function)          def __call__(self, function):          self.thread_local.set(function)          def __call__(self, function):          self.thread_local.set(function)          def __call__(self, function):          self.thread_local.set(function)          def __call__(self, function):          self.thread_local.set(function)          def __call__(self, function):          self.thread_local.set(function)          def __call__(self, function):          self.thread_local.set(function)          def __call__(self, function):          self.thread_local.set(function)          def __call__(self, function):          self.thread_local.set(function)          def __call__(self, function):          self.thread_local.set(function)          def __call__(self, function):          self.thread_local.set(function)          def __call__(self, function):          self.thread_local.set(function)          def __call__(self, function):          self.thread_local.set(function)          def __call__(self, function):          self.thread_local.set(function)          def __call__(self, function):          self.thread_local.set(function)          def __call__(self, function):          self.thread_local.set(function)          def __call__(self, function):          self.thread_local.set(function)          def __call__(self, function):          self.thread_local.set(function)          def __call__(self, function):          self.thread_local.set(function)          def __call__(self, function):          self.thread_local.set(function)          def __call__(self, function):          self.thread_local.set(function)          def __call__(self, function):          self.thread_local.set(function)          def __call__(self, function):          self.thread_
class FastAPI(Starlette):              response_model_exclude_unset=bool(                  response_model_exclude_unset or response_model_skip_defaults              ),              include_in_schema=include_in_schema,              response_class=response_class or self.default_response_class,              name=name,
def self.included(base)   base.extend ClassMethods    def self.included(base)     base.extend ClassMethods   end    def self.included(base)     base.extend ClassMethods   end    def self.included(base)     base.extend ClassMethods   end    def self.included(base)     base.extend ClassMethods   end    def self.included(base)     base.extend ClassMethods   end    def self.included(base)     base.extend ClassMethods   end    def self.included(base)     base.extend ClassMethods   end    def self.included(base)     base.extend ClassMethods   end    def self.included(base)     base.extend ClassMethods   end    def self.included(base)     base.extend ClassMethods   end    def self.included(base)     base.extend ClassMethods   end    def self.included(base)     base.extend ClassMethods   end    def self.included(base)     base.extend ClassMethods   end    def self.included(base)     base.extend ClassMethods   end    def self.included(base)     base.extend ClassMethods   end    def self.included(base)     base.extend ClassMethods   end    def self.included(base)     base.extend ClassMethods   end    def self.included(base)     base.extend ClassMethods   end    def self.included(base)     base.extend ClassMethods   end    def self.included(base)     base.extend ClassMethods   end    def self.included(base)     base.extend ClassMethods   end    def self.included(base)     base.extend ClassMethods   end    def self.included(base)     base.extend ClassMethods   end    def self.included(base)     base.extend ClassMethods   end    def self.included(base)     base.extend
class SimpleRNNCell(Layer):   def __init__(self, dropout, recurrent_dropout, state_size):     Layer.__init__(self)     self.dropout = min(1., max(0., dropout))          self.recurrent_dropout = min(1., max(0., recurrent_dropout))          self.state_size = state_size     self._dropout_mask = None          self._recurrent_dropout_mask = None
def whitespace(leaf: Leaf) -> str:          ):              return NO      elif prev.type in OPENING_BRACKETS:          return NO def whitespace(leaf: Leaf) -> str:          ):              return NO def whitespace(leaf: Leaf) -> str:          ):              return NO def whitespace(leaf: Leaf) -> str:          ):              return NO def whitespace(leaf: Leaf) -> str:          ):              return NO def whitespace(leaf: Leaf) -> str:          ):              return NO def whitespace(leaf: Leaf) -> str:          ):              return NO def whitespace(leaf: Leaf) -> str:          ):              return NO def whitespace(leaf: Leaf) -> str:          ):              return NO def whitespace(leaf: Leaf) -> str:          ):              return NO def whitespace(leaf: Leaf) -> str:          ):              return NO def whitespace(leaf: Leaf) -> str:          ):              return NO def whitespace(leaf: Leaf) -> str:          ):              return NO def whitespace(leaf: Leaf) -> str:          ):              return NO def whitespace(leaf: Leaf) -> str:          ):              return NO def whitespace(leaf: Leaf) -> str:          ):              return NO def whitespace(leaf: Leaf) -> str:          ):              return NO def whitespace(leaf: Leaf) -> str:          ):              return NO def whitespace(leaf: Leaf) -> str:          ):              return NO def whitespace(leaf: Leaf) -> str:          ):              return NO def whitespace(leaf: Leaf) -> str:          ):              return NO def whitespace(leaf: Leaf) -> str:          ):              return NO def whitespace(leaf: Leaf) -> str:          ):              return NO def whitespace(leaf: Leaf) -> str:          ):              return NO def whitespace(leaf: Leaf) -> str:          ):              return NO def whitespace(leaf: Leaf) -> str:          ):              return NO def whitespace(leaf: Leaf) -> str:          ):              return NO def whitespace(leaf: Leaf) -> str:          ):              return NO def whitespace(leaf: Leaf) -> str:          ):              return NO def whitespace
def CSVLogger(Callback):  if not self.writer:              class CustomDialect(csv.excel):                  delimiter = self.sep              self.writer = csv.DictWriter(self.csv_file,                                           fieldnames=['epoch'] + self.keys, dialect=CustomDialect)              if self.append_header:                  self.writer.writeheader()
def standardize_weights(y,      Everything gets normalized to a single sample-wise (or timestep-wise)     weight array.          y: Numpy array of model targets to be weighted. def standardize_weights(y,      Everything gets normalized to a single sample-wise (or timestep-wise)     weight array.          y: Numpy array of model targets to be weighted. def standardize_weights(y,      Everything gets normalized to a single sample-wise (or timestep-wise)     weight array.          y: Numpy array of model targets to be weighted. def standardize_weights(y,      Everything gets normalized to a single sample-wise (or timestep-wise)     weight array.          y: Numpy array of model targets to be weighted. def standardize_weights(y,      Everything gets normalized to a single sample-wise (or timestep-wise)     weight array.          y: Numpy array of model targets to be weighted. def standardize_weights(y,      Everything gets normalized to a single sample-wise (or timestep-wise)     weight array.          y: Numpy array of model targets to be weighted. def standardize_weights(y,      Everything gets normalized to a single sample-wise (or timestep-wise)     weight array.          y: Numpy array of model targets to be weighted. def standardize_weights(y,      Everything gets normalized to a single sample-wise (or timestep-wise)     weight array.          y: Numpy array of model targets to be weighted. def standardize_weights(y,      Everything gets normalized to a single sample-wise (or timestep-wise)     weight array.          y: Numpy array of model targets to be weighted. def standardize_weights(y,      Everything gets normalized to a single sample-wise (or timestep-wise)     weight array.          y: Numpy array of model targets to be weighted. def standardize_weights(y,      Everything gets normalized to a single sample-wise (or timestep-wise)     weight array.          y: Numpy array of model targets to be weighted. def standardize_weights(y,      Everything gets normalized to a single sample-wise (or timestep-wise)     weight array.          y: Numpy array of model targets to be weighted. def standardize_weights(
def _unstack_multiple(data, clocs, fill_value=None):              result = data              for i in range(len(clocs)):                  val = clocs[i]                  result = result.unstack(val)                  clocs = [v if i > v else v - 1 for v in clocs]              return result
def LinuxHardware(Hardware):          pool = ThreadPool(processes=min(len(mtab_entries), cpu_count()))          maxtime = globals().get('GATHER_TIMEOUT') or timeout.DEFAULT_GATHER_TIMEOUT          for fields in mtab_entries:              device, mount, fstype, options = fields[0], fields[1], fields[2], fields[3]
def flatten(arr):     for x in arr:             if isinstance(x, list):                 for y in flatten(x):                 yield y         else:             yield flatten(x)
def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def
def dfxp2srt(dfxp_data):      def dfxp2srt(dfxp_data):      LEGACY_NAMESPACES = (         ('http://www.w3.org/ns/ttml', [             'http://www.w3.org/2004/11/ttaf1',             'http://www.w3.org/2006/04/ttaf1',             'http://www.w3.org/2006/10/ttaf1',          ]),         ('http://www.w3.org/ns/ttml             'http://www.w3.org/ns/ttml          ]),      def dfxp2srt(dfxp_data):      LEGACY_NAMESPACES = (         ('http://www.w3.org/ns/ttml', [             'http://www.w3.org/2004/11/ttaf1',             'http://www.w3.org/2006/04/ttaf1',             'http://www.w3.org/2006/10/ttaf1',          ]),      def dfxp2srt(dfxp_data):      LEGACY_NAMESPACES = (         ('http://www.w3.org/ns/ttml', [             'http://www.w3.org/2004/11/ttaf1',             'http://www.w3.org/2006/04/ttaf1',             'http://www.w3.org/2006/10/ttaf1',          ]),      def dfxp2srt(dfxp_data):      LEGACY_NAMESPACES = (         ('http://www.w3.org/ns/ttml', [             'http://www.w3.org/2004/11/ttaf1',             'http://www.w3.org/2006/04/ttaf1',             'http://www.w3.org/2006/10/ttaf1',          ]),      def dfxp2srt(dfxp_data):      LEGACY_NAMESPACES = (         ('http://www.w3.org/ns/ttml', [             'http://www.w3.org/2004
def test_check_mutually_exclusive_none():  def test_check_mutually_exclusive_no_params(mutually_exclusive_terms):      with pytest.raises(TypeError) as te:          check_mutually_exclusive(mutually_exclusive_terms, None)         assert "TypeError: 'NoneType' object is not iterable" in to_native(te.error)
def FastAPI(Starlette):          response_model_by_alias: bool = True,          response_model_skip_defaults: bool = None,          include_in_schema: bool = True,          response_class: Type[Response] = None,          name: str = None,
def uppercase_escape(s):      return re.sub(          r'\\U([0-9a-fA-F]{8})',          lambda m: compat_chr(int(m.group(1), base=16)), s) def uppercase_escape(s):      return re.sub(          r'\\U([0-9a-fA-F]{8})',          lambda m: compat_chr(int(m.group(1), base=16)), s) def uppercase_escape(s):      return re.sub(          r'\\U([0-9a-fA-F]{8})',          lambda m: compat_chr(int(m.group(1), base=16)), s) def uppercase_escape(s):      return re.sub(          r'\\U([0-9a-fA-F]{8})',          lambda m: compat_chr(int(m.group(1), base=16)), s) def uppercase_escape(s):      return re.sub(          r'\\U([0-9a-fA-F]{8})',          lambda m: compat_chr(int(m.group(1), base=16)), s) def uppercase_escape(s):      return re.sub(          r'\\U([0-9a-fA-F]{8})',          lambda m: compat_chr(int(m.group(1), base=16)), s) def uppercase_escape(s):      return re.sub(          r'\\U([0-9a-fA-F]{8})',          lambda m: compat_chr(int(m.group(1), base=16)), s) def uppercase_escape(s):      return re.sub(          r'\\U([0-9a-fA-F]{8})',          lambda m: compat_chr(int(m.group(1), base=16)), s) def uppercase_escape(s):      return re.sub(          r'\\U([0-9a-fA-F]{8})',          lambda m: compat_chr(int(m.group(1), base=16)), s) def uppercase_escape(s):      return re.sub(          r
def process_list_block(docstring, starting_point, section_end,                         leading_spaces, marker):      def process_list_block(docstring, starting_point, section_end,                         leading_spaces, marker):      def process_list_block(docstring, starting_point, section_end,                         leading_spaces, marker):      def process_list_block(docstring, starting_point, section_end,                         leading_spaces, marker):      def process_list_block(docstring, starting_point, section_end,                         leading_spaces, marker):      def process_list_block(docstring, starting_point, section_end,                         leading_spaces, marker):      def process_list_block(docstring, starting_point, section_end,                         leading_spaces, marker):      def process_list_block(docstring, starting_point, section_end,                         leading_spaces, marker):      def process_list_block(docstring, starting_point, section_end,                         leading_spaces, marker):      def process_list_block(docstring, starting_point, section_end,                         leading_spaces, marker):      def process_list_block(docstring, starting_point, section_end,                         leading_spaces, marker):      def process_list_block(docstring, starting_point, section_end,                         leading_spaces, marker):      def process_list_block(docstring, starting_point, section_end,                         leading_spaces, marker):      def process_list_block(docstring, starting_point, section_end,                         leading_spaces, marker):      def process_list_block(docstring, starting_point, section_end,                         leading_spaces, marker):      def process_list_block(docstring, starting_point, section_end,                         leading_spaces, marker):      def process_list_block(docstring, starting_point, section_end,                         leading_spaces, marker):      def process_list_block(docstring, starting_point, section_end,                         leading_spaces, marker):      def process_list_block(docstring, starting_point, section_end,                         leading_spaces, marker):      def process_list_block(docstring, starting_point, section_end,                         leading_spaces, marker):      def process_list_block(docstring, starting
class Function(object):  def _callable_fn(self, *array_vals):          return self._callable_fn(*array_vals)  def _legacy_call(self, inputs):      def _legacy_call(self, inputs):      def _legacy_call(self, inputs):      def _legacy_call(self, inputs):      def _legacy_call(self, inputs):      def _legacy_call(self, inputs):      def _legacy_call(self, inputs):      def _legacy_call(self, inputs):      def _legacy_call(self, inputs):      def _legacy_call(self, inputs):      def _legacy_call(self, inputs):      def _legacy_call(self, inputs):      def _legacy_call(self, inputs):      def _legacy_call(self, inputs):      def _legacy_call(self, inputs):      def _legacy_call(self, inputs):      def _legacy_call(self, inputs):      def _legacy_call(self, inputs):      def _legacy_call(self, inputs):      def _legacy_call(self, inputs):      def _legacy_call(self, inputs):      def _legacy_call(self, inputs):      def _legacy_call(self, inputs):      def _legacy_call(self, inputs):      def _legacy_call(self, inputs):      def _legacy_call(self, inputs):      def _legacy_call(self, inputs):      def _legacy_call(self, inputs):      def _legacy_call(self, inputs):      def _legacy_call(self, inputs):      def _legacy_call(self, inputs):      def _legacy_call(self, inputs):      def _legacy_call(self, inputs):      def _legacy_call(self, inputs):      def _legacy_call(self, inputs):      def _legacy_call(self, inputs):      def _legacy_call(self, inputs):      def _legacy_call(self, inputs):      def _legacy_call(self, inputs):      def _legacy_call(self, inputs):      def _legacy_call(self, inputs):      def _legacy_call(self, inputs):      def _legacy_call(self, inputs):      def _legacy_call
def update_add(x, increment):  The variable `x` updated.     return tf_state_ops.assign_add(x, increment)  @symbolicEndpointRequest def update_sub(x, increment):          The variable `x` updated.     return tf_state_ops.assign_sub(x, increment)  @symbolicEndpointRequest def update_mul(x, increment):          The variable `x` updated.     return tf_state_ops.assign_mul(x, increment)  @symbolicEndpointRequest def update_div(x, increment):          The variable `x` updated.     return tf_state_ops.assign_div(x, increment)  @symbolicEndpointRequest def update_mod(x, increment):          The variable `x` updated.     return tf_state_ops.assign_mod(x, increment)  @symbolicEndpointRequest def update_mod_add(x, increment):          The variable `x` updated.     return tf_state_ops.assign_mod_add(x, increment)  @symbolicEndpointRequest def update_mod_sub(x, increment):          The variable `x` updated.     return tf_state_ops.assign_mod_sub(x, increment)  @symbolicEndpointRequest def update_mod_mul(x, increment):          The variable `x` updated.     return tf_state_ops.assign_mod_mul(x, increment)  @symbolicEndpointRequest def update_mod_div(x, increment):          The variable `x` updated.     return tf_state_ops.assign_mod_div(x, increment)  @symbolicEndpointRequest def update_mod_mod_add(x, increment):          The variable `x` updated.     return tf_state_ops.assign_mod_mod_add(x, increment)  @symbolicEndpointRequest def update_mod_mod_sub(x, increment):          The variable `x` updated.     return tf_state_ops.assign_mod_mod_sub(x, increment)  @symbolicEndpointRequest def update_mod_mod_mul(x, increment):          The variable `x` updated.     return tf_state_ops.assign_mod_mod_mul(x, increment)  @symbolicEndpointRequest def update
def dispatch_to_series(left, right, func, str_rep=None, axis=None):          def column_op(a, b):             return {i: func(a.iloc[:, i], b.iloc[i]) for i in range(len(a.columns)) def dispatch_to_series(left, right, func, str_rep=None, axis=None):      def column_op(a, b):             return {i: func(a.iloc[:, i], b.iloc[i]) for i in range(len(a.columns)) def dispatch_to_series(left, right, func, str_rep=None, axis=None):      def column_op(a, b):             return {i: func(a.iloc[:, i], b.iloc[i]) for i in range(len(a.columns)) def dispatch_to_series(left, right, func, str_rep=None, axis=None):      def column_op(a, b):             return {i: func(a.iloc[:, i], b.iloc[i]) for i in range(len(a.columns)) def dispatch_to_series(left, right, func, str_rep=None, axis=None):      def column_op(a, b):             return {i: func(a.iloc[:, i], b.iloc[i]) for i in range(len(a.columns)) def dispatch_to_series(left, right, func, str_rep=None, axis=None):      def column_op(a, b):             return {i: func(a.iloc[:, i], b.iloc[i]) for i in range(len(a.columns)) def dispatch_to_series(left, right, func, str_rep=None, axis=None):      def column_op(a, b):             return {i: func(a.iloc[:, i], b.iloc[i]) for i in range(len(a.columns)) def dispatch_to_series(left, right, func, str_rep=None, axis=None):      def column_op(a, b):             return {i: func(a
def GalaxyCLI(CLI):          obj_name = context.CLIARGS['{0}_name'.format(galaxy_type)]          inject_data = dict(             description='your description',              ansible_plugin_list_dir=get_versioned_doclink('plugins/plugins.html'),          )          def GalaxyCLI(CLI):          obj_name = context.CLIARGS['{0}_name'.format(galaxy_type)]          inject_data = dict(             description='your description',              ansible_plugin_list_dir=get_versioned_doclink('plugins/plugins.html'),          )          def GalaxyCLI(CLI):          obj_name = context.CLIARGS['{0}_name'.format(galaxy_type)]          inject_data = dict(             description='your description',              ansible_plugin_list_dir=get_versioned_doclink('plugins/plugins.html'),          )          def GalaxyCLI(CLI):          obj_name = context.CLIARGS['{0}_name'.format(galaxy_type)]          inject_data = dict(             description='your description',              ansible_plugin_list_dir=get_versioned_doclink('plugins/plugins.html'),          )          def GalaxyCLI(CLI):          obj_name = context.CLIARGS['{0}_name'.format(galaxy_type)]          inject_data = dict(             description='your description',              ansible_plugin_list_dir=get_versioned_doclink('plugins/plugins.html'),          )          def GalaxyCLI(CLI):          obj_name = context.CLIARGS['{0}_name'.format(galaxy_type)]          inject_data = dict(             description='your description',              ansible_plugin_list_dir=get_versioned_doclink('plugins/plugins.html'),          )          def GalaxyCLI(CLI):          obj_name = context.CLIARGS['{0}_name'.format(galaxy_type)]          inject_data = dict(             description='your description',              ansible_plugin_list_dir=get_versioned_doclink('plugins/plugins.html'),          )          def GalaxyCLI(CLI):          obj_name = context.CLIARGS['{0
def _isna_old(obj):          return _isna_ndarraylike_old(np.asarray(obj))  def _isna_new(obj):         return obj is None  _isna = _isna_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new_new
def Scraper(object):                      spider=spider, exception=output.value class Scraper(object):                      spider=spider, exception=output.value class Scraper(object):                      spider=spider, exception=output.value class Scraper(object):                      spider=spider, exception=output.value class Scraper(object):                      spider=spider, exception=output.value class Scraper(object):                      spider=spider, exception=output.value class Scraper(object):                      spider=spider, exception=output.value class Scraper(object):                      spider=spider, exception=output.value class Scraper(object):                      spider=spider, exception=output.value class Scraper(object):                      spider=spider, exception=output.value class Scraper(object):                      spider=spider, exception=output.value class Scraper(object):                      spider=spider, exception=output.value class Scraper(object):                      spider=spider, exception=output.value class Scraper(object):                      spider=spider, exception=output.value class Scraper(object):                      spider=spider, exception=output.value class Scraper(object):                      spider=spider, exception=output.value class Scraper(object):                      spider=spider, exception=output.value class Scraper(object):                      spider=spider, exception=output.value class Scraper(object):                      spider=spider, exception=output.value class Scraper(object):                      spider=spider, exception=output.value class Scraper(object):                      spider=spider, exception=output.value class Scraper(object):                      spider=spider, exception=output.value class Scraper(object):                      spider=spider, exception=output.value class Scraper(object):                      spider=spider, exception=output.value class Scraper(object):                      spider=spider, exception=output.value class Scraper(object):                      spider=spider, exception=output.value class Scraper(object):                      spider=spider, exception=output.value class Scraper(object):                      spider=spider, exception=output.value class Scraper(object):
def APIRouter(routing.Router):              response_model_exclude_unset=bool(                  response_model_exclude_unset or response_model_skip_defaults              ),              include_in_schema=include_in_schema,              response_class=response_class or self.default_response_class,              name=name,
def assert_series_equal(          Compare datetime-like which is comparable ignoring dtype.      check_categorical : bool, default True          Whether to compare internal Categorical exactly.      obj : str, default 'Series'          Specify object name being compared, internally used to show appropriate          assertion message. def assert_series_equal(          Compare datetime-like which is comparable ignoring dtype.      check_categorical : bool, default True          Whether to compare internal Categorical exactly.      obj : str, default 'Series'          Specify object name being compared, internally used to show appropriate          assertion message. def assert_series_equal(          Compare datetime-like which is comparable ignoring dtype.      check_categorical : bool, default True          Whether to compare internal Categorical exactly.      obj : str, default 'Series'          Specify object name being compared, internally used to show appropriate          assertion message. def assert_series_equal(          Compare datetime-like which is comparable ignoring dtype.      check_categorical : bool, default True          Whether to compare internal Categorical exactly.      obj : str, default 'Series'          Specify object name being compared, internally used to show appropriate          assertion message. def assert_series_equal(          Compare datetime-like which is comparable ignoring dtype.      check_categorical : bool, default True          Whether to compare internal Categorical exactly.      obj : str, default 'Series'          Specify object name being compared, internally used to show appropriate          assertion message. def assert_series_equal(          Compare datetime-like which is comparable ignoring dtype.      check_categorical : bool, default True          Whether to compare internal Categorical exactly.      obj : str, default 'Series'          Specify object name being compared, internally used to show appropriate          assertion message. def assert_series_equal(          Compare datetime-like which is comparable ignoring dtype.      check_categorical : bool, default True          Whether to compare internal Categorical exactly.      obj : str, default 'Series'          Specify object name being compared, internally used to show appropriate          assertion message. def assert_series_equal(          Compare datetime-like which is comparable ignoring dtype.      check_categorical : bool, default True          Whether to compare internal Categorical exactly.      obj : str, default 'Series'          Specify object name being compared, internally used to show appropriate          assertion message. def assert_series_equal
def MailSender(object):              msg = MIMEMultipart()          else:              msg = MIMENonMultipart(*mimetype.split('/', 1))          msg['From'] = self.mailfrom          msg['To'] = COMMASPACE.join(to)          msg['Date'] = formatdate(localtime=True)
def tqdm(object):                      l_bar_user, r_bar_user = bar_format.split('{bar}')                     l_bar, r_bar = l_bar.format(**bar_args)                  else:                      return bar_format.format(**bar_args)
default: :rc:`scatter.edgecolors`              - 'none': No patch boundary will be drawn.              - A color or sequence of colors.             For non-filled markers, the *edgecolors* kwarg is ignored and forced to 'face' internally. default: :rc:`scatter.edgecolors`              - 'none': No patch boundary will be drawn.              - A color or sequence of colors.             For non-filled markers, the *edgecolors* kwarg is ignored and forced to 'face' internally. default: :rc:`scatter.edgecolors`              - 'none': No patch boundary will be drawn.              - A color or sequence of colors.             For non-filled markers, the *edgecolors* kwarg is ignored and forced to 'face' internally. default: :rc:`scatter.edgecolors`              - 'none': No patch boundary will be drawn.              - A color or sequence of colors.             For non-filled markers, the *edgecolors* kwarg is ignored and forced to 'face' internally. default: :rc:`scatter.edgecolors`              - 'none': No patch boundary will be drawn.              - A color or sequence of colors.             For non-filled markers, the *edgecolors* kwarg is ignored and forced to 'face' internally. default: :rc:`scatter.edgecolors`              - 'none': No patch boundary will be drawn.              - A color or sequence of colors.             For non-filled markers, the *edgecolors* kwarg is ignored and forced to 'face' internally. default: :rc:`scatter.edgecolors`              - 'none': No patch boundary will be drawn.              - A color or sequence of colors.             For non-filled markers, the *edgecolors* kwarg is ignored and forced to 'face' internally. default: :rc:`scatter.edgecolors`              - 'none': No patch boundary will be drawn.              - A color or sequence of colors.             For non-filled markers, the *edgecolors* kwarg is ignored and forced to 'face' internally. default: :rc:`scatter.edgecolors`              - 'none': No patch boundary will be drawn.              - A color or sequence of colors.             For non-filled
def decode_bytes(src: bytes) -> Tuple[FileContent, Encoding, NewLine]:      srcbuf = io.BytesIO(src)      encoding, lines = tokenize.detect_encoding(srcbuf.readline)      newline = "\r\n"      srcbuf.seek(0)      with io.TextIOWrapper(srcbuf, encoding) as tiow:      return (FileContent, Encoding, NewLine)  def decode_bytes(src: bytes) -> Tuple[FileContent, Encoding, NewLine]:      srcbuf = io.BytesIO(src)      encoding, lines = tokenize.detect_encoding(srcbuf.readline)      newline = "\r\n"      srcbuf.seek(0)      with io.TextIOWrapper(srcbuf, encoding) as tiow:      return (FileContent, Encoding, NewLine)  def decode_bytes(src: bytes) -> Tuple[FileContent, Encoding, NewLine]:      srcbuf = io.BytesIO(src)      encoding, lines = tokenize.detect_encoding(srcbuf.readline)      newline = "\r\n"      srcbuf.seek(0)      with io.TextIOWrapper(srcbuf, encoding) as tiow:      return (FileContent, Encoding, NewLine)  def decode_bytes(src: bytes) -> Tuple[FileContent, Encoding, NewLine]:      srcbuf = io.BytesIO(src)      encoding, lines = tokenize.detect_encoding(srcbuf.readline)      newline = "\r\n"      srcbuf.seek(0)      with io.TextIOWrapper(srcbuf, encoding) as tiow:      return (FileContent, Encoding, NewLine)  def decode_bytes(src: bytes) -> Tuple[FileContent, Encoding, NewLine]:      srcbuf = io.BytesIO(src)      encoding, lines = tokenize.detect_encoding(srcbuf.readline)      newline = "\r\n"      srcbuf.seek(0)      with io.TextIOWrapper(srcbuf, encoding) as tiow:      return (FileContent, Encoding, NewLine)  def decode_bytes(src: bytes) -> Tuple[FileContent, Encoding, NewLine]:      srcbuf = io.BytesIO(src)      encoding, lines = tokenize.detect_encoding(srcbuf.readline)      newline =
def info(self):  def info(self):          proc = Popen(['fish', '-c', 'echo $FISH_VERSION'],                       stdout=PIPE, stderr=DEVNULL)          version = proc.stdout.read().decode('utf-8').strip()          return u'Fish Shell {}'.format(version)
def S3CopyToTable(rdbms.CopyToTable):  if '.' in self.table:              query = ("select 1 as table_exists "                       "from information_schema.tables "                      "where table_schema = %s and table_name = %s limit 1")          else:              query = ("select 1 as table_exists "                       "from pg_table_def "                      "where tablename = %s limit 1")          cursor = connection.cursor()          try:              cursor.execute(query, tuple(self.table.split('.')))
def write_flv_header(stream, metadata):      stream.write(b'\x12')      stream.write(pack('!L', len(metadata))[1:])      stream.write(b'\x00\x00\x00\x00\x00\x00')      stream.write(metadata)
class StackedRNNCells(Layer):      '`state_size` attribute.'                                 'received cells:', cells)          self.cells = cells          super(StackedRNNCells, self).__init__(**kwargs)      @property      def state_size(self):          state_size = []          return tuple(state_size)      def call(self, inputs, states, constants=None, **kwargs):          nested_states = []          new_nested_states = nested_states[::-1]          return tuple(new_nested_states)
def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def
class Series(base.IndexOpsMixin, generic.NDFrame):                  indexer = self.index.get_indexer_for(key)                  return self.iloc[indexer]              else:                 return self._get_values(key)  def Series(base.IndexOpsMixin, generic.NDFrame):                  return self._get_values(key)  def Series(base.IndexOpsMixin, generic.NDFrame):                  return self._get_values(key)  def Series(base.IndexOpsMixin, generic.NDFrame):                  return self._get_values(key)  def Series(base.IndexOpsMixin, generic.NDFrame):                  return self._get_values(key)  def Series(base.IndexOpsMixin, generic.NDFrame):                  return self._get_values(key)  def Series(base.IndexOpsMixin, generic.NDFrame):                  return self._get_values(key)  def Series(base.IndexOpsMixin, generic.NDFrame):                  return self._get_values(key)  def Series(base.IndexOpsMixin, generic.NDFrame):                  return self._get_values(key)  def Series(base.IndexOpsMixin, generic.NDFrame):                  return self._get_values(key)  def Series(base.IndexOpsMixin, generic.NDFrame):                  return self._get_values(key)  def Series(base.IndexOpsMixin, generic.NDFrame):                  return self._get_values(key)  def Series(base.IndexOpsMixin, generic.NDFrame):                  return self._get_values(key)  def Series(base.IndexOpsMixin, generic.NDFrame):                  return self._get_values(key)  def Series(base.IndexOpsMixin, generic.NDFrame):                  return self._get_values(key)  def Series(base.IndexOpsMixin, generic.NDFrame):                  return self._get_values(key)  def Series(base.IndexOpsMixin, generic.NDFrame):                  return self._get_values(key)  def Series(base.IndexOpsMixin, generic.NDFrame):                  return self._get_values(key)  def Series(base.IndexOpsMixin, generic.NDFrame):                  return self._get_values(key)  def Series(base.IndexOpsMixin
def MultiIndex(Index):                      indexer = self._get_level_indexer(key, level=level)                      new_index = maybe_mi_droplevels(indexer, [0], drop_level)              return indexer, new_index
def test_resample_categorical_data_with_timedeltaindex():          index=pd.to_timedelta([0, 10], unit="s"),      )      expected = expected.reindex(["Group_obj", "Group"], axis=1)      expected["Group"] = expected["Group_obj"].astype("category")      tm.assert_frame_equal(result, expected)
class CollectionRequirement:                  requirement = req                  op = operator.eq class CollectionRequirement:                  requirement = req                  op = operator.eq class CollectionRequirement:                  requirement = req                  op = operator.eq class CollectionRequirement:                  requirement = req                  op = operator.eq class CollectionRequirement:                  requirement = req                  op = operator.eq class CollectionRequirement:                  requirement = req                  op = operator.eq class CollectionRequirement:                  requirement = req                  op = operator.eq class CollectionRequirement:                  requirement = req                  op = operator.eq class CollectionRequirement:                  requirement = req                  op = operator.eq class CollectionRequirement:                  requirement = req                  op = operator.eq class CollectionRequirement:                  requirement = req                  op = operator.eq class CollectionRequirement:                  requirement = req                  op = operator.eq class CollectionRequirement:                  requirement = req                  op = operator.eq class CollectionRequirement:                  requirement = req                  op = operator.eq class CollectionRequirement:                  requirement = req                  op = operator.eq class CollectionRequirement:                  requirement = req                  op = operator.eq class CollectionRequirement:                  requirement = req                  op = operator.eq class CollectionRequirement:                  requirement = req                  op = operator.eq class CollectionRequirement:                  requirement = req                  op = operator.eq class CollectionRequirement:                  requirement = req                  op = operator.eq class CollectionRequirement:                  requirement = req                  op = operator.eq class CollectionRequirement:                  requirement = req                  op = operator.eq class CollectionRequirement:                  requirement = req                  op = operator.eq class CollectionRequirement:                  requirement = req                  op = operator.eq class CollectionRequirement:                  requirement = req                  op = operator.eq class CollectionRequirement:                  requirement = req                  op = operator.eq class CollectionRequirement:                  requirement = req                  op = operator.eq class CollectionRequirement:                  requirement = req                  op = operator.eq class CollectionRequirement:                  requirement = req                  op = operator.eq class CollectionRequirement:                  requirement = req                  op = operator.eq class CollectionRequirement:                  requirement = req                  op = operator.eq class CollectionRequirement:                  requirement = req                  op = operator.eq class CollectionRequirement:                  requirement = req                  op = operator.eq class CollectionRequirement:                  requirement = req                  op = operator.eq
def _AxesBase(martist.Artist):              if right is None:                  right = old_right         class _AxesBase(martist.Artist):              if self.get_xscale() == 'log':              if left <= 0:                  cbook._warn_external(                      'Attempted to set non-positive left xlim on a '  class _AxesBase(martist.Artist):              if right is None:                  right = old_right         class _AxesBase(martist.Artist):              if self.get_xscale() == 'log':              if left <= 0:                  cbook._warn_external(                      'Attempted to set non-positive left xlim on a '  class _AxesBase(martist.Artist):              if right is None:                  right = old_right         class _AxesBase(martist.Artist):              if self.get_xscale() == 'log':              if left <= 0:                  cbook._warn_external(                      'Attempted to set non-positive left xlim on a '  class _AxesBase(martist.Artist):              if right is None:                  right = old_right         class _AxesBase(martist.Artist):              if self.get_xscale() == 'log':              if left <= 0:                  cbook._warn_external(                      'Attempted to set non-positive left xlim on a '  class _AxesBase(martist.Artist):              if right is None:                  right = old_right         class _AxesBase(martist.Artist):              if self.get_xscale() == 'log':              if left <= 0:                  cbook._warn_external(                      'Attempted to set non-positive left xlim on a '  class _AxesBase(martist.Artist):              if right is None:                  right = old_right         class _AxesBase(martist.Artist):              if self.get_xscale() == 'log':              if left <= 0:                  cbook._warn_external(                      'Attempted to set non-positive left xlim on a '  class _AxesBase(martist.Artist):              if right is None:                  right = old_right         class _AxesBase(martist.Artist):              if self.get_xscale() == 'log':
def check_required_arguments(argument_spec, module_parameters):  missing.append(k)  return missing
def _AxesBase(martist.Artist):          left, right = sorted([left, right], reverse=bool(reverse))          self._viewLim.intervalx = (left, right) class _AxesBase(martist.Artist):          left, right = sorted([left, right], reverse=bool(reverse))          self._viewLim.intervaly = (left, right) class _AxesBase(martist.Artist):          left, right = sorted([left, right], reverse=bool(reverse))          self._viewLim.intervalz = (left, right) class _AxesBase(martist.Artist):          left, right = sorted([left, right], reverse=bool(reverse))          self._viewLim.intervalw = (left, right) class _AxesBase(martist.Artist):          left, right = sorted([left, right], reverse=bool(reverse))          self._viewLim.intervalx = (left, right) class _AxesBase(martist.Artist):          left, right = sorted([left, right], reverse=bool(reverse))          self._viewLim.intervaly = (left, right) class _AxesBase(martist.Artist):          left, right = sorted([left, right], reverse=bool(reverse))          self._viewLim.intervalz = (left, right) class _AxesBase(martist.Artist):          left, right = sorted([left, right], reverse=bool(reverse))          self._viewLim.intervalw = (left, right) class _AxesBase(martist.Artist):          left, right = sorted([left, right], reverse=bool(reverse))          self._viewLim.intervalx = (left, right) class _AxesBase(martist.Artist):          left, right = sorted([left, right], reverse=bool(reverse))          self._viewLim.intervaly = (left, right) class _AxesBase(martist.Artist):          left, right = sorted([left, right], reverse=bool(reverse))          self._viewLim.intervalz = (left, right) class _AxesBase(martist.Artist):          left, right = sorted([left, right], reverse=bool(
def HTTP1Connection(httputil.HTTPConnection):              return connection_header!= "close"          return False
def Language(object):              kwargs = component_cfg.get(name, {})              kwargs.setdefault("batch_size", batch_size)              if not hasattr(pipe, "pipe"):                 docs = _pipe(pipe, docs, kwargs)              else:                  docs = pipe.pipe(docs, **kwargs)          for doc, gold in zip(docs, golds):
def Conv2DTranspose(Conv2D):              output_shape,              self.strides,              padding=self.padding,              data_format=self.data_format class Conv2DTranspose(Conv2D):              output_shape,              self.strides,              padding=self.padding,              data_format=self.data_format class Conv2DTranspose(Conv2D):              output_shape,              self.strides,              padding=self.padding,              data_format=self.data_format class Conv2DTranspose(Conv2D):              output_shape,              self.strides,              padding=self.padding,              data_format=self.data_format class Conv2DTranspose(Conv2D):              output_shape,              self.strides,              padding=self.padding,              data_format=self.data_format class Conv2DTranspose(Conv2D):              output_shape,              self.strides,              padding=self.padding,              data_format=self.data_format class Conv2DTranspose(Conv2D):              output_shape,              self.strides,              padding=self.padding,              data_format=self.data_format class Conv2DTranspose(Conv2D):              output_shape,              self.strides,              padding=self.padding,              data_format=self.data_format class Conv2DTranspose(Conv2D):              output_shape,              self.strides,              padding=self.padding,              data_format=self.data_format class Conv2DTranspose(Conv2D):              output_shape,              self.strides,              padding=self.padding,              data_format=self.data_format class Conv2DTranspose(Conv2D):              output_shape,              self.strides,              padding=self.padding,              data_format=self.data_format class Conv2DTranspose(Conv2D):              output_shape,              self.strides,              padding=self.padding,              data_format=self.data_format class Conv2DTranspose(Conv2D):              output_shape,              self.strides,              padding=self.padding,
185.0          numeric_df = self._get_numeric_data()          cols = numeric_df.columns          idx = cols.copy          mat = numeric_df.values          if method == "pearson":             correl = libalgos.nancorr(ensure_float64(mat), minp=min_periods)          elif method == "spearman":             correl = libalgos.nancorr_spearman(ensure_float64(mat), minp=min_periods)          elif method == "kendall" or callable(method):              if min_periods is None:                  min_periods = 1              mat = ensure_float64(mat).T              corrf = nanops.get_corr_func(method)              K = len(cols)              correl = np.empty((K, K), dtype=float)
default: :rc:`scatter.edgecolors`          collection = mcoll.PathCollection(                  (path,), scales,                 facecolors=colors,                 edgecolors=edgecolors,                  linewidths=linewidths,                  offsets=offsets,                  transOffset=kwargs.pop('transform', self.transData), default: :rc:`scatter.edgecolors`          collection = mcoll.PathCollection(                  (path,), scales,                 facecolors=colors,                 edgecolors=edgecolors,                  linewidths=linewidths,                  offsets=offsets,                  transOffset=kwargs.pop('transform', self.transData), default: :rc:`scatter.edgecolors`          collection = mcoll.PathCollection(                  (path,), scales,                 facecolors=colors,                 edgecolors=edgecolors,                  linewidths=linewidths,                  offsets=offsets,                  transOffset=kwargs.pop('transform', self.transData), default: :rc:`scatter.edgecolors`          collection = mcoll.PathCollection(                  (path,), scales,                 facecolors=colors,                 edgecolors=edgecolors,                  linewidths=linewidths,                  offsets=offsets,                  transOffset=kwargs.pop('transform', self.transData), default: :rc:`scatter.edgecolors`          collection = mcoll.PathCollection(                  (path,), scales,                 facecolors=colors,                 edgecolors=edgecolors,                  linewidths=linewidths,                  offsets=offsets,                  transOffset=kwargs.pop('transform', self.transData), default: :rc:`scatter.edgecolors`          collection = mcoll.PathCollection(                  (path,), scales,                 facecolors=colors,                 edgecolors=edgecolors,                  linewidths=linewidths,                  offsets=offsets,                  transOffset=kwargs.pop('transform', self.transData), default: :rc:`scatter.edgecolors`          collection = mcoll.PathCollection(                  (path,), scales,                 facecolors=colors,                 edgecolors=edgecolors,                  linewidths=linewidths,                  offsets=offsets,                  transOffset=kwargs.pop('transform', self.transData),
class BaseGrouper:  def __init__(self, mask, kind, counts):  self._filter_empty_groups = False class BaseGrouper:  def __init__(self, mask, kind, counts):  self._filter_empty_groups = True class BaseGrouper:  def __init__(self, mask, kind, counts):  self._filter_empty_groups = False class BaseGrouper:  def __init__(self, mask, kind, counts):  self._filter_empty_groups = True class BaseGrouper:  def __init__(self, mask, kind, counts):  self._filter_empty_groups = True class BaseGrouper:  def __init__(self, mask, kind, counts):  self._filter_empty_groups = True class BaseGrouper:  def __init__(self, mask, kind, counts):  self._filter_empty_groups = True class BaseGrouper:  def __init__(self, mask, kind, counts):  self._filter_empty_groups = True class BaseGrouper:  def __init__(self, mask, kind, counts):  self._filter_empty_groups = True class BaseGrouper:  def __init__(self, mask, kind, counts):  self._filter_empty_groups = True class BaseGrouper:  def __init__(self, mask, kind, counts):  self._filter_empty_groups = True class BaseGrouper:  def __init__(self, mask, kind, counts):  self._filter_empty_groups = True class BaseGrouper:  def __init__(self, mask, kind, counts):  self._filter_empty_groups = True class BaseGrouper:  def __init__(self, mask, kind, counts):  self._filter_empty_groups = True class BaseGrouper:  def __init__(self, mask, kind, counts):  self._filter_empty_groups = True class BaseGrouper:  def __init__(self, mask, kind, counts):  self._filter_empty_groups = True class BaseGrouper:  def __init__(self, mask, kind, counts):  self._filter_empty_groups = True
def Model(Container):                  enqueuer.start(workers=workers, max_queue_size=max_queue_size)                  output_generator = enqueuer.get()              else:                 output_generator = generator              callback_model.stop_training = False
def FeedExporter(object):          d.addCallback(lambda _: logger.info(logfmt % "Stored", log_args,                                              extra={'spider': spider}))          d.addErrback(lambda f: logger.error(logfmt % "Error storing", log_args,                                              extra={'spider': spider, 'failure': f}))          return d      def item_scraped(self, item, spider):
def APIRouter(routing.Router):          response_model_by_alias: bool = True,          response_model_skip_defaults: bool = None,          include_in_schema: bool = True,          response_class: Type[Response] = None,          name: str = None,
def BusinessHourMixin(BusinessMixin):              if bd!= 0:                 skip_bd = BusinessDay(n=bd)                  if not self.next_bday.is_on_offset(other):                      prev_open = self._prev_opening_time(other)
setup(              "options_test.cfg",              "static/robots.txt",              "static/dir/index.html",              "templates/utf8.html",              "test.crt",              "test.key")  def setup(              "options_test.cfg",              "static/robots.txt",              "static/dir/index.html",              "templates/utf8.html",              "test.crt",              "test.key") setup(              "options_test.cfg",              "static/robots.txt",              "static/dir/index.html",              "templates/utf8.html",              "test.crt",              "test.key") setup(              "options_test.cfg",              "static/robots.txt",              "static/dir/index.html",              "templates/utf8.html",              "test.crt",              "test.key") setup(              "options_test.cfg",              "static/robots.txt",              "static/dir/index.html",              "templates/utf8.html",              "test.crt",              "test.key") setup(              "options_test.cfg",              "static/robots.txt",              "static/dir/index.html",              "templates/utf8.html",              "test.crt",              "test.key") setup(              "options_test.cfg",              "static/robots.txt",              "static/dir/index.html",              "templates/utf8.html",              "test.crt",              "test.key") setup(              "options_test.cfg",              "static/robots.txt",              "static/dir/index.html",              "templates/utf8.html",              "test.crt",              "test.key") setup(              "options_test.cfg",              "static/robots.txt",              "static/dir/index.html",              "templates/utf8.html",              "test.crt",              "test.key") setup(              "options_test.cfg",              "static/robots.txt",              "static/dir/index.html",              "templates/utf8.html",              "
def Sequential(Model):      @interfaces.legacy_generator_methods_support      def predict_generator(self, generator, steps,                            max_queue_size=10, workers=1,                            use_multiprocessing=False, verbose=0):      def predict_generator(self, generator, steps,                            max_queue_size=10, workers=1,                            use_multiprocessing=False, verbose=0):      def predict_generator(self, generator, steps,                            max_queue_size=10, workers=1,                            use_multiprocessing=False, verbose=0):      def predict_generator(self, generator, steps,                            max_queue_size=10, workers=1,                            use_multiprocessing=False, verbose=0):      def predict_generator(self, generator, steps,                            max_queue_size=10, workers=1,                            use_multiprocessing=False, verbose=0):      def predict_generator(self, generator, steps,                            max_queue_size=10, workers=1,                            use_multiprocessing=False, verbose=0):      def predict_generator(self, generator, steps,                            max_queue_size=10, workers=1,                            use_multiprocessing=False, verbose=0):      def predict_generator(self, generator, steps,                            max_queue_size=10, workers=1,                            use_multiprocessing=False, verbose=0):      def predict_generator(self, generator, steps,                            max_queue_size=10, workers=1,                            use_multiprocessing=False, verbose=0):      def predict_generator(self, generator, steps,                            max_queue_size=10, workers=1,                            use_multiprocessing=False, verbose=0):      def predict_generator(self, generator, steps,                            max_queue_size=10, workers=1,                            use_multiprocessing=False, verbose=0):      def predict_generator(self, generator, steps,                            max_queue_size=10, workers=1,                            use_multiprocessing=False, verbose=0):      def predict_generator(self, generator, steps,                            max_queue_size=10, workers=1,                            use_multiprocessing=False, verbose=0
def format_stdin_to_stdout(      `line_length`, `fast`, `is_pyi`, and `force_py36` arguments are passed to      :func:`format_file_contents`.      src = sys.stdin.read()      dst = src      try:          dst = format_file_contents(src, line_length=line_length, fast=fast, mode=mode) def format_stdin_to_stdout(      `line_length`, `fast`, `is_pyi`, and `force_py36` arguments are passed to      :func:`format_file_contents`.      src = sys.stdin.read()      try:          dst = format_file_contents(src, line_length=line_length, fast=fast, mode=mode) def format_stdin_to_stdout(      `line_length`, `fast`, `is_pyi`, and `force_py36` arguments are passed to      :func:`format_file_contents`.      src = sys.stdin.read()      try:          dst = format_file_contents(src, line_length=line_length, fast=fast, mode=mode) def format_stdin_to_stdout(      `line_length`, `fast`, `is_pyi`, and `force_py36` arguments are passed to      :func:`format_file_contents`.      src = sys.stdin.read()      try:          dst = format_file_contents(src, line_length=line_length, fast=fast, mode=mode) def format_stdin_to_stdout(      `line_length`, `fast`, `is_pyi`, and `force_py36` arguments are passed to      :func:`format_file_contents`.      src = sys.stdin.read()      try:          dst = format_file_contents(src, line_length=line_length, fast=fast, mode=mode) def format_stdin_to_stdout(      `line_length`, `fast`, `is_pyi`, and `force_py36` arguments are passed to      :func:`format_file_contents`.      src = sys.stdin.read()      try:          dst = format_file_contents(src, line_length=line_length, fast=fast, mode
def _convert_scalar_indexer(self, key, kind=None):      def _convert_scalar_indexer(self, key, kind=None):          return super()._convert_scalar_indexer(key, kind=None)      @Appender(_index_shared_docs["_convert_list_indexer"])      def _convert_list_indexer(self, key, kind=None):          return super()._convert_list_indexer(key, kind=None)
def array_equivalent(left, right, strict_nan=False):                  if not isinstance(right_value, float) or not np.isnan(right_value):                      return False              else:                 if left_value!= right_value:                      return False          return True
def _isna_old(obj):      elif isinstance(obj, type):          return False      elif isinstance(obj, (ABCSeries, np.ndarray, ABCIndexClass, ABCExtensionArray)):         return _isna_ndarraylike_old(obj)      elif isinstance(obj, ABCDataFrame):          return obj.isna()      elif isinstance(obj, list):         return _isna_ndarraylike_old(np.asarray(obj, dtype=object))      elif hasattr(obj, "__array__"):         return _isna_ndarraylike_old(np.asarray(obj))      else:          return False
class Task(object):          params_str = {}          params = dict(self.get_params())          for param_name, param_value in six.iteritems(self.param_kwargs):             if params[param_name].significant:                 params_str[param_name] = params[param_name].serialize(param_value)          return params_str
def possible_change(coins, total):  def possible_change(coins, total):      first, *rest = coins      return possible_change(coins, total - first)  return possible_change(rest, total)
def OffsiteMiddleware(object):  if not allowed_domains: return re.compile('')          url_pattern = re.compile("^https?://.*$")          for domain in allowed_domains:             if url_pattern.match(domain):                  message = ("allowed_domains accepts only domains, not URLs. "                             "Ignoring URL entry %s in allowed_domains." % domain)                  warnings.warn(message, URLWarning)          domains = [re.escape(d) for d in allowed_domains if d is not None]          regex = r'^(.*\.)?(%s)$' % '|'.join(domains)          return re.compile(regex)
def uppercase_escape(s):      return re.sub(          r'\\U[0-9a-fA-F]{8}',         lambda m: m.group(0).decode('unicode_escape'), s)  try:      struct.pack(u'!I', 0)
def lib2to3_parse(src_txt: str) -> Node:      grammar = pygram.python_grammar_no_print_statement      if src_txt[-1!= "\n":          nl = "\r\n" if "\r\n" in src_txt[:1024] else "\n"          src_txt += nl      return drv  def lib2to3_parse(src_txt: str) -> Node:      grammar = pygram.python_grammar_no_print_statement      return lib2to3_parse(src_txt)  def lib2to3_parse(src_txt: str) -> Node:      grammar = pygram.python_grammar_no_print_statement      return lib2to3_parse(src_txt)  def lib2to3_parse(src_txt: str) -> Node:      grammar = pygram.python_grammar_no_print_statement      return lib2to3_parse(src_txt)  def lib2to3_parse(src_txt: str) -> Node:      grammar = pygram.python_grammar_no_print_statement      return lib2to3_parse(src_txt)  def lib2to3_parse(src_txt: str) -> Node:      grammar = pygram.python_grammar_no_print_statement      return lib2to3_parse(src_txt)  def lib2to3_parse(src_txt: str) -> Node:      grammar = pygram.python_grammar_no_print_statement      return lib2to3_parse(src_txt)  def lib2to3_parse(src_txt: str) -> Node:      grammar = pygram.python_grammar_no_print_statement      return lib2to3_parse(src_txt)  def lib2to3_parse(src_txt: str) -> Node:      grammar = pygram.python_grammar_no_print_statement      return lib2to3_parse(src_txt)  def lib2to3_parse(src_txt: str) -> Node:      grammar = pygram.python_grammar_no_print_statement      return lib2to3_parse(src_txt)  def lib2to3_
def get_elements_by_attribute(attribute, value, html, escape_value=True):      retlist = []          <([a-zA-Z0-9:._-]+)          (?:\s+[a-zA-Z0-9:._-]+(?:=[a-zA-Z0-9:._-]*|="[^"]*"|="[^"]*"|="[^"]*"))*?          \s*>          (?P<content>.*?)          </\1> def get_elements_by_attribute(attribute, value, html, escape_value=True):      retlist = []          <([a-zA-Z0-9:._-]+)          (?:\s+[a-zA-Z0-9:._-]+(?:=[a-zA-Z0-9:._-]*|="[^"]*"|="[^"]*"))*?          \s*>          (?P<content>.*?)          </\1> def get_elements_by_attribute(attribute, value, html, escape_value=True):      retlist = []          <([a-zA-Z0-9:._-]+)          (?:\s+[a-zA-Z0-9:._-]+(?:=[a-zA-Z0-9:._-]*|="[^"]*"|="[^"]*"))*?          \s*>          (?P<content>.*?)          </\1> def get_elements_by_attribute(attribute, value, html, escape_value=True):      retlist = []          <([a-zA-Z0-9:._-]+)          (?:\s+[a-zA-Z0-9:._-]+(?:=[a-zA-Z0-9:._-]*|="[^"]*"|="[^"]*"))*?          \s*>          (?P<content>.*?)          </\1> def get_elements_by_attribute(attribute, value, html, escape_value=True):      retlist = []          <([a-zA-Z0-9:._-]+)          (?:\s+[a-zA-Z0-9:._-]+(?:=[a-zA-Z0-9:._-]*|="[^"]*"|="
class RetcodesTest(LuigiTestCase):          with mock.patch('luigi.scheduler.Scheduler.add_task', new_func):              self.run_and_expect('RequiringTask', 0)              self.run_and_expect('RequiringTask --retcode-not-run 5', 5)
class Categorical(ExtensionArray, PandasObject):              if dtype == self.dtype:                  return self              return self._set_dtype(dtype)          if is_integer_dtype(dtype) and self.isna().any():              msg = "Cannot convert float NaN to integer"              raise ValueError(msg)  class Categorical(ExtensionArray, PandasObject):              if dtype == self.dtype:                  return self              return self._set_dtype(dtype)          if is_integer_dtype(dtype) and self.isna().any():              msg = "Cannot convert float NaN to integer"              raise ValueError(msg)  class Categorical(ExtensionArray, PandasObject):              if dtype == self.dtype:                  return self              return self._set_dtype(dtype)          if is_integer_dtype(dtype) and self.isna().any():              msg = "Cannot convert float NaN to integer"              raise ValueError(msg)  class Categorical(ExtensionArray, PandasObject):              if dtype == self.dtype:                  return self              return self._set_dtype(dtype)          if is_integer_dtype(dtype) and self.isna().any():              msg = "Cannot convert float NaN to integer"              raise ValueError(msg)  class Categorical(ExtensionArray, PandasObject):              if dtype == self.dtype:                  return self              return self._set_dtype(dtype)          if is_integer_dtype(dtype) and self.isna().any():              msg = "Cannot convert float NaN to integer"              raise ValueError(msg)  class Categorical(ExtensionArray, PandasObject):              if dtype == self.dtype:                  return self              return self._set_dtype(dtype)          if is_integer_dtype(dtype) and self.isna().any():              msg = "Cannot convert float NaN to integer"              raise ValueError(msg)  class Categorical(ExtensionArray, PandasObject):              if dtype == self.dtype:                  return self              return self._set_dtype(dtype)          if is_integer_dtype(dtype) and self.isna().any():              msg = "Cannot convert float NaN to integer"              raise ValueError(msg)  class Categorical(ExtensionArray, PandasObject):              if dtype == self.dtype:                  return self              return self._set_dtype(dtype)          if is
def jsonable_encoder(              )          return jsonable_encoder(              obj_dict,              include_none=include_none,              custom_encoder=encoder,              sqlalchemy_safe=sqlalchemy_safe,          ) def jsonable_encoder(              obj_dict,              include_none=include_none,              custom_encoder=encoder,              sqlalchemy_safe=sqlalchemy_safe,          ) def jsonable_encoder(              obj_dict,              include_none=include_none,              custom_encoder=encoder,              sqlalchemy_safe=sqlalchemy_safe,          ) def jsonable_encoder(              obj_dict,              include_none=include_none,              custom_encoder=encoder,              sqlalchemy_safe=sqlalchemy_safe,          ) def jsonable_encoder(              obj_dict,              include_none=include_none,              custom_encoder=encoder,              sqlalchemy_safe=sqlalchemy_safe,          ) def jsonable_encoder(              obj_dict,              include_none=include_none,              custom_encoder=encoder,              sqlalchemy_safe=sqlalchemy_safe,          ) def jsonable_encoder(              obj_dict,              include_none=include_none,              custom_encoder=encoder,              sqlalchemy_safe=sqlalchemy_safe,          ) def jsonable_encoder(              obj_dict,              include_none=include_none,              custom_encoder=encoder,              sqlalchemy_safe=sqlalchemy_safe,          ) def jsonable_encoder(              obj_dict,              include_none=include_none,              custom_encoder=encoder,              sqlalchemy_safe=sqlalchemy_safe,          ) def jsonable_encoder(              obj_dict,              include_none=include_none,              custom_encoder=encoder,              sqlalchemy_safe=sqlalchemy_safe,          ) def jsonable_encoder(              obj_dict,              include_none=include_none,              custom_encoder=encoder,              sqlalchemy_safe=sqlalchemy_safe,          ) def jsonable_encoder(              obj_dict,              include_none=include_none,              custom_encoder=encoder,              sqlalchemy_safe=sqlalchemy_safe,          ) def jsonable_encoder(              obj_
def fit_generator(model,              if val_gen and workers > 0):                  val_data = validation_data                 if isinstance(val_data, Sequence):                      val_enqueuer = OrderedEnqueuer(                          val_data,                          use_multiprocessing=use_multiprocessing)def fit_generator(model,              if val_gen and workers > 0):                  val_data = validation_data def fit_generator(model,              if val_gen and workers > 0):                  val_data = validation_data def fit_generator(model,              if val_gen and workers > 0):                  val_data = validation_data def fit_generator(model,              if val_gen and workers > 0):                  val_data = validation_data def fit_generator(model,              if val_gen and workers > 0):                  val_data = validation_data def fit_generator(model,              if val_gen and workers > 0):                  val_data = validation_data def fit_generator(model,              if val_gen and workers > 0):                  val_data = validation_data def fit_generator(model,              if val_gen and workers > 0):                  val_data = validation_data def fit_generator(model,              if val_gen and workers > 0):                  val_data = validation_data def fit_generator(model,              if val_gen and workers > 0):                  val_data = validation_data def fit_generator(model,              if val_gen and workers > 0):                  val_data = validation_data def fit_generator(model,              if val_gen and workers > 0):                  val_data = validation_data def fit_generator(model,              if val_gen and workers > 0):                  val_data = validation_data def fit_generator(model,              if val_gen and workers > 0):                  val_data = validation_data def fit_generator(model,              if val_gen and workers > 0):                  val_data = validation_data def fit_generator(model,              if val_gen and workers > 0):                  val_data = validation_data def fit_generator(model,              if val_gen and workers > 0):                  val_data = validation_data def fit_
class PeriodIndex(DatetimeIndexOpsMixin, Int64Index):  @cache_readonly      def _engine(self):          period = weakref.ref(self)          return self._engine_type(period, len(self))      @doc(Index.__contains__)
def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),                      padding='valid', data_format=None):      def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),                      padding='valid', data_format=None):      def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),                      padding='valid', data_format=None):      def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),                      padding='valid', data_format=None):      def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),                      padding='valid', data_format=None):      def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),                      padding='valid', data_format=None):      def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),                      padding='valid', data_format=None):      def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),                      padding='valid', data_format=None):      def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),                      padding='valid', data_format=None):      def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),                      padding='valid', data_format=None):      def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),                      padding='valid', data_format=None):      def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),                      padding='valid', data_format=None):      def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),                      padding='valid', data_format=None):      def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),                      padding='valid', data_format=None):      def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),                      padding='valid', data_format=None):
def test_unstack(self):          def test_unstack(self):         index = MultiIndex(             levels=[["bar", "foo"], ["one", "three", "two"]],             codes=[[1, 1, 0, 0], [0, 1, 0, 2]],         )         s = Series(np.arange(4.0), index=index)         unstacked = s.unstack()         expected = DataFrame(             [[2.0, np.nan, 3.0], [0.0, 1.0, np.nan]],             index=["bar", "foo"],             columns=["one", "three", "two"],         )         tm.assert_frame_equal(unstacked, expected)         unstacked = s.unstack(level=0)         tm.assert_frame_equal(unstacked, expected.T)         index = MultiIndex(             levels=[["bar"], ["one", "two", "three"], [0, 1]],             codes=[[0, 0, 0, 0, 0, 0], [0, 1, 2, 0, 1, 2], [0, 1, 0, 1, 0, 1]],         )         s = Series(np.random.randn(6), index=index)         exp_index = MultiIndex(             levels=[["one", "two", "three"], [0, 1]],             codes=[[0, 1, 2, 0, 1, 2], [0, 1, 0, 1, 0, 1]],         )         expected = DataFrame({"bar": s.values}, index=exp_index).sort_index(level=0)         unstacked = s.unstack(0).sort_index()         tm.assert_frame_equal(unstacked, expected.T)
def APIRoute(routing.Route):   self.response_model_exclude = response_model_exclude          self.response_model_by_alias = response_model_by_alias          self.response_model_exclude_unset = response_model_exclude_unset          self.include_in_schema = include_in_schema          self.response_class = response_class class APIRoute(routing.Route):   self.response_model_exclude = response_model_exclude          self.response_model_by_alias = response_model_by_alias          self.response_model_exclude_unset = response_model_exclude_unset          self.include_in_schema = include_in_schema          self.response_class = response_class class APIRoute(routing.Route):   self.response_model_exclude = response_model_exclude          self.response_model_by_alias = response_model_by_alias          self.response_model_exclude_unset = response_model_exclude_unset          self.include_in_schema = include_in_schema          self.response_class = response_class class APIRoute(routing.Route):   self.response_model_exclude = response_model_exclude          self.response_model_by_alias = response_model_by_alias          self.response_model_exclude_unset = response_model_exclude_unset          self.include_in_schema = include_in_schema          self.response_class = response_class class APIRoute(routing.Route):   self.response_model_exclude = response_model_exclude          self.response_model_by_alias = response_model_by_alias          self.response_model_exclude_unset = response_model_exclude_unset          self.include_in_schema = include_in_schema          self.response_class = response_class class APIRoute(routing.Route):   self.response_model_exclude = response_model_exclude          self.response_model_by_alias = response_model_by_alias          self.response_model_exclude_unset = response_model_exclude_unset          self.include_in_schema = include_in_schema          self.response_class = response_class class APIRoute(routing.
def reverse_linked_list(node):     prevnode = None     while node:         nextnode = node.successor         node.successor = prevnode         node = nextnode     return prevnode
class TimedeltaIndex(                      result._set_freq("infer")              return result     def _fast_union(self, other):  if len(other) == 0:              return self.view(type(self))
def match_filter_func(filter_str):  def parse_dfxp_time_expr(time_expr):      return 0.0      mobj = re.match(r'^(?P<time_offset>\d+(?:\.\d+)?)s?$', time_expr):      return match_filter_func(filter_str) def match_filter_func(filter_str):  def parse_dfxp_time_expr(time_expr):      return match_filter_func(filter_str) def match_filter_func(filter_str):  def parse_dfxp_time_expr(time_expr):      return match_filter_func(filter_str) def match_filter_func(filter_str):  def parse_dfxp_time_expr(time_expr):      return match_filter_func(filter_str) def match_filter_func(filter_str):  def parse_dfxp_time_expr(time_expr):      return match_filter_func(filter_str) def match_filter_func(filter_str):  def parse_dfxp_time_expr(time_expr):      return match_filter_func(filter_str) def match_filter_func(filter_str):  def parse_dfxp_time_expr(time_expr):      return match_filter_func(filter_str) def match_filter_func(filter_str):  def parse_dfxp_time_expr(time_expr):      return match_filter_func(filter_str) def match_filter_func(filter_str):  def parse_dfxp_time_expr(time_expr):      return match_filter_func(filter_str) def match_filter_func(filter_str):  def parse_dfxp_time_expr(time_expr):      return match_filter_func(filter_str) def match_filter_func(filter_str):  def parse_dfxp_time_expr(time_expr):      return match_filter_func(filter_str) def match_filter_func(filter_str):  def parse_dfxp_time_expr(time_expr):      return match_filter_func(filter_str) def match_filter_
class NDFrame(PandasObject, SelectionMixin, indexing.IndexingMixin):              return self         arr = operator.inv(com.values_from_object(self))          return self.__array_wrap__(arr) class NDFrame(PandasObject, SelectionMixin, indexing.IndexingMixin):              return self         arr = operator.inv(com.values_from_object(self))          return self.__array_wrap__(arr) class NDFrame(PandasObject, SelectionMixin, indexing.IndexingMixin):              return self         arr = operator.inv(com.values_from_object(self))          return self.__array_wrap__(arr) class NDFrame(PandasObject, SelectionMixin, indexing.IndexingMixin):              return self         arr = operator.inv(com.values_from_object(self))          return self.__array_wrap__(arr) class NDFrame(PandasObject, SelectionMixin, indexing.IndexingMixin):              return self         arr = operator.inv(com.values_from_object(self))          return self.__array_wrap__(arr) class NDFrame(PandasObject, SelectionMixin, indexing.IndexingMixin):              return self         arr = operator.inv(com.values_from_object(self))          return self.__array_wrap__(arr) class NDFrame(PandasObject, SelectionMixin, indexing.IndexingMixin):              return self         arr = operator.inv(com.values_from_object(self))          return self.__array_wrap__(arr) class NDFrame(PandasObject, SelectionMixin, indexing.IndexingMixin):              return self         arr = operator.inv(com.values_from_object(self))          return self.__array_wrap__(arr) class NDFrame(PandasObject, SelectionMixin, indexing.IndexingMixin):              return self         arr = operator.inv(com.values_from_object(self))          return self.__array_wrap__(arr) class NDFrame(PandasObject, SelectionMixin, indexing.IndexingMixin):              return self         arr = operator.inv(com.values_from_object(self))          return self.__array_wrap__(arr) class NDFrame(PandasObject, SelectionMixin, indexing.IndexingMixin):              return self
def na_value_for_dtype(dtype, compat: bool = True):  def na_value_for_dtype(dtype):          return dtype.na_value      return np.nan_value_for_dtype
class scheduler(Config):      visualization_graph = parameter.Parameter(default="svg", config_path=dict(section='scheduler', name='visualization-graph'))  def fix_time(x):  def fix_time(x):  def fix_time(x):  def fix_time(x):  def fix_time(x):  def fix_time(x):  def fix_time(x):  def fix_time(x):  def fix_time(x):  def fix_time(x):  def fix_time(x):  def fix_time(x):  def fix_time(x):  def fix_time(x):  def fix_time(x):  def fix_time(x):  def fix_time(x):  def fix_time(x):  def fix_time(x):  def fix_time(x):  def fix_time(x):  def fix_time(x):  def fix_time(x):  def fix_time(x):  def fix_time(x):  def fix_time(x):  def fix_time(x):  def fix_time(x):  def fix_time(x):  def fix_time(x):  def fix_time(x):  def fix_time(x):  def fix_time(x):  def fix_time(x):  def fix_time(x):  def fix_time(x):  def fix_time(x):  def fix_time(x):  def fix_time(x):  def fix_time(x):  def fix_time(x):  def fix_time(x):  def fix_time(x):  def fix_time(x):  def fix_time(x):  def fix_time(x):  def fix_time(x):  def fix_time(x):  def fix_time(x):  def fix_time(x):  def fix_time(x):  def fix_time(x):  def fix_time(x):  def fix_time(x):  def fix_time(x):  def fix_time(x):  def fix_time(x):  def fix_time(x):  def fix_time(x):  def fix
def is_string_dtype(arr_or_dtype) -> bool:  is_excluded_checks = (is_period_dtype, is_interval_dtype)  return any(is_excluded(dtype) for is_excluded in is_excluded_checks)
def get_subprocess_encoding(): def unescapeHTML(s):      return re.sub(         r'&([^;]+;)', lambda m: _htmlentity_transform(m.group(1)), s)  def get_subprocess_encoding(): def unescapeHTML(s):      return re.sub(         r'&([^;]+;)', lambda m: _htmlentity_transform(m.group(1)), s)  def get_subprocess_encoding(): def unescapeHTML(s):      return re.sub(         r'&([^;]+;)', lambda m: _htmlentity_transform(m.group(1)), s)  def get_subprocess_encoding(): def unescapeHTML(s):      return re.sub(         r'&([^;]+;)', lambda m: _htmlentity_transform(m.group(1)), s)  def get_subprocess_encoding(): def unescapeHTML(s):      return re.sub(         r'&([^;]+;)', lambda m: _htmlentity_transform(m.group(1)), s)  def get_subprocess_encoding(): def unescapeHTML(s):      return re.sub(         r'&([^;]+;)', lambda m: _htmlentity_transform(m.group(1)), s)  def get_subprocess_encoding(): def unescapeHTML(s):      return re.sub(         r'&([^;]+;)', lambda m: _htmlentity_transform(m.group(1)), s)  def get_subprocess_encoding(): def unescapeHTML(s):      return re.sub(         r'&([^;]+;)', lambda m: _htmlentity_transform(m.group(1)), s)  def get_subprocess_encoding(): def unescapeHTML(s):      return re.sub(         r'&([^;]+;)', lambda m: _htmlentity_transform(m.group(1)), s)  def get_subprocess_encoding(): def unescapeHTML(s):      return re.sub(         r'&([^;]+;)', lambda m: _htmlentity_transform(m.group(1)), s)  def get_subprocess_encoding(): def unescapeHTML(s):      return re.sub(         r'&([^;]+;)', lambda
def send_error(self, *args, **kwargs):          if self.stream is None:              self._on_close_called = True              self.on_close()      def send_error(self, *args, **kwargs):          if self.stream is None:              self._on_close_called = True              self.on_close()      def send_error(self, *args, **kwargs):          if self.stream is None:              self._on_close_called = True              self.on_close()      def send_error(self, *args, **kwargs):          if self.stream is None:              self._on_close_called = True              self.on_close()      def send_error(self, *args, **kwargs):          if self.stream is None:              self._on_close_called = True              self.on_close()      def send_error(self, *args, **kwargs):          if self.stream is None:              self._on_close_called = True              self.on_close()      def send_error(self, *args, **kwargs):          if self.stream is None:              self._on_close_called = True              self.on_close()      def send_error(self, *args, **kwargs):          if self.stream is None:              self._on_close_called = True              self.on_close()      def send_error(self, *args, **kwargs):          if self.stream is None:              self._on_close_called = True              self.on_close()      def send_error(self, *args, **kwargs):          if self.stream is None:              self._on_close_called = True              self.on_close()      def send_error(self, *args, **kwargs):          if self.stream is None:              self._on_close_called = True              self.on_close()      def send_error(self, *args, **kwargs):          if self.stream is None:              self._on_close_called = True              self.on_close()      def send_error(self, *args, **kwargs):          if self.stream is None:              self._on_close_called = True              self.on_close()      def send_
patterns = (          '^lua: {file}:{line}:',          '^{file} \(line {line}\):',          '^{file}: line {line}: ',         '^{file}:{line}:',          '^{file}:{line}:{col}',          'at {file} line {line}',      )
def get_request_handler(                  exclude=response_model_exclude,                  by_alias=response_model_by_alias,                  exclude_unset=response_model_exclude_unset,                  is_coroutine=is_coroutine,              )              response = response_class( def get_request_handler(                  exclude=response_model_exclude,                  by_alias=response_model_by_alias,                  exclude_unset=response_model_exclude_unset,                  is_coroutine=is_coroutine,              )              def get_request_handler(                  exclude=response_model_exclude,                  by_alias=response_model_by_alias,                  exclude_unset=response_model_exclude_unset,                  is_coroutine=is_coroutine,              )              response = response_class( def get_request_handler(                  exclude=response_model_exclude,                  by_alias=response_model_by_alias,                  exclude_unset=response_model_exclude_unset,                  is_coroutine=is_coroutine,              )              def get_request_handler(                  exclude=response_model_exclude,                  by_alias=response_model_by_alias,                  exclude_unset=response_model_exclude_unset,                  is_coroutine=is_coroutine,              )              def get_request_handler(                  exclude=response_model_exclude,                  by_alias=response_model_by_alias,                  exclude_unset=response_model_exclude_unset,                  is_coroutine=is_coroutine,              )              def get_request_handler(                  exclude=response_model_exclude,                  by_alias=response_model_by_alias,                  exclude_unset=response_model_exclude_unset,                  is_coroutine=is_coroutine,              )              def get_request_handler(                  exclude=response_model_exclude,                  by_alias=response_model_by_alias,                  exclude_unset=response_model_exclude_unset,                  is_coroutine=is_coroutine,              )              def get_request_handler(                  exclude=response_model_exclude,                  by_alias=response_model_by_alias,                  exclude_unset=response_model_exclude_unset,                  is_coroutine=is_
def shortest_path_lengths(n, length_by_edge):     length_by_path = defaultdict(lambda: float('inf'))     length_by_path.update({(i, i): 0 for i in range(n)):     return shortest_path_lengths(n, length_by_edge)
class ExecutionEngine(object):          d = self._download(request, spider)          d.addBoth(self._handle_downloader_output, request, spider)          d.addErrback(lambda f: logger.info('Error while handling downloader output',                                            extra={'spider': spider, 'failure': f}))          return d      def _handle_downloader_output(self, response, request, spider):      def _download(self, request, spider):      def _handle_downloader_output(self, response, request, spider):      def _download(self, request, spider):      def _handle_downloader_output(self, response, request, spider):      def _handle_downloader_output(self, response, request, spider):      def _handle_downloader_output(self, response, request, spider):      def _handle_downloader_output(self, response, request, spider):      def _handle_downloader_output(self, response, request, spider):      def _handle_downloader_output(self, response, request, spider):      def _handle_downloader_output(self, response, request, spider):      def _handle_downloader_output(self, response, request, spider):      def _handle_downloader_output(self, response, request, spider):      def _handle_downloader_output(self, response, request, spider):      def _handle_downloader_output(self, response, request, spider):      def _handle_downloader_output(self, response, request, spider):      def _handle_downloader_output(self, response, request, spider):      def _handle_downloader_output(self, response, request, spider):      def _handle_downloader_output(self, response, request, spider):      def _handle_downloader_output(self, response, request, spider):      def _handle_downloader_output(self, response, request, spider):      def _handle_downloader_output(self, response, request, spider):      def _handle_downloader_output(self, response, request, spider):      def _handle_downloader_output(self, response, request, spider):      def _handle_downloader_output(self, response, request, spider):
def split_line(      If `py36` is True, splitting may generate syntax that is only compatible      with Python 3.6 and later.  def split_line(          yield line          return  def split_line(      If `py36` is True, splitting may generate syntax that is only compatible      with Python 3.6 and later.  def split_line(          yield line          return  def split_line(      If `py36` is True, splitting may generate syntax that is only compatible      with Python 3.6 and later.  def split_line(          yield line          return  def split_line(      If `py36` is True, splitting may generate syntax that is only compatible      with Python 3.6 and later.  def split_line(          yield line          return  def split_line(      If `py36` is True, splitting may generate syntax that is only compatible      with Python 3.6 and later.  def split_line(          yield line          return  def split_line(      If `py36` is True, splitting may generate syntax that is only compatible      with Python 3.6 and later.  def split_line(          yield line          return  def split_line(      If `py36` is True, splitting may generate syntax that is only compatible      with Python 3.6 and later.  def split_line(          yield line          return  def split_line(      If `py36` is True, splitting may generate syntax that is only compatible      with Python 3.6 and later.  def split_line(          yield line          return  def split_line(      If `py36` is True, splitting may generate syntax that is only compatible      with Python 3.6 and later.  def split_line(          yield line          return  def split_line(      If `py36` is True, splitting may generate syntax that is only compatible      with Python 3.6 and later.  def split_line(          yield line          return  def split_line(      If `py36` is True, splitting may generate syntax that is only compatible      with Python 3.6 and later.  def split_line(          yield line          return  def split_line(      If `py36` is True, splitting may generate syntax that is only compatible      with Python 3
def set_label(self, label, **kw):  def set_label(self, label, **kw):          self._label = str(label)          self._labelkw = kw
class TokenError(Exception): pass  class StopTokenizing(Exception): pass  def TokenError(Exception): pass  def StopTokenizing(Exception): pass  def TokenError(Exception): pass  def StopTokenizing(Exception): pass  def TokenError(Exception): pass  def StopTokenizing(Exception): pass  def TokenError(Exception): pass  def StopTokenizing(Exception): pass  def TokenError(Exception): pass  def StopTokenizing(Exception): pass  def TokenError(Exception): pass  def StopTokenizing(Exception): pass  def TokenError(Exception): pass  def StopTokenizing(Exception): pass  def TokenError(Exception): pass  def StopTokenizing(Exception): pass  def TokenError(Exception): pass  def StopTokenizing(Exception): pass  def TokenError(Exception): pass  def StopTokenizing(Exception): pass  def TokenError(Exception): pass  def StopTokenizing(Exception): pass  def TokenError(Exception): pass  def StopTokenizing(Exception): pass  def TokenError(Exception): pass  def StopTokenizing(Exception): pass  def TokenError(Exception): pass  def StopTokenizing(Exception): pass  def TokenError(Exception): pass  def StopTokenizing(Exception): pass  def TokenError(Exception): pass  def StopTokenizing(Exception): pass  def TokenError(Exception): pass  def StopTokenizing(Exception): pass  def TokenError(Exception): pass  def StopTokenizing(Exception): pass  def TokenError(Exception): pass  def StopTokenizing(Exception): pass  def TokenError(Exception): pass  def StopTokenizing(Exception): pass  def TokenError(Exception): pass  def StopTokenizing(Exception): pass  def TokenError(Exception): pass  def StopTokenizing(Exception): pass  def TokenError(Exception): pass  def StopTokenizing(Exception): pass  def TokenError(Exception): pass  def StopTokenizing(Exception): pass  def TokenError(Exception): pass  def StopTokenizing(Exception): pass  def TokenError(Exception): pass  def StopTokenizing(Exception): pass  def TokenError(Exception): pass  def StopTokenizing(Exception): pass  def TokenError(Exception): pass  def StopTokenizing(Exception): pass  def TokenError(Exception): pass  def StopTokenizing(Exception): pass
class LSTMCell(Layer):                  inputs_f = inputs                  inputs_c = inputs                  inputs_o = inputs              x_i = K.dot(inputs_i, self.kernel_i) + self.bias_i              x_f = K.dot(inputs_f, self.kernel_f) + self.bias_f              x_c = K.dot(inputs_c, self.kernel_c) + self.bias_c              x_o = K.dot(inputs_o, self.kernel_o) + self.bias_o
def TestInsertIndexCoercion(CoercionBase):          )         msg = "cannot insert TimedeltaIndex with incompatible label"          with pytest.raises(TypeError, match=msg):              obj.insert(1, pd.Timestamp("2012-01-01"))         msg = "cannot insert TimedeltaIndex with incompatible label"          with pytest.raises(TypeError, match=msg):              obj.insert(1, 1)
def __enter__(self):          calling_frame = inspect.currentframe().f_back          if not self._is_internal_frame(calling_frame):              calling_frame.f_trace = self.trace              self.target_frames.add(calling_frame)          stack = self.thread_local.__dict__.setdefault('original_trace_functions', [])          stack.append(sys.gettrace())          sys.settrace(self.trace)      def __exit__(self, exc_type, exc_value, exc_traceback):          stack = self.thread_local.original_trace_functions          sys.settrace(stack.pop())          calling_frame = inspect.currentframe().f_back
def match(command):  @git_support  def get_new_command(command):      push_upstream = command.stderr.split('\n')[-3].strip().partition('git ')[2]      return replace_argument(command.script, 'push', push_upstream)
def js_to_json(code):              ([{,]\s*)              ("[^"]*"|\'[^\']*\'|[a-z0-9A-Z]+)              (:\s*)              ([0-9.]+|true|false|"[^"]*"|\'[^\']*\'|\[|\{      res = re.sub(r',(\s*\])', lambda m: m.group(1), res)      return res
def conv_input_length(output_length, filter_size, padding, stride):      return (output_length - 1) * stride - 2 * pad + filter_size def deconv_length(dim_size, stride_size, kernel_size, padding, output_padding):
def _unstack_multiple(data, clocs, fill_value=None):      index = data.index      clocs = [index._get_level_number(i) for i in clocs]      rlocs = [i for i in range(index.nlevels) if i not in clocs]  def _unstack_multiple(data, clocs, fill_value=None):      index = data.index      clocs = [index._get_level_number(i) for i in clocs]      rlocs = [i for i in range(index.nlevels) if i not in clocs]  def _unstack_multiple(data, clocs, fill_value=None):      index = data.index      clocs = [index._get_level_number(i) for i in clocs]      rlocs = [i for i in range(index.nlevels) if i not in clocs]  def _unstack_multiple(data, clocs, fill_value=None):      index = data.index      clocs = [index._get_level_number(i) for i in clocs]      rlocs = [i for i in range(index.nlevels) if i not in clocs]  def _unstack_multiple(data, clocs, fill_value=None):      index = data.index      clocs = [index._get_level_number(i) for i in clocs]      rlocs = [i for i in range(index.nlevels) if i not in clocs]  def _unstack_multiple(data, clocs, fill_value=None):      index = data.index      clocs = [index._get_level_number(i) for i in clocs]      rlocs = [i for i in range(index.nlevels) if i not in clocs]  def _unstack_multiple(data, clocs, fill_value=None):      index = data.index      clocs = [index._get_level_number(i) for i in clocs]      rlocs = [i for i in range(index.nlevels) if i not in clocs]  def _unstack_multiple(data, clocs, fill_value=None):      index = data.index      clocs
class FormatOn(FormatError):  class WriteBack(Enum):      NO = 0      YES = 2 class CannotSplit(Exception):     It holds the number of bytes of the prefix consumed before the format control comment appeared.         unformatted_prefix = leaf.prefix[: self.consumed]         return Leaf(token.NEWLINE, unformatted_prefix) class FormatOn(FormatError):  class WriteBack(Enum):      NO = 0      YES = 2 class CannotSplit(Exception):     It holds the number of bytes of the prefix consumed before the format control comment appeared.         unformatted_prefix = leaf.prefix[: self.consumed]         return Leaf(token.NEWLINE, unformatted_prefix) class FormatOn(FormatError):  class WriteBack(Enum):      NO = 0      YES = 3 class CannotSplit(Exception):     It holds the number of bytes of the prefix consumed before the format control comment appeared.         unformatted_prefix = leaf.prefix[: self.consumed]         return Leaf(token.NEWLINE, unformatted_prefix) class FormatOn(FormatError):  class WriteBack(Enum):      NO = 0      YES = 4 class CannotSplit(Exception):     It holds the number of bytes of the prefix consumed before the format control comment appeared.         unformatted_prefix = leaf.prefix[: self.consumed]         return Leaf(token.NEWLINE, unformatted_prefix) class FormatOn(FormatError):  class WriteBack(Enum):      NO = 0      YES = 5 class CannotSplit(Exception):     It holds the number of bytes of the prefix consumed before the format control comment appeared.         unformatted_prefix = leaf.prefix[: self.consumed]         return Leaf(token.NEWLINE, unformatted_prefix) class FormatOn(FormatError):  class WriteBack(Enum):      NO = 0      YES = 6 class CannotSplit(Exception):     It holds the number of bytes of the prefix consumed before the format control comment appeared.         unformatted_prefix = leaf.prefix[: self.consumed]         return Leaf(token.NEWLINE, unformatted_prefix) class FormatOn(FormatError):  class WriteBack(Enum):      NO = 0      YES = 7 class CannotSplit(Exception):     It holds the number of bytes of the prefix consumed before the format control comment appeared.         unformatted_prefix =
class BlockManager(PandasObject):                          convert=convert,                          regex=regex,                      )                     class BlockManager(PandasObject):                          convert=convert,                          regex=regex,                      )                     class BlockManager(PandasObject):                          convert=convert,                          regex=regex,                      )                     class BlockManager(PandasObject):                          convert=convert,                          regex=regex,                      )                     class BlockManager(PandasObject):                          convert=convert,                          regex=regex,                      )                     class BlockManager(PandasObject):                          convert=convert,                          regex=regex,                      )                     class BlockManager(PandasObject):                          convert=convert,                          regex=regex,                      )                     class BlockManager(PandasObject):                          convert=convert,                          regex=regex,                      )                     class BlockManager(PandasObject):                          convert=convert,                          regex=regex,                      )                     class BlockManager(PandasObject):                          convert=convert,                          regex=regex,                      )                     class BlockManager(PandasObject):                          convert=convert,                          regex=regex,                      )                     class BlockManager(PandasObject):                          convert=convert,                          regex=regex,                      )                     class BlockManager(PandasObject):                          convert=convert,                          regex=regex,                      )                     class BlockManager(PandasObject):                          convert=convert,                          regex=regex,                      )                     class BlockManager(PandasObject):                          convert=convert,                          regex=regex,                      )                     class BlockManager(PandasObject):                          convert=convert,                          regex=regex,                      )                     class BlockManager(PandasObject):                          convert=convert,                          regex=regex,                      )                     class BlockManager(PandasObject):                          convert=convert,                          regex=regex,                      )                     class BlockManager(PandasObject):                          convert=convert,                          regex=regex,                      )                     class BlockManager(PandasObject):                          convert=convert,                          regex=regex,                      )                     class BlockManager(PandasObject):                          convert=convert,                          regex=regex,                      )                     class BlockManager(PandasObject):                          convert=convert,                          regex=regex,                      )                     class BlockManager(PandasObject):                          convert=convert,                          regex=regex,                      )                     class BlockManager(PandasObject):                          convert=convert,                          regex=regex,                      )                     class BlockManager(Pandas

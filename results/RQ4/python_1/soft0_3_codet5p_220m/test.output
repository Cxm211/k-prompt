class GroupBy(_GroupBy):          ).sortlevel()          if self.as_index:              d = {self.obj._get_axis_name(self.axis): index, "copy": False}              return output.reindex(**d)
def HiveCommandClient(HiveClient):  if partition is None:              stdout = run_hive_cmd('use {0}; show tables like "{1}";'.format(database, table))              return stdout and table in stdout
def BinGrouper(BaseGrouper):              ngroups,          )      @cache_readonly      def result_index(self):          if len(self.binlabels)!= 0 and isna(self.binlabels[0]): class BinGrouper(BaseGrouper):              ngroups,          )      @cache_readonly      def result_index(self):          if len(self.binlabels)!= 0 and isna(self.binlabels[0]): class BinGrouper(BaseGrouper):              ngroups,          )      @cache_readonly      def result_index(self):          if len(self.binlabels)!= 0 and isna(self.binlabels[0]): class BinGrouper(BaseGrouper):              ngroups,          )      @cache_readonly      def result_index(self):          if len(self.binlabels)!= 0 and isna(self.binlabels[0]): class BinGrouper(BaseGrouper):              ngroups,          )      @cache_readonly      def result_index(self):          if len(self.binlabels)!= 0 and isna(self.binlabels[0]): class BinGrouper(BaseGrouper):              ngroups,          )      @cache_readonly      def result_index(self):          if len(self.binlabels)!= 0 and isna(self.binlabels[0]): class BinGrouper(BaseGrouper):              ngroups,          )      @cache_readonly      def result_index(self):          if len(self.binlabels)!= 0 and isna(self.binlabels[0]): class BinGrouper(BaseGrouper):              ngroups,          )      @cache_readonly      def result_index(self):          if len(self.binlabels)!= 0 and isna(self.binlabels[0]): class BinGrouper(BaseGrouper):              ngroups,          )      @cache_readonly      def result_index(self):          if len(self.binlabels)!= 0 and isna(self.binlabels[0]): class BinGrouper(BaseGrouper):              ngroups,          )      @cache_readonly      def result_index(self):          if len(self.binlabels)!= 0 and isna
def DataFrame(NDFrame):          dtype: object          nv.validate_transpose(args, dict())         return super().transpose(1, 0, **kwargs)      T = property(transpose)
def target_version_option_callback(  @click.option(      "--config",      type=click.Path(         exists=False, file_okay=True, dir_okay=True, readable=True, allow_dash=False      ),      is_eager=True,      callback=read_pyproject_toml,  ) def target_version_option_callback(  @click.option(      "--config",      type=click.Path(         exists=False, file_okay=True, dir_okay=True, readable=True, allow_dash=False      ),      is_eager=True,      callback=read_pyproject_toml,  ) def target_version_option_callback(  @click.option(      "--config",      type=click.Path(         exists=False, file_okay=True, dir_okay=True, readable=True, allow_dash=False      ),      is_eager=True,      callback=read_pyproject_toml,  ) def target_version_option_callback(  @click.option(      "--config",      type=click.Path(         exists=False, file_okay=True, dir_okay=True, readable=True, allow_dash=False      ),      is_eager=True,      callback=read_pyproject_toml,  ) def target_version_option_callback(  @click.option(      "--config",      type=click.Path(         exists=False, file_okay=True, dir_okay=True, readable=True, allow_dash=False      ),      is_eager=True,      callback=read_pyproject_toml,  ) def target_version_option_callback(  @click.option(      "--config",      type=click.Path(         exists=False, file_okay=True, dir_okay=True, readable=True, allow_dash=False      ),      is_eager=True,      callback=read_pyproject_toml,  ) def target_version_option_callback(  @click.option(      "--config",      type=click.Path(         exists=False, file_okay=
def middleware(self, middleware_or_request):def middleware(self, middleware_or_request):  def middleware(self, middleware_or_request):  def middleware(self, middleware_or_request):  def middleware(self, middleware_or_request):  def middleware(self, middleware_or_request):  def middleware(self, middleware_or_request):  def middleware(self, middleware_or_request):  def middleware(self, middleware_or_request):  def middleware(self, middleware_or_request):  def middleware(self, middleware_or_request):  def middleware(self, middleware_or_request):  def middleware(self, middleware_or_request):  def middleware(self, middleware_or_request):  def middleware(self, middleware_or_request):  def middleware(self, middleware_or_request):  def middleware(self, middleware_or_request):  def middleware(self, middleware_or_request):  def middleware(self, middleware_or_request):  def middleware(self, middleware_or_request):  def middleware(self, middleware_or_request):  def middleware(self, middleware_or_request):  def middleware(self, middleware_or_request):  def middleware(self, middleware_or_request):  def middleware(self, middleware_or_request):  def middleware(self, middleware_or_request):  def middleware(self, middleware_or_request):  def middleware(self, middleware_or_request):  def middleware(self, middleware_or_request):  def middleware(self, middleware_or_request):  def middleware(self, middleware_or_request):  def middleware(self, middleware_or_request):  def middleware(self, middleware_or_request):  def middleware(self, middleware_or_request):  def middleware(self, middleware_or_request):  def middleware(self, middleware_or_request):  def middleware(self, middleware_or_request):  def middleware(self, middleware_or_request):  def middleware(self, middleware_or_request):  def middleware(self, middleware_or_request):  def middleware(self, middleware_or_request):  def middleware(self, middleware_or_request):  def middleware(self, middleware_
def Model(Container):                  enqueuer.start(workers=workers, max_queue_size=max_queue_size)                  output_generator = enqueuer.get()              if verbose == 1:                  progbar = Progbar(target=steps)
def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),      else:          strides = (1, 1) + strides     x = tf.nn.conv2d_transpose(x, kernel, output_shape, strides,                                padding=padding,                                data_format=tf_data_format)      return x  def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),      else:          strides = (1, 1) + strides     x = tf.nn.conv2d_transpose(x, kernel, output_shape, strides,                                padding=padding,                                data_format=tf_data_format)      return x  def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),      else:          strides = (1, 1) + strides     x = tf.nn.conv2d_transpose(x, kernel, output_shape, strides,                                padding=padding,                                data_format=tf_data_format)      return x  def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),      else:          strides = (1, 1) + strides     x = tf.nn.conv2d_transpose(x, kernel, output_shape, strides,                                padding=padding,                                data_format=tf_data_format)      return x  def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),      else:          strides = (1, 1) + strides     x = tf.nn.conv2d_transpose(x, kernel, output_shape, strides,                                padding=padding,                                data_format=tf_data_format)      return x  def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),      else:          strides = (1, 1) + strides     x = tf.nn.conv2d_transpose(x, kernel, output_shape, strides,                                padding=padding,                                data_format=tf_data_format)      return x  def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),      else:          strides = (1
def XportReader(abc.Iterator):  if isinstance(filepath_or_buffer, (str, bytes)):              self.filepath_or_buffer = open(filepath_or_buffer, "rb")          else:             contents = filepath_or_buffer.read()             try:                 contents = contents.encode(self._encoding)             except UnicodeEncodeError:                 pass             self.filepath_or_buffer = BytesIO(contents)          self._read_header()
class LocalCache(collections.OrderedDict):  def __setitem__(self, key, value):          while len(self) >= self.limit:             self.popitem(last=False)          super(LocalCache, self).__setitem__(key, value)
class AsyncioServer:              task = asyncio.ensure_future(coro, loop=self.loop)              return task      def __await__(self):          task = asyncio.ensure_future(self.serve_coro)
def deconv_length(dim_size, stride_size, kernel_size, padding, output_padding):  def deconv_length(dim_size, stride_size, kernel_size, padding, output_padding):      return None  def deconv_length(dim_size, stride_size, kernel_size, padding, output_padding):      return None  def deconv_length(dim_size, stride_size, kernel_size, padding, output_padding):      return None  def deconv_length(dim_size, stride_size, kernel_size, padding, output_padding):      return None  def deconv_length(dim_size, stride_size, kernel_size, padding, output_padding):      return None  def deconv_length(dim_size, stride_size, kernel_size, padding, output_padding):      return None  def deconv_length(dim_size, stride_size, kernel_size, padding, output_padding):      return None  def deconv_length(dim_size, stride_size, kernel_size, padding, output_padding):      return None  def deconv_length(dim_size, stride_size, kernel_size, padding, output_padding):      return None  def deconv_length(dim_size, stride_size, kernel_size, padding, output_padding):      return None  def deconv_length(dim_size, stride_size, kernel_size, padding, output_padding):      return None  def deconv_length(dim_size, stride_size, kernel_size, padding, output_padding):      return None  def deconv_length(dim_size, stride_size, kernel_size, padding, output_padding):      return None  def deconv_length(dim_size, stride_size, kernel_size, padding, output_padding):      return None  def deconv_length(dim_size, stride_size, kernel_size, padding, output_padding):      return None  def deconv_length(dim_size, stride_size, kernel_size, padding, output_padding):      return None  def deconv_length(dim_size, stride_size, kernel_size, padding, output_padding):      return None  def deconv_length(dim_size
def fit_generator(model,              elif val_gen:                  val_data = validation_data              else:                      val_enqueuer_gen = iter_sequence_infinite(generator) def fit_generator(model,              elif val_gen:                  val_data = validation_data              else:                      val_enqueuer_gen = iter_sequence_infinite(generator) def fit_generator(model,              elif val_gen:                  val_data = validation_data              else:                      val_enqueuer_gen = iter_sequence_infinite(generator) def fit_generator(model,              elif val_gen:                  val_data = validation_data              else:                      val_enqueuer_gen = iter_sequence_infinite(generator) def fit_generator(model,              elif val_gen:                  val_data = validation_data              else:                      val_enqueuer_gen = iter_sequence_infinite(generator) def fit_generator(model,              elif val_gen:                  val_data = validation_data              else:                      val_enqueuer_gen = iter_sequence_infinite(generator) def fit_generator(model,              elif val_gen:                  val_data = validation_data              else:                      val_enqueuer_gen = iter_sequence_infinite(generator) def fit_generator(model,              elif val_gen:                  val_data = validation_data              else:                      val_enqueuer_gen = iter_sequence_infinite(generator) def fit_generator(model,              elif val_gen:                  val_data = validation_data              else:                      val_enqueuer_gen = iter_sequence_infinite(generator) def fit_generator(model,              elif val_gen:                  val_data = validation_data              else:                      val_enqueuer_gen = iter_sequence_infinite(generator) def fit_generator(model,              elif val_gen:                  val_data = validation_data              else:                      val_enqueuer_gen = iter_sequence_infinite(generator) def fit_generator(model,              elif val_gen:                  val_data = validation_data              else:                      val_enqueuer_gen = iter_sequence_
def FastParquetImpl(BaseImpl):          if partition_cols is not None:              kwargs["file_scheme"] = "hive"         if is_s3_url(path):              path, _, _, _ = get_filepath_or_buffer(path, mode="wb")              kwargs["open_with"] = lambda path, _: path          else:              path, _, _, _ = get_filepath_or_buffer(path)
def NumpyArrayIterator(Iterator):                             dtype=K.floatx()          for i, j in enumerate(index_array):              x = self.x[j]              x = self.image_data_generator.random_transform(x.astype(K.floatx()))              x = self.image_data_generator.standardize(x)              batch_x[i] = x
def HTTPRequest(HTTPMessage):          headers = dict(self._orig.headers)          class HTTPRequest(HTTPMessage):          def __init__(self, url):          self._orig = url class HTTPRequest(HTTPMessage):          def __init__(self, url):          self._orig = url class HTTPRequest(HTTPMessage):          def __init__(self, url):          self._orig = url class HTTPRequest(HTTPMessage):          def __init__(self, url):          self._orig = url class HTTPRequest(HTTPMessage):          def __init__(self, url):          self._orig = url class HTTPRequest(HTTPMessage):          def __init__(self, url):          self._orig = url class HTTPRequest(HTTPMessage):          def __init__(self, url):          self._orig = url class HTTPRequest(HTTPMessage):          def __init__(self, url):          self._orig = url class HTTPRequest(HTTPMessage):          def __init__(self, url):          self._orig = url class HTTPRequest(HTTPMessage):          def __init__(self, url):          self._orig = url class HTTPRequest(HTTPMessage):          def __init__(self, url):          self._orig = url class HTTPRequest(HTTPMessage):          def __init__(self, url):          self._orig = url class HTTPRequest(HTTPMessage):          def __init__(self, url):          self._orig = url class HTTPRequest(HTTPMessage):          def __init__(self, url):          self._orig = url class HTTPRequest(HTTPMessage):          def __init__(self, url):          self._orig = url class HTTPRequest(HTTPMessage):          def __init__(self, url):          self._orig = url class HTTPRequest(HTTPMessage):          def __init__(self, url):          self._orig = url class HTTPRequest(HTTPMessage):          def __init__(self, url):          self._orig = url class HTTPRequest(HTTPMessage):          def __init__(self, url):          self._orig = url class HTTPRequest(HTTPMessage):          def __init__(self, url):          self._orig = url class HTTPRequest(HTTPMessage):          def __init__(self, url):          self._orig = url class HTTPRequest(HTTPMessage):          def __
def __init__(self):  def __init__(self):          self.deferred = defer.Deferred()         self.out = ''         self.err = ''          self.exitcode = None      def outReceived(self, data):  def outReceived(self, data):  def outReceived(self, data):  def outReceived(self, data):  def outReceived(self, data):  def outReceived(self, data):  def outReceived(self, data):  def outReceived(self, data):  def outReceived(self, data):  def outReceived(self, data):  def outReceived(self, data):  def outReceived(self, data):  def outReceived(self, data):  def outReceived(self, data):  def outReceived(self, data):  def outReceived(self, data):  def outReceived(self, data):  def outReceived(self, data):  def outReceived(self, data):  def outReceived(self, data):  def outReceived(self, data):  def outReceived(self, data):  def outReceived(self, data):  def outReceived(self, data):  def outReceived(self, data):  def outReceived(self, data):  def outReceived(self, data):  def outReceived(self, data):  def outReceived(self, data):  def outReceived(self, data):  def outReceived(self, data):  def outReceived(self, data):  def outReceived(self, data):  def outReceived(self, data):  def outReceived(self, data):  def outReceived(self, data):  def outReceived(self, data):  def outReceived(self, data):  def outReceived(self, data):  def outReceived(self, data):  def outReceived(self, data):  def outReceived(self, data):  def outReceived(self, data):  def outReceived(self, data):  def outReceived(self, data):  def outReceived(self, data):  def outReceived(self, data):  def outReceived(self, data):  def outReceived(self, data):  def outReceived(self, data):  def outReceived(self, data):  def outReceived(self, data
def _Window(PandasObject, SelectionMixin):              except (ValueError, TypeError):                  raise TypeError("cannot handle this type -> {0}".format(values.dtype)) class _Window(PandasObject, SelectionMixin):              except (ValueError, TypeError):                  raise TypeError("cannot handle this type -> {0}".format(values.dtype)) class _Window(PandasObject, SelectionMixin):              except (ValueError, TypeError):                  raise TypeError("cannot handle this type -> {0}".format(values.dtype)) class _Window(PandasObject, SelectionMixin):              except (ValueError, TypeError):                  raise TypeError("cannot handle this type -> {0}".format(values.dtype)) class _Window(PandasObject, SelectionMixin):              except (ValueError, TypeError):                  raise TypeError("cannot handle this type -> {0}".format(values.dtype)) class _Window(PandasObject, SelectionMixin):              except (ValueError, TypeError):                  raise TypeError("cannot handle this type -> {0}".format(values.dtype)) class _Window(PandasObject, SelectionMixin):              except (ValueError, TypeError):                  raise TypeError("cannot handle this type -> {0}".format(values.dtype)) class _Window(PandasObject, SelectionMixin):              except (ValueError, TypeError):                  raise TypeError("cannot handle this type -> {0}".format(values.dtype)) class _Window(PandasObject, SelectionMixin):              except (ValueError, TypeError):                  raise TypeError("cannot handle this type -> {0}".format(values.dtype)) class _Window(PandasObject, SelectionMixin):              except (ValueError, TypeError):                  raise TypeError("cannot handle this type -> {0}".format(values.dtype)) class _Window(PandasObject, SelectionMixin):              except (ValueError, TypeError):                  raise TypeError("cannot handle this type -> {0}".format(values.dtype)) class _Window(PandasObject, SelectionMixin):              except (ValueError, TypeError):                  raise TypeError("cannot handle this type -> {0}".format(values.dtype)) class _Window(PandasObject, SelectionMixin):              except (ValueError, TypeError):                  raise TypeError("cannot handle this type -> {0}".format(values.dtype)) class _Window(PandasObject, SelectionMixin):              except (ValueError,
def BaseComparisonOpsTests(BaseOpsUtil):  def result is NotImplemented          else:              raise pytest.skip(f"{type(data).__name__} does not implement __eq__")
class CentralPlannerScheduler(Scheduler):          tasks.sort(key=self._rank(), reverse=True)          def _rank(self):              return 0  class CentralPlannerScheduler(Scheduler):          tasks.sort(key=self._rank(), reverse=True)          def _rank(self):              return 1  class CentralPlannerScheduler(Scheduler):          tasks.sort(key=self._rank(), reverse=True)          def _rank(self):              return 2  class CentralPlannerScheduler(Scheduler):          tasks.sort(key=self._rank(), reverse=True)          def _rank(self):              return 3  class CentralPlannerScheduler(Scheduler):          tasks.sort(key=self._rank(), reverse=True)          def _rank(self):              return 4  class CentralPlannerScheduler(Scheduler):          tasks.sort(key=self._rank(), reverse=True)          def _rank(self):              return 5  class CentralPlannerScheduler(Scheduler):          tasks.sort(key=self._rank(), reverse=True)          def _rank(self):              return 6  class CentralPlannerScheduler(Scheduler):          tasks.sort(key=self._rank(), reverse=True)          def _rank(self):              return 7  class CentralPlannerScheduler(Scheduler):          tasks.sort(key=self._rank(), reverse=True)          def _rank(self):              return 8  class CentralPlannerScheduler(Scheduler):          tasks.sort(key=self._rank(), reverse=True)          def _rank(self):              return 9  class CentralPlannerScheduler(Scheduler):          tasks.sort(key=self._rank(), reverse=True)          def _rank(self):              return 10  class CentralPlannerScheduler(Scheduler):          tasks.sort(key=self._rank(), reverse=True)          def _rank(self):              return 11  class CentralPlannerScheduler(Scheduler):          tasks.sort(key=self._rank(), reverse=True)          def _rank(self):              return 12  class CentralPlannerScheduler(Scheduler):          tasks.sort(key=self._rank(), reverse=True)          def _rank(self):              return 13  class CentralPlannerScheduler
def jsonable_encoder(                      exclude=exclude,                      by_alias=by_alias,                      exclude_unset=exclude_unset,                     include_none=include_none,                      custom_encoder=custom_encoder,                      sqlalchemy_safe=sqlalchemy_safe,                  )def jsonable_encoder(                      exclude=exclude,                      by_alias=by_alias,                      exclude_unset=exclude_unset,                     include_none=include_none,                      custom_encoder=custom_encoder,                      sqlalchemy_safe=sqlalchemy_safe,                  )def jsonable_encoder(                      exclude=exclude,                      by_alias=by_alias,                      exclude_unset=exclude_unset,                     include_none=include_none,                      custom_encoder=custom_encoder,                      sqlalchemy_safe=sqlalchemy_safe,                  )def jsonable_encoder(                      exclude=exclude,                      by_alias=by_alias,                      exclude_unset=exclude_unset,                     include_none=include_none,                      custom_encoder=custom_encoder,                      sqlalchemy_safe=sqlalchemy_safe,                  )def jsonable_encoder(                      exclude=exclude,                      by_alias=by_alias,                      exclude_unset=exclude_unset,                     include_none=include_none,                      custom_encoder=custom_encoder,                      sqlalchemy_safe=sqlalchemy_safe,                  )def jsonable_encoder(                      exclude=exclude,                      by_alias=by_alias,                      exclude_unset=exclude_unset,                     include_none=include_none,                      custom_encoder=custom_encoder,                      sqlalchemy_safe=sqlalchemy_safe,                  )def jsonable_encoder(                      exclude=exclude,                      by_alias=by_alias,                      exclude_unset=exclude_unset,                     include_none=include_none,                      custom_encoder=custom_encoder,                      sqlalchemy_safe=sqlalchemy_safe,                  )def jsonable_encoder(                      exclude=exclude,                      by_alias=by_alias,                      exclude_unset=exclude_unset,                     include_none=include_none,                      custom_encoder=custom_encoder,                      sqlalchemy_safe=sqlalchemy_safe,                  )def jsonable_encoder(                      exclude=exclude,                      by_alias=by_alias,                      exclude_unset=exclude_unset,
def unified_timestamp(date_str, day_first=True):      date_str = date_str.replace(',','')      pm_delta = datetime.timedelta(hours=12 if re.search(r'(?i)PM', date_str)      timezone, date_str = extract_timezone(date_str)      return unified_timestamp(date_str, day_first=False)
def eb_wrapper(failure):              case = _create_testcase(method, 'errback')              exc_info = failure.value, failure.type, failure.getTracebackObject()              results.addError(case, exc_info)          request.callback = cb_wrapper
def APIRouter(routing.Router):              response_model_exclude_unset=bool(                  response_model_exclude_unset or response_model_skip_defaults              ),              include_in_schema=include_in_schema,              response_class=response_class or self.default_response_class,              name=name,
def format_file_in_place(          return False      def format_file_in_place(          return False      def format_file_in_place(          return False      def format_file_in_place(          return False      def format_file_in_place(          return False      def format_file_in_place(          return False      def format_file_in_place(          return False      def format_file_in_place(          return False      def format_file_in_place(          return False      def format_file_in_place(          return False      def format_file_in_place(          return False      def format_file_in_place(          return False      def format_file_in_place(          return False      def format_file_in_place(          return False      def format_file_in_place(          return False      def format_file_in_place(          return False      def format_file_in_place(          return False      def format_file_in_place(          return False      def format_file_in_place(          return False      def format_file_in_place(          return False      def format_file_in_place(          return False      def format_file_in_place(          return False      def format_file_in_place(          return False      def format_file_in_place(          return False      def format_file_in_place(          return False      def format_file_in_place(          return False      def format_file_in_place(          return False      def format_file_in_place(          return False      def format_file_in_place(          return False      def format_file_in_place(          return False      def format_file_in_place(          return False      def format_file_in_place(          return False      def format_file_in_place(          return False      def format_file_in_place(          return False      def format_file_in_place(          return False      def format_file_in_place(          return False      def format_file_in_place(          return False      def format_file_in_place(          return False      def format_file_in_place(          return False      def format_
def should_series_dispatch(left, right, op):  return True      return False
def run_script(script_path, cwd='.'):          shell=run_thru_shell,          cwd=cwd      return proc.wait()  def run_script_with_context(script_path, cwd, context): def run_script_with_context(script_path, cwd, context): def run_script_with_context(script_path, cwd, context): def run_script_with_context(script_path, cwd, context): def run_script_with_context(script_path, cwd, context): def run_script_with_context(script_path, cwd, context): def run_script_with_context(script_path, cwd, context): def run_script_with_context(script_path, cwd, context): def run_script_with_context(script_path, cwd, context): def run_script_with_context(script_path, cwd, context): def run_script_with_context(script_path, cwd, context): def run_script_with_context(script_path, cwd, context): def run_script_with_context(script_path, cwd, context): def run_script_with_context(script_path, cwd, context): def run_script_with_context(script_path, cwd, context): def run_script_with_context(script_path, cwd, context): def run_script_with_context(script_path, cwd, context): def run_script_with_context(script_path, cwd, context): def run_script_with_context(script_path, cwd, context): def run_script_with_context(script_path, cwd, context): def run_script_with_context(script_path, cwd, context): def run_script_with_context(script_path, cwd, context): def run_script_with_context(script_path, cwd, context): def run_script_with_context(script_path, cwd, context): def run_script_with_context(script_path, cwd, context): def run_script_with_context(script_path, cwd, context): def run_script_with_context(script_path, cwd, context): def run_script_with_context(script_path, cwd, context):
def ExecutionEngine(object):          d = self.scraper.enqueue_scrape(response, request, spider)          d.addErrback(lambda f: logger.error('Error while enqueuing downloader output',                                              extra={'spider': spider, 'failure': f}))          return d
class InfoExtractor(object):      f['url'] = initialization_url                                  f['fragments'].append({location_key(initialization_url): initialization_url})                              f['fragments'].extend(representation_ms_info['fragments']) class InfoExtractor(object):      f['url'] = initialization_url                                  f['fragments'].append({location_key(initialization_url): initialization_url}) class InfoExtractor(object):      f['url'] = initialization_url                                  f['fragments'].append({location_key(initialization_url): initialization_url}) class InfoExtractor(object):      f['url'] = initialization_url                                  f['fragments'].append({location_key(initialization_url): initialization_url}) class InfoExtractor(object):      f['url'] = initialization_url                                  f['fragments'].append({location_key(initialization_url): initialization_url}) class InfoExtractor(object):      f['url'] = initialization_url                                  f['fragments'].append({location_key(initialization_url): initialization_url}) class InfoExtractor(object):      f['url'] = initialization_url                                  f['fragments'].append({location_key(initialization_url): initialization_url}) class InfoExtractor(object):      f['url'] = initialization_url                                  f['fragments'].append({location_key(initialization_url): initialization_url}) class InfoExtractor(object):      f['url'] = initialization_url                                  f['fragments'].append({location_key(initialization_url): initialization_url}) class InfoExtractor(object):      f['url'] = initialization_url                                  f['fragments'].append({location_key(initialization_url): initialization_url}) class InfoExtractor(object):      f['url'] = initialization_url                                  f['fragments'].append({location_key(initialization_url): initialization_url}) class InfoExtractor(object):      f['url'] = initialization_url                                  f['fragments'].append({location_key(initialization_url): initialization_url}) class InfoExtractor(object):      f['url'] = initialization_url                                  f['fragments'].append({location_key(initialization_url): initialization_url}) class InfoExtractor(object):      f['url'] = initialization_url                                  f['fragments'].append({location_key(initial
class APIRouter(routing.Router):                      response_model_exclude=route.response_model_exclude,                      response_model_by_alias=route.response_model_by_alias,                      response_model_exclude_unset=route.response_model_exclude_unset,                      include_in_schema=route.include_in_schema,                      response_class=route.response_class or default_response_class,
def validate_baseindexer_support(func_name: Optional[str]) -> None:          "median",          "std",          "var",          "kurt",          "quantile", def validate_baseindexer_support(func_name: Optional[str]) -> None:          "median",          "std",          "var",          "kurt",          "quantile", def validate_baseindexer_support(func_name: Optional[str]) -> None:          "median",          "std",          "var",          "kurt",          "quantile", def validate_baseindexer_support(func_name: Optional[str]) -> None:          "median",          "std",          "var",          "kurt",          "quantile", def validate_baseindexer_support(func_name: Optional[str]) -> None:          "median",          "std",          "var",          "kurt",          "quantile", def validate_baseindexer_support(func_name: Optional[str]) -> None:          "median",          "std",          "var",          "kurt",          "quantile", def validate_baseindexer_support(func_name: Optional[str]) -> None:          "median",          "std",          "var",          "kurt",          "quantile", def validate_baseindexer_support(func_name: Optional[str]) -> None:          "median",          "std",          "var",          "kurt",          "quantile", def validate_baseindexer_support(func_name: Optional[str]) -> None:          "median",          "std",          "var",          "kurt",          "quantile", def validate_baseindexer_support(func_name: Optional[str]) -> None:          "median",          "std",          "var",          "kurt",          "quantile", def validate_baseindexer_support(func_name: Optional[str]) -> None:          "median",          "std",          "var",          "kurt",          "quantile", def validate_baseindexer_support(func_name: Optional[str]) -> None:          "median",          "std",          "var",          "kurt",
def _decorate_ticks(self, ax, name, ticklabels, start_edge, end_edge):  def _decorate_ticks(self, ax, name, ticklabels, start_edge, end_edge):  def _decorate_ticks(self, ax, name, ticklabels, start_edge, end_edge):  def _decorate_ticks(self, ax, name, ticklabels, start_edge, end_edge):  def _decorate_ticks(self, ax, name, ticklabels, start_edge, end_edge):      def _decorate_ticks(self, ax, name, ticklabels, start_edge, end_edge):      def _decorate_ticks(self, ax, name, ticklabels, start_edge, end_edge):      def _decorate_ticks(self, ax, name, ticklabels, start_edge, end_edge):      def _decorate_ticks(self, ax, name, ticklabels, start_edge, end_edge):      def _decorate_ticks(self, ax, name, ticklabels, start_edge, end_edge):      def _decorate_ticks(self, ax, name, ticklabels, start_edge, end_edge):      def _decorate_ticks(self, ax, name, ticklabels, start_edge, end_edge):      def _decorate_ticks(self, ax, name, ticklabels, start_edge, end_edge):      def _decorate_ticks(self, ax, name, ticklabels, start_edge, end_edge):      def _decorate_ticks(self, ax, name, ticklabels, start_edge, end_edge):      def _decorate_ticks(self, ax, name, ticklabels, start_edge, end_edge):      def _decorate_ticks(self, ax, name, ticklabels, start_edge, end_edge):      def _decorate_ticks(self, ax, name, ticklabels, start_edge, end_edge):      def _decorate_ticks(self, ax, name, ticklabels, start_edge, end_edge):      def _decorate_ticks(self, ax, name, ticklabels, start_edge, end_edge):      def _decorate_ticks(self, ax
def match(command, settings):  def get_new_command(command, settings):      cmds = command.script.split(' ')      machine = ""      return shells.and_("vagrant up " +  machine, command.script)
def is_trivial_worker(self, state):      def is_trivial_worker(self, state):          return state.get_pending_tasks()      def is_trivial_worker(self, state):          return state.get_pending_tasks()      def is_trivial_worker(self, state):          return state.get_pending_tasks()      def is_trivial_worker(self, state):          return state.get_pending_tasks()      def is_trivial_worker(self, state):          return state.get_pending_tasks()      def is_trivial_worker(self, state):          return state.get_pending_tasks()      def is_trivial_worker(self, state):          return state.get_pending_tasks()      def is_trivial_worker(self, state):          return state.get_pending_tasks()      def is_trivial_worker(self, state):          return state.get_pending_tasks()      def is_trivial_worker(self, state):          return state.get_pending_tasks()      def is_trivial_worker(self, state):          return state.get_pending_tasks()      def is_trivial_worker(self, state):          return state.get_pending_tasks()      def is_trivial_worker(self, state):          return state.get_pending_tasks()      def is_trivial_worker(self, state):          return state.get_pending_tasks()      def is_trivial_worker(self, state):          return state.get_pending_tasks()      def is_trivial_worker(self, state):          return state.get_pending_tasks()      def is_trivial_worker(self, state):          return state.get_pending_tasks()      def is_trivial_worker(self, state):          return state.get_pending_tasks()      def is_trivial_worker(self, state):          return state.get_pending_tasks()      def is_trivial_worker(self, state):          return state.get_pending_tasks()      def is_trivial_worker(self, state):          return state.get_pending_tasks()      def is_trivial_worker(self, state):          return
def pivot_table(                  agged[v] = maybe_downcast_to_dtype(agged[v], data[v].dtype)      table = agged     def pivot_table(                  agged[v] = maybe_downcast_to_dtype(agged[v], data[v].dtype)  def pivot_table(                  agged[v] = maybe_downcast_to_dtype(agged[v], data[v].dtype)  def pivot_table(                  agged[v] = maybe_downcast_to_dtype(agged[v], data[v].dtype)  def pivot_table(                  agged[v] = maybe_downcast_to_dtype(agged[v], data[v].dtype)  def pivot_table(                  agged[v] = maybe_downcast_to_dtype(agged[v], data[v].dtype)  def pivot_table(                  agged[v] = maybe_downcast_to_dtype(agged[v], data[v].dtype)  def pivot_table(                  agged[v] = maybe_downcast_to_dtype(agged[v], data[v].dtype)  def pivot_table(                  agged[v] = maybe_downcast_to_dtype(agged[v], data[v].dtype)  def pivot_table(                  agged[v] = maybe_downcast_to_dtype(agged[v], data[v].dtype)  def pivot_table(                  agged[v] = maybe_downcast_to_dtype(agged[v], data[v].dtype)  def pivot_table(                  agged[v] = maybe_downcast_to_dtype(agged[v], data[v].dtype)  def pivot_table(                  agged[v] = maybe_downcast_to_dtype(agged[v], data[v].dtype)  def pivot_table(                  agged[v] = maybe_downcast_to_dtype(agged[v], data[v].dtype)  def pivot_table(                  agged[v] = maybe_downcast_to_dtype(agged[v], data[v].dtype)  def pivot_table(                  agged[v
def create_cloned_field(field: ModelField) -> ModelField:              original_type.__name__, __config__=original_type.__config          )          for f in original_type.__fields__.values():             use_type.__fields__[f.name]          use_type.__validators__      if PYDANTIC_1:          new_field = ModelField( original_type.__name__, __config__=original_type.__config          )          return new_field  def create_cloned_field(field: ModelField) -> ModelField:              original_type.__name__, __config__=original_type.__config          )          for f in original_type.__fields__.values():             use_type.__fields__[f.name]          use_type.__validators__      if PYDANTIC_1:          new_field = ModelField( original_type.__name__, __config__=original_type.__config          )          return new_field  def create_cloned_field(field: ModelField) -> ModelField:              original_type.__name__, __config__=original_type.__config          )          for f in original_type.__fields__.values():             use_type.__fields__[f.name]          use_type.__validators__      if PYDANTIC_1:          new_field = ModelField( original_type.__name__, __config__=original_type.__config          )          return new_field  def create_cloned_field(field: ModelField) -> ModelField:              original_type.__name__, __config__=original_type.__config          )          for f in original_type.__fields__.values():             use_type.__fields__[f.name]          use_type.__validators__      if PYDANTIC_1:          new_field = ModelField( original_type.__name__, __config__=original_type.__config          )          return new_field  def create_cloned_field(field: ModelField) -> ModelField:              original_type.__name__, __config__=original_type.__config          )          for f in original_type.__fields__.values():             use_type.__fields__[f.name]          use_type.__validators__      if PYDANTIC_
def read_conllx(input_data, use_morphology=False, n=0):                      continue                  try:                      id_ = int(id_) - 1                     head = (int(head) - 1) if head!= "0"                      dep = "ROOT" if dep == "root" else dep                      tag = pos if tag == "_" else tag                      tag = tag + "__" def read_conllx(input_data, use_morphology=False, n=0):                      continue                  try:                      id_ = int(id_) - 1                     head = (int(head) - 1) if head!= "0"                      dep = "ROOT" if dep == "root" else dep                      tag = pos if tag == "_" else tag                      tag = tag + "__" def read_conllx(input_data, use_morphology=False, n=0):                      continue                  try:                      id_ = int(id_) - 1                     head = (int(head) - 1) if head!= "0"                      dep = "ROOT" if dep == "root" else dep                      tag = pos if tag == "_" else tag                      tag = tag + "__" def read_conllx(input_data, use_morphology=False, n=0):                      continue                  try:                      id_ = int(id_) - 1                     head = (int(head) - 1) if head!= "0"                      dep = "ROOT" if dep == "root" else dep                      tag = pos if tag == "_" else tag                      tag = tag + "__" def read_conllx(input_data, use_morphology=False, n=0):                      continue                  try:                      id_ = int(id_) - 1                     head = (int(head) - 1) if head!= "0"                      dep = "ROOT" if dep == "root" else dep                      tag = pos if tag == "_" else tag                      tag = tag + "__" def read_conllx(input_data, use_morphology=False, n=0):                      continue                  try:                      id_ = int(id_) - 1                     head = (int(head) - 1) if head!= "0"                      dep = "ROOT" if dep == "root" else dep
def BaseReshapingTests(BaseExtensionTests):          result[0]          assert data[0] == data[1] class BaseReshapingTests(BaseExtensionTests):          result[0]          assert data[0] == data[1] class BaseReshapingTests(BaseExtensionTests):          result[0]          assert data[0] == data[1] class BaseReshapingTests(BaseExtensionTests):          result[0]          assert data[0] == data[1] class BaseReshapingTests(BaseExtensionTests):          result[0]          assert data[0] == data[1] class BaseReshapingTests(BaseExtensionTests):          result[0]          assert data[0] == data[1] class BaseReshapingTests(BaseExtensionTests):          result[0]          assert data[0] == data[1] class BaseReshapingTests(BaseExtensionTests):          result[0]          assert data[0] == data[1] class BaseReshapingTests(BaseExtensionTests):          result[0]          assert data[0] == data[1] class BaseReshapingTests(BaseExtensionTests):          result[0]          assert data[0] == data[1] class BaseReshapingTests(BaseExtensionTests):          result[0]          assert data[0] == data[1] class BaseReshapingTests(BaseExtensionTests):          result[0]          assert data[0] == data[1] class BaseReshapingTests(BaseExtensionTests):          result[0]          assert data[0] == data[1] class BaseReshapingTests(BaseExtensionTests):          result[0]          assert data[0] == data[1] class BaseReshapingTests(BaseExtensionTests):          result[0]          assert data[0] == data[1] class BaseReshapingTests(BaseExtensionTests):          result[0]          assert data[0] == data[1] class BaseReshapingTests(BaseExtensionTests):          result[0]          assert data[0] == data[1] class BaseReshapingTests(BaseExtensionTests):          result[0]          assert data[0] == data[1] class BaseReshapingTests
class CorrectedCommand(object):              compatibility_call(self.side_effect, old_cmd, self.script) class CorrectedCommand(object):              compatibility_call(self.side_effect, old_cmd, self.script) class CorrectedCommand(object):              compatibility_call(self.side_effect, old_cmd, self.script) class CorrectedCommand(object):              compatibility_call(self.side_effect, old_cmd, self.script) class CorrectedCommand(object):              compatibility_call(self.side_effect, old_cmd, self.script) class CorrectedCommand(object):              compatibility_call(self.side_effect, old_cmd, self.script) class CorrectedCommand(object):              compatibility_call(self.side_effect, old_cmd, self.script) class CorrectedCommand(object):              compatibility_call(self.side_effect, old_cmd, self.script) class CorrectedCommand(object):              compatibility_call(self.side_effect, old_cmd, self.script) class CorrectedCommand(object):              compatibility_call(self.side_effect, old_cmd, self.script) class CorrectedCommand(object):              compatibility_call(self.side_effect, old_cmd, self.script) class CorrectedCommand(object):              compatibility_call(self.side_effect, old_cmd, self.script) class CorrectedCommand(object):              compatibility_call(self.side_effect, old_cmd, self.script) class CorrectedCommand(object):              compatibility_call(self.side_effect, old_cmd, self.script) class CorrectedCommand(object):              compatibility_call(self.side_effect, old_cmd, self.script) class CorrectedCommand(object):              compatibility_call(self.side_effect, old_cmd, self.script) class CorrectedCommand(object):              compatibility_call(self.side_effect, old_cmd, self.script) class CorrectedCommand(object):              compatibility_call(self.side_effect, old_cmd, self.script) class CorrectedCommand(object):              compatibility_call(self.side_effect, old_cmd, self.
def add_codes(err_cls):      class ErrorsWithCodes(object):      def __getattribute__(self, code):             msg = getattr(err_cls, code)      return ErrorsWithCodes()
class GroupBy(_GroupBy): func(**kwargs)              if result_is_index:                 result = algorithms.take_nd(obj.values, result)              if post_processing:                  result = post_processing(result, inferences) class GroupBy(_GroupBy): func(**kwargs)              if result_is_index:                 result = algorithms.take_nd(obj.values, result)              if post_processing:                  result = post_processing(result, inferences) class GroupBy(_GroupBy): func(**kwargs)              if result_is_index:                 result = algorithms.take_nd(obj.values, result)              if post_processing:                  result = post_processing(result, inferences) class GroupBy(_GroupBy): func(**kwargs)              if result_is_index:                 result = algorithms.take_nd(obj.values, result)              if post_processing:                  result = post_processing(result, inferences) class GroupBy(_GroupBy): func(**kwargs)              if result_is_index:                 result = algorithms.take_nd(obj.values, result)              if post_processing:                  result = post_processing(result, inferences) class GroupBy(_GroupBy): func(**kwargs)              if result_is_index:                 result = algorithms.take_nd(obj.values, result)              if post_processing:                  result = post_processing(result, inferences) class GroupBy(_GroupBy): func(**kwargs)              if result_is_index:                 result = algorithms.take_nd(obj.values, result)              if post_processing:                  result = post_processing(result, inferences) class GroupBy(_GroupBy): func(**kwargs)              if result_is_index:                 result = algorithms.take_nd(obj.values, result)              if post_processing:                  result = post_processing(result, inferences) class GroupBy(_GroupBy): func(**kwargs)              if result_is_index:                 result = algorithms.take_nd(obj.values, result)              if post_processing:                  result = post_processing(result, inferences) class GroupBy(_GroupBy): func(**kwargs)              if result_is_index:                 result = algorithms.take_nd(obj.values, result
def _isna_ndarraylike_old(obj):  return result  def notna(obj):      Detect non-missing values for an array-like object. def _isna_ndarraylike_old(obj):  return result  def notna(obj):      Detect non-missing values for an array-like object. def _isna_ndarraylike_old(obj):  return result  def notna(obj):      Detect non-missing values for an array-like object. def _isna_ndarraylike_old(obj):  return result  def notna(obj):      Detect non-missing values for an array-like object. def _isna_ndarraylike_old(obj):  return result  def notna(obj):      Detect non-missing values for an array-like object. def _isna_ndarraylike_old(obj):  return result  def notna(obj):      Detect non-missing values for an array-like object. def _isna_ndarraylike_old(obj):  return result  def notna(obj):      Detect non-missing values for an array-like object. def _isna_ndarraylike_old(obj):  return result  def notna(obj):      Detect non-missing values for an array-like object. def _isna_ndarraylike_old(obj):  return result  def notna(obj):      Detect non-missing values for an array-like object. def _isna_ndarraylike_old(obj):  return result  def notna(obj):      Detect non-missing values for an array-like object. def _isna_ndarraylike_old(obj):  return result  def notna(obj):      Detect non-missing values for an array-like object. def _isna_ndarraylike_old(obj):  return result  def notna(obj):      Detect non-missing values for an array-like object. def _isna_ndarraylike_old(obj):  return result  def notna(obj):      Detect non-missing values for an array-like object. def _isna_ndarraylike_old(obj):  return result  def notna(obj):      Detect non-missing values for an array-like object. def _isna_ndarray
def _LocIndexer(_LocationIndexer):  if isinstance(labels, MultiIndex):             if isinstance(key, str) and labels.levels[0].is_all_dates:                  key = tuple([key] + [slice(None)] * (len(labels.levels) - 1)) class _LocIndexer(_LocationIndexer):  if isinstance(labels, MultiIndex):             if isinstance(key, str) and labels.levels[0].is_all_dates:                  key = tuple([key] + [slice(None)] * (len(labels.levels) - 1)) class _LocIndexer(_LocationIndexer):  if isinstance(labels, MultiIndex):             if isinstance(key, str) and labels.levels[0].is_all_dates:                  key = tuple([key] + [slice(None)] * (len(labels.levels) - 1)) class _LocIndexer(_LocationIndexer):  if isinstance(labels, MultiIndex):             if isinstance(key, str) and labels.levels[0].is_all_dates:                  key = tuple([key] + [slice(None)] * (len(labels.levels) - 1)) class _LocIndexer(_LocationIndexer):  if isinstance(labels, MultiIndex):             if isinstance(key, str) and labels.levels[0].is_all_dates:                  key = tuple([key] + [slice(None)] * (len(labels.levels) - 1)) class _LocIndexer(_LocationIndexer):  if isinstance(labels, MultiIndex):             if isinstance(key, str) and labels.levels[0].is_all_dates:                  key = tuple([key] + [slice(None)] * (len(labels.levels) - 1)) class _LocIndexer(_LocationIndexer):  if isinstance(labels, MultiIndex):             if isinstance(key, str) and labels.levels[0].is_all_dates:                  key = tuple([key] + [slice(None)] * (len(labels.levels) - 1)) class _LocIndexer(_LocationIndexer):  if isinstance(labels, MultiIndex):             if isinstance(key, str) and labels.levels[0].is_all_dates:                  key = tuple([key] + [slice(None)] * (len(labels.levels) - 1)) class _LocIndexer(_Location
class BracketTracker:         if self._lambda_arguments and leaf.type == token.COLON:              self.depth -= 1             self._lambda_arguments -= 1              return True          return False
def DatetimeIndexOpsMixin(ExtensionIndex, ExtensionOpsMixin):  if isinstance(maybe_slice, slice):              return self[maybe_slice]         taken = ExtensionIndex.take(              self, indices, axis, allow_fill, fill_value, **kwargs          )         freq = self.freq if is_period_dtype(self)      return self._shallow_copy(taken, freq=freq)
def _isna_new(obj):  return _isna_ndarraylike(np.asarray(obj))  def _isna_old(obj):  def _isna_new(obj):  return _isna_ndarraylike(np.asarray(obj))
def TestSeriesComparison:          dti = dti.tz_localize("US/Central")          ser = Series(dti).rename(names[1])          result = op(ser, dti)          assert result.name == names[2]
def js_to_json(code):  if v in ('true', 'false', 'null'):              return v          if v.startswith('"'):              return v         if v.startswith("'"):              v = v[1:-1]              v = re.sub(r"\\\\|\\'|\"", lambda m: {                  '\\\\': '\\\\',
class Model(BaseModel):  class ModelSubclass(Model):      y: int  @app.get("/", response_model=Model, response_model_exclude_unset=True)  def get() -> ModelSubclass:     return ModelSubclass(sub={}, y=1)  client = TestClient(app)
def _simple_new(new_dates, dtype=DT64NS_DTYPE, freq=self.freq)  def _simple_new(new_dates, dtype=DT64NS_DTYPE, freq=self.freq)  def _simple_new(new_dates, dtype=DT64NS_DTYPE, freq=self.freq)  def _simple_new(new_dates, dtype=DT64NS_DTYPE, freq=self.freq)  def _simple_new(new_dates, dtype=DT64NS_DTYPE, freq=self.freq):  def _simple_new(new_dates, dtype=DT64NS_DTYPE, freq=self.freq):  def _simple_new(new_dates, dtype=DT64NS_DTYPE, freq=self.freq):  def _simple_new(new_dates, dtype=DT64NS_DTYPE, freq=self.freq):  def _simple_new(new_dates, dtype=DT64NS_DTYPE, freq=self.freq):  def _simple_new(new_dates, dtype=DT64NS_DTYPE, freq=self.freq):  def _simple_new(new_dates, dtype=DT64NS_DTYPE, freq=self.freq):  def _simple_new(new_dates, dtype=DT64NS_DTYPE, freq=self.freq):  def _simple_new(new_dates, dtype=DT64NS_DTYPE, freq=self.freq):  def _simple_new(new_dates, dtype=DT64NS_DTYPE, freq=self.freq):  def _simple_new(new_dates, dtype=DT64NS_DTYPE, freq=self.freq):  def _simple_new(new_dates, dtype=DT64NS_DTYPE, freq=self.freq):  def _simple_new(new_dates, dtype=DT64NS_DTYPE, freq=self.freq):  def _simple_new(new_dates, dtype=DT64NS_DTYPE, freq=self.freq):  def _simple_new(new_dates, dtype=DT64NS_DTYPE, freq=self.freq):  def _simple_new(new_dates, dtype=DT64NS
def ReduceLROnPlateau(Callback):              self.mode = 'auto'          if (self.mode =='min' or             (self.mode == 'auto and 'acc' not in self.monitor)):             self.monitor_op = lambda a, b: np.less(a, b - self.epsilon)              self.best = -np.Inf          self.cooldown_counter = 0          self.wait = 0
def get_objs_combined_axis(          The axis to extract indexes from.      sort : bool, default True          Whether the result index should come out sorted or not.      Returns      -------      Index      obs_idxes = [obj._get_axis(axis) for obj in objs]     return _get_combined_index(obs_idxes, intersect=intersect, sort=sort) def _get_distinct_objs(objs: List[Index]) -> List[Index]:
def QuarterOffset(DateOffset):          shifted = liboffsets.shift_quarters(              dtindex.asi8, self.n, self.startingMonth, self._day_opt          )          return type(dtindex)._simple_new(             shifted, freq=dtindex.freq, dtype=dtindex.dtype         )  class BQuarterEnd(QuarterOffset):
def ImageDataGenerator(object):              The inputs, normalized.         if self.preprocessing_function:             x = self.preprocessing_function(x)          if self.rescale:              x *= self.rescale          if self.samplewise_center:              x = self.samplewise_center(x)  class ImageDataGenerator(object):              The inputs, normalized.         if self.preprocessing_function:              x = self.preprocessing_function(x)          if self.rescale:              x *= self.rescale          if self.samplewise_center:              x = self.samplewise_center(x)  class ImageDataGenerator(object):              The inputs, normalized.         if self.preprocessing_function:              x = self.preprocessing_function(x)          if self.rescale:              x *= self.rescale          if self.samplewise_center:              x = self.samplewise_center(x)  class ImageDataGenerator(object):              The inputs, normalized.         if self.preprocessing_function:              x = self.preprocessing_function(x)          if self.rescale:              x *= self.rescale          if self.samplewise_center:              x = self.samplewise_center(x)  class ImageDataGenerator(object):              The inputs, normalized.         if self.preprocessing_function:              x = self.preprocessing_function(x)          if self.rescale:              x *= self.rescale          if self.samplewise_center:              x = self.samplewise_center(x)  class ImageDataGenerator(object):              The inputs, normalized.         if self.preprocessing_function:              x = self.preprocessing_function(x)          if self.rescale:              x *= self.rescale          if self.samplewise_center:              x = self.samplewise_center(x)  class ImageDataGenerator(object):              The inputs, normalized.         if self.preprocessing_function:              x = self.preprocessing_function(x)          if self.rescale:              x *= self.rescale          if self.samplewise_center:              x = self.samplewise_center(x)  class ImageDataGenerator(object):              The inputs, normalized.
def _cat_compare_op(op):              mask = (self._codes == -1)              return ret          def _cat_compare_op(op):              return _cat_compare_op def _cat_compare_op(op):              return _cat_compare_op def _cat_compare_op(op):              return _cat_compare_op def _cat_compare_op(op):              return _cat_compare_op def _cat_compare_op(op):              return _cat_compare_op def _cat_compare_op(op):              return _cat_compare_op def _cat_compare_op(op):              return _cat_compare_op def _cat_compare_op(op):              return _cat_compare_op def _cat_compare_op(op):              return _cat_compare_op def _cat_compare_op(op):              return _cat_compare_op def _cat_compare_op(op):              return _cat_compare_op def _cat_compare_op(op):              return _cat_compare_op def _cat_compare_op(op):              return _cat_compare_op def _cat_compare_op(op):              return _cat_compare_op def _cat_compare_op(op):              return _cat_compare_op def _cat_compare_op(op):              return _cat_compare_op def _cat_compare_op(op):              return _cat_compare_op def _cat_compare_op(op):              return _cat_compare_op def _cat_compare_op(op):              return _cat_compare_op def _cat_compare_op(op):              return _cat_compare_op def _cat_compare_op(op):              return _cat_compare_op def _cat_compare_op(op):              return _cat_compare_op def _cat_compare_op(op):              return _cat_compare_op def _cat_compare_op(op):              return _cat_compare_op def _cat_compare_op(op):              return _cat_compare_op def _cat_compare_op(op):
def match(command, settings):      return _search(command.stderr)  def get_new_command(command, settings):      m = _search(command.stdout)      editor_call = '{} {} +{}'.format(os.environ['EDITOR'],                                      m.group('file'),                                      m.group('line'))      return shells.and_(editor_call, command.script)
def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),          padding: string, "same" or "valid".          data_format: "channels_last" or "channels_first".              Whether to use Theano or TensorFlow data format         in inputs/kernels/outputs.          ValueError: if using an even kernel size with padding'same'. def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),          padding: string, "same" or "valid".          data_format: "channels_last" or "channels_first".              Whether to use Theano or TensorFlow data format         in inputs/kernels/outputs.          ValueError: if using an even kernel size with padding'same'. def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),          padding: string, "same" or "valid".          data_format: "channels_last" or "channels_first".              Whether to use Theano or TensorFlow data format         in inputs/kernels/outputs.          ValueError: if using an even kernel size with padding'same'. def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),          padding: string, "same" or "valid".          data_format: "channels_last" or "channels_first".              Whether to use Theano or TensorFlow data format         in inputs/kernels/outputs.          ValueError: if using an even kernel size with padding'same'. def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),          padding: string, "same" or "valid".          data_format: "channels_last" or "channels_first".              Whether to use Theano or TensorFlow data format         in inputs/kernels/outputs.          ValueError: if using an even kernel size with padding'same'. def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),          padding: string, "same" or "valid".          data_format: "channels_last" or "channels_first".              Whether to use Theano or TensorFlow data format         in inputs/kernels/outputs.          ValueError: if using an even kernel size with padding'same'.
def Spider(object_ref):          crawler.signals.connect(self.close, signals.spider_closed)  def start_requests(self):          def make_requests_from_url(self, url):              return crawler.requests.get(url)
def reformat_many(      if sys.platform == "win32":          worker_count = min(worker_count, 61)     executor = ProcessPoolExecutor(max_workers=worker_count)      try:          loop.run_until_complete(              schedule_formatting(  def reformat_many(  ):  def reformat_many(  ):  def reformat_many(  ):  def reformat_many(  ):  def reformat_many(  ):  def reformat_many(  ):  def reformat_many(  ):  def reformat_many(  ):  def reformat_many(  ):  def reformat_many(  ):  def reformat_many(  ):  def reformat_many(  ):  def reformat_many(  ):  def reformat_many(  ):  def reformat_many(  ):  def reformat_many(  ):  def reformat_many(  ):  def reformat_many(  ):  def reformat_many(  ):  def reformat_many(  ):  def reformat_many(  ):  def reformat_many(  ):  def reformat_many(  ):  def reformat_many(  ):  def reformat_many(  ):  def reformat_many(  ):  def reformat_many(  ):  def reformat_many(  ):  def reformat_many(  ):  def reformat_many(  ):  def reformat_many(  ):  def reformat_many(  ):  def reformat_many(  ):  def reformat_many(  ):  def reformat_many(  ):  def reformat_many(  ):  def reformat_many(  ):  def reformat_many(  ):  def reformat_many(  ):  def reformat_many(  ):  def reformat_many(  ):  def reformat_many(  ):  def reformat_many(  ):  def reformat_many(  ):  def reformat_many(
class PeriodIndex(DatetimeIndexOpsMixin, Int64Index, PeriodDelegateMixin):              try:                  loc = self._get_string_slice(key)                  return series[loc]             except (TypeError, ValueError):                  pass              asdt, reso = parse_time_string(key, self.freq)
def base_url(url):  def urljoin(base, path):      if not isinstance(path, compat_str):  return None      return compat_urlparse.urljoin(base, path) def base_url(url):  def urljoin(base, path):      return compat_urlparse.urljoin(base, path) def base_url(url):  def urljoin(base, path):      return compat_urlparse.urljoin(base, path) def base_url(url):  def urljoin(base, path):      return compat_urlparse.urljoin(base, path) def base_url(url):  def urljoin(base, path):      return compat_urlparse.urljoin(base, path) def base_url(url):  def urljoin(base, path):      return compat_urlparse.urljoin(base, path) def base_url(url):  def urljoin(base, path):      return compat_urlparse.urljoin(base, path) def base_url(url):  def urljoin(base, path):      return compat_urlparse.urljoin(base, path) def base_url(url):  def urljoin(base, path):      return compat_urlparse.urljoin(base, path) def base_url(url):  def urljoin(base, path):      return compat_urlparse.urljoin(base, path) def base_url(url):  def urljoin(base, path):      return compat_urlparse.urljoin(base, path) def base_url(url):  def urljoin(base, path):      return compat_urlparse.urljoin(base, path) def base_url(url):  def urljoin(base, path):      return compat_urlparse.urljoin(base, path) def base_url(url):  def urljoin(base, path):      return compat_urlparse.urljoin(base, path) def base_url(url):  def urljoin(base, path):      return compat_urlparse.urljoin(base, path) def base_url(url):  def urljoin(base, path):      return compat_urlparse.urljoin(base, path) def base_url(url):  def urljoin(base, path):
class _LocIndexer(_LocationIndexer):              return self._getbool_axis(key, axis=axis)          elif is_list_like_indexer(key):             if isinstance(labels, ABCMultiIndex):                 if isinstance(key, (ABCSeries, np.ndarray)) and key.ndim <= 1:                     key = list(key)                 elif isinstance(key, ABCDataFrame):                     raise NotImplementedError(                         "Indexing a MultiIndex with a "                         "DataFrame key is not "                         "implemented"                 elif hasattr(key, "ndim") and key.ndim > 1:                     raise NotImplementedError(                         "Indexing a MultiIndex with a "                         "multidimensional key is not "                         "implemented"                 if (                     not isinstance(key, tuple)                     and len(key)                     and not isinstance(key[0], tuple)                 ):                     key = tuple([key])              if not (isinstance(key, tuple) and isinstance(labels, ABCMultiIndex)):
def print_tensor(x, message=''):          The same tensor `x`, unchanged.     return tf.Print(x, [x], message)
class Block(PandasObject):  def check_setitem_lengths(indexer, value, values):  pass
def RedirectMiddleware(BaseRedirectMiddleware):  if 'Location' not in response.headers or response.status not in allowed_status:              return response         location = to_native_str(response.headers['location'].decode('latin1'))          redirected_url = urljoin(request.url, location)
def _prepare_response_content(     res: Any, *, by_alias: bool = True, exclude_unset: bool  ) -> Any:      def _prepare_response_content(          res: Any, *, by_alias: bool  ):      return res.dict(                 by_alias=by_alias, skip_defaults=exclude_unset)
def _make_concat_multiindex(indexes, keys, levels=None, names=None) -> MultiInde:          for hlevel, level in zip(zipped, levels):              to_concat = []              for key, index in zip(hlevel, indexes):                 try:                     i = level.get_loc(key)                  to_concat.append(np.repeat(i, len(index)))              codes_list.append(np.concatenate(to_concat)) def _make_concat_multiindex(indexes, keys, levels=None, names=None) -> MultiInde:          for hlevel, level in zip(zipped, levels):              to_concat = []              for key, index in zip(hlevel, indexes):                 try:                     i = level.get_loc(key)                  to_concat.append(np.repeat(i, len(index)))              codes_list.append(np.concatenate(to_concat)) def _make_concat_multiindex(indexes, keys, levels=None, names=None) -> MultiInde:          for hlevel, level in zip(zipped, levels):              to_concat = []              for key, index in zip(hlevel, indexes):                 try:                     i = level.get_loc(key)                  to_concat.append(np.repeat(i, len(index)))              codes_list.append(np.concatenate(to_concat)) def _make_concat_multiindex(indexes, keys, levels=None, names=None) -> MultiInde:          for hlevel, level in zip(zipped, levels):              to_concat = []              for key, index in zip(hlevel, indexes):                 try:                     i = level.get_loc(key)                  to_concat.append(np.repeat(i, len(index)))              codes_list.append(np.concatenate(to_concat)) def _make_concat_multiindex(indexes, keys, levels=None, names=None) -> MultiInde:          for hlevel, level in zip(zipped, levels):              to_concat = []              for key, index in zip(hlevel, indexes):                 try:                     i = level.get_loc(key)                  to_concat.
def FastAPI(Starlette):          response_model_by_alias: bool = True,          response_model_skip_defaults: bool = None,          include_in_schema: bool = True,          response_class: Type[Response] = None,          name: str = None,
class tqdm(Comparable):  if disable is None and hasattr(file, "isatty") and not file.isatty():              disable = True          if disable:              self.iterable = iterable              self.disable = False              self.pos = self._get_free_pos(self)              self._instances.remove(self)              self.n = initial
def Index(IndexOpsMixin, PandasObject):              multi_join_idx = multi_join_idx.remove_unused_levels()              return multi_join_idx, lidx, ridx class Index(IndexOpsMixin, PandasObject):              multi_join_idx = multi_join_idx.remove_unused_levels()              return multi_join_idx, lidx, ridx class Index(IndexOpsMixin, PandasObject):              multi_join_idx = multi_join_idx.remove_unused_levels()              return multi_join_idx, lidx, ridx class Index(IndexOpsMixin, PandasObject):              multi_join_idx = multi_join_idx.remove_unused_levels()              return multi_join_idx, lidx, ridx class Index(IndexOpsMixin, PandasObject):              multi_join_idx = multi_join_idx.remove_unused_levels()              return multi_join_idx, lidx, ridx class Index(IndexOpsMixin, PandasObject):              multi_join_idx = multi_join_idx.remove_unused_levels()              return multi_join_idx, lidx, ridx class Index(IndexOpsMixin, PandasObject):              multi_join_idx = multi_join_idx.remove_unused_levels()              return multi_join_idx, lidx, ridx class Index(IndexOpsMixin, PandasObject):              multi_join_idx = multi_join_idx.remove_unused_levels()              return multi_join_idx, lidx, ridx class Index(IndexOpsMixin, PandasObject):              multi_join_idx = multi_join_idx.remove_unused_levels()              return multi_join_idx, lidx, ridx class Index(IndexOpsMixin, PandasObject):              multi_join_idx = multi_join_idx.remove_unused_levels()              return multi_join_idx, lidx, ridx class Index(IndexOpsMixin, PandasObject):              multi_join_idx = multi_join_idx.remove_unused_levels()              return multi_join_idx, lidx, ridx class Index(IndexOpsMixin, PandasObject):              multi_join_idx = multi_join_idx.remove_unused_levels()              return multi_join_idx,
def to_native_types(self, slicer=None, na_rep="", quoting=None, **kwargs):  def _holder(self):          return Categorical      def to_native_types(self, slicer=None, na_rep="", quoting=None, **kwargs):          return CategoricalBlock(ExtensionBlock):  def _holder(self):          return Categorical      def to_native_types(self, slicer=None, na_rep="", quoting=None, **kwargs):          return CategoricalBlock(ExtensionBlock):  def _holder(self):          return Categorical      def to_native_types(self, slicer=None, na_rep="", quoting=None, **kwargs):          return CategoricalBlock(ExtensionBlock):  def _holder(self):          return Categorical      def to_native_types(self, slicer=None, na_rep="", quoting=None, **kwargs):          return CategoricalBlock(ExtensionBlock):  def _holder(self):          return Categorical      def to_native_types(self, slicer=None, na_rep="", quoting=None, **kwargs):          return CategoricalBlock(ExtensionBlock):  def _holder(self):          return Categorical      def to_native_types(self, slicer=None, na_rep="", quoting=None, **kwargs):          return CategoricalBlock(ExtensionBlock):  def _holder(self):          return Categorical      def to_native_types(self, slicer=None, na_rep="", quoting=None, **kwargs):          return CategoricalBlock(ExtensionBlock):  def _holder(self):          return Categorical      def to_native_types(self, slicer=None, na_rep="", quoting=None, **kwargs):          return CategoricalBlock(ExtensionBlock):  def _holder(self):          return Categorical      def to_native_types(self, slicer=None, na_rep="", quoting=None, **kwargs):          return CategoricalBlock(ExtensionBlock):  def _holder(self):          return Categorical      def to_native_types(self, slicer=None, na_rep="", quoting=None, **kwargs):          return CategoricalBlock(ExtensionBlock):  def _holder(self):          return Categorical      def to
def Model(Container):                  val_data += [0.]              for cbk in callbacks:                  cbk.validation_data = val_data         is_sequence = isinstance(generator, Sequence)          if not is_sequence and use_multiprocessing and workers > 1:             warnings.warn(                 UserWarning('Using a generator with `use_multiprocessing=True`'                            'and multiple workers may duplicate your data.'                            'Please consider using the`keras.utils.Sequence'                            'class.'))
def melt(          else:              value_vars = list(value_vars)              missing = Index(np.ravel(value_vars)).difference(cols)              if not missing.empty:                  raise KeyError(                      "The following 'value_vars' are not present in"
class TFOptimizer(Optimizer):      @interfaces.legacy_get_updates_support      def get_updates(self, loss, params):          grads = self.optimizer.compute_gradients(loss, params)          self.updates = [K.update_add(self.iterations, 1)]          opt_update = self.optimizer.apply_gradients(              grads, global_step=self.iterations)
def YoutubeIE(YoutubeBaseInfoExtractor):          video_id = mobj.group(2)          return video_id
class ItemMeta(ABCMeta):   def __new__(mcs, class_name, bases, new_attrs):       return super(ItemMeta, mcs).__new__(mcs, class_name, bases, new_attrs)  class ItemMeta(ABCMeta):   def __new__(mcs, class_name, bases, new_attrs):       return super(ItemMeta, mcs).__new__(mcs, class_name, bases, new_attrs)  class ItemMeta(ABCMeta):   def __new__(mcs, class_name, bases, new_attrs):       return super(ItemMeta, mcs).__new__(mcs, class_name, bases, new_attrs)  class ItemMeta(ABCMeta):   def __new__(mcs, class_name, bases, new_attrs):       return super(ItemMeta, mcs).__new__(mcs, class_name, bases, new_attrs)  class ItemMeta(ABCMeta):   def __new__(mcs, class_name, bases, new_attrs):       return super(ItemMeta, mcs).__new__(mcs, class_name, bases, new_attrs)  class ItemMeta(ABCMeta):   def __new__(mcs, class_name, bases, new_attrs):       return super(ItemMeta, mcs).__new__(mcs, class_name, bases, new_attrs)  class ItemMeta(ABCMeta):   def __new__(mcs, class_name, bases, new_attrs):       return super(ItemMeta, mcs).__new__(mcs, class_name, bases, new_attrs)  class ItemMeta(ABCMeta):   def __new__(mcs, class_name, bases, new_attrs):       return super(ItemMeta, mcs).__new__(mcs, class_name, bases, new_attrs)  class ItemMeta(ABCMeta):   def __new__(mcs, class_name, bases, new_attrs):       return super(ItemMeta, mcs).__new__(mcs, class_name, bases, new_attrs
def ListParameter(Parameter):         Ensure that list parameter is converted to a tuple so it can be hashed.          :param str x: the value to parse.          :return: the normalized (hashable/immutable) value.
class _MergeOperation:                      )                  ]              else:                 left_keys = [self.left.index.values]          if left_drop:              self.left = self.left._drop_labels_or_levels(left_drop)
class NumericIndex(Index):              name = data.name          return cls._simple_new(subarr, name=name)      @Appender(_index_shared_docs["_maybe_cast_slice_bound"])      def _maybe_cast_slice_bound(self, label, side, kind):          assert kind in ["ix", "loc", "getitem", None]
def _urlencode(seq, enc):  def _get_form(response, formname, formid, formnumber, formxpath):      text = response.body_as_unicode()      root = create_root_node(text, lxml.html.HTMLParser, base_url=response.url)      forms = root.xpath('//form')      def _get_form(response, formname, formid, formnumber, formxpath):      text = response.body_as_unicode()      def _get_form(response, formname, formid, formnumber, formxpath):      text = response.body_as_unicode()      def _get_form(response, formname, formid, formnumber, formxpath):      text = response.body_as_unicode()      def _get_form(response, formname, formid, formnumber, formxpath):      text = response.body_as_unicode()      def _get_form(response, formname, formid, formnumber, formxpath):      text = response.body_as_unicode()      def _get_form(response, formname, formid, formnumber, formxpath):      text = response.body_as_unicode()      def _get_form(response, formname, formid, formnumber, formxpath):      text = response.body_as_unicode()      def _get_form(response, formname, formid, formnumber, formxpath):      text = response.body_as_unicode()      def _get_form(response, formname, formid, formnumber, formxpath):      text = response.body_as_unicode()      def _get_form(response, formname, formid, formnumber, formxpath):      text = response.body_as_unicode()      def _get_form(response, formname, formid, formnumber, formxpath):      text = response.body_as_unicode()      def _get_form(response, formname, formid, formnumber, formxpath):      text = response.body_as_unicode()      def _get_form(response, formname, formid, formnumber, formxpath):      text = response.body_as_unicode()      def _get_form(response, formname, formid, form
def Request(object_ref):          s = safe_url_string(url, self.encoding)          self._url = escape_ajax(s)      url = property(_get_url, obsolete_setter(_set_url, 'url'))
class EmptyLineTracker:                  return 0, 0              newlines = 2              if current_line.depth:                  newlines -= 1              return 0, 0 class EmptyLineTracker:                  return 0, 0 class EmptyLineTracker:                  return 0, 0 class EmptyLineTracker:                  return 0, 0 class EmptyLineTracker:                  return 0, 0 class EmptyLineTracker:                  return 0, 0 class EmptyLineTracker:                  return 0, 0 class EmptyLineTracker:                  return 0, 0 class EmptyLineTracker:                  return 0, 0 class EmptyLineTracker:                  return 0, 0 class EmptyLineTracker:                  return 0, 0 class EmptyLineTracker:                  return 0, 0 class EmptyLineTracker:                  return 0, 0 class EmptyLineTracker:                  return 0, 0 class EmptyLineTracker:                  return 0, 0 class EmptyLineTracker:                  return 0, 0 class EmptyLineTracker:                  return 0, 0 class EmptyLineTracker:                  return 0, 0 class EmptyLineTracker:                  return 0, 0 class EmptyLineTracker:                  return 0, 0 class EmptyLineTracker:                  return 0, 0 class EmptyLineTracker:                  return 0, 0 class EmptyLineTracker:                  return 0, 0 class EmptyLineTracker:                  return 0, 0 class EmptyLineTracker:                  return 0, 0 class EmptyLineTracker:                  return 0, 0 class EmptyLineTracker:                  return 0, 0 class EmptyLineTracker:                  return 0, 0 class EmptyLineTracker:                  return 0, 0 class EmptyLineTracker:                  return 0, 0 class EmptyLineTracker:                  return 0, 0 class EmptyLineTracker:                  return 0, 0 class EmptyLineTracker:                  return 0, 0 class EmptyLineTracker:                  return 0, 0 class EmptyLineTracker:                  return 0, 0 class EmptyLineTracker:                  return 0, 0 class EmptyLineTracker:                  return 0, 0 class EmptyLineTracker:                  return 0, 0 class EmptyLineTracker:                  return 0, 0 class EmptyLineTracker:                  return 0, 0 class EmptyLineTracker:                  return 0, 0 class EmptyLineTracker:                  return 0, 0 class EmptyLineTracker:                  return 0, 0 class EmptyLineTracker:                  return 0, 0 class EmptyLineTracker:
def _combine_match_index(self, other, func):  def _combine_match_index(self, other, func):  return new_data  def _combine_match_index(self, other, func):  return new_data  def _combine_match_index(self, other, func):  return new_data  def _combine_match_index(self, other, func):  return new_data  def _combine_match_index(self, other, func):  return new_data  def _combine_match_index(self, other, func):  return new_data  def _combine_match_index(self, other, func):  return new_data  def _combine_match_index(self, other, func):  return new_data  def _combine_match_index(self, other, func):  return new_data  def _combine_match_index(self, other, func):  return new_data  def _combine_match_index(self, other, func):  return new_data  def _combine_match_index(self, other, func):  return new_data  def _combine_match_index(self, other, func):  return new_data  def _combine_match_index(self, other, func):  return new_data  def _combine_match_index(self, other, func):  return new_data  def _combine_match_index(self, other, func):  return new_data  def _combine_match_index(self, other, func):  return new_data  def _combine_match_index(self, other, func):  return new_data  def _combine_match_index(self, other, func):  return new_data  def _combine_match_index(self, other, func):  return new_data  def _combine_match_index(self, other, func):  return new_data  def _combine_match_index(self, other, func):  return new_data  def _combine_match_index(self, other, func):  return new_data  def _combine_match_index(self, other, func):  return new_data  def _combine_match_index(self, other, func):
def disp_trim(data, length):  if len(data) == disp_len(data):          return data[:length] while disp_len(data) > length:          data = data[:-1]      return data + "\033[0m" def disp_trim(data, length):  return disp_trim(data, length) def disp_trim(data, length):  return disp_trim(data, length) def disp_trim(data, length):  return disp_trim(data, length) def disp_trim(data, length):  return disp_trim(data, length) def disp_trim(data, length):  return disp_trim(data, length) def disp_trim(data, length):  return disp_trim(data, length) def disp_trim(data, length):  return disp_trim(data, length) def disp_trim(data, length):  return disp_trim(data, length) def disp_trim(data, length):  return disp_trim(data, length) def disp_trim(data, length):  return disp_trim(data, length) def disp_trim(data, length):  return disp_trim(data, length) def disp_trim(data, length):  return disp_trim(data, length) def disp_trim(data, length):  return disp_trim(data, length) def disp_trim(data, length):  return disp_trim(data, length) def disp_trim(data, length):  return disp_trim(data, length) def disp_trim(data, length):  return disp_trim(data, length) def disp_trim(data, length):  return disp_trim(data, length) def disp_trim(data, length):  return disp_trim(data, length) def disp_trim(data, length):  return disp_trim(data, length) def disp_trim(data, length):  return disp_trim(data, length) def disp_trim(data, length):  return disp_trim(data, length) def disp_trim(data, length):  return disp_trim(data, length) def disp_trim(data, length):  return disp_
def _unstack_multiple(data, clocs, fill_value=None):              for i in range(len(clocs)):                  val = clocs[i]                  result = result.unstack(val, fill_value=fill_value)              return result
def jsonable_encoder(                      value,                      by_alias=by_alias,                      exclude_unset=exclude_unset,                     include_none=include_none,                      custom_encoder=custom_encoder,                      sqlalchemy_safe=sqlalchemy_safe,                  )def jsonable_encoder(                      value,                      by_alias=by_alias,                      exclude_unset=exclude_unset,                     include_none=include_none,                      custom_encoder=custom_encoder,                      sqlalchemy_safe=sqlalchemy_safe,                  )def jsonable_encoder(                      value,                      by_alias=by_alias,                      exclude_unset=exclude_unset,                     include_none=include_none,                      custom_encoder=custom_encoder,                      sqlalchemy_safe=sqlalchemy_safe,                  )def jsonable_encoder(                      value,                      by_alias=by_alias,                      exclude_unset=exclude_unset,                     include_none=include_none,                      custom_encoder=custom_encoder,                      sqlalchemy_safe=sqlalchemy_safe,                  )def jsonable_encoder(                      value,                      by_alias=by_alias,                      exclude_unset=exclude_unset,                     include_none=include_none,                      custom_encoder=custom_encoder,                      sqlalchemy_safe=sqlalchemy_safe,                  )def jsonable_encoder(                      value,                      by_alias=by_alias,                      exclude_unset=exclude_unset,                     include_none=include_none,                      custom_encoder=custom_encoder,                      sqlalchemy_safe=sqlalchemy_safe,                  )def jsonable_encoder(                      value,                      by_alias=by_alias,                      exclude_unset=exclude_unset,                     include_none=include_none,                      custom_encoder=custom_encoder,                      sqlalchemy_safe=sqlalchemy_safe,                  )def jsonable_encoder(                      value,                      by_alias=by_alias,                      exclude_unset=exclude_unset,                     include_none=include_none,                      custom_encoder=custom_encoder,                      sqlalchemy_safe=sqlalchemy_safe,                  )def jsonable_encoder(                      value,                      by_alias=by_alias,                      exclude_unset=exclude_unset,                     include_none=include_none,                      custom_encoder=custom_encoder,
class CollectionRequirement:              manifest = info['manifest_file']['collection_info']              namespace = manifest['namespace']              name = manifest['name']              version = manifest['version']              dependencies = manifest['dependencies']
def get_mount_info(self, mount, device, uuids):      def get_mount_info(self, mount, device, uuids):          mount_size = get_mount_size(mount)  def get_mount_info(self, mount, device, uuids):      def get_mount_info(self, mount, device, uuids):      def get_mount_info(self, mount, device, uuids):      def get_mount_info(self, mount, device, uuids):      def get_mount_info(self, mount, device, uuids):      def get_mount_info(self, mount, device, uuids):      def get_mount_info(self, mount, device, uuids):      def get_mount_info(self, mount, device, uuids):      def get_mount_info(self, mount, device, uuids):      def get_mount_info(self, mount, device, uuids):      def get_mount_info(self, mount, device, uuids):      def get_mount_info(self, mount, device, uuids):      def get_mount_info(self, mount, device, uuids):      def get_mount_info(self, mount, device, uuids):      def get_mount_info(self, mount, device, uuids):      def get_mount_info(self, mount, device, uuids):      def get_mount_info(self, mount, device, uuids):      def get_mount_info(self, mount, device, uuids):      def get_mount_info(self, mount, device, uuids):      def get_mount_info(self, mount, device, uuids):      def get_mount_info(self, mount, device, uuids):      def get_mount_info(self, mount, device, uuids):      def get_mount_info(self, mount, device, uuids):      def get_mount_info(self, mount, device, uuids):      def get_mount_info(self, mount, device, uuids):      def get_mount_info(self, mount, device, uuids):      def get_mount_info(self, mount, device, uuids):      def get_mount_info(self, mount, device, uuids):      def get_mount_info(self, mount, device, uuids):      def
def Categorical(ExtensionArray, PandasObject):          min : the minimum of this `Categorical`          self.check_for_ordered("min")          good = self._codes!= -1          return Categorical
def _get_spider_loader(settings):              'Please use SPIDER_LOADER_CLASS.',              category=ScrapyDeprecationWarning, stacklevel=2          )      cls_path = settings.get('SPIDER_LOADER_CLASS',                             settings.get('SPIDER_MANAGER_CLASS'))      loader_cls = load_object(cls_path)      return loader_cls.from_settings(settings.frozencopy())
def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def def
async def serialize_response(              exclude=exclude,              by_alias=by_alias,          )      else  return jsonable_encoder(response_content)
class WebSocketHandler(tornado.web.RequestHandler):         .. versionadded:: 3.1         def on_connection_close(self) -> None:          if self.ws_connection:          self.stream.set_nodelay(value)
def get_file(fname,          Path to the downloaded file      if cache_dir is None:          cache_dir = os.path.join(os.path.expanduser('~'), '.keras')      def get_file(fname,          Path to the downloaded file      if md5_hash is not None and file_hash is None:          file_hash = md5_hash          hash_algorithm ='md5'      def get_file(fname,          Path to the downloaded file      def get_file(fname,          Path to the downloaded file      def get_file(fname,          Path to the downloaded file      def get_file(fname,          Path to the downloaded file      def get_file(fname,          Path to the downloaded file      def get_file(fname,          Path to the downloaded file      def get_file(fname,          Path to the downloaded file      def get_file(fname,          Path to the downloaded file      def get_file(fname,          Path to the downloaded file      def get_file(fname,          Path to the downloaded file      def get_file(fname,          Path to the downloaded file      def get_file(fname,          Path to the downloaded file      def get_file(fname,          Path to the downloaded file      def get_file(fname,          Path to the downloaded file      def get_file(fname,          Path to the downloaded file      def get_file(fname,          Path to the downloaded file      def get_file(fname,          Path to the downloaded file      def get_file(fname,          Path to the downloaded file      def get_file(fname,          Path to the downloaded file      def get_file(fname,          Path to the downloaded file      def get_file(fname,          Path to the downloaded file      def get_file(fname,          Path to the downloaded file      def get_file(fname,          Path to the downloaded file      def get_file(fname,          Path to the downloaded file      def get_file(fname,          Path to the downloaded file      def get_file(fname,          Path to the downloaded file      def get_file(fname,          Path to the downloaded file      def get_file(fname,          Path to the downloaded file      def get_file(fname,          Path to the downloaded file      def get_file(fname,          Path to
def get_flat_dependant(dependant: Dependant) -> Dependant:  def is_scalar_field(field: Field) -> bool:     return (          field.shape == Shape.SINGLETON          and not lenient_issubclass(field.type_, BaseModel)          and not lenient_issubclass(field.type_, sequence_types + (dict,))          and not isinstance(field.schema, params.Body)     return  def is_scalar_sequence_field(field: Field) -> bool:
def _partition_tasks(worker):      set_tasks["completed"] = {task for (task, status, ext) in task_history}      set_tasks["already_done"] = {task for (task, status, ext) in task_history                                   if status == 'DONE' and task not in set_tasks["completed"]       set_tasks["failed"] = {task for (task, status, ext) in task_history                                   if status == 'FAILED'}      set_tasks["scheduling_error"] = {task for(task, status, ext) in task_history if status == 'UNKNOWN'       set_tasks["still_pending_ext"] = {task for (task, status, ext) in task_history                                       if status == 'PENDING' and task not in set_tasks["failed"] and task not in set_tasks["completed"] and not ext}      set_tasks["still_pending_not_ext"] = {task for (task, status, ext) in task_history                                           if status == 'PENDING' and task not in set_tasks["failed"] and task not in set_tasks["completed"] and ext}      set_tasks["run_by_other_worker"]      set_tasks["upstream_failure"] = set()      set_tasks["upstream_missing_dependency"] = set()
def Parameter(object):          :raises MissingParameterException: if x is false-y and no default is specified.          if not x:             if self.has_value:                 return self.value              elif self.is_bool:                  return False              elif self.is_list:                  return False
def FloatBlock(FloatOrComplexBlock):          return formatter.get_result_as_array()      def should_store(self, value) -> bool:          return issubclass(value.dtype.type, np.floating) and value.dtype == self.dtype
def Categorical(ExtensionArray, PandasObject):          good = self._codes!= -1          if not good.all():              return np.nan class Categorical(ExtensionArray, PandasObject):          good = self._codes!= -1          if not good.all():              return np.nan class Categorical(ExtensionArray, PandasObject):          good = self._codes!= -1 class Categorical(ExtensionArray, PandasObject):          good = self._codes!= -1 class Categorical(ExtensionArray, PandasObject):          good = self._codes!= -1 class Categorical(ExtensionArray, PandasObject):          good = self._codes!= -1 class Categorical(ExtensionArray, PandasObject):          good = self._codes!= -1 class Categorical(ExtensionArray, PandasObject):          good = self._codes!= -1 class Categorical(ExtensionArray, PandasObject):          good = self._codes!= -1 class Categorical(ExtensionArray, PandasObject):          good = self._codes!= -1 class Categorical(ExtensionArray, PandasObject):          good = self._codes!= -1 class Categorical(ExtensionArray, PandasObject):          good = self._codes!= -1 class Categorical(ExtensionArray, PandasObject):          good = self._codes!= -1 class Categorical(ExtensionArray, PandasObject):          good = self._codes!= -1 class Categorical(ExtensionArray, PandasObject):          good = self._codes!= -1 class Categorical(ExtensionArray, PandasObject):          good = self._codes!= -1 class Categorical(ExtensionArray, PandasObject):          good = self._codes!= -1 class Categorical(ExtensionArray, PandasObject):          good = self._codes!= -1 class Categorical(ExtensionArray, PandasObject):          good = self._codes!= -1 class Categorical(ExtensionArray, PandasObject):          good = self._codes!= -1 class Categorical(ExtensionArray, PandasObject):          good = self._codes!= -1 class Categorical(ExtensionArray, PandasObject):          good = self._codes!= -1 class Categorical(ExtensionArray, PandasObject):          good = self._codes!= -1 class Categorical(ExtensionArray, PandasObject):          good = self._codes!= -1 class Categorical(ExtensionArray
def process_response(self, request, response, spider):          def process_response(self, request, response, spider):              return response          if request.method == 'HEAD':              return response
def get_new_command(command):          pass      return replace_argument(" ".join(command.script_parts), 'push', get_new_command)
def TestPeriodIndex(DatetimeLike):          idx = PeriodIndex([2000, 2007, 2007, 2009, 2007], freq="A-JUN")          ts = Series(np.random.randn(len(idx)), index=idx)          result = ts[2007]          expected = ts[idx == "2007"]          tm.assert_series_equal(result, expected)
def evaluate_generator(model, generator,      steps_done = 0      outs_per_batch = []      batch_sizes = []      is_sequence = isinstance(generator, Sequence):  def evaluate_generator(model, generator,      steps_done = 0      outs_per_batch = []      batch_sizes = []      is_sequence = isinstance(generator, Sequence):      def evaluate_generator(model, generator,      steps_done = 0      outs_per_batch = []      batch_sizes = []      is_sequence = isinstance(generator, Sequence):      def evaluate_generator(model, generator,      steps_done = 0      outs_per_batch = []      batch_sizes = []      is_sequence = isinstance(generator, Sequence):      def evaluate_generator(model, generator,      steps_done = 0      outs_per_batch = []      batch_sizes = []      is_sequence = isinstance(generator, Sequence):      def evaluate_generator(model, generator,      steps_done = 0      outs_per_batch = []      batch_sizes = []      is_sequence = isinstance(generator, Sequence):      def evaluate_generator(model, generator,      steps_done = 0      outs_per_batch = []      batch_sizes = []      is_sequence = isinstance(generator, Sequence):      def evaluate_generator(model, generator,      steps_done = 0      outs_per_batch = []      batch_sizes = []      is_sequence = isinstance(generator, Sequence):      def evaluate_generator(model, generator,      steps_done = 0      outs_per_batch = []      batch_sizes = []      is_sequence = isinstance(generator, Sequence):      def evaluate_generator(model, generator,      steps_done = 0      outs_per_batch = []      batch_sizes = []      is_sequence = isinstance(generator, Sequence):      def evaluate_generator(model, generator,      steps_done = 0      outs_per_batch = []      batch_sizes = []      is_sequence = isinstance(generator, Sequence):      def evaluate_generator(model, generator,      steps_done = 0      outs_per_batch = []      batch_sizes = []      is_sequence = isinstance(generator, Sequence):      def evaluate_generator(model, generator,      steps_done = 0      outs_
class Series(base.IndexOpsMixin, generic.NDFrame):          kwargs["inplace"] = validate_bool_kwarg(kwargs.get("inplace", False), "inplace")          return super().rename(index=index, **kwargs)      @Substitution(**_shared_doc_kwargs)      @Appender(generic.NDFrame.reindex.__doc__)
def add_handler(self, fd, handler, events):          fd, fileobj = self.split_fd(fd)  def add_handler(self, fd, handler, events):          fd, fileobj = self.split_fd(fd)  def add_handler(self, fd, handler, events):          fd, fileobj = self.split_fd(fd)  def add_handler(self, fd, handler, events):          fd, fileobj = self.split_fd(fd)  def add_handler(self, fd, handler, events):          fd, fileobj = self.split_fd(fd)  def add_handler(self, fd, handler, events):          fd, fileobj = self.split_fd(fd)  def add_handler(self, fd, handler, events):          fd, fileobj = self.split_fd(fd)  def add_handler(self, fd, handler, events):          fd, fileobj = self.split_fd(fd)  def add_handler(self, fd, handler, events):          fd, fileobj = self.split_fd(fd)  def add_handler(self, fd, handler, events):          fd, fileobj = self.split_fd(fd)  def add_handler(self, fd, handler, events):          fd, fileobj = self.split_fd(fd)  def add_handler(self, fd, handler, events):          fd, fileobj = self.split_fd(fd)  def add_handler(self, fd, handler, events):          fd, fileobj = self.split_fd(fd)  def add_handler(self, fd, handler, events):          fd, fileobj = self.split_fd(fd)  def add_handler(self, fd, handler, events):          fd, fileobj = self.split_fd(fd)  def add_handler(self, fd, handler, events):          fd, fileobj = self.split_fd(fd)  def add_handler(self, fd, handler, events):          fd, fileobj = self.split_fd(fd)  def add_handler(self, fd, handler, events):          fd, fileobj = self.split_fd(fd)  def add_handler(self, fd, handler, events):          fd, fileobj = self.split_fd(
class ObjectBlock(Block):  def convert(numeric=False, copy=True):              return [b.convert(numeric=False, copy=True) for b in block] class ObjectBlock(Block):  def convert(numeric=False, copy=True):              return [b.convert(numeric=False, copy=True) for b in block] class ObjectBlock(Block):  def convert(numeric=False, copy=True):              return [b.convert(numeric=False, copy=True) for b in block] class ObjectBlock(Block):  def convert(numeric=False, copy=True):              return [b.convert(numeric=False, copy=True) for b in block] class ObjectBlock(Block):  def convert(numeric=False, copy=True):              return [b.convert(numeric=False, copy=True) for b in block] class ObjectBlock(Block):  def convert(numeric=False, copy=True):              return [b.convert(numeric=False, copy=True) for b in block] class ObjectBlock(Block):  def convert(numeric=False, copy=True):              return [b.convert(numeric=False, copy=True) for b in block] class ObjectBlock(Block):  def convert(numeric=False, copy=True):              return [b.convert(numeric=False, copy=True) for b in block] class ObjectBlock(Block):  def convert(numeric=False, copy=True):              return [b.convert(numeric=False, copy=True) for b in block] class ObjectBlock(Block):  def convert(numeric=False, copy=True):              return [b.convert(numeric=False, copy=True) for b in block] class ObjectBlock(Block):  def convert(numeric=False, copy=True):              return [b.convert(numeric=False, copy=True) for b in block] class ObjectBlock(Block):  def convert(numeric=False, copy=True):              return [b.convert(numeric=False, copy=True) for b in block] class ObjectBlock(Block):  def convert(numeric=False, copy=True):              return [b.convert(numeric=False, copy=True) for b in block] class ObjectBlock
class Categorical(ExtensionArray, PandasObject):          Only ordered `Categoricals` have a maximum!          Raises          ------          TypeErrorTypeError class Categorical(ExtensionArray, PandasObject):          Only ordered `Categoricals` have a maximum!          Raises          ------          TypeErrorTypeError class Categorical(ExtensionArray, PandasObject):          Only ordered `Categoricals` have a maximum!          Raises          ------          TypeErrorTypeError class Categorical(ExtensionArray, PandasObject):          Only ordered `Categoricals` have a maximum!          Raises          ------          TypeErrorTypeError class Categorical(ExtensionArray, PandasObject):          Only ordered `Categoricals` have a maximum!          Raises          ------          TypeErrorTypeError class Categorical(ExtensionArray, PandasObject):          Only ordered `Categoricals` have a maximum!          Raises          ------          TypeErrorTypeError class Categorical(ExtensionArray, PandasObject):          Only ordered `Categoricals` have a maximum!          Raises          ------          TypeErrorTypeError class Categorical(ExtensionArray, PandasObject):          Only ordered `Categoricals` have a maximum!          Raises          ------          TypeErrorTypeError class Categorical(ExtensionArray, PandasObject):          Only ordered `Categoricals` have a maximum!          Raises          ------          TypeErrorTypeError class Categorical(ExtensionArray, PandasObject):          Only ordered `Categoricals` have a maximum!          Raises          ------          TypeErrorTypeError class Categorical(ExtensionArray, PandasObject):          Only ordered `Categoricals` have a maximum!          Raises          ------          TypeErrorTypeError class Categorical(ExtensionArray, PandasObject):          Only ordered `Categoricals` have a maximum!          Raises          ------          TypeErrorTypeError class Categorical(ExtensionArray, PandasObject):          Only ordered `Categoricals` have a maximum!          Raises          ------          TypeErrorTypeError class Categorical(ExtensionArray, PandasObject):          Only ordered `Categoricals` have a maximum!          Raises          ------          TypeErrorTypeError class Categorical(ExtensionArray, PandasObject):          Only ordered `Categoricals` have a maximum!          Raises          ------          TypeErrorTypeError class Categorical(ExtensionArray, PandasObject):          Only ordered `Categoricals` have a maximum!          Raises          ------          TypeErrorTypeError class Categorical(ExtensionArray, PandasObject):          Only ordered `
def get_openapi_security_definitions(flat_dependant: Dependant) -> Tuple[Dict, L          security_definition = jsonable_encoder(              security_requirement.security_scheme.model,              by_alias=True,             include_none=False,          )          security_name = security_requirement.security_scheme.scheme_name          security_definitions[security_name] = security_definition
def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),      if isinstance(output_shape, (tuple, list)):          output_shape = tf.stack(output_shape)      x, tf_data_format = _preprocess_conv2d_input(x, data_format)      return conv2d_transpose(x, kernel, output_shape, strides=(1, 1)) def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),      if isinstance(output_shape, (tuple, list)):          output_shape = tf.stack(output_shape)      x, tf_data_format = _preprocess_conv2d_input(x, data_format)      return conv2d_transpose(x, kernel, output_shape, strides=(1, 1)) def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),      if isinstance(output_shape, (tuple, list)):          output_shape = tf.stack(output_shape)      x, tf_data_format = _preprocess_conv2d_input(x, data_format)      return conv2d_transpose(x, kernel, output_shape, strides=(1, 1)) def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),      if isinstance(output_shape, (tuple, list)):          output_shape = tf.stack(output_shape)      x, tf_data_format = _preprocess_conv2d_input(x, data_format)      return conv2d_transpose(x, kernel, output_shape, strides=(1, 1)) def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),      if isinstance(output_shape, (tuple, list)):          output_shape = tf.stack(output_shape)      x, tf_data_format = _preprocess_conv2d_input(x, data_format)      return conv2d_transpose(x, kernel, output_shape, strides=(1, 1)) def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),      if isinstance
def next_palindrome(digit_list):     high_mid = len(digit_list) // 2     low_mid = (len(digit_list) - 1) // 2     while high_mid < len(digit_list) and low_mid >= 0:         if digit_list[high_mid] == 9:             digit_list[high_mid] = 0             digit_list[low_mid] = 0             high_mid += 1             low_mid -= 1         else:             digit_list[high_mid] += 1             return digit_list     return [1] + (len(digit_list)) * [0] + [1]
def bucketsort(arr, k):     counts = [0] * k     for x in arr:         counts[x] += 1     sorted_arr = []     for i, count in enumerate(arr):         sorted_arr.extend([i] * count)     return sorted_arr
def to_base(num, b):     result = ''     alphabet = string.digits + string.ascii_uppercase     while num > 0:         i = num % b         num = num // b         result = result + alphabet[i]     return result
def shunting_yard(tokens):     precedence = {         '+': 1,         '-': 1,         '*': 2,         '/': 2     }     rpntokens = []     opstack = []     for token in tokens:         if isinstance(token, int):             rpntokens.append(token)         else:             while opstack and precedence[token] <= precedence[opstack[-1]]:                 rpntokens.append(opstack.pop())     return rpntokens

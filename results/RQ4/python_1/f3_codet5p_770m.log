Namespace(log_name='./RQ5/python_1/f3_codet5p_770m.log', model_name='Salesforce/codet5p-770m', lang='python', output_dir='RQ5/python_1/f3_codet5p_770m', data_dir='./data/RQ5/python_1_3', no_cuda=False, visible_gpu='0', add_task_prefix=False, add_lang_ids=False, num_train_epochs=10, num_test_epochs=10, train_batch_size=8, eval_batch_size=4, gradient_accumulation_steps=2, load_model_path=None, config_name='', tokenizer_name='', max_source_length=128, max_target_length=128, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, do_lower_case=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, max_steps=-1, eval_steps=-1, train_steps=-1, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, model_name: Salesforce/codet5p-770m
model created!
Total 1 training instances 
***** Running training *****
  Num examples = 1
  Batch size = 8
  Num epoch = 10

***** Running evaluation *****
  Num examples = 103
  Batch size = 4
  epoch = 0
  eval_ppl = 1.00282
  global_step = 1
  train_loss = 0.9729
  ********************
Previous best ppl:inf
Achieve Best ppl:1.00282
  ********************
BLEU file: ./data/RQ5/python_1_3/validation.jsonl
  codebleu-4 = 18.78 	 Previous best codebleu 0
  ********************
 Achieve Best bleu:18.78
  ********************

***** Running evaluation *****
  Num examples = 103
  Batch size = 4
  epoch = 1
  eval_ppl = 1.00282
  global_step = 1
  train_loss = 0.91
  ********************
Previous best ppl:1.00282
BLEU file: ./data/RQ5/python_1_3/validation.jsonl
  codebleu-4 = 18.78 	 Previous best codebleu 18.78
  ********************

***** Running evaluation *****
  Num examples = 103
  Batch size = 4
  epoch = 2
  eval_ppl = 1.00282
  global_step = 1
  train_loss = 1.1105
  ********************
Previous best ppl:1.00282
BLEU file: ./data/RQ5/python_1_3/validation.jsonl
  codebleu-4 = 18.78 	 Previous best codebleu 18.78
  ********************

***** Running evaluation *****
  Num examples = 103
  Batch size = 4
  epoch = 3
  eval_ppl = 1.00282
  global_step = 1
  train_loss = 0.9467
  ********************
Previous best ppl:1.00282
BLEU file: ./data/RQ5/python_1_3/validation.jsonl
  codebleu-4 = 18.78 	 Previous best codebleu 18.78
  ********************
reload model from RQ5/python_1/f3_codet5p_770m/checkpoint-best-bleu
BLEU file: ./data/RQ5/python_1_3/test.jsonl
  codebleu = 21.27 
  Total = 113 
  Exact Fixed = 0 
[]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  ********************
  Total = 113 
  Exact Fixed = 0 
[]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  codebleu = 21.27 
[0.11567895591825603, 0.13659507445324887, 0.301245288430746, 0.4052833929757812, 0.02677944046844502, 0.3365945748819247, 0.11281746036286268, 0.32010359929258053, 0.09792738963737461, 0.18141018702699077, 0.26895892417119643, 0.1258119355069759, 0.3012296883202368, 0.3063959390444712, 0.19205290210919032, 0.18067007075497726, 0.20161587046674967, 0.06776992765491252, 0.35246121268548214, 0.24210204035036623, 0.0021542326419465778, 0.3014429222766674, 0.27286414172020806, 0.030815770085265363, 0.17508509116681822, 0.2842429592310985, 0.19918323331260035, 0.14293176479163866, 0.19123237619230515, 0.030301395788566117, 0.26973129967972453, 0.34430960407784467, 0.578805361789136, 0.1724315042521241, 0.023239414357221627, 0.2571160520082049, 0.15643252109747244, 0.3246537622234833, 0.29988187536555005, 0.24403545824574757, 0.19758253767220937, 0.22097613753411635, 0.4484546393371929, 0.2575315903284878, 0.31296500549798306, 0.17395987787226724, 0.5842119026958161, 0.09851169814617236, 0.3087195973575269, 0.29448858190257304, 0.3684035185222258, 0.28175688944379906, 0.21228912671030511, 0.022513495581302702, 0.24043568611039623, 0.2584513474509599, 0.137222018439976, 0.17125122952921285, 0.16387037624238518, 0.24570601563463407, 0.26868898332480656, 0.09766439489764521, 0.12093761595541908, 0.18184122689277427, 0.07417472104188312, 0.2063275721535342, 0.10266590107456319, 0.1239791836516794, 0.36576838928043237, 0.13283537849359878, 0.1346813977468099, 0.116591155376448, 0.08415086385889857, 0.04701821668264621, 0.19034202489059157, 0.10506676739453288, 0.03736414696427542, 0.04166187718102196, 0.28659212365283837, 0.31307279298512747, 0.14918291846989654, 0.08061534463554385, 0.2679728552223303, 0.1075315301106852, 0.2302675616894552, 0.026603661094646368, 0.13716551092110132, 0.3243809587850692, 0.23668392528162485, 0.370735961468444, 0.3686527413742004, 0.031708807361823674, 0.17247521158120524, 0.3440399513855229, 0.3601843984514039, 0.7371642831468738, 0.3478342953131304, 0.28228003904446625, 0.18477274493520424, 0.32399222162595276, 0.09226442410495196, 0.33571212972107406, 0.36725261003654647, 0.09549345752120848, 0.07505954775184676, 0.09269006382529268, 0.03793103448275862, 0.12746574910885633, 0.3065749282309857, 0.34376660200604264, 0.2646295775178173, 0.04926115023929537, 0.1592209958151769]
Finish training and take 37m

def GroupBy(_GroupBy):          ).sortlevel()          if self.as_index:             d = {self.obj._get_axis_name(self.axis): index, "copy": False              return output.reindex(**d)
def run_hive_cmd(cmd):          stdout = run_hive_cmd(cmd)          return stdout and table in stdout          def run_hive_cmd(cmd):          stdout = run_hive_cmd(cmd)          return stdout and table in stdout          def run_hive_cmd(cmd):          stdout = run_hive_cmd(cmd)          return stdout and table in stdout          def run_hive_cmd(cmd):          stdout = run_hive_cmd(cmd)          return stdout and table in stdout          def run_hive_cmd(cmd):          stdout = run_hive_cmd(cmd)          return stdout and table in stdout          def run_hive_cmd(cmd):          stdout = run_hive_cmd(cmd)          return stdout and table in stdout          def run_hive_cmd(cmd):          stdout = run_hive_cmd(cmd)          return stdout and table in stdout          def run_hive_cmd(cmd):          stdout = run_hive_cmd(cmd)          return stdout and table in stdout          def run_hive_cmd(cmd):          stdout = run_hive_cmd(cmd)          return stdout and table in stdout          def run_hive_cmd(cmd):          stdout = run_hive_cmd(cmd)          return stdout and table in stdout          def run_hive_cmd(cmd):          stdout = run_hive_cmd(cmd)          return stdout and table in stdout          def run_hive_cmd(cmd):          stdout = run_hive_cmd(cmd)          return stdout and table in stdout          def run_hive_cmd(cmd):          stdout = run_hive_cmd(cmd)          return stdout and table in stdout          def run_hive_cmd(cmd):          stdout = run_hive_cmd(cmd)          return stdout and table in stdout          def run_hive_cmd(cmd):          stdout = run_hive_cmd(cmd)          return stdout and table in stdout          def run_hive_cmd(cmd):          stdout = run_hive_cmd(cmd)          return stdout and table in stdout          def run_hive_cmd(cmd):          stdout = run_hive_cmd(cmd)          return stdout and table in stdout
def result_index(self):          if len(self.binlabels)!= 0 and isna(self.binlabels[0]):      def result_index(self):          if len(self.binlabels)!= 0 and isna(self.binlabels[0]):      def result_index(self):          if len(self.binlabels)!= 0 and isna(self.binlabels[0]):      def result_index(self):          if len(self.binlabels)!= 0 and isna(self.binlabels[0]):      def result_index(self):          if len(self.binlabels)!= 0 and isna(self.binlabels[0]):      def result_index(self):          if len(self.binlabels)!= 0 and isna(self.binlabels[0]):      def result_index(self):          if len(self.binlabels)!= 0 and isna(self.binlabels[0]):      def result_index(self):          if len(self.binlabels)!= 0 and isna(self.binlabels[0]):      def result_index(self):          if len(self.binlabels)!= 0 and isna(self.binlabels[0]):      def result_index(self):          if len(self.binlabels)!= 0 and isna(self.binlabels[0]):      def result_index(self):          if len(self.binlabels)!= 0 and isna(self.binlabels[0]):      def result_index(self):          if len(self.binlabels)!= 0 and isna(self.binlabels[0]):      def result_index(self):          if len(self.binlabels)!= 0 and isna(self.binlabels[0]):      def result_index(self):          if len(self.binlabels)!= 0 and isna(self.binlabels[0]):      def result_index(self):          if len(self.binlabels)!= 0 and isna(self.binlabels[0]):      def result_index(self):          if len(self.binlabels)!= 0 and isna(self.binlabels[0]):      def result_index(self):          if len(self.bin
def transpose(self, args, kwargs):          dtype: object          nv.validate_transpose(args, kwargs)      return super().transpose(1, 0, **kwargs      T = property(transpose)      # def transpose(self, args, kwargs):          dtype: object          nv.validate_transpose(args, kwargs)      return super().transpose(1, 0, **kwargs      T = property(transpose)      # def transpose(self, args, kwargs):          dtype: object          nv.validate_transpose(args, kwargs)      return super().transpose(1, 0, **kwargs      T = property(transpose)      # def transpose(self, args, kwargs):          dtype: object          nv.validate_transpose(args, kwargs)      return super().transpose(1, 0, **kwargs      T = property(transpose)      # def transpose(self, args, kwargs):          dtype: object          nv.validate_transpose(args, kwargs)      return super().transpose(1, 0, **kwargs      T = property(transpose)      # def transpose(self, args, kwargs):          dtype: object          nv.validate_transpose(args, kwargs)      return super().transpose(1, 0, **kwargs      T = property(transpose)      # def transpose(self, args, kwargs):          dtype: object          nv.validate_transpose(args, kwargs)      return super().transpose(1, 0, **kwargs      T = property(transpose)      # def transpose(self, args, kwargs):          dtype: object          nv.validate_transpose(args, kwargs)      return super().transpose(1, 0, **kwargs      T = property(transpose)      # def transpose(self, args, kwargs):          dtype: object          nv.validate_transpose(args, kwargs)      return super().transpose(1, 0, **kwargs      T = property(transpose)      # def transpose(self, args, kwargs):          dtype: object          nv.validate_transpose(args, kwargs)      return super().transpose(1, 0, **kwargs      T = property(transpose)      # def transpose(self, args, kwargs):          dtype: object          nv.validate_transpose(args, kwargs)      return super().trans
def target_version_option_callback(  @click.option(      "--config",      type=click.Path(         exists=False, file_okay=True, dir_okay=True, readable=True, allow_dash=False ),      is_eager=True,      callback=read_pyproject_toml) def target_version_option_callback(  @click.option(      "--config",      type=click.Path(         exists=False, file_okay=True, dir_okay=True, readable=True, allow_dash=False ),      is_eager=True,      callback=read_pyproject_toml) def target_version_option_callback(  @click.option(      "--config",      type=click.Path(         exists=False, file_okay=True, dir_okay=True, readable=True, allow_dash=False ),      is_eager=True,      callback=read_pyproject_toml) def target_version_option_callback(  @click.option(      "--config",      type=click.Path(         exists=False, file_okay=True, dir_okay=True, readable=True, allow_dash=False ),      is_eager=True,      callback=read_pyproject_toml) def target_version_option_callback(  @click.option(      "--config",      type=click.Path(         exists=False, file_okay=True, dir_okay=True, readable=True, allow_dash=False ),      is_eager=True,      callback=read_pyproject_toml) def target_version_option_callback(  @click.option(      "--config",      type=click.Path(         exists=False, file_okay=True, dir_okay=True, readable=True, allow_dash=False ),      is_eager=True,      callback=read_pyproject_toml) def target_version_option_callback(  @click.option(      "--config",      type=click.Path(         exists=False, file_okay=True, dir_okay=True, readable=True, allow_dash=False
def middleware(self, middleware_or_request): def middleware(self, middleware_or_request): def middleware(self, middleware_or_request): def middleware(self, middleware_or_request): def middleware(self, middleware_or_request): def middleware(self, middleware_or_request): def middleware(self, middleware_or_request): def middleware(self, middleware_or_request): def middleware(self, middleware_or_request): def middleware(self, middleware_or_request): def middleware(self, middleware_or_request): def middleware(self, middleware_or_request): def middleware(self, middleware_or_request): def middleware(self, middleware_or_request): def middleware(self, middleware_or_request): def middleware(self, middleware_or_request): def middleware(self, middleware_or_request): def middleware(self, middleware_or_request): def middleware(self, middleware_or_request): def middleware(self, middleware_or_request): def middleware(self, middleware_or_request): def middleware(self, middleware_or_request): def middleware(self, middleware_or_request): def middleware(self, middleware_or_request): def middleware(self, middleware_or_request): def middleware(self, middleware_or_request): def middleware(self, middleware_or_request): def middleware(self, middleware_or_request): def middleware(self, middleware_or_request): def middleware(self, middleware_or_request): def middleware(self, middleware_or_request): def middleware(self, middleware_or_request): def middleware(self, middleware_or_request): def middleware(self, middleware_or_request): def middleware(self, middleware_or_request): def middleware(self, middleware_or_request): def middleware(self, middleware_or_request): def middleware(self, middleware_or_request): def middleware(self, middleware_or_request): def middleware(self, middleware_or_request): def middleware(self, middleware_or_request): def middleware(self, middleware_or_request): def middleware(self, middleware_or_request): def middleware(self, middleware_or_request): def middleware(self, middleware_or_request): def middleware(self, middleware_or_request): def middleware(self
def Model(Container):                  enqueuer.start(workers=workers, max_queue_size=max_queue_size)                  output_generator = enqueuer.get()              if verbose == 1:                  progbar = Progbar(target=target)
def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),      else:          strides = (1, 1) + strides     x = tf.nn.conv2d_transpose(x, kernel, output_shape, strides,                                padding=padding,                                data_format=tf_data_format)      return x def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),      else:          strides = (1, 1) + strides     x = tf.nn.conv2d_transpose(x, kernel, output_shape, strides,                                padding=padding,                                data_format=tf_data_format)      return x def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),      else:          strides = (1, 1) + strides     x = tf.nn.conv2d_transpose(x, kernel, output_shape, strides,                                padding=padding,                                data_format=tf_data_format)      return x def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),      else:          strides = (1, 1) + strides     x = tf.nn.conv2d_transpose(x, kernel, output_shape, strides,                                padding=padding,                                data_format=tf_data_format)      return x def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),      else:          strides = (1, 1) + strides     x = tf.nn.conv2d_transpose(x, kernel, output_shape, strides,                                padding=padding,                                data_format=tf_data_format)      return x def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),      else:          strides = (1, 1) + strides     x = tf.nn.conv2d_transpose(x, kernel, output_shape, strides,                                padding=padding,                                data_format=tf_data_format)      return x def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),      else:          strides = (1, 1) + strides
def _read_header(self):          self._read_header()          self._read_header()          self._read_header()          self._read_header()          self._read_header()          self._read_header()          self._read_header()          self._read_header()          self._read_header()          self._read_header()          self._read_header()          self._read_header()          self._read_header()          self._read_header()          self._read_header()          self._read_header()          self._read_header()          self._read_header()          self._read_header()          self._read_header()          self._read_header()          self._read_header()          self._read_header()          self._read_header()          self._read_header()          self._read_header()          self._read_header()          self._read_header()          self._read_header()          self._read_header()          self._read_header()          self._read_header()          self._read_header()          self._read_header()          self._read_header()          self._read_header()          self._read_header()          self._read_header()          self._read_header()          self._read_header()          self._read_header()          self._read_header()          self._read_header()          self._read_header()          self._read_header()          self._read_header()          self._read_header()          self._read_header()          self._read_header()          self._read_header()          self._read_header()          self._read_header()          self._read_header()          self._read_header()          self._read_header()          self._read_header()          self._read_header()          self._read_header()          self._read_header()          self._read_header()          self._read_header()          self._read_header()          self._read_header()          self._read_header()          self._read_header()          self._read_header()          self._read_header()          self._read_header()          self._read_header()          self._read_header()          self._read_header()          self._read_
def __setitem__(self, key, value):         while len(self) >= self.limit:             self.popitem(last=False)          super(LocalCache, self).__setitem__(key, value)      def __setitem__(self, key, value):         while len(self) >= self.limit:             self.popitem(last=False)          super(LocalCache, self).__setitem__(key, value)      def __setitem__(self, key, value):         while len(self) >= self.limit:             self.popitem(last=False)          super(LocalCache, self).__setitem__(key, value)      def __setitem__(self, key, value):         while len(self) >= self.limit:             self.popitem(last=False)          super(LocalCache, self).__setitem__(key, value)      def __setitem__(self, key, value):         while len(self) >= self.limit:             self.popitem(last=False)          super(LocalCache, self).__setitem__(key, value)      def __setitem__(self, key, value):         while len(self) >= self.limit:             self.popitem(last=False)          super(LocalCache, self).__setitem__(key, value)      def __setitem__(self, key, value):         while len(self) >= self.limit:             self.popitem(last=False)          super(LocalCache, self).__setitem__(key, value)      def __setitem__(self, key, value):         while len(self) >= self.limit:             self.popitem(last=False)          super(LocalCache, self).__setitem__(key, value)      def __setitem__(self, key, value):         while len(self) >= self.limit:             self.popitem(last=False)          super(LocalCache, self).__setitem__(key, value)      def __setitem__(self, key, value):         while len(self) >= self.limit:             self.popitem(last=False)          super(LocalCache, self).__setitem__(key, value)
def __await__(self):          task = asyncio.ensure_future(self.serve_coro, loop=self.loop      def __await__(self):          task = asyncio.ensure_future(self.serve_coro, loop=self.loop      def __await__(self):          task = asyncio.ensure_future(self.serve_coro, loop=self.loop      def __await__(self):          task = asyncio.ensure_future(self.serve_coro, loop=self.loop      def __await__(self):          task = asyncio.ensure_future(self.serve_coro, loop=self.loop      def __await__(self):          task = asyncio.ensure_future(self.serve_coro, loop=self.loop      def __await__(self):          task = asyncio.ensure_future(self.serve_coro, loop=self.loop      def __await__(self):          task = asyncio.ensure_future(self.serve_coro, loop=self.loop      def __await__(self):          task = asyncio.ensure_future(self.serve_coro, loop=self.loop      def __await__(self):          task = asyncio.ensure_future(self.serve_coro, loop=self.loop      def __await__(self):          task = asyncio.ensure_future(self.serve_coro, loop=self.loop      def __await__(self):          task = asyncio.ensure_future(self.serve_coro, loop=self.loop      def __await__(self):          task = asyncio.ensure_future(self.serve_coro, loop=self.loop      def __await__(self):          task = asyncio.ensure_future(self.serve_coro, loop=self.loop      def __await__(self):          task = asyncio.ensure_future(self.serve_coro, loop=self.loop      def __await__(self):          task = asyncio.ensure_future(self.serve_coro, loop=self.loop      def __await__(self):          task = asyncio.ensure_future(self.serve_coro, loop=self.loop      def __await__(self):          task = asyncio.ensure_future(self
def deconv_length(dim_size, stride_size, kernel_size, padding, output_padding):      if dim_size is None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return None      return
def fit_generator(model,              elif val_gen):                  val_data = validation_data                  if isinstance(val_data, Sequence):                     val_enqueuer_gen = iter_sequence_infinite(generator)                  else:                      val_enqueuer_gen = val_data              else:
def is_s3_url(path):          if partition_cols is not None              kwargs["file_scheme"] = "hive"          if is_s3_url(path):              path, _, _, _ = get_filepath_or_buffer(path, mode="wb")              kwargs["open_with"] = lambda path: path          else:              path, _, _, _ = get_filepath_or_buffer(path)
def NumpyArrayIterator(Iterator):                             dtype=K.floatx())              for i, j in enumerate(index_array):              x = self.x[j]              x = self.image_data_generator.random_transform(x.astype(K.floatx()))              x = self.image_data_generator.standardize(x)              batch_x[i] = x
def HTTPRequest(HTTPMessage):          )          headers = dict(self.orig.headers)          if 'Host' not in headers:              headers['Host']          headers = ['%s: %s' % (name, value)
def __init__(self):          self.deferred = defer.Deferred()      def outReceived(self, data):      def outReceived(self, data):      def outReceived(self, data):      def outReceived(self, data):      def outReceived(self, data):      def outReceived(self, data):      def outReceived(self, data):      def outReceived(self, data):      def outReceived(self, data):      def outReceived(self, data):      def outReceived(self, data):      def outReceived(self, data):      def outReceived(self, data):      def outReceived(self, data):      def outReceived(self, data):      def outReceived(self, data):      def outReceived(self, data):      def outReceived(self, data):      def outReceived(self, data):      def outReceived(self, data):      def outReceived(self, data):      def outReceived(self, data):      def outReceived(self, data):      def outReceived(self, data):      def outReceived(self, data):      def outReceived(self, data):      def outReceived(self, data):      def outReceived(self, data):      def outReceived(self, data):      def outReceived(self, data):      def outReceived(self, data):      def outReceived(self, data):      def outReceived(self, data):      def outReceived(self, data):      def outReceived(self, data):      def outReceived(self, data):      def outReceived(self, data):      def outReceived(self, data):      def outReceived(self, data):      def outReceived(self, data):      def outReceived(self, data):      def outReceived(self, data):      def outReceived(self, data):      def outReceived(self, data):      def outReceived(self, data):      def outReceived(self, data):      def outReceived(self, data):      def outReceived(self, data):      def outReceived(self, data):      def outReceived(self, data):      def outReceived(self, data):      def outReceived(self, data):      def outReceived(self, data):      def outReceived(self, data):      def outReceived(self, data
def _Window(PandasObject, SelectionMixin):              except (ValueError, TypeError):                  raise TypeError("cannot handle this type -> {0}         values[np.isinf(values)]          return values
def BaseComparisonOpsTests(BaseOpsUtil):              assert result is NotImplemented          else:              raise pytest.skip(f"{type(data) does not implement __eq__")
def CentralPlannerScheduler(Scheduler):          tasks.sort(key=self._rank(), reverse=True)          for task in tasks:             in_workers = assistant or worker in task.workers              if task.status == 'RUNNING and in_workers:
def jsonable_encoder(                      exclude=exclude,                      by_alias=by_alias,                     exclude_unset=exclude_unset,                      include_none=include_none,                      custom_encoder=custom_encoder,                      sqlalchemy_safe=sqlalchemy_safe,                  ) def jsonable_encoder(                      exclude=exclude,                      by_alias=by_alias,                     exclude_unset=exclude_unset,                      include_none=include_none,                      custom_encoder=custom_encoder,                      sqlalchemy_safe=sqlalchemy_safe,                  ) def jsonable_encoder(                      exclude=exclude,                      by_alias=by_alias,                     exclude_unset=exclude_unset,                      include_none=include_none,                      custom_encoder=custom_encoder,                      sqlalchemy_safe=sqlalchemy_safe,                  ) def jsonable_encoder(                      exclude=exclude,                      by_alias=by_alias,                     exclude_unset=exclude_unset,                      include_none=include_none,                      custom_encoder=custom_encoder,                      sqlalchemy_safe=sqlalchemy_safe,                  ) def jsonable_encoder(                      exclude=exclude,                      by_alias=by_alias,                     exclude_unset=exclude_unset,                      include_none=include_none,                      custom_encoder=custom_encoder,                      sqlalchemy_safe=sqlalchemy_safe,                  ) def jsonable_encoder(                      exclude=exclude,                      by_alias=by_alias,                     exclude_unset=exclude_unset,                      include_none=include_none,                      custom_encoder=custom_encoder,                      sqlalchemy_safe=sqlalchemy_safe,                  ) def jsonable_encoder(                      exclude=exclude,                      by_alias=by_alias,                     exclude_unset=exclude_unset,                      include_none=include_none,                      custom_encoder=custom_encoder,                      sqlalchemy_safe=sqlalchemy_safe,                  ) def jsonable_encoder(                      exclude=exclude,                      by_alias=by_alias,                     exclude_unset=exclude_unset,                      include_none=include_none,                      custom_encoder=custom_encoder,                      sqlalchemy_safe=sqlalchemy_safe,                  ) def jsonable_encoder(                      exclude=exclude,                      by_alias=by_alias,                     exclude
def unified_timestamp(date_str, day_first=True):      date_str = date_str.replace(',','')      pm_delta = datetime.timedelta(hours=12 if re.search(r'(?i)PM', date_str) else 0)      timezone, date_str = extract_timezone(date_str)
def eb_wrapper(failure):              case = _create_testcase(method, 'errback')              exc_info = failure.value, failure.type, failure.getTracebackObject()              results.addError(case, exc_info)          request.callback = cb_wrapper
def APIRouter(routing.Router):              response_model_exclude_unset=bool(                  response_model_exclude_unset or response_model_skip_defaults              ),              include_in_schema=include_in_schema,              response_class=response_class or self.default_response_class,              name=name,
def format_file_in_place(          return False      if write_back == write_back.YES:         with open(src, "w", encoding=src_buffer.encoding) as f              f.write(dst_contents)      elif write_back == write_back.DIFF:          src_name = f"{src}  (original)"
def is_series_dispatch(left, right, op):          return True     if is_datetime64_dtype(ldtype) and is_object_dtype(rdtype):          return False      return False
def run_script_with_context(script_path, cwd, context):      def run_script_with_context(script_path, cwd, context):      def run_script_with_context(script_path, cwd, context):      def run_script_with_context(script_path, cwd, context):      def run_script_with_context(script_path, cwd, context):      def run_script_with_context(script_path, cwd, context):      def run_script_with_context(script_path, cwd, context):      def run_script_with_context(script_path, cwd, context):      def run_script_with_context(script_path, cwd, context):      def run_script_with_context(script_path, cwd, context):      def run_script_with_context(script_path, cwd, context):      def run_script_with_context(script_path, cwd, context):      def run_script_with_context(script_path, cwd, context):      def run_script_with_context(script_path, cwd, context):      def run_script_with_context(script_path, cwd, context):      def run_script_with_context(script_path, cwd, context):      def run_script_with_context(script_path, cwd, context):      def run_script_with_context(script_path, cwd, context):      def run_script_with_context(script_path, cwd, context):      def run_script_with_context(script_path, cwd, context):      def run_script_with_context(script_path, cwd, context):      def run_script_with_context(script_path, cwd, context):      def run_script_with_context(script_path, cwd, context):      def run_script_with_context(script_path, cwd, context):      def run_script_with_context(script_path, cwd, context):      def run_script_with_context(script_path, cwd, context):      def run_script_with_context(script_path, cwd, context):      def run_script_with_context(script_path, cwd, context):      def run_script_with
def enqueue_scrape(self, response, request, spider):          d = self.scraper.enqueue_scrape(response, request, spider)          d.addErrback(lambda f: logger.error('Error while enqueuing downloader output',                                              extra={'spider': spider, 'failure': f}))          return d      def spider_is_idle(self, spider):      def spider_is_idle(self, spider):      def spider_is_idle(self, spider):      def spider_is_idle(self, spider):      def spider_is_idle(self, spider):      def spider_is_idle(self, spider):      def spider_is_idle(self, spider):      def spider_is_idle(self, spider):      def spider_is_idle(self, spider):      def spider_is_idle(self, spider):      def spider_is_idle(self, spider):      def spider_is_idle(self, spider):      def spider_is_idle(self, spider):      def spider_is_idle(self, spider):      def spider_is_idle(self, spider):      def spider_is_idle(self, spider):      def spider_is_idle(self, spider):      def spider_is_idle(self, spider):      def spider_is_idle(self, spider):      def spider_is_idle(self, spider):      def spider_is_idle(self, spider):      def spider_is_idle(self, spider):      def spider_is_idle(self, spider):      def spider_is_idle(self, spider):      def spider_is_idle(self, spider):      def spider_is_idle(self, spider):      def spider_is_idle(self, spider):      def spider_is_idle(self, spider):      def spider_is_idle(self, spider):      def spider_is_idle(self, spider):      def spider_is_idle(self, spider):      def spider_is_idle(self, spider):      def spider_is_idle(self, spider):      def spider_is_idle(self, spider):      def spider_is_idle(self, spider):      def spider_is_idle(self, spider):      def spider_
def InfoExtractor(object):                                      f['url'] = initialization_url                                  f['fragments'].append({location_key(initialization_url): initialization_url                                  f['fragments'].extend(representation_ms_info['fragments'])                         try:                             existing_format = next(                                 fo for fo in formats                                 if fo['format_id'] == representation_id)                         except StopIteration:                             full_info = formats_dict.get(representation_id, {}).copy()                             full_info.update(f)                             formats.append(full_info)                         else:                             existing_format.update(f)                      else:                          self.report_warning('Unknown MIME type %s in DASH manifest' % mime_type)          formats
def APIRouter(routing.Router):                      response_model_exclude=route.response_model_exclude,                      response_model_by_alias=route.response_model_by_alias,                      response_model_exclude_unset=route.response_model_exclude_unset,                      include_in_schema=route.include_in_schema,                      response_class=route.response_class or default_response_class,                      name=route.name,
def validate_baseindexer_support(func_name: Optional[str]) -> None:          "median",          "std",          "var",          "kurt",          "quantile",
def _decorate_ticks(self, ax, name, ticklabels, start_edge, end_edge):          ax.set_xlim((start_edge, end_edge))         ax.set_xticks(self.tick_pos)          if name is not None and self.use_index:              ax.set_xlabel(name)
def match(command, settings):  def get_new_command(command, settings):      cmds = command.script.split(' ')      machine = ""      return shells.and_("vagrant up " +  machine, command.script)
def is_trivial_worker(self, state): def is_trivial_worker(self, state): def is_trivial_worker(self, state): def is_trivial_worker(self, state): def is_trivial_worker(self, state): def is_trivial_worker(self, state): def is_trivial_worker(self, state): def is_trivial_worker(self, state): def is_trivial_worker(self, state): def is_trivial_worker(self, state): def is_trivial_worker(self, state): def is_trivial_worker(self, state): def is_trivial_worker(self, state): def is_trivial_worker(self, state): def is_trivial_worker(self, state): def is_trivial_worker(self, state): def is_trivial_worker(self, state): def is_trivial_worker(self, state): def is_trivial_worker(self, state): def is_trivial_worker(self, state): def is_trivial_worker(self, state): def is_trivial_worker(self, state): def is_trivial_worker(self, state): def is_trivial_worker(self, state): def is_trivial_worker(self, state): def is_trivial_worker(self, state): def is_trivial_worker(self, state): def is_trivial_worker(self, state): def is_trivial_worker(self, state): def is_trivial_worker(self, state): def is_trivial_worker(self, state): def is_trivial_worker(self, state): def is_trivial_worker(self, state): def is_trivial_worker(self, state): def is_trivial_worker(self, state): def is_trivial_worker(self, state): def is_trivial_worker(self, state): def is_trivial_worker(self, state): def is_trivial_worker(self, state): def is_trivial_worker(self, state): def is_trivial_worker(self, state): def is_trivial_worker(self, state): def is_trivial_
def pivot_table(                  agged[v] = maybe_downcast_to_dtype(agged[v], data[v].dtype)) def pivot_table(                  agged[v] = maybe_downcast_to_dtype(agged[v], data[v].dtype)) def pivot_table(                  agged[v] = maybe_downcast_to_dtype(agged[v], data[v].dtype)) def pivot_table(                  agged[v] = maybe_downcast_to_dtype(agged[v], data[v].dtype)) def pivot_table(                  agged[v] = maybe_downcast_to_dtype(agged[v], data[v].dtype)) def pivot_table(                  agged[v] = maybe_downcast_to_dtype(agged[v], data[v].dtype)) def pivot_table(                  agged[v] = maybe_downcast_to_dtype(agged[v], data[v].dtype)) def pivot_table(                  agged[v] = maybe_downcast_to_dtype(agged[v], data[v].dtype)) def pivot_table(                  agged[v] = maybe_downcast_to_dtype(agged[v], data[v].dtype)) def pivot_table(                  agged[v] = maybe_downcast_to_dtype(agged[v], data[v].dtype)) def pivot_table(                  agged[v] = maybe_downcast_to_dtype(agged[v], data[v].dtype)) def pivot_table(                  agged[v] = maybe_downcast_to_dtype(agged[v], data[v].dtype)) def pivot_table(                  agged[v] = maybe_downcast_to_dtype(agged[v], data[v].dtype)) def pivot_table(                  agged[v] = maybe_downcast_to_dtype(agged[v], data[v].dtype)) def pivot_table(                  agged[v] = maybe_downcast_to_dtype(agged[v], data[v].dtype)) def pivot_table(                  agged[v] = maybe_downcast_to_dtype(agged[v], data[v].
def create_cloned_field(field: ModelField) -> ModelField:              original_type.__name__, __config__=original_type.__config__          )          for f in original_type.__fields__.values():             use_type.__fields__[f.name]          use_type.__validators__ = original_type.__validators__      if PYDANTIC_1:          new_field = ModelField(
def read_conllx(input_data, use_morphology=False, n=0):                      continue                  try:                      id_ = int(id_) - 1                      head = (int(head) - 1) if head!= "0" else id_                      dep = "ROOT" if dep == "root" else dep                      tag = pos if tag == "_" else tag                      tag = tag + "__" + morph if use_morphology else tag
def BaseReshapingTests(BaseExtensionTests):          result[0] == result[1]
def compatibility_call(self, side_effect, old_cmd, self.script):          logs.debug(u'PYTHONIOENCODING: {}'.format(             os.environ.get('PYTHONIOENCODING', '>-not-set-<')))          print(self.script)
def add_codes(err_cls):      class ErrorsWithCodes(object):          def __getattribute__(self, code):             msg = getattr(err_cls, code)             return "[{code}] {msg}".format(code=code, msg=msg)
def func(**kwargs):              if result_is_index:                 result = algorithms.take_nd(obj.values, result)              if post_processing:                  result = post_processing(result, obj)
def _isna_ndarraylike_old(obj):      return result  def notna(obj):      Detect non-missing values for an array-like object  def _isna_ndarraylike_old(obj):      return result  def notna(obj):      Detect non-missing values for an array-like object  def _isna_ndarraylike_old(obj):      return result  def notna(obj):      Detect non-missing values for an array-like object  def _isna_ndarraylike_old(obj):      return result  def notna(obj):      Detect non-missing values for an array-like object  def _isna_ndarraylike_old(obj):      return result  def notna(obj):      Detect non-missing values for an array-like object  def _isna_ndarraylike_old(obj):      return result  def notna(obj):      Detect non-missing values for an array-like object  def _isna_ndarraylike_old(obj):      return result  def notna(obj):      Detect non-missing values for an array-like object  def _isna_ndarraylike_old(obj):      return result  def notna(obj):      Detect non-missing values for an array-like object  def _isna_ndarraylike_old(obj):      return result  def notna(obj):      Detect non-missing values for an array-like object  def _isna_ndarraylike_old(obj):      return result  def notna(obj):      Detect non-missing values for an array-like object  def _isna_ndarraylike_old(obj):      return result  def notna(obj):      Detect non-missing values for an array-like object  def _isna_ndarraylike_old(obj):      return result  def notna(obj):      Detect non-missing values for an array-like object  def _isna_ndarraylike_old(obj):      return result  def notna(obj):      Detect non-missing values for an array-like object  def _isna_ndarraylike_old(obj):      return result  def notna(obj):      Detect non-missing values for an array-like object  def _isna_ndarraylike_old(obj):      return result  def notna(
def _LocIndexer(_LocationIndexer):          if isinstance(labels, MultiIndex):             if isinstance(key, str):                  key = tuple([key] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(None)] + [slice(
def BracketTracker:         if self._lambda_arguments and leaf.type == token.COLON              self.depth -= 1             self._lambda_arguments = False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False          return False
def take(self, indices, axis, allow_fill, fill_value, **kwargs):          if isinstance(maybe_slice, slice):              return self[maybe_slice]         taken = ExtensionIndex.take(              self, indices, axis, allow_fill, fill_value, **kwargs          )         freq = self.freq if is_period_dtype(self) else None         assert taken.freq == freq, (taken.freq, freq, taken)      _can_hold_na = True      _na_value = NaT      def _shallow_copy(self, taken, freq=None):      def _shallow_copy(self, taken, freq=None):      def _shallow_copy(self, taken, freq=None):      def _shallow_copy(self, taken, freq=None):      def _shallow_copy(self, taken, freq=None):      def _shallow_copy(self, taken, freq=None):      def _shallow_copy(self, taken, freq=None):      def _shallow_copy(self, taken, freq=None):      def _shallow_copy(self, taken, freq=None):      def _shallow_copy(self, taken, freq=None):      def _shallow_copy(self, taken, freq=None):      def _shallow_copy(self, taken, freq=None):      def _shallow_copy(self, taken, freq=None):      def _shallow_copy(self, taken, freq=None):      def _shallow_copy(self, taken, freq=None):      def _shallow_copy(self, taken, freq=None):      def _shallow_copy(self, taken, freq=None):      def _shallow_copy(self, taken, freq=None):      def _shallow_copy(self, taken, freq=None):      def _shallow_copy(self, taken, freq=None):      def _shallow_copy(self, taken, freq=None):      def _shallow_copy(self, taken, freq=None):      def _shallow_copy(self, taken, freq=None):      def _shallow_copy(self, taken, freq=None):      def _shallow_copy(self,
def _isna_new(obj):      elif hasattr(obj, "__array__"):          return _isna_ndarraylike(np.asarray(obj))      else:         return obj is None  def _isna_old(obj): def _isna_new(obj):      elif hasattr(obj, "__array__"):          return _isna_ndarraylike(np.asarray(obj))      else:         return obj is None  def _isna_old(obj): def _isna_new(obj):      elif hasattr(obj, "__array__"):          return _isna_ndarraylike(np.asarray(obj))      else:         return obj is None  def _isna_old(obj): def _isna_new(obj):      elif hasattr(obj, "__array__"):          return _isna_ndarraylike(np.asarray(obj))      else:         return obj is None  def _isna_old(obj): def _isna_new(obj):      elif hasattr(obj, "__array__"):          return _isna_ndarraylike(np.asarray(obj))      else:         return obj is None  def _isna_old(obj): def _isna_new(obj):      elif hasattr(obj, "__array__"):          return _isna_ndarraylike(np.asarray(obj))      else:         return obj is None  def _isna_old(obj): def _isna_new(obj):      elif hasattr(obj, "__array__"):          return _isna_ndarraylike(np.asarray(obj))      else:         return obj is None  def _isna_old(obj): def _isna_new(obj):      elif hasattr(obj, "__array__"):          return _isna_ndarraylike(np.asarray(obj))      else:         return obj is None  def _isna_old(obj): def _isna_new(obj):      elif hasattr(obj, "__array__"):          return _isna_ndarraylike(np.asarray(obj))      else:         return obj is None  def _isna_old(obj): def _isna_new(obj):      elif hasattr(obj, "__array__"):          return _isna_ndarraylike(np.asarray(
def TestSeriesComparison:          dti = dti.tz_localize("US/Central")          ser = Series(dti).rename(names[1])          result = op(ser, dti)          assert result.name == names[2]
def js_to_json(code):          if v in ('true', 'false', 'null'):              return v          if v.startswith('"'):             return v          if v.startswith(''"):              v = v[1:-1]              v = re.sub(r"\\\\|\\'|\"", lambda m: {                  '\\\\': '\\\\',
def get() -> ModelSubclass:     return ModelSubclass(sub={}, y=1)  client = TestClient(app)  def get() -> ModelSubclass:     return ModelSubclass(sub={}, y=1)  client = TestClient(app)  def get() -> ModelSubclass:     return ModelSubclass(sub={}, y=1)  client = TestClient(app)  def get() -> ModelSubclass:     return ModelSubclass(sub={}, y=1)  client = TestClient(app)  def get() -> ModelSubclass:     return ModelSubclass(sub={}, y=1)  client = TestClient(app)  def get() -> ModelSubclass:     return ModelSubclass(sub={}, y=1)  client = TestClient(app)  def get() -> ModelSubclass:     return ModelSubclass(sub={}, y=1)  client = TestClient(app)  def get() -> ModelSubclass:     return ModelSubclass(sub={}, y=1)  client = TestClient(app)  def get() -> ModelSubclass:     return ModelSubclass(sub={}, y=1)  client = TestClient(app)  def get() -> ModelSubclass:     return ModelSubclass(sub={}, y=1)  client = TestClient(app)  def get() -> ModelSubclass:     return ModelSubclass(sub={}, y=1)  client = TestClient(app)  def get() -> ModelSubclass:     return ModelSubclass(sub={}, y=1)  client = TestClient(app)  def get() -> ModelSubclass:     return ModelSubclass(sub={}, y=1)  client = TestClient(app)  def get() -> ModelSubclass:     return ModelSubclass(sub={}, y=1)  client = TestClient(app)  def get() -> ModelSubclass:     return ModelSubclass(sub={}, y=1)  client = TestClient(app)  def get() -> ModelSubclass:     return ModelSubclass(sub={}, y=1)  client = TestClient(app)  def get() -> ModelSubclass:     return ModelSubclass(sub={}, y=1)  client = TestClient(app)  def get() -> ModelSubclass:     return ModelSubclass(sub={}, y
def _simple_new(self, new_dates, dtype, freq=self.freq):          new_dates = new_dates.view(DT64NS_DTYPE)          dtype = tz_to_dtype(tz)          return self._simple_new(new_dates, dtype, freq=self.freq)
def reduceLROnPlateau(self):              self.mode = 'auto'          if (self.mode =='min' or             (self.mode == 'auto' and 'acc' not in self.monitor)):             self.monitor_op = lambda a, b: np.less(a, b - self.epsilon)              self.best = np.Inf          self.cooldown_counter = 0          self.best = -np.Inf          self.cooldown_counter = 0          self.best = 0          self.cooldown_counter = 0          self.best = 0          self.cooldown_counter = 0          self.best = 0          self.cooldown_counter = 0          self.best = 0          self.cooldown_counter = 0          self.best = 0          self.cooldown_counter = 0          self.best = 0          self.cooldown_counter = 0          self.best = 0          self.cooldown_counter = 0          self.best = 0          self.cooldown_counter = 0          self.best = 0          self.cooldown_counter = 0          self.best = 0          self.cooldown_counter = 0          self.best = 0          self.cooldown_counter = 0          self.best = 0          self.cooldown_counter = 0          self.best = 0          self.cooldown_counter = 0          self.best = 0          self.cooldown_counter = 0          self.best = 0          self.cooldown_counter = 0          self.best = 0          self.cooldown_counter = 0          self.best = 0          self.cooldown_counter = 0          self.best = 0          self.cooldown_counter = 0          self.best = 0          self.cooldown_counter = 0          self.best = 0          self.cooldown_counter = 0          self.best = 0          self.cooldown_counter = 0          self.best = 0          self.cooldown_counter = 0          self.best = 0          self.cooldown_counter = 0          self.best = 0          self.cooldown_counter = 0          self.best = 0          self.cooldown_counter =
def get_objs_combined_axis(          The axis to extract indexes from.      sort : bool, default True          Whether the result index should come out sorted or not      Returns      -------      Index      obs_idxes = [obj._get_axis(axis) for obj in objs]     return _get_combined_index(obs_idxes, intersect=intersect, sort=sort) def _get_distinct_objs(objs: List[Index]) -> List[Index]:
def BQuarterEnd(DateOffset):          shifted = liboffsets.shift_quarters(              dtindex.asi8, self.n, self.startingMonth, self._day_opt          )          return type(dtindex)._simple_new(             shifted, freq=dtindex.freq, dtype=dtindex.dtype         )  class BQuarterEnd(DateOffset):          shifted = liboffsets.shift_quarters(              dtindex.asi8, self.n, self.startingMonth, self._day_opt          )          return type(dtindex)._simple_new(             shifted, freq=dtindex.freq, dtype=dtindex.dtype         )  class BQuarterEnd(DateOffset):          shifted = liboffsets.shift_quarters(              dtindex.asi8, self.n, self.startingMonth, self._day_opt          )          return type(dtindex)._simple_new(             shifted, freq=dtindex.freq, dtype=dtindex.dtype         )  class BQuarterEnd(DateOffset):          shifted = liboffsets.shift_quarters(              dtindex.asi8, self.n, self.startingMonth, self._day_opt          )          return type(dtindex)._simple_new(             shifted, freq=dtindex.freq, dtype=dtindex.dtype         )  class BQuarterEnd(DateOffset):          shifted = liboffsets.shift_quarters(              dtindex.asi8, self.n, self.startingMonth, self._day_opt          )          return type(dtindex)._simple_new(             shifted, freq=dtindex.freq, dtype=dtindex.dtype         )  class BQuarterEnd(DateOffset):          shifted = liboffsets.shift_quarters(              dtindex.asi8, self.n, self.startingMonth, self._day_opt          )          return type(dtindex)._simple_new(             shifted, freq=dtindex.freq, dtype=dtindex.dtype         )  class BQuarterEnd(DateOffset):          shifted = liboffsets.shift_quarters(              dtindex.asi8, self.n, self.startingMonth, self._day_opt          )          return type(dtindex)._simple_new(             shifted, freq
def ImageDataGenerator(object):              The inputs, normalized.         if self.preprocessing_function:             x = self.preprocessing_function(x)          if self.rescale:              x *= self.rescale          if self.samplewise_center:
def _cat_compare_op(op):              mask = (self._codes == -1) | (other_codes == -1)              return ret          if is_scalar(other): def _cat_compare_op(op):              mask = (self._codes == -1) | (other_codes == -1)              return ret          if is_scalar(other): def _cat_compare_op(op):              mask = (self._codes == -1) | (other_codes == -1)              return ret          if is_scalar(other): def _cat_compare_op(op):              mask = (self._codes == -1) | (other_codes == -1)              return ret          if is_scalar(other): def _cat_compare_op(op):              mask = (self._codes == -1) | (other_codes == -1)              return ret          if is_scalar(other): def _cat_compare_op(op):              mask = (self._codes == -1) | (other_codes == -1)              return ret          if is_scalar(other): def _cat_compare_op(op):              mask = (self._codes == -1) | (other_codes == -1)              return ret          if is_scalar(other): def _cat_compare_op(op):              mask = (self._codes == -1) | (other_codes == -1)              return ret          if is_scalar(other): def _cat_compare_op(op):              mask = (self._codes == -1) | (other_codes == -1)              return ret          if is_scalar(other): def _cat_compare_op(op):              mask = (self._codes == -1) | (other_codes == -1)              return ret          if is_scalar(other): def _cat_compare_op(op):              mask = (self._codes == -1) | (other_codes == -1)              return ret          if is_scalar(other): def _cat_compare_op(op):              mask = (self._codes == -1) | (other_codes == -1)              return ret          if is_scalar(other): def _cat_compare_op(op):              mask = (self._codes ==
def match(command, settings):      return _search(command.stderr) or _search(command.stdout)  def get_new_command(command, settings):      m = _search(command.stderr) or _search(command.stdout)     editor_call = '{} {} +{}'.format(os.environ['EDITOR'],                                      m.group('file'),                                      m.group('line'))      return shells.and_(editor_call, command.script)
def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),          padding: string, "same" or "valid".          data_format: "channels_last" or "channels_first".              Whether to use The The TensorFlow data format         in inputs/kernels/outputs.          ValueError: if using an even kernel size with padding'same'.
def make_requests_from_url(self, url):          def start_requests(self):         if self.make_requests_from_url is not Spider.make_requests_from_url:              warnings.warn(                 "Spider.make_requests_from_url method is deprecated. "                 "It won't be called in future Scrapy releases. "                 "Please override start_requests method instead."              for url in self.start_urls:                  yield self.make_requests_from_url(url)
def reformat_many(      if sys.platform == "win32"          worker_count = min(worker_count, 61)     executor = ProcessPoolExecutor(max_workers=worker_count)      try:          loop.run_until_complete(              schedule_formatting(      def schedule_formatting(      def schedule_formatting(      def schedule_formatting(      def schedule_formatting(      def schedule_formatting(      def schedule_formatting(      def schedule_formatting(      def schedule_formatting(      def schedule_formatting(      def schedule_formatting(      def schedule_formatting(      def schedule_formatting(      def schedule_formatting(      def schedule_formatting(      def schedule_formatting(      def schedule_formatting(      def schedule_formatting(      def schedule_formatting(      def schedule_formatting(      def schedule_formatting(      def schedule_formatting(      def schedule_formatting(      def schedule_formatting(      def schedule_formatting(      def schedule_formatting(      def schedule_formatting(      def schedule_formatting(      def schedule_formatting(      def schedule_formatting(      def schedule_formatting(      def schedule_formatting(      def schedule_formatting(      def schedule_formatting(      def schedule_formatting(      def schedule_formatting(      def schedule_formatting(      def schedule_formatting(      def schedule_formatting(      def schedule_formatting(      def schedule_formatting(      def schedule_formatting(      def schedule_formatting(      def schedule_formatting(      def schedule_formatting(      def schedule_formatting(      def schedule_formatting(      def schedule_formatting(      def schedule_formatting(      def schedule_formatting(      def schedule_formatting(      def schedule_formatting(      def schedule_formatting(      def schedule_formatting(      def schedule_formatting(      def schedule_formatting(      def schedule_formatting(      def schedule_formatting(      def schedule_formatting(      def schedule_formatting(      def schedule_formatting(      def schedule_formatting(      def schedule_formatting(      def schedule_formatting(      def schedule_formatting(
def _get_string_slice(self, key):              try:                  loc = self._get_string_slice(key)                  return series[loc]              except (TypeError, ValueError):                  pass              asdt, reso = parse_time_string(key, self.freq)
def base_url(url):  def urljoin(base, path):      if not isinstance(path, compat_str) or not path      return compat_urlparse.urljoin(base, path) def base_url(url):  def urljoin(base, path):      if not isinstance(path, compat_str) or not path      return compat_urlparse.urljoin(base, path) def base_url(url):  def urljoin(base, path):      if not isinstance(path, compat_str) or not path      return compat_urlparse.urljoin(base, path) def base_url(url):  def urljoin(base, path):      if not isinstance(path, compat_str) or not path      return compat_urlparse.urljoin(base, path) def base_url(url):  def urljoin(base, path):      if not isinstance(path, compat_str) or not path      return compat_urlparse.urljoin(base, path) def base_url(url):  def urljoin(base, path):      if not isinstance(path, compat_str) or not path      return compat_urlparse.urljoin(base, path) def base_url(url):  def urljoin(base, path):      if not isinstance(path, compat_str) or not path      return compat_urlparse.urljoin(base, path) def base_url(url):  def urljoin(base, path):      if not isinstance(path, compat_str) or not path      return compat_urlparse.urljoin(base, path) def base_url(url):  def urljoin(base, path):      if not isinstance(path, compat_str) or not path      return compat_urlparse.urljoin(base, path) def base_url(url):  def urljoin(base, path):      if not isinstance(path, compat_str) or not path      return compat_urlparse.urljoin(base, path) def base_url(url):  def urljoin(base, path):      if not isinstance(path, compat_str) or not path      return compat_urlparse.urljoin(base, path) def base_url(url):  def urljoin(base, path):      if not isinstance(path, compat_str)
def is_list_like_indexer(key):             if isinstance(labels, ABCMultiIndex):                 if isinstance(key, (ABCSeries, np.ndarray)) and key.ndim <= 1:                     key = list(key)                 elif isinstance(key, ABCDataFrame):                     raise NotImplementedError(                         "Indexing a MultiIndex with a "                         "DataFrame key is not "                         "implemented"                     )              return self._getbool_axis(key, axis=axis)          elif is_list_like_indexer(key):             if isinstance(labels, ABCMultiIndex):                 if isinstance(key, (ABCSeries, np.ndarray)) and key.ndim <= 1:                     key = list(key)                 elif isinstance(key, ABCDataFrame):                     raise NotImplementedError(                         "Indexing a MultiIndex with a "                         "DataFrame key is not "                         "implemented"                     )              return self._getbool_axis(key, axis=axis)          elif is_list_like_indexer(key):             if isinstance(labels, ABCMultiIndex):                 if isinstance(key, (ABCSeries, np.ndarray)) and key.ndim <= 1:                     key = list(key)                 elif isinstance(key, ABCDataFrame):                     raise NotImplementedError(                         "Indexing a MultiIndex with a "                         "DataFrame key is not "                         "implemented"                     )              return self._getbool_axis(key, axis=axis)          elif is_list_like_indexer(key):             if isinstance(labels, ABCMultiIndex):                 if isinstance(key, (ABCSeries, np.ndarray)) and key.ndim <= 1:                     key = list(key)                 elif isinstance(key, ABCDataFrame):                     raise NotImplementedError(                         "Indexing a MultiIndex with a "                         "DataFrame key is not "                         "implemented"                     )              return self._getbool_axis(key, axis=axis)          elif is_list_like_indexer(key):             if isinstance(labels, ABCMultiIndex):                 if isinstance(key, (ABCSeries, np.ndarray)) and key.ndim <= 1:                     key = list(key)                 elif isinstance(key, ABCDataFrame):                     raise NotImplementedError(                         "Indexing a MultiIndex with a "                         "DataFrame key is not "                         "implemented"                     )              return self._getbool_axis(key, axis=axis)          elif is_list_
def print_tensor(x, message=''):          The same tensor `x`, unchanged def print_tensor(x, message=''):          The same tensor `x`, unchanged def print_tensor(x, message=''):          The same tensor `x`, unchanged def print_tensor(x, message=''):          The same tensor `x`, unchanged def print_tensor(x, message=''):          The same tensor `x`, unchanged def print_tensor(x, message=''):          The same tensor `x`, unchanged def print_tensor(x, message=''):          The same tensor `x`, unchanged def print_tensor(x, message=''):          The same tensor `x`, unchanged def print_tensor(x, message=''):          The same tensor `x`, unchanged def print_tensor(x, message=''):          The same tensor `x`, unchanged def print_tensor(x, message=''):          The same tensor `x`, unchanged def print_tensor(x, message=''):          The same tensor `x`, unchanged def print_tensor(x, message=''):          The same tensor `x`, unchanged def print_tensor(x, message=''):          The same tensor `x`, unchanged def print_tensor(x, message=''):          The same tensor `x`, unchanged def print_tensor(x, message=''):          The same tensor `x`, unchanged def print_tensor(x, message=''):          The same tensor `x`, unchanged def print_tensor(x, message=''):          The same tensor `x`, unchanged def print_tensor(x, message=''):          The same tensor `x`, unchanged def print_tensor(x, message=''):          The same tensor `x`, unchanged def print_tensor(x, message=''):          The same tensor `x`, unchanged def print_tensor(x, message=''):          The same tensor `x`, unchanged def print_tensor(x, message=''):          The same tensor `x`, unchanged def print_tensor(x, message=''):          The same tensor `x`, unchanged def print_tensor(x, message=''):          The same tensor `x`, unchanged def print_tensor(x, message=''
def check_setitem_lengths(indexer, value, values):          pass
def RedirectMiddleware(BaseRedirectMiddleware):          if 'Location' not in response.headers or response.status not in allowed_status:              return response         location = to_native_str(response.headers['location'].decode('latin1'))          redirected_url = urljoin(request.url, location)
def _prepare_response_content(     res: Any, *, by_alias: bool = True, exclude_unset: bool  ) -> Any:      if isinstance(res, BaseModel):          if PYDANTIC_1:             return res.dict(by_alias=by_alias, exclude_unset=exclude_unset )      elif isinstance(res, list):          return [             _prepare_response_content(item, exclude_unset=exclude_unset) for item in res          ]      elif isinstance(res, dict):          return {             k: _prepare_response_content(v, exclude_unset=exclude_unset)              for k, v in res.items()      return res
def _make_concat_multiindex(indexes, keys, levels=None, names=None):          for hlevel, level in zip(zipped, levels):              to_concat = []              for key, index in zip(hlevel, indexes):                 try:                     i = level.get_loc(key)                  to_concat.append(np.repeat(i, len(index)))              codes_list.append(np.concatenate(to_concat)) def _make_concat_multiindex(indexes, keys, levels=None, names=None):          for hlevel, level in zip(zipped, levels):              to_concat = []              for key, index in zip(hlevel, indexes):                 try:                     i = level.get_loc(key)                  to_concat.append(np.repeat(i, len(index)))              codes_list.append(np.concatenate(to_concat)) def _make_concat_multiindex(indexes, keys, levels=None, names=None):          for hlevel, level in zip(zipped, levels):              to_concat = []              for key, index in zip(hlevel, indexes):                 try:                     i = level.get_loc(key)                  to_concat.append(np.repeat(i, len(index)))              codes_list.append(np.concatenate(to_concat)) def _make_concat_multiindex(indexes, keys, levels=None, names=None):          for hlevel, level in zip(zipped, levels):              to_concat = []              for key, index in zip(hlevel, indexes):                 try:                     i = level.get_loc(key)                  to_concat.append(np.repeat(i, len(index)))              codes_list.append(np.concatenate(to_concat)) def _make_concat_multiindex(indexes, keys, levels=None, names=None):          for hlevel, level in zip(zipped, levels):              to_concat = []              for key, index in zip(hlevel, indexes):                 try:                     i = level.get_loc(key)                  to_concat.append(np.repeat(i, len(index)))              codes_list.append(np.concatenate(
def FastAPI(Starlette):          response_model_by_alias: bool = True,          response_model_skip_defaults: bool = None,          response_model_exclude_unset: bool = False,          include_in_schema: bool = True,          response_class: Type[Response] = None,          name: str = None,
def tqdm(Comparable):          if disable is None and hasattr(file, "isatty") and not file.isatty():              disable = True          if disable:              self.iterable = iterable              self.disable = disable              self.pos = self._get_free_pos(self)              self._instances.remove(self)              self.n = initial              return          if kwargs:
def multi_join_idx(IndexOpsMixin, PandasObject):              multi_join_idx = multi_join_idx.remove_unused_levels()          return multi_join_idx, lidx, ridx          jl = list(overlap)[0]
def _holder(self):          return Categorical      def to_native_types(self, slicer=None, na_rep="", quoting=None, **kwargs):          values = self.values      def to_native_types(self, slicer=None, na_rep="", quoting=None, **kwargs):          values = self.values      def to_native_types(self, slicer=None, na_rep="", quoting=None, **kwargs):          values = self.values      def to_native_types(self, slicer=None, na_rep="", quoting=None, **kwargs):          values = self.values      def to_native_types(self, slicer=None, na_rep="", quoting=None, **kwargs):          values = self.values      def to_native_types(self, slicer=None, na_rep="", quoting=None, **kwargs):          values = self.values      def to_native_types(self, slicer=None, na_rep="", quoting=None, **kwargs):          values = self.values      def to_native_types(self, slicer=None, na_rep="", quoting=None, **kwargs):          values = self.values      def to_native_types(self, slicer=None, na_rep="", quoting=None, **kwargs):          values = self.values      def to_native_types(self, slicer=None, na_rep="", quoting=None, **kwargs):          values = self.values      def to_native_types(self, slicer=None, na_rep="", quoting=None, **kwargs):          values = self.values      def to_native_types(self, slicer=None, na_rep="", quoting=None, **kwargs):          values = self.values      def to_native_types(self, slicer=None, na_rep="", quoting=None, **kwargs):          values = self.values      def to_native_types(self, slicer=None, na_rep="", quoting=None, **kwargs):          values = self.values      def to_native_types(self, slicer=None, na_rep="", quoting=None, **kwargs):          values = self.values      def to_native
def __init__(self, generator=None, use_multiprocessing=True, workers=1, val_data=[], callbacks=[]):          def Model(Container):                  val_data += [0.]              for cbk in callbacks:                  cbk.validation_data = val_data         is_sequence = isinstance(generator, Sequence)         if not is_sequence and use_multiprocessing and workers > 1:             warnings.warn(                 UserWarning('Using a generator with `use_multiprocessing=True`'                            'and multiple workers may duplicate your data.'                            'Please consider using the`keras.utils.Sequence'                            'class.'))         if is_sequence:             steps_per_epoch = len(generator)          enqueuer = None          try: def __init__(self, generator=None, use_multiprocessing=True, workers=1, val_data=[], callbacks=[]):          def Model(Container):                  val_data += [0.]              for cbk in callbacks:                  cbk.validation_data = val_data         is_sequence = isinstance(generator, Sequence)         if not is_sequence and use_multiprocessing and workers > 1:             warnings.warn(                 UserWarning('Using a generator with `use_multiprocessing=True`'                            'and multiple workers may duplicate your data.'                            'Please consider using the`keras.utils.Sequence'                            'class.'))         if is_sequence:             steps_per_epoch = len(generator)          enqueuer = None          try: def __init__(self, generator=None, use_multiprocessing=True, workers=1, val_data=[], callbacks=[]):          def Model(Container):                  val_data += [0.]              for cbk in callbacks:                  cbk.validation_data = val_data         is_sequence = isinstance(generator, Sequence)         if not is_sequence and use_multiprocessing and workers > 1:             warnings.warn(                 UserWarning('Using a generator with `use_multiprocessing=True`'                            'and multiple workers may duplicate your data.'                            'Please consider using the`keras.utils.Sequence'                            'class.'))         if is_sequence:             steps_per_epoch = len(generator)          enqueuer = None          try:
def melt(          else:              value_vars = list(value_vars)             missing = Index(np.ravel(value_vars)).difference(cols)              if not missing.empty:                  raise KeyError(                      "The following 'value_vars' are not present in" def melt(          else:              value_vars = list(value_vars)             missing = Index(np.ravel(value_vars)).difference(cols)              if not missing.empty:                  raise KeyError(                      "The following 'value_vars' are not present in" def melt(          else:              value_vars = list(value_vars)             missing = Index(np.ravel(value_vars)).difference(cols)              if not missing.empty:                  raise KeyError(                      "The following 'value_vars' are not present in" def melt(          else:              value_vars = list(value_vars)             missing = Index(np.ravel(value_vars)).difference(cols)              if not missing.empty:                  raise KeyError(                      "The following 'value_vars' are not present in" def melt(          else:              value_vars = list(value_vars)             missing = Index(np.ravel(value_vars)).difference(cols)              if not missing.empty:                  raise KeyError(                      "The following 'value_vars' are not present in" def melt(          else:              value_vars = list(value_vars)             missing = Index(np.ravel(value_vars)).difference(cols)              if not missing.empty:                  raise KeyError(                      "The following 'value_vars' are not present in" def melt(          else:              value_vars = list(value_vars)             missing = Index(np.ravel(value_vars)).difference(cols)              if not missing.empty:                  raise KeyError(                      "The following 'value_vars' are not present in" def melt(          else:              value_vars = list(value_vars)             missing = Index(np.ravel(value_vars)).difference(cols)              if not missing.empty:                  raise KeyError(                      "The following 'value_vars' are not present in" def melt(          else:              value_vars = list(
def get_updates(self, loss, params):         grads = self.optimizer.compute_gradients(loss, params)          self.updates = [K.update_add(self.iterations, 1)]          opt_update = self.optimizer.apply_gradients(              grads, global_step=self.iterations)
def _extract_chapters(description, duration):          return None      @staticmethod     def _extract_chapters(description, duration):          return None      @staticmethod     def _extract_chapters(description, duration):          return None      @staticmethod     def _extract_chapters(description, duration):          return None      @staticmethod     def _extract_chapters(description, duration):          return None      @staticmethod     def _extract_chapters(description, duration):          return None      @staticmethod     def _extract_chapters(description, duration):          return None      @staticmethod     def _extract_chapters(description, duration):          return None      @staticmethod     def _extract_chapters(description, duration):          return None      @staticmethod     def _extract_chapters(description, duration):          return None      @staticmethod     def _extract_chapters(description, duration):          return None      @staticmethod     def _extract_chapters(description, duration):          return None      @staticmethod     def _extract_chapters(description, duration):          return None      @staticmethod     def _extract_chapters(description, duration):          return None      @staticmethod     def _extract_chapters(description, duration):          return None      @staticmethod     def _extract_chapters(description, duration):          return None      @staticmethod     def _extract_chapters(description, duration):          return None      @staticmethod     def _extract_chapters(description, duration):          return None      @staticmethod     def _extract_chapters(description, duration):          return None      @staticmethod     def _extract_chapters(description, duration):          return None      @staticmethod     def _extract_chapters(description, duration):          return None      @staticmethod     def _extract_chapters(description, duration):          return None      @staticmethod     def _extract_chapters(description, duration):          return None      @staticmethod     def _extract_chapters(description, duration):          return None      @staticmethod     def _extract_chapters(description, duration):          return None      @staticmethod     def _extract_chapters(description,
def __new__(mcs, class_name, bases, new_attrs):          return super(ItemMeta, mcs).__new__(mcs, class_name, bases, new_attrs)          return super(ItemMeta, mcs).__new__(mcs, class_name, bases, new_attrs)          return super(ItemMeta, mcs).__new__(mcs, class_name, bases, new_attrs)          return super(ItemMeta, mcs).__new__(mcs, class_name, bases, new_attrs)          return super(ItemMeta, mcs).__new__(mcs, class_name, bases, new_attrs)          return super(ItemMeta, mcs).__new__(mcs, class_name, bases, new_attrs)          return super(ItemMeta, mcs).__new__(mcs, class_name, bases, new_attrs)          return super(ItemMeta, mcs).__new__(mcs, class_name, bases, new_attrs)          return super(ItemMeta, mcs).__new__(mcs, class_name, bases, new_attrs)          return super(ItemMeta, mcs).__new__(mcs, class_name, bases, new_attrs)          return super(ItemMeta, mcs).__new__(mcs, class_name, bases, new_attrs)          return super(ItemMeta, mcs).__new__(mcs, class_name, bases, new_attrs)          return super(ItemMeta, mcs).__new__(mcs, class_name, bases, new_attrs)          return super(ItemMeta, mcs).__new__(mcs, class_name, bases, new_attrs)          return super(ItemMeta, mcs).__new__(mcs, class_name, bases, new_attrs)          return super(ItemMeta, mcs).__new__(mcs, class_name, bases, new_attrs)          return super(ItemMeta, mcs).__new__(mcs, class_name, bases, new_attrs)          return super(ItemMeta, mcs).__new__(mcs, class_name, bases, new_attrs)          return super(ItemMeta
def ListParameter(Parameter):         Ensure that list parameter is converted to a tuple so it can be hashed.          :param str x: the value to parse.          :return: the normalized (hashable/immutable value.
def _drop_labels_or_levels(self, left_drop):              left_keys = [self.left.index.values]          if left_drop:              self.left = self.left._drop_labels_or_levels(left_drop)          else:                 left_keys = [self.left.index.values]          if left_drop:              self.left = self.left._drop_labels_or_levels(left_drop)          else:                 left_keys = [self.left.index.values]          if left_drop:              self.left = self.left._drop_labels_or_levels(left_drop)          else:                 left_keys = [self.left.index.values]          if left_drop:              self.left = self.left._drop_labels_or_levels(left_drop)          else:                 left_keys = [self.left.index.values]          if left_drop:              self.left = self.left._drop_labels_or_levels(left_drop)          else:                 left_keys = [self.left.index.values]          if left_drop:              self.left = self.left._drop_labels_or_levels(left_drop)          else:                 left_keys = [self.left.index.values]          if left_drop:              self.left = self.left._drop_labels_or_levels(left_drop)          else:                 left_keys = [self.left.index.values]          if left_drop:              self.left = self.left._drop_labels_or_levels(left_drop)          else:                 left_keys = [self.left.index.values]          if left_drop:              self.left = self.left._drop_labels_or_levels(left_drop)          else:                 left_keys = [self.left.index.values]          if left_drop:              self.left = self.left._drop_labels_or_levels(left_drop)          else:                 left_keys = [self.left.index.values]          if left_drop:              self.left = self.left._drop_labels_or_levels(left_drop)          else:                 left_keys = [self.left.
def _maybe_cast_slice_bound(self, label, side, kind):          assert kind in ["ix", "loc", "getitem", None]          return cls._simple_new(subarr, name=data.name          @Appender(_index_shared_docs["_maybe_cast_slice_bound"])      def _maybe_cast_slice_bound(self, label, side, kind):          assert kind in ["ix", "loc", "getitem", None]          return cls._simple_new(subarr, name=data.name          @Appender(_index_shared_docs["_maybe_cast_slice_bound"])      def _maybe_cast_slice_bound(self, label, side, kind):          assert kind in ["ix", "loc", "getitem", None]          return cls._simple_new(subarr, name=data.name          @Appender(_index_shared_docs["_maybe_cast_slice_bound"])      def _maybe_cast_slice_bound(self, label, side, kind):          assert kind in ["ix", "loc", "getitem", None]          return cls._simple_new(subarr, name=data.name          @Appender(_index_shared_docs["_maybe_cast_slice_bound"])      def _maybe_cast_slice_bound(self, label, side, kind):          assert kind in ["ix", "loc", "getitem", None]          return cls._simple_new(subarr, name=data.name          @Appender(_index_shared_docs["_maybe_cast_slice_bound"])      def _maybe_cast_slice_bound(self, label, side, kind):          assert kind in ["ix", "loc", "getitem", None]          return cls._simple_new(subarr, name=data.name          @Appender(_index_shared_docs["_maybe_cast_slice_bound"])      def _maybe_cast_slice_bound(self, label, side, kind):          assert kind in ["ix", "loc", "getitem", None]          return cls._simple_new(subarr, name=data.name          @Appender(_index_shared_docs["_maybe_cast_slice_bound"])      def _maybe_cast_slice_bound(self, label, side, kind):          assert
def _urlencode(seq, enc):  def _get_form(response, formname, formid, formnumber, formxpath):      text = response.body_as_unicode()      root = create_root_node(text, lxml.html.HTMLParser, base_url=response.url)      forms = root.xpath('//form')      if not forms:          raise ValueError("No <form> element found in %s" % response)
def _get_url(object_ref):          s = safe_url_string(url, self.encoding)          self._url = escape_ajax(s)          return property(_get_url, obsolete_setter(_set_url, 'url'))
def EmptyLineTracker:                  return 0, 0              newlines = 2              if current_line.depth                  newlines -= 1
def _combine_match_index(self, other, func):          return new_data     def _combine_match_index(self, other, func):          return new_data     def _combine_match_index(self, other, func):          return new_data     def _combine_match_index(self, other, func):          return new_data     def _combine_match_index(self, other, func):          return new_data     def _combine_match_index(self, other, func):          return new_data     def _combine_match_index(self, other, func):          return new_data     def _combine_match_index(self, other, func):          return new_data     def _combine_match_index(self, other, func):          return new_data     def _combine_match_index(self, other, func):          return new_data     def _combine_match_index(self, other, func):          return new_data     def _combine_match_index(self, other, func):          return new_data     def _combine_match_index(self, other, func):          return new_data     def _combine_match_index(self, other, func):          return new_data     def _combine_match_index(self, other, func):          return new_data     def _combine_match_index(self, other, func):          return new_data     def _combine_match_index(self, other, func):          return new_data     def _combine_match_index(self, other, func):          return new_data     def _combine_match_index(self, other, func):          return new_data     def _combine_match_index(self, other, func):          return new_data     def _combine_match_index(self, other, func):          return new_data     def _combine_match_index(self, other, func):          return new_data     def _combine_match_index(self, other, func):          return new_data     def _combine_match_index(self, other, func):          return new_data     def _combine_match_index(self, other, func):          return new_data     def _combine_match_index(self,
def disp_trim(data, length):      if len(data) == disp_len(data):          return data[:length] while disp_len(data) > length          data = data[:-1]      if RE_ANSI.search(data):         return data + "\033[0m"      return data
def _unstack_multiple(data, clocs, fill_value=None):              for i in range(len(len(clocs))):                  val = clocs[i]                  result = result.unstack(val, fill_value=fill_value)                 clocs = [v if i > v else v - 1 for v in clocs]              return result def _unstack_multiple(data, clocs, fill_value=None):              for i in range(len(len(clocs))):                  val = clocs[i]                  result = result.unstack(val, fill_value=fill_value)                 clocs = [v if i > v else v - 1 for v in clocs]              return result def _unstack_multiple(data, clocs, fill_value=None):              for i in range(len(len(clocs))):                  val = clocs[i]                  result = result.unstack(val, fill_value=fill_value)                 clocs = [v if i > v else v - 1 for v in clocs]              return result def _unstack_multiple(data, clocs, fill_value=None):              for i in range(len(len(clocs))):                  val = clocs[i]                  result = result.unstack(val, fill_value=fill_value)                 clocs = [v if i > v else v - 1 for v in clocs]              return result def _unstack_multiple(data, clocs, fill_value=None):              for i in range(len(len(clocs))):                  val = clocs[i]                  result = result.unstack(val, fill_value=fill_value)                 clocs = [v if i > v else v - 1 for v in clocs]              return result def _unstack_multiple(data, clocs, fill_value=None):              for i in range(len(len(clocs))):                  val = clocs[i]                  result = result.unstack(val, fill_value=fill_value)                 clocs = [v if i > v else v - 1 for v in clocs]              return result def _unstack_multiple(data, clocs, fill_value=None):
def jsonable_encoder(                      value,                      by_alias=by_alias,                      exclude_unset=exclude_unset,                     include_none=include_none,                      custom_encoder=custom_encoder,                      sqlalchemy_safe=sqlalchemy_safe,                  ) def jsonable_encoder(                      value,                      by_alias=by_alias,                      exclude_unset=exclude_unset,                     include_none=include_none,                      custom_encoder=custom_encoder,                      sqlalchemy_safe=sqlalchemy_safe,                  ) def jsonable_encoder(                      value,                      by_alias=by_alias,                      exclude_unset=exclude_unset,                     include_none=include_none,                      custom_encoder=custom_encoder,                      sqlalchemy_safe=sqlalchemy_safe,                  ) def jsonable_encoder(                      value,                      by_alias=by_alias,                      exclude_unset=exclude_unset,                     include_none=include_none,                      custom_encoder=custom_encoder,                      sqlalchemy_safe=sqlalchemy_safe,                  ) def jsonable_encoder(                      value,                      by_alias=by_alias,                      exclude_unset=exclude_unset,                     include_none=include_none,                      custom_encoder=custom_encoder,                      sqlalchemy_safe=sqlalchemy_safe,                  ) def jsonable_encoder(                      value,                      by_alias=by_alias,                      exclude_unset=exclude_unset,                     include_none=include_none,                      custom_encoder=custom_encoder,                      sqlalchemy_safe=sqlalchemy_safe,                  ) def jsonable_encoder(                      value,                      by_alias=by_alias,                      exclude_unset=exclude_unset,                     include_none=include_none,                      custom_encoder=custom_encoder,                      sqlalchemy_safe=sqlalchemy_safe,                  ) def jsonable_encoder(                      value,                      by_alias=by_alias,                      exclude_unset=exclude_unset,                     include_none=include_none,                      custom_encoder=custom_encoder,                      sqlalchemy_safe=sqlalchemy_safe,                  ) def jsonable_encoder(                      value,                      by_alias=by_alias,                      exclude_unset=exclude_unset,                     include_none=include_none,                      custom_encoder=custom_encoder,
def CollectionRequirement:              manifest = info['manifest_file']['collection_info']              namespace = manifest['namespace']              name = manifest['name']             version = manifest['version']              dependencies = manifest['dependencies']
def get_mount_size(self, mount):          mount_size = get_mount_size(mount)      def get_mount_info(self, mount, device, uuids):          mount_size = get_mount_size(mount)      def get_mount_info(self, mount, device, uuids):          mount_size = get_mount_size(mount)      def get_mount_info(self, mount, device, uuids):          mount_size = get_mount_size(mount)      def get_mount_info(self, mount, device, uuids):          mount_size = get_mount_size(mount)      def get_mount_info(self, mount, device, uuids):          mount_size = get_mount_size(mount)      def get_mount_info(self, mount, device, uuids):          mount_size = get_mount_size(mount)      def get_mount_info(self, mount, device, uuids):          mount_size = get_mount_size(mount)      def get_mount_info(self, mount, device, uuids):          mount_size = get_mount_size(mount)      def get_mount_info(self, mount, device, uuids):          mount_size = get_mount_size(mount)      def get_mount_info(self, mount, device, uuids):          mount_size = get_mount_size(mount)      def get_mount_info(self, mount, device, uuids):          mount_size = get_mount_size(mount)      def get_mount_info(self, mount, device, uuids):          mount_size = get_mount_size(mount)      def get_mount_info(self, mount, device, uuids):          mount_size = get_mount_size(mount)      def get_mount_info(self, mount, device, uuids):          mount_size = get_mount_size(mount)      def get_mount_info(self, mount, device, uuids):          mount_size = get_mount_size(mount)      def get_mount_info(self, mount, device, uuids):          mount_size = get_mount_size(mount)      def get_mount_info(self, mount, device, uuids):          mount_size = get
def Categorical(ExtensionArray, PandasObject):          min : the minimum of this `Categorical`          self.check_for_ordered("min")          good = self._codes!= -1          if not good.all():              if skipna:
def _get_spider_loader(settings):              'Please use SPIDER_LOADER_CLASS.'      cls_path = settings.get('SPIDER_LOADER_CLASS',                             settings.get('SPIDER_MANAGER_CLASS'))      loader_cls = load_object(cls_path)      verifyClass(ISpiderLoader, loader_cls)      return loader_cls.from_settings(settings.frozenc())
def title_regex(self):  def title_regex(self):  def title_regex(self):  def title_regex(self):  def title_regex(self):  def title_regex(self):  def title_regex(self):  def title_regex(self):  def title_regex(self):  def title_regex(self):  def title_regex(self):  def title_regex(self):  def title_regex(self):  def title_regex(self):  def title_regex(self):  def title_regex(self):  def title_regex(self):  def title_regex(self):  def title_regex(self):  def title_regex(self):  def title_regex(self):  def title_regex(self):  def title_regex(self):  def title_regex(self):  def title_regex(self):  def title_regex(self):  def title_regex(self):  def title_regex(self):  def title_regex(self):  def title_regex(self):  def title_regex(self):  def title_regex(self):  def title_regex(self):  def title_regex(self):  def title_regex(self):  def title_regex(self):  def title_regex(self):  def title_regex(self):  def title_regex(self):  def title_regex(self):  def title_regex(self):  def title_regex(self):  def title_regex(self):  def title_regex(self):  def title_regex(self):  def title_regex(self):  def title_regex(self):  def title_regex(self):  def title_regex(self):  def title_regex(self):  def title_regex(self):  def title_regex(self):  def title_regex(self):  def title_regex(self):  def title_regex(self):  def title_regex(self):  def title_regex(self):  def title_regex(self):  def title_regex(self):  def title_regex(self):  def title_regex(self):  def title_regex(self):  def title_regex(self):  def title_regex(self
def serialize_response(              exclude=exclude,              by_alias=by_alias,              exclude_unset=exclude_unset,          )
def on_connection_close(self):          if self.ws_connection:          def on_connection_close(self):          def on_connection_close(self):          def on_connection_close(self):          def on_connection_close(self):          def on_connection_close(self):          def on_connection_close(self):          def on_connection_close(self):          def on_connection_close(self):          def on_connection_close(self):          def on_connection_close(self):          def on_connection_close(self):          def on_connection_close(self):          def on_connection_close(self):          def on_connection_close(self):          def on_connection_close(self):          def on_connection_close(self):          def on_connection_close(self):          def on_connection_close(self):          def on_connection_close(self):          def on_connection_close(self):          def on_connection_close(self):          def on_connection_close(self):          def on_connection_close(self):          def on_connection_close(self):          def on_connection_close(self):          def on_connection_close(self):          def on_connection_close(self):          def on_connection_close(self):          def on_connection_close(self):          def on_connection_close(self):          def on_connection_close(self):          def on_connection_close(self):          def on_connection_close(self):          def on_connection_close(self):          def on_connection_close(self):          def on_connection_close(self):          def on_connection_close(self):          def on_connection_close(self):          def on_connection_close(self):          def on_connection_close(self):          def on_connection_close(self):          def on_connection_close(self):          def on_connection_close(self):          def on_connection_close(self):          def on_connection_close(self):          def on_connection_close(self):          def on_connection_close(self):          def on_connection_close(self):          def on_connection_close(self):          def on
def get_file(fname,          Path to the downloaded file      if cache_dir is None:         cache_dir = os.path.join(os.path.expanduser('~'), '.keras')      if md5_hash is not None and file_hash is None          file_hash = md5_hash          hash_algorithm ='md5'
def get_flat_dependant(dependant: Dependant) -> Dependant:  def is_scalar_field(field: Field) -> bool:     return (          field.shape == Shape.SINGLETON          and not lenient_issubclass(field.type_, BaseModel          and not lenient_issubclass(field.type_, sequence_types + (dict,))          and not isinstance(field.schema, params.Body)  def is_scalar_sequence_field(field: Field) -> bool:
def _partition_tasks(worker):      set_tasks["completed"] = {task for (task, status, ext) in task_history if status == 'DONE' and task in pending_tasks}      set_tasks["already_done"] = {task for (task, status, ext) in task_history                                   if status == 'DONE' and task not in pending_tasks and task not in set_tasks["completed"]      set_tasks["failed"] = {task for (task, status, ext) in task_history if status == 'FAILED'      set_tasks["scheduling_error"] = {task for(task, status, ext) in task_history if status == 'UNKNOWN'}      set_tasks["still_pending_ext"] = {task for (task, status, ext) in task_history                                       if status == 'PENDING' and task not in set_tasks["failed"] and task not in set_tasks["completed"] and not ext}      set_tasks["still_pending_not_ext"] = {task for (task, status, ext) in task_history                                           if status == 'PENDING' and task not in set_tasks["failed"] and task not in set_tasks["completed"] and ext}      set_tasks["run_by_other_worker"] = set()      set_tasks["upstream_failure"] = set()      set_tasks["upstream_missing_dependency"] = set()
def Parameter(object):          :raises MissingParameterException: if x is false-y and no default is specified.          if not x:             if self.has_value:                 return self.value              elif self.is_bool:                  return False              elif self.is_list:
def should_store(self, value) -> bool:          return issubclass(value.dtype.type, np.floating) and value.dtype == self.dtype
def Categorical(ExtensionArray, PandasObject):          good = self._codes!= -1          if not good.all():             if skipna:                  pointer = self._codes[good].min()          else                  return np.nan
def process_response(self, request, response, spider):          if (request.meta.get('dont_redirect', False)):              return response          if request.method == 'HEAD':
def get_new_command(command):          pass      if upstream_option_index is not -1:          command.script_parts.pop(upstream_option_index)      push_upstream = command.stderr.split('\n')[-3].strip().partition('git ')[2]      return replace_argument(" ".join(command.script_parts), 'push', push_upstream)
def TestPeriodIndex(DatetimeLike):          idx = PeriodIndex([2000, 2007, 2007, 2009, 2007], freq="A-JUN")          ts = Series(np.random.randn(len(idx)), index=idx)          result = ts[2007]          expected = ts[idx == "2007"]          tm.assert_series_equal(result, expected)
def evaluate_generator(model, generator,      steps_done = 0      outs_per_batch = []      batch_sizes = []     is_sequence = isinstance(generator, Sequence)      if not is_sequence and use_multiprocessing and workers > 1:          warnings.warn(              UserWarning('Using a generator with `use_multiprocessing=True`'                         'and multiple workers may duplicate your data.'                         'Please consider using the`keras.utils.Sequence'                         'class.'))      if steps is None:         if is_sequence:              steps = len(generator)      else              raise ValueError('`steps=None` is only valid for a generator'
def rename(self, index, **kwargs):          non_mapping = is_scalar(index) or (             is_list_like(index) and not is_dict_like(index)      return super().rename(index=index, **kwargs)      @Substitution(**_shared_doc_kwargs)      @Appender(generic.NDFrame.reindex.__doc__)
def add_handler(self, fd, handler, events):          fd, fileobj = self.split_fd(fd)          def add_handler(self, fd, handler, events):          fd, fileobj = self.split_fd(fd)          def add_handler(self, fd, handler, events):          fd, fileobj = self.split_fd(fd)          def add_handler(self, fd, handler, events):          fd, fileobj = self.split_fd(fd)          def add_handler(self, fd, handler, events):          fd, fileobj = self.split_fd(fd)          def add_handler(self, fd, handler, events):          fd, fileobj = self.split_fd(fd)          def add_handler(self, fd, handler, events):          fd, fileobj = self.split_fd(fd)          def add_handler(self, fd, handler, events):          fd, fileobj = self.split_fd(fd)          def add_handler(self, fd, handler, events):          fd, fileobj = self.split_fd(fd)          def add_handler(self, fd, handler, events):          fd, fileobj = self.split_fd(fd)          def add_handler(self, fd, handler, events):          fd, fileobj = self.split_fd(fd)          def add_handler(self, fd, handler, events):          fd, fileobj = self.split_fd(fd)          def add_handler(self, fd, handler, events):          fd, fileobj = self.split_fd(fd)          def add_handler(self, fd, handler, events):          fd, fileobj = self.split_fd(fd)          def add_handler(self, fd, handler, events):          fd, fileobj = self.split_fd(fd)          def add_handler(self, fd, handler, events):          fd, fileobj = self.split_fd(fd)          def add_handler(self, fd, handler, events):          fd, fileobj = self.split_fd(fd)          def add_handler(self, fd, handler, events):          fd, fileobj = self.split_fd(fd)          def add_handler(self, fd, handler, events):          fd, fileobj = self.split_fd(
def ObjectBlock(Block):              if convert:                  block = [b.convert(numeric=False, copy=True) for b in block]              return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return self          return
def Categorical(ExtensionArray, PandasObject):          Only ordered `Categoricals` have a maximum!          Raises          ------          TypeError def Categorical(ExtensionArray, PandasObject):          Only ordered `Categoricals` have a maximum!          Raises          ------          TypeError def Categorical(ExtensionArray, PandasObject):          Only ordered `Categoricals` have a maximum!          Raises          ------          TypeError def Categorical(ExtensionArray, PandasObject):          Only ordered `Categoricals` have a maximum!          Raises          ------          TypeError def Categorical(ExtensionArray, PandasObject):          Only ordered `Categoricals` have a maximum!          Raises          ------          TypeError def Categorical(ExtensionArray, PandasObject):          Only ordered `Categoricals` have a maximum!          Raises          ------          TypeError def Categorical(ExtensionArray, PandasObject):          Only ordered `Categoricals` have a maximum!          Raises          ------          TypeError def Categorical(ExtensionArray, PandasObject):          Only ordered `Categoricals` have a maximum!          Raises          ------          TypeError def Categorical(ExtensionArray, PandasObject):          Only ordered `Categoricals` have a maximum!          Raises          ------          TypeError def Categorical(ExtensionArray, PandasObject):          Only ordered `Categoricals` have a maximum!          Raises          ------          TypeError def Categorical(ExtensionArray, PandasObject):          Only ordered `Categoricals` have a maximum!          Raises          ------          TypeError def Categorical(ExtensionArray, PandasObject):          Only ordered `Categoricals` have a maximum!          Raises          ------          TypeError def Categorical(ExtensionArray, PandasObject):          Only ordered `Categoricals` have a maximum!          Raises          ------          TypeError def Categorical(ExtensionArray, PandasObject):          Only ordered `Categoricals` have a maximum!          Raises          ------          TypeError def Categorical(ExtensionArray, PandasObject):          Only ordered `Categoricals` have a maximum!          Raises          ------          TypeError def Categorical(ExtensionArray, PandasObject):          Only ordered `Categoricals` have a maximum!          Raises          ------          TypeError def Categorical(ExtensionArray, PandasObject):          Only ordered `Categoricals` have a maximum!          Raises          ------          TypeError def Categorical(ExtensionArray, PandasObject):          Only ordered `Categoric
def get_openapi_security_definitions(flat_dependant: Dependant) -> Tuple[Dict, L          security_definition = jsonable_encoder(              security_requirement.security_scheme.model,              by_alias=True,             include_none=False          )          security_name = security_requirement.security_scheme.scheme_name          security_definitions[security_name]          return security_definition
def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),      if isinstance(output_shape, (tuple, list)):          output_shape = tf.stack(output_shape)          x, tf_data_format = _preprocess_conv2d_input(x, data_format)      if data_format == 'channels_first' and tf_data_format == 'NHC':          output_shape = (output_shape[0],
def next_palindrome(digit_list):     high_mid = len(digit_list) // 2     low_mid = (len(digit_list) - 1) // 2     while high_mid < len(digit_list) and low_mid >= 0:         if digit_list[high_mid] == 9:             digit_list[high_mid] = 0             digit_list[low_mid] = 0             high_mid += 1             low_mid -= 1     return [1] + (len(digit_list)) * [0] + [1]
def bucketsort(arr, k):     counts = [0] * k     for x in arr:         counts[x] += 1     sorted_arr = []     for i, count in enumerate(arr):         sorted_arr.extend([i] * count)     return sorted_arr
def to_base(num, b):     result = ''     alphabet = string.digits + string.ascii_uppercase     while num > 0:         i = num % b         num = num // b         result + alphabet[i]     return result
def shunting_yard(tokens):     precedence = {         '+': 1,         '-': 1,         '*': 2,         '/': 2     rpntokens = []     opstack = []     for token in tokens:         if isinstance(token, int):             rpntokens.append(token)         else:             while opstack and precedence[token] <= precedence[opstack[-1]]:                 rpntokens.append(opstack.pop())     return rpntokens

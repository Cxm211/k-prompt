Namespace(log_name='./RQ5/python_1/f2_codet5p_220m.log', model_name='Salesforce/codet5p-220m', lang='java', output_dir='RQ5/python_1/f2_codet5p_220m', data_dir='./data/RQ5/python_1_2', no_cuda=False, visible_gpu='0', add_task_prefix=False, add_lang_ids=False, num_train_epochs=10, num_test_epochs=10, train_batch_size=8, eval_batch_size=4, gradient_accumulation_steps=2, load_model_path=None, config_name='', tokenizer_name='', max_source_length=128, max_target_length=128, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, do_lower_case=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, max_steps=-1, eval_steps=-1, train_steps=-1, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, model_name: Salesforce/codet5p-220m
model created!
Total 1 training instances 
***** Running training *****
  Num examples = 1
  Batch size = 8
  Num epoch = 10

***** Running evaluation *****
  Num examples = 103
  Batch size = 4
  epoch = 0
  eval_ppl = 1.00267
  global_step = 1
  train_loss = 0.7969
  ********************
Previous best ppl:inf
Achieve Best ppl:1.00267
  ********************
BLEU file: ./data/RQ5/python_1_2/validation.jsonl
  codebleu-4 = 9.4 	 Previous best codebleu 0
  ********************
 Achieve Best bleu:9.4
  ********************

***** Running evaluation *****
  Num examples = 103
  Batch size = 4
  epoch = 1
  eval_ppl = 1.00267
  global_step = 1
  train_loss = 0.7371
  ********************
Previous best ppl:1.00267
BLEU file: ./data/RQ5/python_1_2/validation.jsonl
  codebleu-4 = 9.4 	 Previous best codebleu 9.4
  ********************

***** Running evaluation *****
  Num examples = 103
  Batch size = 4
  epoch = 2
  eval_ppl = 1.00267
  global_step = 1
  train_loss = 0.8215
  ********************
Previous best ppl:1.00267
BLEU file: ./data/RQ5/python_1_2/validation.jsonl
  codebleu-4 = 9.4 	 Previous best codebleu 9.4
  ********************

***** Running evaluation *****
  Num examples = 103
  Batch size = 4
  epoch = 3
  eval_ppl = 1.00267
  global_step = 1
  train_loss = 0.767
  ********************
Previous best ppl:1.00267
BLEU file: ./data/RQ5/python_1_2/validation.jsonl
  codebleu-4 = 9.4 	 Previous best codebleu 9.4
  ********************
reload model from RQ5/python_1/f2_codet5p_220m/checkpoint-best-bleu
BLEU file: ./data/RQ5/python_1_2/test.jsonl
  codebleu = 10.23 
  Total = 113 
  Exact Fixed = 0 
[]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  ********************
  Total = 113 
  Exact Fixed = 0 
[]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  codebleu = 10.23 
[0.018925831202046037, 0.07272990380587739, 0.25883876000040473, 0.10487393787346667, 0.08138634764250527, 0.05042305378902186, 0.02975206611570248, 0.2983889949895705, 0.020689655172413793, 0.05862068965517241, 0.18825806451612903, 0.06205249883119262, 0.15319451756334512, 0.0348938844385614, 0.18449463575928296, 0.0005267145655300999, 0.010714285714285713, 0.20707589381304947, 0.14186362909684172, 0.00851063829787234, 0.049999999999999996, 0.22047637408034748, 0.09963714014717193, 0.04414366670713007, 0.23029541863023217, 0.03139380495737998, 0.02692307692307692, 0.010988372093023255, 0.12216423951436788, 0.08233792174284968, 0.0, 0.08955616068346138, 0.047813180353095786, 0.0004902055890267552, 0.2105453091469827, 0.07724551797441295, 0.15765781883140728, 0.0, 0.32999999999999996, 0.044651495851921796, 0.0, 0.03846153846153846, 0.05866711332108094, 0.019216910615140196, 0.1252881505411582, 0.1384885004779189, 0.0, 0.06162845382849188, 0.15886917960088692, 0.0006653254413616732, 0.3377490319716993, 0.06388842066670924, 0.058536585365853655, 0.07038695542193019, 0.041379310344827586, 0.09914207129203112, 0.23160667755878703, 0.27738571342479273, 0.00022650521218499828, 0.02599209024115989, 0.05888701620532372, 0.058023380758706264, 0.00023425938954060212, 0.09294549536008169, 0.0363879151027674, 0.13183157941645252, 0.19758817659165293, 0.03116883116883117, 0.3627772793138117, 0.026582278481012658, 0.2188940852386771, 0.00045407016796784124, 0.047297166694767065, 0.07777777777777777, 0.14922774076317383, 0.0005018860658870098, 0.014754257309286232, 0.04152579632135221, 0.03891731873671173, 0.03685190874803119, 0.0005878211007116764, 0.008070693606516625, 0.02195121951219512, 0.4819048819427586, 0.16443118694948666, 0.03846153846153846, 0.1005822332013181, 0.06835443037974683, 0.18546917135420468, 0.050203981879791595, 0.3029923321129706, 0.01875, 0.18045132594950067, 0.02278481012658228, 0.33272271785279683, 0.35708942169506613, 0.019797668762074245, 0.20560081094477015, 0.11955383226735844, 0.28842067550068023, 0.06103198864761226, 0.05384615384615384, 0.06889855344344811, 0.015589816735549435, 0.23046607462548674, 0.04704946749319349, 0.00024782615474421666, 0.12518367711962156, 0.06323279346627479, 0.0933454169762728, 0.006297030927420869, 0.4994979841734397, 0.032539326261276307]
Finish training and take 19m
Namespace(log_name='./RQ5/python_1/f2_codet5p_220m.log', model_name='Salesforce/codet5p-220m', lang='python', output_dir='RQ5/python_1/f2_codet5p_220m', data_dir='./data/RQ5/python_1_2', no_cuda=False, visible_gpu='0', add_task_prefix=False, add_lang_ids=False, num_train_epochs=10, num_test_epochs=10, train_batch_size=8, eval_batch_size=4, gradient_accumulation_steps=2, load_model_path=None, config_name='', tokenizer_name='', max_source_length=128, max_target_length=128, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, do_lower_case=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, max_steps=-1, eval_steps=-1, train_steps=-1, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, model_name: Salesforce/codet5p-220m
model created!
Total 1 training instances 
***** Running training *****
  Num examples = 1
  Batch size = 8
  Num epoch = 10

***** Running evaluation *****
  Num examples = 103
  Batch size = 4
  epoch = 0
  eval_ppl = 1.00267
  global_step = 1
  train_loss = 0.7969
  ********************
Previous best ppl:inf
Achieve Best ppl:1.00267
  ********************
BLEU file: ./data/RQ5/python_1_2/validation.jsonl
Namespace(log_name='./RQ5/python_1/f2_codet5p_220m.log', model_name='Salesforce/codet5p-220m', lang='python', output_dir='RQ5/python_1/f2_codet5p_220m', data_dir='./data/RQ5/python_1_2', no_cuda=False, visible_gpu='0', add_task_prefix=False, add_lang_ids=False, num_train_epochs=10, num_test_epochs=10, train_batch_size=8, eval_batch_size=4, gradient_accumulation_steps=2, load_model_path=None, config_name='', tokenizer_name='', max_source_length=128, max_target_length=128, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, do_lower_case=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, max_steps=-1, eval_steps=-1, train_steps=-1, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, model_name: Salesforce/codet5p-220m
model created!
Total 1 training instances 
***** Running training *****
  Num examples = 1
  Batch size = 8
  Num epoch = 10

***** Running evaluation *****
  Num examples = 103
  Batch size = 4
  epoch = 0
  eval_ppl = 1.00267
  global_step = 1
  train_loss = 0.7969
  ********************
Previous best ppl:inf
Achieve Best ppl:1.00267
  ********************
BLEU file: ./data/RQ5/python_1_2/validation.jsonl
  codebleu-4 = 12.88 	 Previous best codebleu 0
  ********************
 Achieve Best bleu:12.88
  ********************

***** Running evaluation *****
  Num examples = 103
  Batch size = 4
  epoch = 1
  eval_ppl = 1.00267
  global_step = 1
  train_loss = 0.7371
  ********************
Previous best ppl:1.00267
BLEU file: ./data/RQ5/python_1_2/validation.jsonl
  codebleu-4 = 12.88 	 Previous best codebleu 12.88
  ********************

***** Running evaluation *****
  Num examples = 103
  Batch size = 4
  epoch = 2
  eval_ppl = 1.00267
  global_step = 1
  train_loss = 0.8215
  ********************
Previous best ppl:1.00267
BLEU file: ./data/RQ5/python_1_2/validation.jsonl
  codebleu-4 = 12.88 	 Previous best codebleu 12.88
  ********************

***** Running evaluation *****
  Num examples = 103
  Batch size = 4
  epoch = 3
  eval_ppl = 1.00267
  global_step = 1
  train_loss = 0.767
  ********************
Previous best ppl:1.00267
BLEU file: ./data/RQ5/python_1_2/validation.jsonl
  codebleu-4 = 12.88 	 Previous best codebleu 12.88
  ********************
reload model from RQ5/python_1/f2_codet5p_220m/checkpoint-best-bleu
BLEU file: ./data/RQ5/python_1_2/test.jsonl
  codebleu = 13.18 
  Total = 113 
  Exact Fixed = 0 
[]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  ********************
  Total = 113 
  Exact Fixed = 0 
[]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  codebleu = 13.18 
[0.12288907673523057, 0.10549297143071334, 0.2579060631091834, 0.10104843942689554, 0.01992740471869328, 0.40597686087168516, 0.14958838735335056, 0.3358607715113683, 0.056487224013892334, 0.056767554479418884, 0.16281324309493322, 0.05500160646392207, 0.19369515941186888, 0.07584410358777909, 0.13280358910278878, 0.15073316246170065, 0.04353383458646616, 0.23090037506185968, 0.11742998650128374, 0.13171929824561404, 0.03387096774193548, 0.14825188675692494, 0.338047880603589, 0.03854019690842663, 0.08697307998221881, 0.021851809852853787, 0.0478494623655914, 0.0, 0.2046798619299455, 0.03782016479210535, 0.012121212121212121, 0.05675897974224659, 0.08545468716780866, 0.10068739170653807, 0.04267960514947222, 0.08026788145774663, 0.1276943289661171, 0.19999999999999998, 0.09727891156462584, 0.05863643285927381, 0.09999999999999999, 0.022105263157894735, 0.07945526044982656, 0.112584425128057, 0.15215122894036467, 0.16595099868579394, 0.15, 0.06319804748329402, 0.14315257352941174, 0.200858186031041, 0.3770988901110506, 0.19200873762211074, 0.05574448529411764, 0.2028080839272557, 0.050166642515577446, 0.06156732508801167, 0.27737279923454944, 0.257859960488228, 0.05081010762663194, 0.033080330299967785, 0.08378977218025883, 0.06816989860473488, 0.046422601516745196, 0.21653178949660457, 0.04244362093337309, 0.11330489938226931, 0.3402227284676259, 0.02736054093214199, 0.351447511801693, 0.05941224489795918, 0.17488700053314138, 0.15065578069784802, 0.038160119546347696, 0.06364057433997221, 0.15481413597571453, 0.05069907218339832, 0.027794775824575034, 0.1750662488161559, 0.10590457514077373, 0.06554161506123593, 0.15078068169039102, 0.16917866000350137, 0.05523897058823529, 0.47921822877489173, 0.32854372371513807, 0.024193548387096774, 0.18153945230974666, 0.061503030303030296, 0.13732759093795038, 0.06075564945569007, 0.3103286889542254, 0.03557422969187675, 0.21800449875794436, 0.0, 0.3694485753880939, 0.5831446324305354, 0.08369299585507116, 0.19095339278524487, 0.10557492729740253, 0.24629806587914055, 0.07881806403587502, 0.09081133919843597, 0.0977175284184813, 0.10437708605244288, 0.12132982259618184, 0.07075733562660011, 0.0039977992922841776, 0.1318731821904287, 0.07875479324274144, 0.2794973789433163, 0.00776044556156721, 0.17536992242613642, 0.032539326261276307]
Finish training and take 20m

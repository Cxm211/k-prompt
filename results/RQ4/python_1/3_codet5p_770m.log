Namespace(log_name='./RQ5/python_1/3_codet5p_770m.log', model_name='Salesforce/codet5p-770m', lang='python', output_dir='RQ5/python_1/3_codet5p_770m', data_dir='./data/RQ5/python_1_3', no_cuda=False, visible_gpu='0', num_train_epochs=10, num_test_epochs=1, train_batch_size=4, eval_batch_size=2, gradient_accumulation_steps=1, load_model_path=None, config_name='', tokenizer_name='', max_source_length=512, max_target_length=512, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, freeze=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
Model created!!
[[{'text': "def map_config_to_obj(module):  def map_params_to_obj(module):      text = module.params['text']     if text:         text = str(text).strip()      return {          'banner': module.params['banner'],          'text': text,", 'loss_ids': 0, 'shortenable_ids': 1}, {'text': '<mask>', 'loss_ids': 1, 'shortenable_ids': 0}, {'text': '', 'loss_ids': 0, 'shortenable_ids': 0}], {'guid': 0, 'tgt_text': "def map_config_to_obj(module):  def map_params_to_obj(module):      text = module.params['text']      return {          'banner': module.params['banner'],          'text': text,"}]
***** Running training *****
  Num examples = 1
  Batch size = 4
  Num epoch = 10

***** Running evaluation *****
  Num examples = 104
  Batch size = 2
  epoch = 0
  eval_ppl = inf
  global_step = 2
  train_loss = 45.3638
  ********************
Previous best ppl:inf
Achieve Best ppl:inf
  ********************
BLEU file: ./data/RQ5/python_1_3/validation.jsonl
  codebleu-4 = 22.45 	 Previous best codebleu 0
  ********************
 Achieve Best bleu:22.45
  ********************

***** Running evaluation *****
  Num examples = 104
  Batch size = 2
  epoch = 1
  eval_ppl = inf
  global_step = 3
  train_loss = 49.2965
  ********************
Previous best ppl:inf
Achieve Best ppl:inf
  ********************
BLEU file: ./data/RQ5/python_1_3/validation.jsonl
  codebleu-4 = 28.04 	 Previous best codebleu 22.45
  ********************
 Achieve Best bleu:28.04
  ********************

***** Running evaluation *****
  Num examples = 104
  Batch size = 2
  epoch = 2
  eval_ppl = inf
  global_step = 4
  train_loss = 17.9616
  ********************
Previous best ppl:inf
Achieve Best ppl:inf
  ********************
BLEU file: ./data/RQ5/python_1_3/validation.jsonl
  codebleu-4 = 29.04 	 Previous best codebleu 28.04
  ********************
 Achieve Best bleu:29.04
  ********************

***** Running evaluation *****
  Num examples = 104
  Batch size = 2
  epoch = 3
  eval_ppl = inf
  global_step = 5
  train_loss = 4.7524
  ********************
Previous best ppl:inf
BLEU file: ./data/RQ5/python_1_3/validation.jsonl
  codebleu-4 = 33.81 	 Previous best codebleu 29.04
  ********************
 Achieve Best bleu:33.81
  ********************

***** Running evaluation *****
  Num examples = 104
  Batch size = 2
  epoch = 4
  eval_ppl = inf
  global_step = 6
  train_loss = 1.6193
  ********************
Previous best ppl:inf
BLEU file: ./data/RQ5/python_1_3/validation.jsonl
  codebleu-4 = 40.17 	 Previous best codebleu 33.81
  ********************
 Achieve Best bleu:40.17
  ********************

***** Running evaluation *****
  Num examples = 104
  Batch size = 2
  epoch = 5
  eval_ppl = inf
  global_step = 7
  train_loss = 4.6196
  ********************
Previous best ppl:inf
BLEU file: ./data/RQ5/python_1_3/validation.jsonl
  codebleu-4 = 42.04 	 Previous best codebleu 40.17
  ********************
 Achieve Best bleu:42.04
  ********************

***** Running evaluation *****
  Num examples = 104
  Batch size = 2
  epoch = 6
  eval_ppl = inf
  global_step = 8
  train_loss = 0.5474
  ********************
Previous best ppl:inf
BLEU file: ./data/RQ5/python_1_3/validation.jsonl
  codebleu-4 = 44.27 	 Previous best codebleu 42.04
  ********************
 Achieve Best bleu:44.27
  ********************

***** Running evaluation *****
  Num examples = 104
  Batch size = 2
  epoch = 7
  eval_ppl = inf
  global_step = 9
  train_loss = 0.4077
  ********************
Previous best ppl:inf
BLEU file: ./data/RQ5/python_1_3/validation.jsonl
  codebleu-4 = 45.03 	 Previous best codebleu 44.27
  ********************
 Achieve Best bleu:45.03
  ********************

***** Running evaluation *****
  Num examples = 104
  Batch size = 2
  epoch = 8
  eval_ppl = inf
  global_step = 10
  train_loss = 1.7129
  ********************
Previous best ppl:inf
BLEU file: ./data/RQ5/python_1_3/validation.jsonl
  codebleu-4 = 45.61 	 Previous best codebleu 45.03
  ********************
 Achieve Best bleu:45.61
  ********************

***** Running evaluation *****
  Num examples = 104
  Batch size = 2
  epoch = 9
  eval_ppl = inf
  global_step = 11
  train_loss = 0.5178
  ********************
Previous best ppl:inf
BLEU file: ./data/RQ5/python_1_3/validation.jsonl
  codebleu-4 = 46.64 	 Previous best codebleu 45.61
  ********************
 Achieve Best bleu:46.64
  ********************
reload model from RQ5/python_1/3_codet5p_770m/checkpoint-best-bleu
BLEU file: ./data/RQ5/python_1_3/test.jsonl
  codebleu = 48.2 
  Total = 113 
  Exact Fixed = 0 
[]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  ********************
  Total = 113 
  Exact Fixed = 0 
[]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  codebleu = 48.2 
[0.5988080629048599, 0.03787942467039288, 0.2879660988458514, 0.1610676389491525, 0.20345678619401794, 0.3163781368836666, 0.6511377244434423, 0.27704458676190225, 0.1567428570412095, 0.3298088122098814, 0.2577203723321257, 0.5916934857143832, 0.5561658356992166, 0.5567069126755104, 0.6559299263736871, 0.7295172897514681, 0.02301269599123251, 0.653455512512524, 0.45857932421237557, 0.7485184709688255, 0.29341625082188516, 0.583933634540305, 0.8517652071939987, 0.5340582311947082, 0.7702510467928358, 0.5510611535639117, 0.29927281627987634, 0.31894761871640187, 0.45802579852605346, 0.5031454515892138, 0.7502249062515224, 0.7814538109929585, 0.7426812429281804, 0.014378274991856264, 0.28700509643419553, 0.84788310595391, 0.8703246706459902, 0.40521948335871755, 0.5542542516365543, 0.6900299907977767, 0.5236540690540936, 0.2653093092326273, 0.2576302668100705, 0.3091446021495886, 0.07763283496604702, 0.20687704542047386, 0.7781006907840748, 0.7508650198569218, 0.23452173548450272, 0.38999722300540896, 0.31380961224592446, 0.7574377891387083, 0.3022739331824744, 0.529233623054851, 0.29147351245592523, 0.5117566728908322, 0.7420869867438586, 0.46970156063468593, 0.06497523187578183, 0.6135400252926712, 0.2565792489619432, 0.16729622709085606, 0.12040773109149398, 0.028543774381171408, 0.813574282179609, 0.6700720495886723, 0.287963053924415, 0.8149486591058304, 0.6242685849169879, 0.49739872709512956, 0.20964495315944026, 0.06798742062189049, 0.311598328829906, 0.6121621400753143, 0.025040014129729733, 0.2670695519462781, 0.6478173403947095, 0.23470360205244845, 0.31056766527277113, 0.8912022993575596, 0.38205798979799166, 0.39298056377921375, 0.1538602175127799, 0.7382563371754685, 0.2100132316867166, 0.32151312740389615, 0.5674719919611682, 0.24093190260462918, 0.7688417694606244, 0.6159161218995269, 0.15, 0.675415693810289, 0.23760488717951272, 0.7830978277305174, 0.7371782123552555, 0.9262875886241427, 0.8489616085234697, 0.7931103118166348, 0.6520539970707262, 0.7085861017321415, 0.7643613010325891, 0.8366765466415856, 0.8246717818091027, 0.35704691497052454, 0.2531962464055635, 0.23802484788048095, 0.12276039750941245, 0.8136782861484442, 0.6924797213956112, 0.7510595721793696, 0.9046292183049148, 0.7211062806198592, 0.6763579323284526]
Finish training and take 2h0m

Namespace(log_name='./RQ5/python_1/soft0_3_codet5p_220m.log', model_name='Salesforce/codet5p-220m', lang='python', output_dir='RQ5/python_1/soft0_3_codet5p_220m', data_dir='./data/RQ5/python_1_3', no_cuda=False, visible_gpu='0', num_train_epochs=10, num_test_epochs=1, train_batch_size=16, eval_batch_size=2, gradient_accumulation_steps=1, load_model_path=None, config_name='', tokenizer_name='', max_source_length=512, max_target_length=512, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, freeze=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
Model created!!
Namespace(log_name='./RQ5/python_1/soft0_3_codet5p_220m.log', model_name='Salesforce/codet5p-220m', lang='python', output_dir='RQ5/python_1/soft0_3_codet5p_220m', data_dir='./data/RQ5/python_1_3', no_cuda=False, visible_gpu='0', num_train_epochs=10, num_test_epochs=1, train_batch_size=16, eval_batch_size=2, gradient_accumulation_steps=1, load_model_path=None, config_name='', tokenizer_name='', max_source_length=512, max_target_length=512, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, freeze=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
Namespace(log_name='./RQ5/python_1/soft0_3_codet5p_220m.log', model_name='Salesforce/codet5p-220m', lang='python', output_dir='RQ5/python_1/soft0_3_codet5p_220m', data_dir='./data/RQ5/python_1_3', no_cuda=False, visible_gpu='0', num_train_epochs=10, num_test_epochs=1, train_batch_size=16, eval_batch_size=2, gradient_accumulation_steps=1, load_model_path=None, config_name='', tokenizer_name='', max_source_length=512, max_target_length=512, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, freeze=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
Model created!!
[[{'text': "def map_config_to_obj(module):  def map_params_to_obj(module):      text = module.params['text']     if text:         text = str(text).strip()      return {          'banner': module.params['banner'],          'text': text,", 'loss_ids': 0, 'shortenable_ids': 1}, {'text': '<mask>', 'loss_ids': 1, 'shortenable_ids': 0}, {'text': '', 'loss_ids': 0, 'shortenable_ids': 0}], {'guid': 0, 'tgt_text': "def map_config_to_obj(module):  def map_params_to_obj(module):      text = module.params['text']      return {          'banner': module.params['banner'],          'text': text,"}]
***** Running training *****
  Num examples = 1
  Batch size = 16
  Num epoch = 10

***** Running evaluation *****
  Num examples = 104
  Batch size = 2
  epoch = 0
  eval_ppl = inf
  global_step = 2
  train_loss = 48.1254
  ********************
Previous best ppl:inf
Achieve Best ppl:inf
  ********************
BLEU file: ./data/RQ5/python_1_3/validation.jsonl
  codebleu-4 = 18.59 	 Previous best codebleu 0
  ********************
 Achieve Best bleu:18.59
  ********************

***** Running evaluation *****
  Num examples = 104
  Batch size = 2
  epoch = 1
  eval_ppl = inf
  global_step = 3
  train_loss = 42.0084
  ********************
Previous best ppl:inf
Achieve Best ppl:inf
  ********************
BLEU file: ./data/RQ5/python_1_3/validation.jsonl
  codebleu-4 = 22.12 	 Previous best codebleu 18.59
  ********************
 Achieve Best bleu:22.12
  ********************

***** Running evaluation *****
  Num examples = 104
  Batch size = 2
  epoch = 2
  eval_ppl = inf
  global_step = 4
  train_loss = 21.9105
  ********************
Previous best ppl:inf
Achieve Best ppl:inf
  ********************
BLEU file: ./data/RQ5/python_1_3/validation.jsonl
  codebleu-4 = 19.74 	 Previous best codebleu 22.12
  ********************

***** Running evaluation *****
  Num examples = 104
  Batch size = 2
  epoch = 3
  eval_ppl = inf
  global_step = 5
  train_loss = 13.7092
  ********************
Previous best ppl:inf
Achieve Best ppl:inf
  ********************
BLEU file: ./data/RQ5/python_1_3/validation.jsonl
Namespace(log_name='./RQ5/python_1/soft0_3_codet5p_220m.log', model_name='Salesforce/codet5p-220m', lang='python', output_dir='RQ5/python_1/soft0_3_codet5p_220m', data_dir='./data/RQ5/python_1_3', no_cuda=False, visible_gpu='0', num_train_epochs=10, num_test_epochs=1, train_batch_size=16, eval_batch_size=2, gradient_accumulation_steps=1, load_model_path=None, config_name='', tokenizer_name='', max_source_length=512, max_target_length=512, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, freeze=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
Model created!!
[[{'text': "def map_config_to_obj(module):  def map_params_to_obj(module):      text = module.params['text']     if text:         text = str(text).strip()      return {          'banner': module.params['banner'],          'text': text,", 'loss_ids': 0, 'shortenable_ids': 1}, {'text': '<mask>', 'loss_ids': 1, 'shortenable_ids': 0}, {'text': '', 'loss_ids': 0, 'shortenable_ids': 0}], {'guid': 0, 'tgt_text': "def map_config_to_obj(module):  def map_params_to_obj(module):      text = module.params['text']      return {          'banner': module.params['banner'],          'text': text,"}]
***** Running training *****
  Num examples = 1
  Batch size = 16
  Num epoch = 10

***** Running evaluation *****
  Num examples = 104
  Batch size = 2
  epoch = 0
  eval_ppl = inf
  global_step = 2
  train_loss = 41.151
  ********************
Previous best ppl:inf
Achieve Best ppl:inf
  ********************
BLEU file: ./data/RQ5/python_1_3/validation.jsonl
  codebleu-4 = 18.59 	 Previous best codebleu 0
  ********************
 Achieve Best bleu:18.59
  ********************

***** Running evaluation *****
  Num examples = 104
  Batch size = 2
  epoch = 1
  eval_ppl = inf
  global_step = 3
  train_loss = 41.4053
  ********************
Previous best ppl:inf
Achieve Best ppl:inf
  ********************
BLEU file: ./data/RQ5/python_1_3/validation.jsonl
  codebleu-4 = 18.41 	 Previous best codebleu 18.59
  ********************

***** Running evaluation *****
  Num examples = 104
  Batch size = 2
  epoch = 2
  eval_ppl = inf
  global_step = 4
  train_loss = 19.4107
  ********************
Previous best ppl:inf
Achieve Best ppl:inf
  ********************
BLEU file: ./data/RQ5/python_1_3/validation.jsonl
  codebleu-4 = 19.09 	 Previous best codebleu 18.59
  ********************
 Achieve Best bleu:19.09
  ********************

***** Running evaluation *****
  Num examples = 104
  Batch size = 2
  epoch = 3
  eval_ppl = inf
  global_step = 5
  train_loss = 13.6413
  ********************
Previous best ppl:inf
Achieve Best ppl:inf
  ********************
BLEU file: ./data/RQ5/python_1_3/validation.jsonl
  codebleu-4 = 22.66 	 Previous best codebleu 19.09
  ********************
 Achieve Best bleu:22.66
  ********************

***** Running evaluation *****
  Num examples = 104
  Batch size = 2
  epoch = 4
  eval_ppl = inf
  global_step = 6
  train_loss = 9.4925
  ********************
Previous best ppl:inf
BLEU file: ./data/RQ5/python_1_3/validation.jsonl
  codebleu-4 = 24.21 	 Previous best codebleu 22.66
  ********************
 Achieve Best bleu:24.21
  ********************

***** Running evaluation *****
  Num examples = 104
  Batch size = 2
  epoch = 5
  eval_ppl = inf
  global_step = 7
  train_loss = 4.5788
  ********************
Previous best ppl:inf
BLEU file: ./data/RQ5/python_1_3/validation.jsonl
  codebleu-4 = 27.63 	 Previous best codebleu 24.21
  ********************
 Achieve Best bleu:27.63
  ********************

***** Running evaluation *****
  Num examples = 104
  Batch size = 2
  epoch = 6
  eval_ppl = inf
  global_step = 8
  train_loss = 2.2965
  ********************
Previous best ppl:inf
BLEU file: ./data/RQ5/python_1_3/validation.jsonl
  codebleu-4 = 29.46 	 Previous best codebleu 27.63
  ********************
 Achieve Best bleu:29.46
  ********************

***** Running evaluation *****
  Num examples = 104
  Batch size = 2
  epoch = 7
  eval_ppl = inf
  global_step = 9
  train_loss = 2.7647
  ********************
Previous best ppl:inf
BLEU file: ./data/RQ5/python_1_3/validation.jsonl
  codebleu-4 = 35.73 	 Previous best codebleu 29.46
  ********************
 Achieve Best bleu:35.73
  ********************

***** Running evaluation *****
  Num examples = 104
  Batch size = 2
  epoch = 8
  eval_ppl = inf
  global_step = 10
  train_loss = 1.7989
  ********************
Previous best ppl:inf
BLEU file: ./data/RQ5/python_1_3/validation.jsonl
  codebleu-4 = 43.02 	 Previous best codebleu 35.73
  ********************
 Achieve Best bleu:43.02
  ********************

***** Running evaluation *****
  Num examples = 104
  Batch size = 2
  epoch = 9
  eval_ppl = inf
  global_step = 11
  train_loss = 6.8905
  ********************
Previous best ppl:inf
BLEU file: ./data/RQ5/python_1_3/validation.jsonl
  codebleu-4 = 46.05 	 Previous best codebleu 43.02
  ********************
 Achieve Best bleu:46.05
  ********************
reload model from RQ5/python_1/soft0_3_codet5p_220m/checkpoint-best-bleu
BLEU file: ./data/RQ5/python_1_3/test.jsonl
  codebleu = 46.31 
  Total = 113 
  Exact Fixed = 0 
[]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  ********************
  Total = 113 
  Exact Fixed = 0 
[]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  codebleu = 46.31 
[0.6728230800934798, 0.815818247971489, 0.3038196947232708, 0.41805820044498665, 0.20122800942293234, 0.31794242479484397, 0.675475223912508, 0.2771504002092295, 0.5217952554642049, 0.7638847477997331, 0.7714650156104186, 0.2446250397517233, 0.25151871437698264, 0.7509942969143784, 0.51246658043467, 0.11663516201905699, 0.06859013962720337, 0.3292418478335817, 0.5580871613571617, 0.24839814145080852, 0.2947694749463006, 0.39711776174040664, 0.8517652071939987, 0.5340582311947082, 0.023417782307444453, 0.45472562564808194, 0.27395476508402006, 0.6880800959195585, 0.2787349700205406, 0.4381357487542596, 0.2813127919970617, 0.32584186602479476, 0.7426812429281804, 0.17739604033688666, 0.2933220793463995, 0.25483630511378863, 0.2346884592127954, 0.20811446227453992, 0.20351643372098974, 0.6938401878810492, 0.205105399577621, 0.2378400969490396, 0.32038130198549536, 0.4740532618616287, 0.43768826904009245, 0.29374209676640034, 0.7781006907840748, 0.8782734899756608, 0.549916846856608, 0.12659574468085105, 0.6810015223391338, 0.7549669674736412, 0.7053409078583737, 0.2294811769240674, 0.29867362931893765, 0.4697114844217023, 0.27446686707256684, 0.5564459155199564, 0.06763565369512531, 0.860117164263619, 0.2776515238008453, 0.22632437201108838, 0.6356257812621184, 0.2511620218106624, 0.813574282179609, 0.5323080684224424, 0.3114120031824913, 0.7427913793368753, 0.5735267232477851, 0.2215441772192705, 0.16356752920187675, 0.2769767788930313, 0.9472873156881443, 0.676525822803221, 0.6544452409330017, 0.20432389144352037, 0.7646426648382283, 0.9056583090096291, 0.7449734989717058, 0.27079911168332693, 0.5559330911230723, 0.060186637957838414, 0.15804978432976163, 0.14526086384366405, 0.6089407398530304, 0.3221566043052433, 0.44554278174453965, 0.06191131075909258, 0.5357843195790143, 0.8419696121829401, 0.15, 0.6662959068824235, 0.581210036147918, 0.13676681672436794, 0.7684660417472544, 0.86275118124194, 0.6940362022020281, 0.7880312717060245, 0.14170806403097697, 0.5370803918707686, 0.6318951543525639, 0.8366765466415856, 0.2420651007406257, 0.6993206704987984, 0.2531962464055635, 0.23628941877891455, 0.11884466534056767, 0.8611544762176193, 0.20551334256645382, 0.8076545069480704, 0.9046292183049148, 0.7415658664772448, 0.8637158857744637]
Finish training and take 1h17m

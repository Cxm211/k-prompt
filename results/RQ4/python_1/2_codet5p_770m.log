Namespace(log_name='./RQ5/python_1/2_codet5p_770m.log', model_name='Salesforce/codet5p-770m', lang='python', output_dir='RQ5/python_1/2_codet5p_770m', data_dir='./data/RQ5/python_1_2', no_cuda=False, visible_gpu='0', num_train_epochs=10, num_test_epochs=1, train_batch_size=4, eval_batch_size=2, gradient_accumulation_steps=1, load_model_path=None, config_name='', tokenizer_name='', max_source_length=512, max_target_length=512, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, freeze=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
Model created!!
[[{'text': 'class Index(IndexOpsMixin, PandasObject):          if is_categorical(target):              tgt_values = np.asarray(target)         elif self.is_all_dates:              tgt_values = target.asi8          else:              tgt_values = target._ndarray_values', 'loss_ids': 0, 'shortenable_ids': 1}, {'text': '<mask>', 'loss_ids': 1, 'shortenable_ids': 0}, {'text': '', 'loss_ids': 0, 'shortenable_ids': 0}], {'guid': 0, 'tgt_text': 'class Index(IndexOpsMixin, PandasObject):          if is_categorical(target):              tgt_values = np.asarray(target)         elif self.is_all_dates and target.is_all_dates:              tgt_values = target.asi8          else:              tgt_values = target._ndarray_values'}]
***** Running training *****
  Num examples = 1
  Batch size = 4
  Num epoch = 10

***** Running evaluation *****
  Num examples = 104
  Batch size = 2
  epoch = 0
  eval_ppl = inf
  global_step = 2
  train_loss = 47.2319
  ********************
Previous best ppl:inf
Achieve Best ppl:inf
  ********************
BLEU file: ./data/RQ5/python_1_2/validation.jsonl
  codebleu-4 = 22.45 	 Previous best codebleu 0
  ********************
 Achieve Best bleu:22.45
  ********************

***** Running evaluation *****
  Num examples = 104
  Batch size = 2
  epoch = 1
  eval_ppl = inf
  global_step = 3
  train_loss = 52.8281
  ********************
Previous best ppl:inf
Achieve Best ppl:inf
  ********************
BLEU file: ./data/RQ5/python_1_2/validation.jsonl
  codebleu-4 = 27.49 	 Previous best codebleu 22.45
  ********************
 Achieve Best bleu:27.49
  ********************

***** Running evaluation *****
  Num examples = 104
  Batch size = 2
  epoch = 2
  eval_ppl = inf
  global_step = 4
  train_loss = 19.8381
  ********************
Previous best ppl:inf
Achieve Best ppl:inf
  ********************
BLEU file: ./data/RQ5/python_1_2/validation.jsonl
  codebleu-4 = 31.84 	 Previous best codebleu 27.49
  ********************
 Achieve Best bleu:31.84
  ********************

***** Running evaluation *****
  Num examples = 104
  Batch size = 2
  epoch = 3
  eval_ppl = inf
  global_step = 5
  train_loss = 7.1365
  ********************
Previous best ppl:inf
BLEU file: ./data/RQ5/python_1_2/validation.jsonl
  codebleu-4 = 38.97 	 Previous best codebleu 31.84
  ********************
 Achieve Best bleu:38.97
  ********************

***** Running evaluation *****
  Num examples = 104
  Batch size = 2
  epoch = 4
  eval_ppl = inf
  global_step = 6
  train_loss = 6.0515
  ********************
Previous best ppl:inf
BLEU file: ./data/RQ5/python_1_2/validation.jsonl
  codebleu-4 = 48.0 	 Previous best codebleu 38.97
  ********************
 Achieve Best bleu:48.0
  ********************

***** Running evaluation *****
  Num examples = 104
  Batch size = 2
  epoch = 5
  eval_ppl = inf
  global_step = 7
  train_loss = 4.0778
  ********************
Previous best ppl:inf
BLEU file: ./data/RQ5/python_1_2/validation.jsonl
  codebleu-4 = 54.98 	 Previous best codebleu 48.0
  ********************
 Achieve Best bleu:54.98
  ********************

***** Running evaluation *****
  Num examples = 104
  Batch size = 2
  epoch = 6
  eval_ppl = inf
  global_step = 8
  train_loss = 11.3912
  ********************
Previous best ppl:inf
BLEU file: ./data/RQ5/python_1_2/validation.jsonl
  codebleu-4 = 57.51 	 Previous best codebleu 54.98
  ********************
 Achieve Best bleu:57.51
  ********************

***** Running evaluation *****
  Num examples = 104
  Batch size = 2
  epoch = 7
  eval_ppl = inf
  global_step = 9
  train_loss = 3.4891
  ********************
Previous best ppl:inf
BLEU file: ./data/RQ5/python_1_2/validation.jsonl
  codebleu-4 = 56.95 	 Previous best codebleu 57.51
  ********************

***** Running evaluation *****
  Num examples = 104
  Batch size = 2
  epoch = 8
  eval_ppl = inf
  global_step = 10
  train_loss = 2.2462
  ********************
Previous best ppl:inf
BLEU file: ./data/RQ5/python_1_2/validation.jsonl
  codebleu-4 = 56.0 	 Previous best codebleu 57.51
  ********************

***** Running evaluation *****
  Num examples = 104
  Batch size = 2
  epoch = 9
  eval_ppl = inf
  global_step = 11
  train_loss = 5.9455
  ********************
Previous best ppl:inf
BLEU file: ./data/RQ5/python_1_2/validation.jsonl
  codebleu-4 = 57.1 	 Previous best codebleu 57.51
  ********************
early stopping!!!
reload model from RQ5/python_1/2_codet5p_770m/checkpoint-best-bleu
BLEU file: ./data/RQ5/python_1_2/test.jsonl
  codebleu = 59.52 
  Total = 113 
  Exact Fixed = 0 
[]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  ********************
  Total = 113 
  Exact Fixed = 0 
[]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  codebleu = 59.52 
[0.26834647487299246, 0.8834124216164225, 0.656947034688705, 0.47166395418323315, 0.223443071594268, 0.32178761703833597, 0.7690182397845626, 0.7841335330833195, 0.5571314709024371, 0.7953587603777192, 0.2937681763906797, 0.6038809041233579, 0.835982014095209, 0.7768711691119308, 0.29616784057072515, 0.8673208349360431, 0.7111305141258621, 0.7363507703775912, 0.5465574335200324, 0.8033158123816395, 0.047215508785698655, 0.5462463332248342, 0.8261347116348294, 0.4784726595893233, 0.8234479137638847, 0.0, 0.22679579720621262, 0.8387451272413023, 0.6188765007848422, 0.568803606953774, 0.5066764917309767, 0.8808919461147899, 0.7374462635601402, 0.3963146940011453, 0.838750369867548, 0.24697729978812233, 0.8703246706459902, 0.3083061908811996, 0.9142445273649933, 0.6443270862571485, 0.6141830477189014, 0.6807959319445236, 0.7184614813437915, 0.5006586123452743, 0.42092407157002426, 0.7219888085734718, 0.17421372887063066, 0.25334027700332173, 0.549916846856608, 0.16754032258064516, 0.7722515742658139, 0.7680104457345107, 0.30610964248944195, 0.4951766531824895, 0.8156338304785944, 0.4889393741456346, 0.7507179666293025, 0.6658776393213339, 0.2318983570605234, 0.8050044229858189, 0.7514572282443166, 0.18369921710566087, 0.6356257812621184, 0.477494730851435, 0.8475332565755729, 0.5891194013278918, 0.6487258704654236, 0.848034624064077, 0.34997410077253854, 0.5659203606220613, 0.578842341731666, 0.07438413860647908, 0.8716458411290686, 0.676525822803221, 0.13320072344277112, 0.38403406786446487, 0.1552755939981136, 0.23107875045102994, 0.6583607974542184, 0.8419185800071731, 0.8727790091136098, 0.6288516563175959, 0.31262349217428553, 0.71357631893127, 0.7118649769440533, 0.03787676376753257, 0.44554278174453965, 0.7332519354895861, 0.7619034364085033, 0.8217077734855331, 0.8814955038434287, 0.7579539969913704, 0.5266112195874727, 0.8736270526063763, 0.7161374055638184, 0.8843613808893851, 0.23733216518145728, 0.7422503363865474, 0.25437224899418137, 0.7741364884334869, 0.7324180261718023, 0.878865255109752, 0.8002475620249734, 0.5944582043769604, 0.7438519009807991, 0.8631855387221548, 0.6113777135550589, 0.67067897181773, 0.5290602856233175, 0.8623268635091106, 0.9046292183049148, 0.7127118878052279, 0.7417310765212264]
Finish training and take 1h53m

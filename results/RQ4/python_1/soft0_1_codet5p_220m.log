Namespace(log_name='./RQ5/python_1/soft0_1_codet5p_220m.log', model_name='Salesforce/codet5p-220m', lang='python', output_dir='RQ5/python_1/soft0_1_codet5p_220m', data_dir='./data/RQ5/python_1_1', no_cuda=False, visible_gpu='0', num_train_epochs=10, num_test_epochs=1, train_batch_size=16, eval_batch_size=2, gradient_accumulation_steps=1, load_model_path=None, config_name='', tokenizer_name='', max_source_length=512, max_target_length=512, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, freeze=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
Model created!!
Namespace(log_name='./RQ5/python_1/soft0_1_codet5p_220m.log', model_name='Salesforce/codet5p-220m', lang='python', output_dir='RQ5/python_1/soft0_1_codet5p_220m', data_dir='./data/RQ5/python_1_2', no_cuda=False, visible_gpu='0', num_train_epochs=10, num_test_epochs=1, train_batch_size=8, eval_batch_size=2, gradient_accumulation_steps=1, load_model_path=None, config_name='', tokenizer_name='', max_source_length=512, max_target_length=512, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, freeze=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
Namespace(log_name='./RQ5/python_1/soft0_1_codet5p_220m.log', model_name='Salesforce/codet5p-220m', lang='python', output_dir='RQ5/python_1/soft0_1_codet5p_220m', data_dir='./data/RQ5/python_1_2', no_cuda=False, visible_gpu='0', num_train_epochs=10, num_test_epochs=1, train_batch_size=8, eval_batch_size=2, gradient_accumulation_steps=1, load_model_path=None, config_name='', tokenizer_name='', max_source_length=512, max_target_length=512, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, freeze=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
Model created!!
[[{'text': 'class Index(IndexOpsMixin, PandasObject):          if is_categorical(target):              tgt_values = np.asarray(target)         elif self.is_all_dates:              tgt_values = target.asi8          else:              tgt_values = target._ndarray_values', 'loss_ids': 0, 'shortenable_ids': 1}, {'text': '<mask>', 'loss_ids': 1, 'shortenable_ids': 0}, {'text': '', 'loss_ids': 0, 'shortenable_ids': 0}], {'guid': 0, 'tgt_text': 'class Index(IndexOpsMixin, PandasObject):          if is_categorical(target):              tgt_values = np.asarray(target)         elif self.is_all_dates and target.is_all_dates:              tgt_values = target.asi8          else:              tgt_values = target._ndarray_values'}]
***** Running training *****
  Num examples = 1
  Batch size = 8
  Num epoch = 10

***** Running evaluation *****
  Num examples = 104
  Batch size = 2
  epoch = 0
  eval_ppl = inf
  global_step = 2
  train_loss = 55.7948
  ********************
Previous best ppl:inf
Achieve Best ppl:inf
  ********************
BLEU file: ./data/RQ5/python_1_2/validation.jsonl
Namespace(log_name='./RQ5/python_1/soft0_1_codet5p_220m.log', model_name='Salesforce/codet5p-220m', lang='python', output_dir='RQ5/python_1/soft0_1_codet5p_220m', data_dir='./data/RQ5/python_1_2', no_cuda=False, visible_gpu='0', num_train_epochs=10, num_test_epochs=1, train_batch_size=8, eval_batch_size=2, gradient_accumulation_steps=1, load_model_path=None, config_name='', tokenizer_name='', max_source_length=512, max_target_length=512, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, freeze=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
Model created!!
[[{'text': 'class Index(IndexOpsMixin, PandasObject):          if is_categorical(target):              tgt_values = np.asarray(target)         elif self.is_all_dates:              tgt_values = target.asi8          else:              tgt_values = target._ndarray_values', 'loss_ids': 0, 'shortenable_ids': 1}, {'text': '<mask>', 'loss_ids': 1, 'shortenable_ids': 0}, {'text': '', 'loss_ids': 0, 'shortenable_ids': 0}], {'guid': 0, 'tgt_text': 'class Index(IndexOpsMixin, PandasObject):          if is_categorical(target):              tgt_values = np.asarray(target)         elif self.is_all_dates and target.is_all_dates:              tgt_values = target.asi8          else:              tgt_values = target._ndarray_values'}]
***** Running training *****
  Num examples = 1
  Batch size = 8
  Num epoch = 10

***** Running evaluation *****
  Num examples = 104
  Batch size = 2
  epoch = 0
  eval_ppl = inf
  global_step = 2
  train_loss = 55.7948
  ********************
Previous best ppl:inf
Achieve Best ppl:inf
  ********************
BLEU file: ./data/RQ5/python_1_2/validation.jsonl
  codebleu-4 = 18.59 	 Previous best codebleu 0
  ********************
 Achieve Best bleu:18.59
  ********************

***** Running evaluation *****
  Num examples = 104
  Batch size = 2
  epoch = 1
  eval_ppl = inf
  global_step = 3
  train_loss = 50.1517
  ********************
Previous best ppl:inf
Achieve Best ppl:inf
  ********************
BLEU file: ./data/RQ5/python_1_2/validation.jsonl
  codebleu-4 = 26.15 	 Previous best codebleu 18.59
  ********************
 Achieve Best bleu:26.15
  ********************

***** Running evaluation *****
  Num examples = 104
  Batch size = 2
  epoch = 2
  eval_ppl = inf
  global_step = 4
  train_loss = 17.3801
  ********************
Previous best ppl:inf
Achieve Best ppl:inf
  ********************
BLEU file: ./data/RQ5/python_1_2/validation.jsonl
  codebleu-4 = 29.04 	 Previous best codebleu 26.15
  ********************
 Achieve Best bleu:29.04
  ********************

***** Running evaluation *****
  Num examples = 104
  Batch size = 2
  epoch = 3
  eval_ppl = inf
  global_step = 5
  train_loss = 9.4965
  ********************
Previous best ppl:inf
Achieve Best ppl:inf
  ********************
BLEU file: ./data/RQ5/python_1_2/validation.jsonl
  codebleu-4 = 34.26 	 Previous best codebleu 29.04
  ********************
 Achieve Best bleu:34.26
  ********************

***** Running evaluation *****
  Num examples = 104
  Batch size = 2
  epoch = 4
  eval_ppl = inf
  global_step = 6
  train_loss = 7.9274
  ********************
Previous best ppl:inf
Achieve Best ppl:inf
  ********************
BLEU file: ./data/RQ5/python_1_2/validation.jsonl
  codebleu-4 = 42.59 	 Previous best codebleu 34.26
  ********************
 Achieve Best bleu:42.59
  ********************

***** Running evaluation *****
  Num examples = 104
  Batch size = 2
  epoch = 5
  eval_ppl = inf
  global_step = 7
  train_loss = 9.6595
  ********************
Previous best ppl:inf
Achieve Best ppl:inf
  ********************
BLEU file: ./data/RQ5/python_1_2/validation.jsonl
  codebleu-4 = 48.04 	 Previous best codebleu 42.59
  ********************
 Achieve Best bleu:48.04
  ********************

***** Running evaluation *****
  Num examples = 104
  Batch size = 2
  epoch = 6
  eval_ppl = inf
  global_step = 8
  train_loss = 2.4277
  ********************
Previous best ppl:inf
Achieve Best ppl:inf
  ********************
BLEU file: ./data/RQ5/python_1_2/validation.jsonl
Namespace(log_name='./RQ5/python_1/soft0_1_codet5p_220m.log', model_name='Salesforce/codet5p-220m', lang='python', output_dir='RQ5/python_1/soft0_1_codet5p_220m', data_dir='./data/RQ5/python_1_2', no_cuda=False, visible_gpu='0', num_train_epochs=10, num_test_epochs=1, train_batch_size=8, eval_batch_size=2, gradient_accumulation_steps=1, load_model_path=None, config_name='', tokenizer_name='', max_source_length=512, max_target_length=512, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, freeze=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
Model created!!
[[{'text': 'class Index(IndexOpsMixin, PandasObject):          if is_categorical(target):              tgt_values = np.asarray(target)         elif self.is_all_dates:              tgt_values = target.asi8          else:              tgt_values = target._ndarray_values', 'loss_ids': 0, 'shortenable_ids': 1}, {'text': '<mask>', 'loss_ids': 1, 'shortenable_ids': 0}, {'text': '', 'loss_ids': 0, 'shortenable_ids': 0}], {'guid': 0, 'tgt_text': 'class Index(IndexOpsMixin, PandasObject):          if is_categorical(target):              tgt_values = np.asarray(target)         elif self.is_all_dates and target.is_all_dates:              tgt_values = target.asi8          else:              tgt_values = target._ndarray_values'}]
***** Running training *****
  Num examples = 1
  Batch size = 8
  Num epoch = 10

***** Running evaluation *****
  Num examples = 104
  Batch size = 2
  epoch = 0
  eval_ppl = inf
  global_step = 2
  train_loss = 71.1468
  ********************
Previous best ppl:inf
Achieve Best ppl:inf
  ********************
BLEU file: ./data/RQ5/python_1_2/validation.jsonl
  codebleu-4 = 18.59 	 Previous best codebleu 0
  ********************
 Achieve Best bleu:18.59
  ********************

***** Running evaluation *****
  Num examples = 104
  Batch size = 2
  epoch = 1
  eval_ppl = inf
  global_step = 3
  train_loss = 60.6353
  ********************
Previous best ppl:inf
Achieve Best ppl:inf
  ********************
BLEU file: ./data/RQ5/python_1_2/validation.jsonl
  codebleu-4 = 28.47 	 Previous best codebleu 18.59
  ********************
 Achieve Best bleu:28.47
  ********************

***** Running evaluation *****
  Num examples = 104
  Batch size = 2
  epoch = 2
  eval_ppl = inf
  global_step = 4
  train_loss = 21.4481
  ********************
Previous best ppl:inf
Achieve Best ppl:inf
  ********************
BLEU file: ./data/RQ5/python_1_2/validation.jsonl
  codebleu-4 = 29.65 	 Previous best codebleu 28.47
  ********************
 Achieve Best bleu:29.65
  ********************

***** Running evaluation *****
  Num examples = 104
  Batch size = 2
  epoch = 3
  eval_ppl = inf
  global_step = 5
  train_loss = 13.0008
  ********************
Previous best ppl:inf
Achieve Best ppl:inf
  ********************
BLEU file: ./data/RQ5/python_1_2/validation.jsonl
  codebleu-4 = 31.88 	 Previous best codebleu 29.65
  ********************
 Achieve Best bleu:31.88
  ********************

***** Running evaluation *****
  Num examples = 104
  Batch size = 2
  epoch = 4
  eval_ppl = inf
  global_step = 6
  train_loss = 9.5178
  ********************
Previous best ppl:inf
Achieve Best ppl:inf
  ********************
BLEU file: ./data/RQ5/python_1_2/validation.jsonl
  codebleu-4 = 41.05 	 Previous best codebleu 31.88
  ********************
 Achieve Best bleu:41.05
  ********************

***** Running evaluation *****
  Num examples = 104
  Batch size = 2
  epoch = 5
  eval_ppl = inf
  global_step = 7
  train_loss = 7.6916
  ********************
Previous best ppl:inf
BLEU file: ./data/RQ5/python_1_2/validation.jsonl
  codebleu-4 = 46.5 	 Previous best codebleu 41.05
  ********************
 Achieve Best bleu:46.5
  ********************

***** Running evaluation *****
  Num examples = 104
  Batch size = 2
  epoch = 6
  eval_ppl = inf
  global_step = 8
  train_loss = 10.2756
  ********************
Previous best ppl:inf
BLEU file: ./data/RQ5/python_1_2/validation.jsonl
  codebleu-4 = 54.27 	 Previous best codebleu 46.5
  ********************
 Achieve Best bleu:54.27
  ********************

***** Running evaluation *****
  Num examples = 104
  Batch size = 2
  epoch = 7
  eval_ppl = inf
  global_step = 9
  train_loss = 3.0776
  ********************
Previous best ppl:inf
BLEU file: ./data/RQ5/python_1_2/validation.jsonl
  codebleu-4 = 56.6 	 Previous best codebleu 54.27
  ********************
 Achieve Best bleu:56.6
  ********************

***** Running evaluation *****
  Num examples = 104
  Batch size = 2
  epoch = 8
  eval_ppl = inf
  global_step = 10
  train_loss = 3.3523
  ********************
Previous best ppl:inf
BLEU file: ./data/RQ5/python_1_2/validation.jsonl
  codebleu-4 = 58.47 	 Previous best codebleu 56.6
  ********************
 Achieve Best bleu:58.47
  ********************

***** Running evaluation *****
  Num examples = 104
  Batch size = 2
  epoch = 9
  eval_ppl = inf
  global_step = 11
  train_loss = 2.6867
  ********************
Previous best ppl:inf
BLEU file: ./data/RQ5/python_1_2/validation.jsonl
  codebleu-4 = 60.04 	 Previous best codebleu 58.47
  ********************
 Achieve Best bleu:60.04
  ********************
reload model from RQ5/python_1/soft0_1_codet5p_220m/checkpoint-best-bleu
BLEU file: ./data/RQ5/python_1_2/test.jsonl
  codebleu = 59.21 
  Total = 113 
  Exact Fixed = 0 
[]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  ********************
  Total = 113 
  Exact Fixed = 0 
[]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  codebleu = 59.21 
[0.6728230800934798, 0.17114097114967003, 0.30516301103979504, 0.47166395418323315, 0.20431115687288243, 0.32202230512360086, 0.7765857065652169, 0.3196649533599848, 0.5571314709024371, 0.7953587603777192, 0.7714650156104186, 0.34224937313753173, 0.2145518905855763, 0.7768711691119308, 0.6883720951974961, 0.8714262284358163, 0.14897267256618252, 0.6413921957402942, 0.7443181170763433, 0.6594680838384535, 0.040802588668024775, 0.510844534113245, 0.9204219587780458, 0.24919621826033717, 0.8038985157366865, 0.566631478406872, 0.28487412740201135, 0.7163669362752553, 0.6853803599169206, 0.5242858618777545, 0.5066764917309767, 0.8808919461147899, 0.6380980217318013, 0.8235679216062044, 0.2746613843285824, 0.14503251149916763, 0.8703246706459902, 0.7507982187182929, 0.9142445273649933, 0.5904654316690492, 0.16962494169701203, 0.7305838949010892, 0.8548397899287874, 0.4740532618616287, 0.3778129901811716, 0.23609905447336993, 0.8077895563342797, 0.4459837035415737, 0.549916846856608, 0.4152377725154969, 0.8484585607242681, 0.2750234176871011, 0.286693217000988, 0.515599849811825, 0.7925022941900064, 0.5117566728908322, 0.8923125000332248, 0.6934703677992331, 0.5748440807844462, 0.860117164263619, 0.8043022983720753, 0.214796347997955, 0.6356257812621184, 0.45921863126339835, 0.8475332565755729, 0.6057788430165783, 0.7671059053225888, 0.7890278782295435, 0.3202469430259529, 0.5750974938187585, 0.6439391185600173, 0.09931334304894703, 0.6020701024774191, 0.676525822803221, 0.32669183024215515, 0.49150427670545643, 0.8096114788906146, 0.9056583090096291, 0.7449734989717058, 0.8355234009221034, 0.8727790091136098, 0.1410236310665639, 0.31944057229228656, 0.7957602882832283, 0.7460293008575779, 0.03158239269604357, 0.4902704874187754, 0.32842120885126513, 0.2881435313242401, 0.8686435415724127, 0.656541194472775, 0.8021170040829606, 0.5746277553591552, 0.8288221338307671, 0.35501948233037645, 0.8843613808893851, 0.7295586116525126, 0.8834630241782442, 0.7884485258508804, 0.3496861221525442, 0.6922185072791587, 0.7768277736984348, 0.7530107802617916, 0.610067068626702, 0.8300101016746005, 0.8904005689380714, 0.5380924621292474, 0.8611544762176193, 0.24582436014450126, 0.911776276896314, 0.838881722040137, 0.7120009773363332, 0.8972750564356766]
Finish training and take 59m

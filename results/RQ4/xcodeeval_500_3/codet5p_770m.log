Namespace(log_name='./RQ5/xcodeeval_500_3/codet5p_770m.log', model_name='Salesforce/codet5p-770m', lang='c', output_dir='RQ5/xcodeeval_500_3/codet5p_770m', data_dir='./data/RQ5/xcodeeval_500_3', choice=0, no_cuda=False, visible_gpu='0', num_train_epochs=10, num_test_epochs=1, train_batch_size=4, eval_batch_size=4, gradient_accumulation_steps=1, load_model_path=None, config_name='', tokenizer_name='', max_source_length=512, max_target_length=512, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, freeze=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
Model created!!
[[{'text': '#pragma warning(disable:4996) #pragma comment(linker, "/STACK:16777216") #include <stdio.h> #include <string.h> #include <math.h>  #define PI 3.1415926535897932384  #ifndef ONLINE_JUDGE  FILE *stream; #endif  int main() {  char str[100002];  int m;  int l, r;  int len;  int i;  char currentSym;  int result; #ifndef ONLINE_JUDGE   freopen_s(&stream, "D:\\\\Work\\\\CodeForces\\\\input.txt", "rt", stdin);    freopen_s(&stream, "D:\\\\Work\\\\CodeForces\\\\output.txt", "wt", stdout); #endif  scanf("%s%i", &str[1], &m);    len = strlen(&str[1]);  currentSym = str[1];  str[1] = 1;  for (i = 2; i <= len; i++){   if (str[i] == currentSym)    str[i] = str[i-1] + 1;   else{    currentSym = str[i];    str[i] = 1;   }  }   for (; m > 0; m--){   scanf("%i%i", &l, &r);    result = 0;   while (l < r){    if (r - str[r] >= l)     result += str[r] - 1;    else     result += str[r] - str[l];     r -= str[r];   }    printf("%i\\n", result);  }    return 0; }', 'loss_ids': 0, 'shortenable_ids': 1}, {'text': '<mask>', 'loss_ids': 1, 'shortenable_ids': 0}, {'text': 'is the fixed version', 'loss_ids': 0, 'shortenable_ids': 0}], {'guid': 0, 'tgt_text': '#pragma warning(disable:4996) #pragma comment(linker, "/STACK:16777216") #include <stdio.h> #include <string.h> #include <math.h>  #define PI 3.1415926535897932384  #ifndef ONLINE_JUDGE  FILE *stream; #endif  int main() {  char str[100001];  int  arr[100000];  int m;  int l, r;  int len;  int i;  char currentSym; #ifndef ONLINE_JUDGE   freopen_s(&stream, "D:\\\\Work\\\\CodeForces\\\\input.txt", "rt", stdin);    freopen_s(&stream, "D:\\\\Work\\\\CodeForces\\\\output.txt", "wt", stdout); #endif  scanf("%s%i", str, &m);    len = strlen(str);  currentSym = str[0];  arr[0] = 0;  for (i = 1; i < len; i++){   if (str[i] == currentSym)    arr[i] = arr[i-1] + 1;   else{    currentSym = str[i];    arr[i] = arr[i-1];   }  }   for (; m > 0; m--){   scanf("%i%i", &l, &r);    printf("%i\\n", arr[r-1] - arr[l-1]);  }    return 0; }'}]
***** Running training *****
  Num examples = 500
  Batch size = 4
  Num epoch = 10

***** Running evaluation *****
  Num examples = 100
  Batch size = 4
  epoch = 0
  eval_ppl = 1.1739882083626514e+301
  global_step = 126
  train_loss = 62.1281
  ********************
Previous best ppl:inf
Achieve Best ppl:1.1739882083626514e+301
  ********************
BLEU file: ./data/RQ5/xcodeeval_500_3/validation.jsonl
  codebleu-4 = 73.32 	 Previous best codebleu 0
  ********************
 Achieve Best bleu:73.32
  ********************

***** Running evaluation *****
  Num examples = 100
  Batch size = 4
  epoch = 1
  eval_ppl = inf
  global_step = 251
  train_loss = 47.7072
  ********************
Previous best ppl:1.1739882083626514e+301
BLEU file: ./data/RQ5/xcodeeval_500_3/validation.jsonl
  codebleu-4 = 73.22 	 Previous best codebleu 73.32
  ********************

***** Running evaluation *****
  Num examples = 100
  Batch size = 4
  epoch = 2
  eval_ppl = inf
  global_step = 376
  train_loss = 33.3201
  ********************
Previous best ppl:1.1739882083626514e+301
BLEU file: ./data/RQ5/xcodeeval_500_3/validation.jsonl
  codebleu-4 = 73.14 	 Previous best codebleu 73.32
  ********************

***** Running evaluation *****
  Num examples = 100
  Batch size = 4
  epoch = 3
  eval_ppl = inf
  global_step = 501
  train_loss = 23.0596
  ********************
Previous best ppl:1.1739882083626514e+301
BLEU file: ./data/RQ5/xcodeeval_500_3/validation.jsonl
  codebleu-4 = 73.08 	 Previous best codebleu 73.32
  ********************
early stopping!!!
reload model from RQ5/xcodeeval_500_3/codet5p_770m/checkpoint-best-bleu
BLEU file: ./data/RQ5/xcodeeval_500_3/test.jsonl
  codebleu = 74.29 
  Total = 500 
  Exact Fixed = 3 
[187, 322, 451]
  Syntax Fixed = 3 
[15, 88, 308]
  Cleaned Fixed = 1 
[481]
  ********************
  Total = 500 
  Exact Fixed = 3 
[187, 322, 451]
  Syntax Fixed = 3 
[15, 88, 308]
  Cleaned Fixed = 1 
[481]
  codebleu = 74.29 
[0.5003909451993059, 0.9294151499698242, 0.6386890640788627, 0.4507986952593763, 0.7167784203410406, 0.7679881745093895, 0.988076477678953, 0.8152127997896537, 0.7852857892799938, 0.930723952533191, 0.6460242325891442, 0.7772868173384335, 0.9623971198135532, 0.736036573233421, 0.7971886413768894, 0.5413427461678596, 0.9621715437613865, 0.7428715295728313, 0.7747165634300157, 0.792709799130249, 0.8276821254560949, 0.3446503101961176, 0.9617896364191245, 0.8925560777052948, 0.7972962677594202, 0.0009061008383891935, 0.8434094165290678, 0.6930401265841843, 0.3600824707101461, 0.947727377152082, 0.9380700193415508, 0.7113416142390256, 0.6569729679812651, 0.5431168861528274, 0.9274309768041398, 0.4964785177490538, 0.7336996602379647, 0.9691599747588928, 0.7411039840168427, 0.9866836999577304, 0.43871215196390306, 0.8833038098770115, 0.9422467314785667, 0.8789031862578742, 0.6458094453040173, 0.834870050816076, 0.5338617744031935, 0.8602181220443288, 0.8226980351644886, 0.9358086045306386, 0.6349077239728745, 0.9765120913566805, 0.9060197123625242, 0.8840316284511491, 0.9732049512552536, 0.938955604347008, 0.8901175622126745, 0.9339299975598521, 0.5550806435553547, 0.2884494942340172, 0.6984927771743764, 0.5415454260109173, 0.9126538866701963, 0.33460070946115567, 0.9853863431203176, 0.9752926493864778, 0.9661574667855231, 0.7858041122445381, 0.7086389356161231, 0.915465568076623, 0.5140532373556195, 0.7769943668010335, 0.9268555414820475, 0.9853133667641483, 0.9191158481207378, 0.9402009240478387, 0.9189149325906292, 0.4932733020018213, 0.9835575139456028, 0.9595814751894158, 0.8979589771065096, 0.3816824572563564, 0.7597100033179813, 0.9616100740405664, 0.9319685888076141, 0.4546305576901091, 0.608990714278228, 0.9738014890069033, 0.7248773843271845, 0.967199892711541, 0.29319275081975693, 0.9714892269638897, 0.8952672769095782, 0.8876242548612938, 0.8511121182268683, 0.37642420748881267, 0.9441722498573561, 0.9602694033492566, 0.9319272046508655, 0.8283719455395986, 0.7529046737306214, 0.9019464684129248, 0.9542331310807404, 0.7462546419750544, 0.9332853238782861, 0.8605777694417731, 0.8919148343923553, 0.934871427061674, 0.7219385539808008, 0.8311319696696027, 0.925790468693755, 0.636874953887632, 0.41762464329668847, 0.6077745179229681, 0.8900074689819688, 0.5662939894609251, 0.8481107547515385, 0.5881328279337963, 0.5590904557449987, 0.8887562240561163, 0.3581561425025056, 0.2154366420897607, 0.6424313341672772, 0.9904426405617919, 0.9626078108742977, 0.9094363868933528, 0.9773514349376944, 0.9297985504031074, 0.7766635086825822, 0.5748716981227209, 0.9477648614326466, 0.7356016911336336, 0.5905970914641867, 0.8816150641180378, 0.8281921553475021, 0.9616895841800797, 0.8355015737804767, 0.9055073576552588, 0.6095574224256186, 0.8985522579180052, 0.7419603506497722, 0.7570424755458874, 0.6237731005828068, 0.604839031295729, 0.3053935253252723, 0.8824490961357763, 0.47213667611022436, 0.15843999506651799, 0.9565343127552286, 0.9630021049296447, 0.9084408246013599, 0.8055864673667326, 0.49239571749879285, 0.541576060393789, 0.9799354517153449, 0.7538835519216083, 0.3482162888328536, 0.6711901181086953, 0.7466017902771492, 0.29082790521790003, 0.580390274877845, 0.7394221641354216, 0.2247554870980143, 0.9742694293836827, 0.8789418017653541, 0.9472207997658679, 0.9872442369212986, 0.9699049873809091, 0.9834700980058935, 0.9610721917709997, 0.7467361709133309, 0.9396221339246325, 0.563820434327718, 0.3728341211055949, 0.5578323336329495, 0.653856905605865, 0.9254463017658894, 0.7393217893863222, 0.9793904089186172, 0.8952891576931634, 0.5174196783096494, 0.916272560211627, 0.7847099524235768, 0.5341374618194692, 0.968840592678585, 0.7812724940853781, 1.0, 0.9652619679712691, 0.5068659560969915, 0.9732316438707951, 0.6034321191256158, 0.3843652002149621, 0.5608695652173913, 0.8798091526516568, 0.9087123429574342, 0.8218539480382933, 0.5004645722281954, 0.9439902380234699, 0.9455324591153114, 0.771209043929753, 0.35789698790386626, 0.7723465943512586, 0.6266772080766958, 0.9045356516494829, 0.7329092834998171, 0.7733039571663103, 0.591865368526167, 0.9756645028428577, 0.8448484385996908, 0.9462436191847843, 0.8699110799666838, 0.31901035322613436, 0.8678976437379708, 0.8922609224808372, 0.9496735450823421, 0.5012127116833381, 0.7938304679800914, 0.9683231065091749, 0.7576176996301744, 0.9171073467519609, 0.8523029357043744, 0.8909108204830978, 0.9299331052516924, 0.5604039895828797, 0.9602235397377306, 0.7793412065446155, 0.30374499657601767, 0.9848726663737328, 0.8734013068767044, 0.6401493417553263, 0.5075905017189635, 0.8123152846477772, 0.6712489158652961, 0.7247563047282455, 0.7336298486605038, 0.8426084577017585, 0.29796257451212327, 0.9661469642895737, 0.9420317788392338, 0.9508626724864289, 0.890935580421016, 0.20461399075573877, 0.956301548538977, 0.014827337779471383, 0.7631147824884003, 0.904590355528839, 0.9521775318277603, 0.7435162629159059, 0.9477354798086446, 0.8840914738153709, 0.9363924664229649, 0.11099182272418787, 0.8007515343249314, 0.9315998402460983, 0.7102398037343798, 0.2941969248494424, 0.804200052095828, 0.9402435148414863, 0.42689251969146835, 0.46398377548871184, 0.8866527473204353, 0.9375347445890254, 0.9722588250235882, 0.8449844779326559, 0.9039488787188537, 0.7086954249958265, 0.5200719655481933, 0.8078101910282451, 0.8188115370159288, 0.4883323987643829, 0.2942761537144616, 0.739351212728503, 0.7200309361219595, 0.9271490169747502, 0.9088627028234778, 0.9179223973142112, 0.8612115435287002, 0.7500618999751993, 0.9739259348026441, 0.9312591482604915, 0.6857318503066976, 0.3389172964204146, 0.8553117284030648, 0.9166795416411146, 0.9455409660105238, 0.5961867498988478, 0.8548231708514218, 0.43808453932073843, 0.9798219468937557, 0.4119890403418556, 0.9780384047260811, 0.595036047883924, 0.41151709383031154, 0.8065424278669349, 0.8421901762909951, 0.9379197320725001, 0.5639282857191146, 0.4990931771166349, 0.9060784269672213, 0.654357949555753, 0.9110292935350885, 0.5180316628760537, 0.9229689108517303, 0.41615305393866364, 0.3821796477166763, 0.760540475117339, 0.8201225427424705, 0.9272945586059962, 0.7444340059656643, 0.8876077472866535, 0.8253992652807371, 0.3448279680258582, 0.9494075997300704, 0.9241588430999468, 0.20519665134428633, 0.5452319958492986, 0.7243913306646597, 0.8735531700555859, 0.8545467071813517, 0.7942436421266241, 0.9700955926135699, 0.9765419032562443, 0.3202665169509859, 0.40411923690813695, 0.9135100043880224, 0.897868274842214, 0.9783839332393924, 0.5075736355169622, 0.5790261988125887, 0.9173075584052859, 0.3854398044418995, 0.4260664847736758, 0.5306850501150199, 0.9273759004975819, 0.2982712119361176, 0.9617625014218179, 0.5775688552444397, 0.9006848455688443, 0.47836466842490655, 0.4011929009233417, 0.9821809817650384, 0.7736787852368014, 0.7237665674551859, 0.6521082397979208, 0.9784487939574704, 0.6074300350442166, 0.6178552508101587, 0.8392607952096078, 0.7364277966461198, 0.9477010657352742, 0.5288231788023587, 0.79613668751892, 0.7880782435693265, 0.19242379301366364, 0.9303593500095784, 0.9319984976298381, 0.8547407048712858, 0.35460088266646006, 0.8665928958491977, 0.9168638777441369, 0.9851725027600269, 0.33756552100145387, 0.9749244080949804, 0.9737915388152598, 0.987950922923978, 0.666255179278667, 0.7611563185052843, 0.7460110532720265, 0.758988839562897, 0.7369406553821242, 0.9297142167581356, 0.5856932549625964, 0.926204910376385, 0.6642573369010278, 0.617743843617936, 0.6312231658015864, 0.9496316376212464, 0.8667057770035502, 0.9062536363993366, 0.9112403027721032, 0.4155596630877777, 0.9613152634801625, 0.7684448062183817, 0.907558018935852, 0.5506135469714823, 0.6682381920753772, 0.2678778375625262, 0.7553669838227834, 0.9409103501190933, 0.9500527933709615, 0.703409246380515, 0.652332618488931, 0.9059801416992133, 0.27352354506300447, 0.7559987541863575, 0.9823448177520746, 0.8289087893134257, 0.40730915905680976, 0.8948688296336118, 0.5312651095051248, 0.6880129319273884, 0.9344855036532616, 0.6145389598641935, 0.9005114947975497, 0.9430502379464849, 0.8981156159858223, 0.2776969881491722, 0.5594513215122114, 0.9344036047014783, 0.421886906571103, 0.5748074573837764, 0.9189645726561522, 0.538527452336219, 0.801591636721631, 0.49935819383309804, 0.841210527867613, 0.3374521240368497, 0.663952114335559, 0.9233388471345003, 0.7756256761612133, 0.9569630499588484, 0.8923874092298095, 0.5456895014045992, 0.9270106106387801, 0.619196145402581, 0.9057365595839495, 0.6993849093249114, 0.1459086942388002, 0.8819214421291581, 0.9385995189394607, 0.6024654179447738, 0.34069178592303917, 0.8618888636933246, 0.7401308818980097, 0.954238606427035, 0.5181203323339844, 0.788605483443716, 0.8940132574712745, 0.752282086494554, 0.5951602009255168, 0.8446277710305241, 0.9613909345310157, 0.9259753718181323, 0.6926460160796639, 0.3330584663396393, 0.5519976151622354, 0.7582667513762903, 0.9507728285008596, 0.4211523280742633, 0.6902777777999555, 0.993565204007768, 0.9822516624818802, 0.7412367177908079, 0.8787838168173723, 0.8021007111795594, 0.6292033005698606, 0.9163391393733058, 0.957243053310842, 0.8125644963696795, 0.883875362704373, 0.11032417015561033, 0.011803874246352868, 0.9633179652022956, 0.4799605515288722, 0.7669842146074164, 0.848267646108612, 0.45592789552418267, 0.41747534088469995, 0.8627505126882897, 0.9181208637326026, 0.6109912370917434, 0.9386019990279018, 0.5735025861665138, 0.6483178789815982, 0.9301413913926806, 0.7141494776867402, 0.9201326445882663, 0.9270078518894367, 0.4027266047248116, 0.5750475616489092, 0.9684863847527501, 0.590335920863919, 0.778151370761023, 0.6623464465436505, 0.9426242057849843, 0.8206082150573881, 0.9040645444308273, 0.3912389405401651, 0.8667436416243068, 0.472048350719695, 0.5687023138391892, 0.8865494815086647, 0.9096266419399884, 0.7744889932682666, 0.6511144444174561, 0.46802465703730456, 0.9545187036711082, 0.4207598960402934, 0.7816554973329877, 0.9675726678238403]
Finish training and take 45m
Namespace(log_name='./RQ5/xcodeeval_500_3/codet5p_770m.log', model_name='Salesforce/codet5p-770m', lang='c', output_dir='RQ5/xcodeeval_500_3/codet5p_770m', data_dir='./data/RQ5/xcodeeval_500_3', choice=0, no_cuda=False, visible_gpu='0', num_train_epochs=10, num_test_epochs=1, train_batch_size=4, eval_batch_size=4, gradient_accumulation_steps=1, load_model_path=None, config_name='', tokenizer_name='', max_source_length=512, max_target_length=512, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, freeze=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
Model created!!
[[{'text': '#pragma warning(disable:4996) #pragma comment(linker, "/STACK:16777216") #include <stdio.h> #include <string.h> #include <math.h>  #define PI 3.1415926535897932384  #ifndef ONLINE_JUDGE  FILE *stream; #endif  int main() {  char str[100002];  int m;  int l, r;  int len;  int i;  char currentSym;  int result; #ifndef ONLINE_JUDGE   freopen_s(&stream, "D:\\\\Work\\\\CodeForces\\\\input.txt", "rt", stdin);    freopen_s(&stream, "D:\\\\Work\\\\CodeForces\\\\output.txt", "wt", stdout); #endif  scanf("%s%i", &str[1], &m);    len = strlen(&str[1]);  currentSym = str[1];  str[1] = 1;  for (i = 2; i <= len; i++){   if (str[i] == currentSym)    str[i] = str[i-1] + 1;   else{    currentSym = str[i];    str[i] = 1;   }  }   for (; m > 0; m--){   scanf("%i%i", &l, &r);    result = 0;   while (l < r){    if (r - str[r] >= l)     result += str[r] - 1;    else     result += str[r] - str[l];     r -= str[r];   }    printf("%i\\n", result);  }    return 0; }', 'loss_ids': 0, 'shortenable_ids': 1}, {'text': '<mask>', 'loss_ids': 1, 'shortenable_ids': 0}, {'text': 'is the fixed version', 'loss_ids': 0, 'shortenable_ids': 0}], {'guid': 0, 'tgt_text': '#pragma warning(disable:4996) #pragma comment(linker, "/STACK:16777216") #include <stdio.h> #include <string.h> #include <math.h>  #define PI 3.1415926535897932384  #ifndef ONLINE_JUDGE  FILE *stream; #endif  int main() {  char str[100001];  int  arr[100000];  int m;  int l, r;  int len;  int i;  char currentSym; #ifndef ONLINE_JUDGE   freopen_s(&stream, "D:\\\\Work\\\\CodeForces\\\\input.txt", "rt", stdin);    freopen_s(&stream, "D:\\\\Work\\\\CodeForces\\\\output.txt", "wt", stdout); #endif  scanf("%s%i", str, &m);    len = strlen(str);  currentSym = str[0];  arr[0] = 0;  for (i = 1; i < len; i++){   if (str[i] == currentSym)    arr[i] = arr[i-1] + 1;   else{    currentSym = str[i];    arr[i] = arr[i-1];   }  }   for (; m > 0; m--){   scanf("%i%i", &l, &r);    printf("%i\\n", arr[r-1] - arr[l-1]);  }    return 0; }'}]
***** Running training *****
  Num examples = 500
  Batch size = 4
  Num epoch = 10

***** Running evaluation *****
  Num examples = 100
  Batch size = 4
  epoch = 0
  eval_ppl = 3.623181205517783e+294
  global_step = 126
  train_loss = 62.3672
  ********************
Previous best ppl:inf
Achieve Best ppl:3.623181205517783e+294
  ********************
BLEU file: ./data/RQ5/xcodeeval_500_3/validation.jsonl
  codebleu-4 = 73.17 	 Previous best codebleu 0
  ********************
 Achieve Best bleu:73.17
  ********************

***** Running evaluation *****
  Num examples = 100
  Batch size = 4
  epoch = 1
  eval_ppl = inf
  global_step = 251
  train_loss = 47.8366
  ********************
Previous best ppl:3.623181205517783e+294
BLEU file: ./data/RQ5/xcodeeval_500_3/validation.jsonl
  codebleu-4 = 73.14 	 Previous best codebleu 73.17
  ********************

***** Running evaluation *****
  Num examples = 100
  Batch size = 4
  epoch = 2
  eval_ppl = inf
  global_step = 376
  train_loss = 34.2023
  ********************
Previous best ppl:3.623181205517783e+294
BLEU file: ./data/RQ5/xcodeeval_500_3/validation.jsonl
  codebleu-4 = 73.24 	 Previous best codebleu 73.17
  ********************
 Achieve Best bleu:73.24
  ********************

***** Running evaluation *****
  Num examples = 100
  Batch size = 4
  epoch = 3
  eval_ppl = inf
  global_step = 501
  train_loss = 23.2466
  ********************
Previous best ppl:3.623181205517783e+294
BLEU file: ./data/RQ5/xcodeeval_500_3/validation.jsonl
  codebleu-4 = 73.03 	 Previous best codebleu 73.24
  ********************

***** Running evaluation *****
  Num examples = 100
  Batch size = 4
  epoch = 4
  eval_ppl = inf
  global_step = 626
  train_loss = 15.2123
  ********************
Previous best ppl:3.623181205517783e+294
BLEU file: ./data/RQ5/xcodeeval_500_3/validation.jsonl
  codebleu-4 = 73.14 	 Previous best codebleu 73.24
  ********************

***** Running evaluation *****
  Num examples = 100
  Batch size = 4
  epoch = 5
  eval_ppl = inf
  global_step = 751
  train_loss = 10.4776
  ********************
Previous best ppl:3.623181205517783e+294
BLEU file: ./data/RQ5/xcodeeval_500_3/validation.jsonl
  codebleu-4 = 73.13 	 Previous best codebleu 73.24
  ********************
early stopping!!!
reload model from RQ5/xcodeeval_500_3/codet5p_770m/checkpoint-best-bleu
BLEU file: ./data/RQ5/xcodeeval_500_3/test.jsonl
  codebleu = 74.52 
  Total = 500 
  Exact Fixed = 8 
[10, 20, 25, 128, 171, 187, 322, 451]
  Syntax Fixed = 1 
[15]
  Cleaned Fixed = 1 
[481]
  ********************
  Total = 500 
  Exact Fixed = 8 
[10, 20, 25, 128, 171, 187, 322, 451]
  Syntax Fixed = 1 
[15]
  Cleaned Fixed = 1 
[481]
  codebleu = 74.52 
[0.5003909451993059, 0.9294151499698242, 0.6386890640788627, 0.4507986952593763, 0.7167784203410406, 0.7679881745093895, 0.988076477678953, 0.8394311373107994, 0.7852857892799938, 0.9811390010032224, 0.6622400912006872, 0.7772868173384335, 0.9623971198135532, 0.7189030386327381, 0.7971886413768894, 0.5413427461678596, 0.9621715437613865, 0.7373572915600461, 0.8054255423928414, 0.8800171005968664, 0.8276821254560949, 0.3446503101961176, 0.9617896364191245, 0.8925560777052948, 1.0, 0.39570630887752717, 0.8434094165290678, 0.7089270802000895, 0.3600824707101461, 0.9606328090250909, 0.952851260737474, 0.7249876253142388, 0.6569729679812651, 0.4995916629202774, 0.348719279092569, 0.4835000669850591, 0.7336996602379647, 0.9691599747588928, 0.7411039840168427, 0.9866836999577304, 0.43871215196390306, 0.8833038098770115, 0.9507226760300971, 0.9104066605958898, 0.6593510546130777, 0.8616680155829046, 0.5338617744031935, 0.8602181220443288, 0.8226980351644886, 0.9358086045306386, 0.6349077239728745, 0.9765120913566805, 0.9202770890052219, 0.9310190262555729, 0.9660322844955553, 0.938955604347008, 0.9088121389774579, 0.9339299975598521, 0.561801583155677, 0.29130069276959497, 0.6984927771743764, 0.5415454260109173, 0.9126538866701963, 0.33460070946115567, 0.9853863431203176, 0.9752926493864778, 0.98154990280289, 0.7858041122445381, 0.7016234777170453, 0.915465568076623, 0.5140532373556195, 0.7769943668010335, 0.9268555414820475, 0.9853133667641483, 0.9191158481207378, 0.9402009240478387, 0.9189149325906292, 0.4932733020018213, 0.9835575139456028, 0.9391536438932522, 0.8979589771065096, 0.4065190849702931, 0.7597100033179813, 0.9616100740405664, 0.9046968076517605, 0.4724215445506942, 0.608990714278228, 0.9738014890069033, 0.7248773843271845, 0.9822720623046208, 0.29319275081975693, 0.9714892269638897, 0.8952672769095782, 0.8876242548612938, 0.8511121182268683, 0.37642420748881267, 0.9441722498573561, 0.9602694033492566, 0.9319272046508655, 0.8283719455395986, 0.764851317992308, 0.9019464684129248, 0.9518479807436881, 0.7462546419750544, 0.9464173775678764, 0.9036755986162253, 0.89687501719581, 0.934871427061674, 0.7219385539808008, 0.843779606891953, 0.925790468693755, 0.636874953887632, 0.4181059355834638, 0.6077745179229681, 0.8900074689819688, 0.5662939894609251, 0.8481107547515385, 0.5881328279337963, 0.5590904557449987, 0.8791480128107484, 0.34541274340654515, 0.2154366420897607, 0.6424313341672772, 0.9904426405617919, 0.9876378378993536, 0.9094363868933528, 0.9728059803922399, 1.0, 0.802202097529589, 0.5970326258085109, 0.9477648614326466, 0.7421234302640685, 0.5920295413051476, 0.8816150641180378, 0.8345680283779763, 0.9582090124974589, 0.8355015737804767, 0.9055073576552588, 0.4087787283872885, 0.9472873156881443, 0.6333873199069301, 0.7643810428304513, 0.6237731005828068, 0.5980807901464653, 0.3053935253252723, 0.901175714210833, 0.47213667611022436, 0.31410182882648663, 0.967544928466902, 0.9630021049296447, 0.9084408246013599, 0.7807381465202919, 0.4642707174987929, 0.5459516898043106, 0.9799354517153449, 0.7665708243215428, 0.35174423017740575, 0.6711901181086953, 0.7466017902771492, 0.2908131894449784, 0.580390274877845, 0.7577774779855018, 0.2247554870980143, 0.9742694293836827, 0.8789418017653541, 0.9472207997658679, 0.38502072754729244, 0.9699049873809091, 0.9834700980058935, 0.9551975148162357, 0.9129869340329653, 0.9396221339246325, 0.563820434327718, 0.3728341211055949, 0.5578323336329495, 0.653856905605865, 0.9254463017658894, 0.7897511138044075, 0.9859793679627393, 0.9139108143266295, 0.5174196783096494, 0.916272560211627, 0.8024559273788541, 0.535206429623671, 0.968840592678585, 0.8005748846405311, 1.0, 0.9652619679712691, 0.5068659560969915, 0.9732316438707951, 0.6034321191256158, 0.3843652002149621, 0.5608695652173913, 0.8798091526516568, 0.9087123429574342, 0.8218539480382933, 0.5062338029974262, 0.9514807328154506, 0.9607993165323487, 0.7885343223120463, 0.3579424928858859, 0.7910965943512587, 0.6266772080766958, 0.9045356516494829, 0.7156414320739874, 0.7733039571663103, 0.591865368526167, 0.9756645028428577, 0.8533534577368376, 0.9534374669038357, 0.8699110799666838, 0.35732195151786816, 0.8678976437379708, 0.9621819666971321, 0.9496735450823421, 0.5012127116833381, 0.7938304679800914, 0.9683231065091749, 0.6672357733837689, 0.9171073467519609, 0.8523029357043744, 0.8909108204830978, 0.9447445835540222, 0.5604039895828797, 0.9602235397377306, 0.7793412065446155, 0.30374499657601767, 0.9804019211187358, 0.8734013068767044, 0.6845151505128717, 0.5075905017189635, 0.8123152846477772, 0.6732163514148213, 0.7247563047282455, 0.7336298486605038, 0.8426084577017585, 0.3024540539982831, 0.9661469642895737, 0.9420317788392338, 0.9508626724864289, 0.879580704785943, 0.20461399075573877, 0.9427240488559883, 0.014827337779471383, 0.7650431430220939, 0.904590355528839, 0.9521775318277603, 0.7459040842816722, 0.9477354798086446, 0.9276347349756966, 0.9363924664229649, 0.11200213653664287, 0.8491583316973768, 0.9315998402460983, 0.7169644820547282, 0.2941969248494424, 0.8110033734683955, 0.9241415348095889, 0.42689251969146835, 0.46398377548871184, 0.8866527473204353, 0.9375347445890254, 0.9722588250235882, 0.8449844779326559, 0.9184585843480406, 0.7086954249958265, 0.5200719655481933, 0.8078101910282451, 0.8188115370159288, 0.4862866040364421, 0.2839456338649154, 0.739351212728503, 0.8508806954653587, 0.9271490169747502, 0.9088627028234778, 0.9063468547889519, 0.8592711336525962, 0.7601507876079147, 0.9802492338492401, 0.9312591482604915, 0.6857318503066976, 0.3329380293736354, 0.8553117284030648, 0.9166795416411146, 0.9455409660105238, 0.5961867498988478, 0.8548231708514218, 0.43808453932073843, 0.9798219468937557, 0.4119890403418556, 0.9780384047260811, 0.595036047883924, 0.41151709383031154, 0.8065424278669349, 0.8421901762909951, 0.9379197320725001, 0.5667558470674415, 0.4990931771166349, 0.9060784269672213, 0.654357949555753, 0.9110292935350885, 0.5289514092792647, 0.9495780518930732, 0.9489374752009117, 0.3821796477166763, 0.760540475117339, 0.8794100936019331, 0.8897945586059963, 0.7444340059656643, 0.8876077472866535, 0.8290622858030623, 0.3448279680258582, 0.9494075997300704, 0.9241588430999468, 0.20519665134428633, 0.571808930335286, 0.7243913306646597, 0.8735531700555859, 0.8545467071813517, 0.7942436421266241, 0.9838722535113, 0.9765419032562443, 0.3202665169509859, 0.40411923690813695, 0.962676181664404, 0.897868274842214, 0.9567062760825847, 0.5075736355169622, 0.5790261988125887, 0.9173075584052859, 0.3854398044418995, 0.4260664847736758, 0.5306850501150199, 0.9273759004975819, 0.2982712119361176, 0.9617625014218179, 0.597398385186501, 0.9006848455688443, 0.5116980017582399, 0.4011929009233417, 0.9821809817650384, 0.7736787852368014, 0.7486759848652709, 0.6521082397979208, 0.9784487939574704, 0.6074300350442166, 0.6191086679909932, 0.8810946359492662, 0.7606454622988796, 0.974183904376235, 0.5288231788023587, 0.8521108081796271, 0.7880782435693265, 0.19242379301366364, 0.9303593500095784, 0.9319984976298381, 0.893881805930556, 0.34968284987957476, 0.8665928958491977, 0.9168638777441369, 0.9851725027600269, 0.33756552100145387, 0.9749244080949804, 0.9737915388152598, 0.987950922923978, 0.6693406223166416, 0.7611563185052843, 0.7460110532720265, 0.758988839562897, 0.7369406553821242, 0.9149764717609801, 0.6122977216109866, 0.9331552365394689, 0.6642573369010278, 0.6350077342091638, 0.6312231658015864, 0.9496316376212464, 0.8667057770035502, 0.9062536363993366, 0.9112403027721032, 0.4155596630877777, 0.8002917572195963, 0.7684448062183817, 0.907558018935852, 0.5506135469714823, 0.6721138344847708, 0.4130042192803641, 0.7580685995528176, 0.9409103501190933, 0.9698138929646263, 0.703409246380515, 0.652332618488931, 0.9059801416992133, 0.27352354506300447, 0.7559987541863575, 0.9823448177520746, 0.9040449515722547, 0.40730915905680976, 0.9301710411526725, 0.5301303934515195, 0.8085510356683345, 0.9344855036532616, 0.6030344531891404, 0.9327820820761272, 0.9669138743101213, 0.8981156159858223, 0.2776969881491722, 0.31664838452333466, 0.9647434403630581, 0.421886906571103, 0.5727257536013239, 0.9189645726561522, 0.539612684703451, 0.804631742207644, 0.49935819383309804, 0.841210527867613, 0.3374521240368497, 0.663952114335559, 0.9233388471345003, 0.7756256761612133, 0.9569630499588484, 0.8990210844129167, 0.5456895014045992, 0.9248274324168049, 0.619196145402581, 0.9057365595839495, 0.6993849093249114, 0.1459086942388002, 0.8819214421291581, 0.9385995189394607, 0.6201992213394104, 0.3606607079181603, 0.8899151396534579, 0.7648837329883056, 0.954238606427035, 0.5220942811428554, 0.8001883461221011, 0.251863754094517, 0.8169189094593757, 0.5927427516158115, 0.8554076307279366, 0.3787964080732937, 0.967235610505617, 0.7507801222761162, 0.3330584663396393, 0.5666317615036989, 0.7718761136325316, 0.957228209570204, 0.4211523280742633, 0.6902777777999555, 0.9872114221460186, 0.900623198349459, 0.7412367177908079, 0.8787838168173723, 0.8021007111795594, 0.666210611458786, 0.8249778474748566, 0.957243053310842, 0.8375795025499561, 0.883875362704373, 0.5290842345678486, 0.011803874246352868, 0.9633179652022956, 0.4799605515288722, 0.7669842146074164, 0.978606091610698, 0.45592789552418267, 0.41747534088469995, 0.7015098220065575, 0.9181208637326026, 0.619988254124251, 0.9386019990279018, 0.7430105578459573, 0.653157845848791, 0.9331089552213916, 0.7141494776867402, 0.947633855490319, 0.8384459213032074, 0.4027266047248116, 0.5750475616489092, 0.9684863847527501, 0.590335920863919, 0.8151829986495325, 0.6623464465436505, 0.9426242057849843, 0.8206082150573881, 0.9040645444308273, 0.4076647468368658, 0.8667436416243068, 0.472048350719695, 0.5730501399261457, 0.9386210590467857, 0.9098079026089206, 0.7744889932682666, 0.6246201772140735, 0.46802465703730456, 0.9545187036711082, 0.4207598960402934, 0.8042710150175236, 0.9743096727362683]
Finish training and take 1h5m

Namespace(log_name='./RQ5/tfix_500_1/codet5p_770m_f.log', model_name='Salesforce/codet5p-770m', lang='javascript', output_dir='RQ5/tfix_500_1/codet5p_770m_f', data_dir='./data/RQ5/tfix_500_1', no_cuda=False, visible_gpu='0', add_task_prefix=False, add_lang_ids=False, num_train_epochs=10, num_test_epochs=10, train_batch_size=4, eval_batch_size=4, gradient_accumulation_steps=2, load_model_path=None, config_name='', tokenizer_name='', max_source_length=512, max_target_length=512, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, do_lower_case=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, max_steps=-1, eval_steps=-1, train_steps=-1, local_rank=-1, seed=42, early_stop_threshold=2)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, model_name: Salesforce/codet5p-770m
model created!
Total 500 training instances 
***** Running training *****
  Num examples = 500
  Batch size = 4
  Num epoch = 10

***** Running evaluation *****
  Num examples = 100
  Batch size = 4
  epoch = 0
  eval_ppl = 1.00441
  global_step = 126
  train_loss = 0.776
  ********************
Previous best ppl:inf
Achieve Best ppl:1.00441
  ********************
BLEU file: ./data/RQ5/tfix_500_1/validation.jsonl
  codebleu-4 = 65.31 	 Previous best codebleu 0
  ********************
 Achieve Best bleu:65.31
  ********************

***** Running evaluation *****
  Num examples = 100
  Batch size = 4
  epoch = 1
  eval_ppl = 1.00446
  global_step = 251
  train_loss = 0.3119
  ********************
Previous best ppl:1.00441
BLEU file: ./data/RQ5/tfix_500_1/validation.jsonl
  codebleu-4 = 62.61 	 Previous best codebleu 65.31
  ********************

***** Running evaluation *****
  Num examples = 100
  Batch size = 4
  epoch = 2
  eval_ppl = 1.00476
  global_step = 376
  train_loss = 0.1507
  ********************
Previous best ppl:1.00441
BLEU file: ./data/RQ5/tfix_500_1/validation.jsonl
  codebleu-4 = 63.19 	 Previous best codebleu 65.31
  ********************
reload model from RQ5/tfix_500_1/codet5p_770m_f/checkpoint-best-bleu
BLEU file: ./data/RQ5/tfix_500_1/test.jsonl
  codebleu = 63.53 
  Total = 500 
  Exact Fixed = 71 
[1, 12, 16, 17, 18, 23, 31, 42, 49, 53, 64, 67, 69, 73, 78, 83, 84, 86, 91, 92, 93, 94, 101, 107, 108, 109, 115, 119, 121, 126, 133, 143, 145, 172, 183, 184, 185, 200, 201, 214, 224, 234, 236, 238, 243, 255, 263, 265, 267, 284, 301, 316, 326, 331, 356, 367, 372, 374, 385, 399, 400, 401, 404, 411, 416, 419, 421, 443, 446, 465, 482]
  Syntax Fixed = 3 
[129, 144, 434]
  Cleaned Fixed = 7 
[14, 22, 58, 253, 300, 371, 432]
  ********************
  Total = 500 
  Exact Fixed = 71 
[1, 12, 16, 17, 18, 23, 31, 42, 49, 53, 64, 67, 69, 73, 78, 83, 84, 86, 91, 92, 93, 94, 101, 107, 108, 109, 115, 119, 121, 126, 133, 143, 145, 172, 183, 184, 185, 200, 201, 214, 224, 234, 236, 238, 243, 255, 263, 265, 267, 284, 301, 316, 326, 331, 356, 367, 372, 374, 385, 399, 400, 401, 404, 411, 416, 419, 421, 443, 446, 465, 482]
  Syntax Fixed = 3 
[129, 144, 434]
  Cleaned Fixed = 7 
[14, 22, 58, 253, 300, 371, 432]
  codebleu = 63.53 
[1.0, 0.8789433149074164, 0.6673387930115595, 0.5451417837590342, 0.3519980391978243, 0.8216460780407606, 0.3398382857983091, 0.828218881300387, 0.794039094142812, 0.5505831472572245, 0.824425175651095, 1.0, 0.3121594417706924, 0.6553082743436025, 0.5055431170332984, 1.0, 1.0, 1.0, 0.5701122864094044, 0.522583151455642, 0.9097825010853771, 0.41130178148606267, 0.8114529051148651, 0.5058144125160369, 0.3793314282186518, 0.8465532719298088, 0.18830381490559944, 0.6287206814660993, 0.38702445125781215, 0.6459857482140212, 1.0, 0.7691225780114581, 0.7461273419647574, 0.621862347508016, 0.6888724788208753, 0.45040497426175063, 0.8774634481857526, 0.26493187938965956, 0.5650018011029692, 0.4136911179244788, 0.4427200451626767, 0.9891483218006352, 0.7122853668557851, 0.6785036503543816, 0.6137433105819801, 0.9431571237072573, 0.2558003592103332, 0.5682239332168229, 1.0, 0.5491888156140188, 0.736415359709709, 0.5563385782378045, 1.0, 0.8696847134058581, 0.8576593989567298, 0.396349572956634, 0.6863884298635612, 0.6175859114164861, 0.45715804963968226, 0.6273520828335467, 0.4905880158658711, 0.5854978414909923, 0.8052607518236046, 0.9891483218006352, 0.7679708111714716, 0.9260406910477721, 1.0, 0.7341007521231433, 1.0, 0.5189589454524783, 0.5129834344293507, 0.6206334767740918, 1.0, 0.5843871292056362, 0.6204202090757367, 0.5885921454827882, 0.47433538990729357, 1.0, 0.6759395432065562, 0.6884734483714399, 0.6948237739189728, 0.6578602200025533, 1.0, 1.0, 0.7148321218614053, 1.0, 0.588804774838485, 0.6760716731396678, 0.5295971223679855, 0.8630487585927691, 0.9891483218006352, 1.0, 0.8114529051148651, 1.0, 0.44375943570639337, 0.6745410470195684, 0.8387991383668074, 0.39873667339437135, 0.6746584174428315, 0.9266829146927709, 0.9891483218006352, 0.6416532852733938, 0.7275723927836586, 0.6671186498543635, 0.7464240007681606, 0.6265958401383632, 1.0, 1.0, 0.7135428903906851, 0.712525195562845, 0.8974634481857526, 0.7347169240849791, 0.6555342747735904, 0.5442862628913174, 1.0, 0.6357741351064675, 0.8255980153481091, 0.7722719423576758, 0.8114529051148651, 0.6933766349070695, 1.0, 0.0731716191316424, 0.619380623260443, 0.81163354088051, 0.8990265449613299, 1.0, 0.4531855447309179, 0.556487662226795, 0.8399103850027161, 0.02357226111775114, 0.6508081453961951, 0.5811409219639153, 1.0, 0.884411967378405, 0.45438169149982227, 0.2298355357735218, 0.6201281281538, 0.704138988439773, 0.42599664456047265, 0.8591190003999107, 0.7264603256176001, 0.49694040509490167, 1.0, 0.6755831472572245, 1.0, 0.762178754714643, 0.5624075100152208, 0.36482184137761786, 0.5157990952074163, 0.5365573165566148, 0.8132623593969441, 0.7026136760976884, 0.6002569359025927, 0.6536911179244789, 0.20167918995135747, 0.8330693404648544, 0.6712302104522061, 0.5390272275654318, 0.3253313725311576, 0.596309309173441, 0.5289052690315463, 0.11367377306961232, 0.9002579146195044, 0.4471047149903593, 0.521955614980073, 0.003157006751173676, 0.47245646351861303, 0.48074569931823535, 0.5264886858900315, 0.6625508357540224, 0.38333251237656163, 0.9891483218006352, 0.027660853979899265, 0.28168179022383655, 0.5407132877459149, 0.6600032525510597, 0.46978313398707483, 0.35586539345697804, 0.9039342742606371, 0.7462637890346522, 0.06808859345352361, 0.35260703155848694, 1.0, 1.0, 1.0, 0.6006394976554918, 0.6153934274260637, 0.6653650919390386, 0.36857333884076315, 0.636964721661222, 0.7163791393142085, 0.10355282536317818, 0.44478640618236376, 0.597415144816797, 0.0, 0.13825557556207113, 0.8821296454239946, 0.5334126180997758, 0.5960182409639856, 0.8114529051148651, 1.0, 0.35522983054028545, 0.8387838840911439, 0.9130169160146575, 0.8724634481857527, 0.7417094915222344, 0.7248340517831167, 0.8301971233899816, 0.7623676872921671, 0.5575523755474183, 0.5550049310474542, 0.5312476853243514, 0.8034443090225696, 1.0, 0.625500606374912, 0.7451384298635613, 0.7423958127221755, 0.5616798194467534, 0.177190822574687, 0.8291884689534064, 0.21100892280323053, 0.5924424048742483, 0.0, 1.0, 0.5016265496309229, 0.643118800625064, 0.751662055050515, 0.0, 0.6092728765398896, 0.5654481856728993, 0.0, 0.5566984938224081, 0.8232148025904986, 1.0, 0.40563523302493104, 1.0, 0.3305982337929354, 1.0, 0.5227886222566653, 0.09138854364080462, 0.5996874926360537, 0.980720400721969, 1.0, 0.8845572237610086, 0.7302007404183433, 0.2594673832307821, 0.3449411645032098, 0.7834298712141025, 0.3583507427572924, 0.47480421767347836, 0.08152573352530099, 0.7170369693946632, 0.764529302035556, 0.43096007508570255, 1.0, 0.6903510788203177, 0.4326263272143769, 0.6451645648968785, 0.4115122702896197, 0.7432501073422515, 0.5499214919756144, 0.9211131842675646, 1.0, 0.8300792809207385, 1.0, 0.29514178375903416, 1.0, 0.503404575411008, 0.8513726633741598, 0.6661120443406857, 0.19192238765013264, 0.6273977784387645, 0.4237755479780052, 0.7648103351245981, 0.8736081095465102, 0.5615879115133554, 0.5768908160692684, 0.8643234750474205, 0.07153421598018944, 0.7383139646397308, 0.6196263559246291, 0.6830331470954286, 0.9033331043272477, 1.0, 0.5334126180997758, 0.8604457071320422, 0.7970182644937875, 0.2636668331849268, 0.6021070400262399, 0.6489448749779825, 0.6558003592103332, 0.9130169160146575, 0.34505477483848507, 0.39969884422068214, 0.31407610853279483, 0.5381429054415754, 0.7535419386514548, 0.8291884689534064, 0.47180509653022784, 0.9519671371303184, 1.0, 0.0, 0.7240472661630808, 0.6094226038504491, 0.5410631333323874, 0.7500330416345474, 0.6959824458765473, 0.8178607431385985, 0.2094047330273616, 0.6355230163254099, 0.45222870310832236, 0.5383089748131177, 0.6573864448926988, 0.5763021068539383, 0.6887796716807859, 1.0, 0.882842712474619, 0.43738883487779967, 0.5342084433274925, 0.8642470965743208, 0.26347186640984777, 0.7894413517535362, 0.4714698407062744, 0.4964902913435728, 0.8525484975498633, 1.0, 0.576907475658101, 0.593453164785819, 0.5365573165566148, 0.47786341412302047, 1.0, 0.6892870539097846, 0.5879792831098578, 0.714297617187952, 0.6517765449003101, 0.6490264366907621, 0.6999566173218232, 0.13810543558529642, 0.514529302035556, 0.6846354401872717, 0.38315024898948147, 0.5421867136374356, 0.5857892446781248, 0.5551317306014439, 0.7686443097434874, 0.6431227591816079, 0.8017397827309225, 0.10175881749697105, 0.8586064963566447, 0.12179140591536411, 0.6066855853913183, 0.5961439611994732, 0.3882203984945388, 0.5609260915878896, 0.6490694936483706, 1.0, 0.20034796016239415, 0.6125559617261662, 0.08869475457310907, 0.6793788456922385, 0.41585825915406704, 0.9092813183436577, 0.8477702569340995, 0.7765996497158698, 0.4121673239558469, 0.15421129818718932, 0.9891483218006352, 0.70248174129905, 0.6530550965302279, 0.7970182644937875, 0.6179694287810409, 1.0, 0.5774963429007336, 1.0, 0.5519698034749387, 0.7553637155933474, 0.8525366466180964, 0.7883092393403118, 0.6628244028734973, 0.3610202619925232, 0.6392333266349789, 0.5402233947178415, 0.6099862522167108, 0.075, 1.0, 0.40660822240095185, 0.36857333884076315, 0.47180509653022784, 0.9039342742606371, 0.6903510788203177, 0.6643574653172584, 0.8357967156935899, 0.6289313661614635, 0.5845720003763292, 0.676275735434565, 0.3714764154580026, 0.09999999999999999, 0.2465085296294044, 1.0, 1.0, 1.0, 0.367641751923923, 0.593328204480502, 1.0, 0.7418205419054216, 0.0, 0.34601002308352846, 0.5705557495072049, 0.5796605122596801, 0.64272438732935, 1.0, 0.5027616393658039, 0.5927200451626766, 0.15, 0.7396270263254157, 1.0, 0.6020305474481882, 0.7416865196891184, 0.6922382617563554, 0.7969743810233871, 1.0, 0.13116306037298567, 0.7148321218614053, 0.7144948346694379, 0.7543841330490832, 0.6173480165831692, 0.6607530176165711, 0.6793200369028839, 0.23687288125023864, 0.026198875192873054, 0.5745852221368928, 0.7919953379147748, 0.38183354569032213, 0.9728592687718631, 0.8661547359011423, 0.3259403648918202, 0.5334147323445907, 0.9292132304382279, 0.5482809733022559, 0.9320894171538912, 0.5827243873293501, 0.8205326290822457, 1.0, 0.6870606775436042, 0.6995228788727517, 0.7135428903906851, 0.7916479842275448, 0.28605185738761973, 0.6983761581889011, 0.7401287898502638, 0.5753733239286534, 0.8386800272334847, 0.3339955250179895, 0.4357531581653759, 0.5470783037679993, 0.5149139863647084, 0.7065605978001186, 0.859655200961138, 0.5466127647565298, 0.75659181734345, 0.5801154532856382, 0.3831939362196469, 0.5030534500279102, 0.4861819120064648, 1.0, 0.7076923076923076, 0.8642470965743208, 0.3166508010405151, 0.04362372606317965, 0.8072438843453339, 0.07944994767545024, 0.33433367971754413, 0.26772438732935, 0.7569706667451968, 0.7191441569283882, 0.13337173484667555, 0.7776444295139451, 0.565671952352334, 0.8857441887419302, 0.5824710111837532, 0.806126732435826, 1.0, 0.7687807999167482, 0.5602783237004767, 0.6828922179236726, 0.6162109760811862, 0.3445683217133939, 0.8586654659334061, 0.5752851510050542, 0.6, 0.33036017439379955, 0.48676489763808506, 0.3683458566180241, 0.5974634481857527, 0.5536344968786626, 0.8150666162955742, 0.5335665191868353, 0.7325798303723143, 0.6573831527026088, 0.19794175949732912]
Finish training and take 16m

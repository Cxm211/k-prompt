Namespace(log_name='./RQ5/xcodeeval_1_3/codet5p_770m_f.log', model_name='Salesforce/codet5p-770m', lang='c', output_dir='RQ5/xcodeeval_1_3/codet5p_770m_f', data_dir='./data/RQ5/xcodeeval_1_3', no_cuda=False, visible_gpu='0', add_task_prefix=False, add_lang_ids=False, num_train_epochs=10, num_test_epochs=10, train_batch_size=4, eval_batch_size=4, gradient_accumulation_steps=2, load_model_path=None, config_name='', tokenizer_name='', max_source_length=512, max_target_length=512, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, do_lower_case=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, max_steps=-1, eval_steps=-1, train_steps=-1, local_rank=-1, seed=42, early_stop_threshold=2)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, model_name: Salesforce/codet5p-770m
model created!
Total 1 training instances 
***** Running training *****
  Num examples = 1
  Batch size = 4
  Num epoch = 10

***** Running evaluation *****
  Num examples = 100
  Batch size = 4
  epoch = 0
  eval_ppl = 1.00055
  global_step = 1
  train_loss = 0.865
  ********************
Previous best ppl:inf
Achieve Best ppl:1.00055
  ********************
BLEU file: ./data/RQ5/xcodeeval_1_3/validation.jsonl
  codebleu-4 = 6.46 	 Previous best codebleu 0
  ********************
 Achieve Best bleu:6.46
  ********************

***** Running evaluation *****
  Num examples = 100
  Batch size = 4
  epoch = 1
  eval_ppl = 1.00055
  global_step = 1
  train_loss = 0.849
  ********************
Previous best ppl:1.00055
BLEU file: ./data/RQ5/xcodeeval_1_3/validation.jsonl
  codebleu-4 = 6.46 	 Previous best codebleu 6.46
  ********************

***** Running evaluation *****
  Num examples = 100
  Batch size = 4
  epoch = 2
  eval_ppl = 1.00055
  global_step = 1
  train_loss = 0.8887
  ********************
Previous best ppl:1.00055
BLEU file: ./data/RQ5/xcodeeval_1_3/validation.jsonl
  codebleu-4 = 6.46 	 Previous best codebleu 6.46
  ********************
reload model from RQ5/xcodeeval_1_3/codet5p_770m_f/checkpoint-best-bleu
BLEU file: ./data/RQ5/xcodeeval_1_3/test.jsonl
  codebleu = 5.32 
  Total = 500 
  Exact Fixed = 0 
[]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  ********************
  Total = 500 
  Exact Fixed = 0 
[]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  codebleu = 5.32 
[0.03518518518518518, 0.059259259259259255, 0.45420730641452634, 0.025440598832248352, 0.08333333333333333, 0.0037037037037037034, 0.0, 0.04472049689440994, 0.0574074074074074, 0.08414634146341464, 0.03888888888888888, 0.05590062111801242, 0.07222222222222222, 0.0225, 0.022259926747618446, 0.07037037037037036, 0.07818181818181819, 0.07592592592592592, 0.06296296296296296, 0.007407407407407407, 0.07962962962962963, 0.03333333333333333, 0.0554140127388535, 0.01840490797546012, 0.02149387944305044, 0.0, 0.0, 0.02481557084203163, 0.091875, 0.027777777777777776, 0.0685185185185185, 0.07962962962962963, 0.05185185185185185, 0.07777777777777777, 0.0, 0.05555555555555555, 0.04785276073619631, 0.059259259259259255, 0.020042910836692292, 0.0, 0.058536585365853655, 0.09570552147239263, 0.07222222222222222, 0.059259259259259255, 0.03148148148148148, 0.03518518518518518, 0.04285714285714285, 0.0, 0.024295943615301737, 0.024786487232619333, 0.06296296296296296, 0.03971007310166665, 0.08518518518518518, 0.046296296296296294, 0.08518518518518518, 0.03148148148148148, 0.025033019490301376, 0.054375, 0.024381988844017422, 0.018518518518518517, 0.0, 0.0, 0.0, 0.02608695652173913, 0.04203821656050955, 0.04285714285714285, 0.0, 0.050625, 0.04390243902439024, 0.17894243026455775, 0.034394904458598725, 0.03540372670807453, 0.0685185185185185, 0.026751592356687896, 0.025766871165644172, 0.09074074074074075, 0.016770186335403725, 0.05185185185185185, 0.0, 0.0, 0.029813664596273288, 0.05555555555555555, 0.018518518518518517, 0.0, 0.044171779141104296, 0.03333333333333333, 0.14081815293782313, 0.26740214176855487, 0.03333333333333333, 0.0, 0.06149068322981366, 0.0, 0.06296296296296296, 0.07777777777777777, 0.027777777777777776, 0.025366791754338952, 0.024372103677983988, 0.05185185185185185, 0.06666666666666667, 0.07777777777777777, 0.05590062111801242, 0.023926380368098157, 0.0, 0.09905309157871287, 0.049999999999999996, 0.04472049689440994, 0.05555555555555555, 0.025180214583527708, 0.03518518518518518, 0.03888888888888888, 0.005555555555555555, 0.06481481481481481, 0.24338594083556148, 0.08333333333333333, 0.0, 0.07639751552795031, 0.07407407407407407, 0.06481481481481481, 0.04777070063694267, 0.0611111111111111, 0.0, 0.018518518518518517, 0.08888888888888888, 0.07592592592592592, 0.0007190794457189174, 0.08769139069922235, 0.0611111111111111, 0.05403726708074534, 0.02236024844720497, 0.0607361963190184, 0.09814814814814815, 0.059259259259259255, 0.07037037037037036, 0.029447852760736196, 0.04394904458598726, 0.0, 0.0037037037037037034, 0.06809815950920245, 0.01923076923076923, 0.03888888888888888, 0.03248407643312102, 0.051533742331288344, 0.04259259259259259, 0.10125, 0.01111111111111111, 0.06296296296296296, 0.059259259259259255, 0.05590062111801242, 0.0574074074074074, 0.007407407407407407, 0.046583850931677016, 0.016666666666666666, 0.09503105590062111, 0.049999999999999996, 0.0, 0.04814814814814814, 0.05031055900621118, 0.017197452229299363, 0.06296296296296296, 0.04285714285714285, 0.03518518518518518, 0.046296296296296294, 0.018518518518518517, 0.027439024390243903, 0.04394904458598726, 0.029447852760736196, 0.000726629590704665, 0.04814814814814814, 0.03888888888888888, 0.06666666666666667, 0.011180124223602485, 0.03148148148148148, 0.059259259259259255, 0.0, 0.20153499073919035, 0.027777777777777776, 0.03333333333333333, 0.029629629629629627, 0.018292682926829267, 0.07407407407407407, 0.029447852760736196, 0.05185185185185185, 0.04814814814814814, 0.05185185185185185, 0.08650306748466258, 0.02608469902403444, 0.051219512195121955, 0.0, 0.04444444444444444, 0.06481481481481481, 0.01863780632424658, 0.04024390243902439, 0.031914893617021274, 0.06481481481481481, 0.027777777777777776, 0.3023344596996763, 0.0574074074074074, 0.4035629374285104, 0.0, 0.17889033866100207, 0.037037037037037035, 0.04814814814814814, 0.04074074074074074, 0.06585365853658537, 0.08650306748466258, 0.0, 0.10555555555555556, 0.0, 0.6809066093546878, 0.000710590162752014, 0.04444444444444444, 0.016770186335403725, 0.0, 0.07407407407407407, 0.01111111111111111, 0.03518518518518518, 0.025925925925925925, 0.03888888888888888, 0.04472049689440994, 0.07037037037037036, 0.0574074074074074, 0.07080745341614907, 0.07222222222222222, 0.0, 0.03888888888888888, 0.03518518518518518, 0.16736380030509165, 0.0, 0.03913043478260869, 0.02222222222222222, 0.059259259259259255, 0.07592592592592592, 0.07407407407407407, 0.08650306748466258, 0.07222222222222222, 0.03865030674846626, 0.003821656050955414, 0.0, 0.0, 0.046583850931677016, 0.06481481481481481, 0.02222222222222222, 0.0, 0.0, 0.08148148148148147, 0.03148148148148148, 0.014814814814814814, 0.03913043478260869, 0.08703703703703704, 0.3584337751606125, 0.19104273555887458, 0.0, 0.02407407407407407, 0.0, 0.0, 0.014814814814814814, 0.06666666666666667, 0.0037037037037037034, 0.08333333333333333, 0.06521739130434782, 0.07978723404255318, 0.03888888888888888, 0.0, 0.02484639361108076, 0.000590659187355161, 0.016488064865126037, 0.024295943615301737, 0.0, 0.04785276073619631, 0.057055214723926384, 0.0, 0.049999999999999996, 0.0574074074074074, 0.06481481481481481, 0.09444444444444444, 0.05337423312883435, 0.06666666666666667, 0.0611111111111111, 0.0, 0.02222222222222222, 0.04814814814814814, 0.04207317073170732, 0.07962962962962963, 0.049999999999999996, 0.03846153846153846, 0.06625766871165643, 0.0037037037037037034, 0.046012269938650305, 0.04259259259259259, 0.0611111111111111, 0.0, 0.05217391304347826, 0.036585365853658534, 0.05185185185185185, 0.0004269462393879465, 0.03333333333333333, 0.07037037037037036, 0.08936170212765956, 0.01875, 0.02236024844720497, 0.04074074074074074, 0.03148148148148148, 0.04814814814814814, 0.0, 0.03333333333333333, 0.04969325153374233, 0.029629629629629627, 0.026244279557747184, 0.04814814814814814, 0.013043478260869565, 0.04074074074074074, 0.05403726708074534, 0.04259259259259259, 0.06296296296296296, 0.03333333333333333, 0.028662420382165606, 0.02608695652173913, 0.02484639361108076, 0.030573248407643312, 0.0, 0.11411042944785277, 0.03148148148148148, 0.04472049689440994, 0.366764951224932, 0.024708313681900476, 0.03333333333333333, 0.08963414634146341, 0.0, 0.08333333333333333, 0.0685185185185185, 0.059259259259259255, 0.03333333333333333, 0.04814814814814814, 0.037037037037037035, 0.0537037037037037, 0.031677018633540374, 0.02236024844720497, 0.08148148148148147, 0.024602012268648783, 0.059259259259259255, 0.08148148148148147, 0.046583850931677016, 0.03518518518518518, 0.09386503067484663, 0.02407407407407407, 0.046583850931677016, 0.051592356687898085, 0.031677018633540374, 0.046012269938650305, 0.0, 0.059259259259259255, 0.046296296296296294, 0.17870540807043683, 0.06481481481481481, 0.03913043478260869, 0.07222222222222222, 0.029629629629629627, 0.03148148148148148, 0.03540372670807453, 0.0, 0.0, 0.08363636363636363, 0.028662420382165606, 0.0, 0.0, 0.07962962962962963, 0.04472049689440994, 0.049999999999999996, 0.08333333333333333, 0.049999999999999996, 0.0, 0.07037037037037036, 0.06296296296296296, 0.0, 0.059259259259259255, 0.0, 0.0574074074074074, 0.0, 0.583424848747611, 0.07592592592592592, 0.029813664596273288, 0.0, 0.04207317073170732, 0.03333333333333333, 0.03333333333333333, 0.07125, 0.0, 0.06481481481481481, 0.07340425531914893, 0.07080745341614907, 0.03888888888888888, 0.059259259259259255, 0.05590062111801242, 0.06481481481481481, 0.012883435582822086, 0.02422360248447205, 0.09444444444444444, 0.08980891719745222, 0.06481481481481481, 0.0, 0.06481481481481481, 0.07962962962962963, 0.0574074074074074, 0.0, 0.03518518518518518, 0.059627329192546576, 0.05590062111801242, 0.059259259259259255, 0.0, 0.024311112201016824, 0.07222222222222222, 0.02037037037037037, 0.03518518518518518, 0.03333333333333333, 0.32704196164073157, 0.03496932515337423, 0.0, 0.07407407407407407, 0.0, 0.0484472049689441, 0.021019108280254776, 0.06666666666666667, 0.05555555555555555, 0.0, 0.024436859277734865, 0.046296296296296294, 0.049999999999999996, 0.0537037037037037, 0.07777777777777777, 0.0577639751552795, 0.08518518518518518, 0.0, 0.20637495845462384, 0.05217391304347826, 0.07037037037037036, 0.0, 0.024758999557544452, 0.0, 0.031677018633540374, 0.05403726708074534, 0.04259259259259259, 0.0, 0.059259259259259255, 0.06149068322981366, 0.02422360248447205, 0.0611111111111111, 0.08333333333333333, 0.06666666666666667, 0.04, 0.014906832298136644, 0.07914110429447851, 0.0, 0.03865030674846626, 0.03333333333333333, 0.03888888888888888, 0.19091347879640824, 0.0, 0.059259259259259255, 0.059259259259259255, 0.040993788819875775, 0.07037037037037036, 0.0, 0.04259259259259259, 0.030573248407643312, 0.02795031055900621, 0.10858895705521472, 0.01760783626675427, 0.03841463414634146, 0.07222222222222222, 0.04259259259259259, 0.17851631030468235, 0.059259259259259255, 0.04024390243902439, 0.06296296296296296, 0.04285714285714285, 0.06296296296296296, 0.0, 0.08062499999999999, 0.02222222222222222, 0.06257668711656442, 0.07037037037037036, 0.05185185185185185, 0.09814814814814815, 0.04472049689440994, 0.04444444444444444, 0.07592592592592592, 0.06521739130434782, 0.02760736196319018, 0.0574074074074074, 0.03148148148148148, 0.5374610285395175, 0.019961703777678537, 0.40113419806246164, 0.05555555555555555, 0.024999999999999998, 0.07777777777777777, 0.031677018633540374, 0.029629629629629627, 0.020042910836692292, 0.02406982119481511]
Finish training and take 1h1m

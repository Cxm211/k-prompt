Namespace(log_name='./RQ5/xcodeeval_1_3/codet5p_220m_f.log', model_name='Salesforce/codet5p-220m', lang='c', output_dir='RQ5/xcodeeval_1_3/codet5p_220m_f', data_dir='./data/RQ5/xcodeeval_1_3', no_cuda=False, visible_gpu='0', add_task_prefix=False, add_lang_ids=False, num_train_epochs=10, num_test_epochs=10, train_batch_size=8, eval_batch_size=4, gradient_accumulation_steps=2, load_model_path=None, config_name='', tokenizer_name='', max_source_length=512, max_target_length=512, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, do_lower_case=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, max_steps=-1, eval_steps=-1, train_steps=-1, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, model_name: Salesforce/codet5p-220m
model created!
Total 1 training instances 
***** Running training *****
  Num examples = 1
  Batch size = 8
  Num epoch = 10

***** Running evaluation *****
  Num examples = 100
  Batch size = 4
  epoch = 0
  eval_ppl = 1.00057
  global_step = 1
  train_loss = 0.8051
  ********************
Previous best ppl:inf
Achieve Best ppl:1.00057
  ********************
BLEU file: ./data/RQ5/xcodeeval_1_3/validation.jsonl
  codebleu-4 = 15.57 	 Previous best codebleu 0
  ********************
 Achieve Best bleu:15.57
  ********************

***** Running evaluation *****
  Num examples = 100
  Batch size = 4
  epoch = 1
  eval_ppl = 1.00057
  global_step = 1
  train_loss = 0.9323
  ********************
Previous best ppl:1.00057
BLEU file: ./data/RQ5/xcodeeval_1_3/validation.jsonl
  codebleu-4 = 15.57 	 Previous best codebleu 15.57
  ********************

***** Running evaluation *****
  Num examples = 100
  Batch size = 4
  epoch = 2
  eval_ppl = 1.00057
  global_step = 1
  train_loss = 0.9741
  ********************
Previous best ppl:1.00057
BLEU file: ./data/RQ5/xcodeeval_1_3/validation.jsonl
  codebleu-4 = 15.57 	 Previous best codebleu 15.57
  ********************

***** Running evaluation *****
  Num examples = 100
  Batch size = 4
  epoch = 3
  eval_ppl = 1.00057
  global_step = 1
  train_loss = 0.9787
  ********************
Previous best ppl:1.00057
BLEU file: ./data/RQ5/xcodeeval_1_3/validation.jsonl
  codebleu-4 = 15.57 	 Previous best codebleu 15.57
  ********************
reload model from RQ5/xcodeeval_1_3/codet5p_220m_f/checkpoint-best-bleu
BLEU file: ./data/RQ5/xcodeeval_1_3/test.jsonl
  codebleu = 15.12 
  Total = 500 
  Exact Fixed = 0 
[]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  ********************
  Total = 500 
  Exact Fixed = 0 
[]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  codebleu = 15.12 
[0.15578083511118881, 0.12307692307692307, 0.02278481012658228, 0.1752591073961184, 0.21520917567121828, 0.007692307692307692, 0.00200595145054974, 0.300786917340205, 0.24948739782866902, 0.24331356156672884, 0.15582588536274464, 0.21064373615352297, 0.1389835369819519, 0.30085720852817377, 0.25052347774796374, 0.13512275018850514, 0.11783366024691706, 0.14810126582278482, 0.12527472527472527, 0.05528511768420313, 0.13369565217391302, 0.1712576403119502, 0.21929467734559335, 0.04936708860759493, 0.14195207742815658, 0.0010820181564900134, 0.0006148464107250708, 0.10384615384615384, 0.27851965589318517, 0.06195652173913043, 0.20132410088349945, 0.0625, 0.2005372782244601, 0.24242882219424464, 0.0012364637635133699, 0.10055205065739674, 0.17152582940625447, 0.11153846153846154, 0.1826464688504824, 0.001513589386416787, 0.20425425513014542, 0.17802197802197803, 0.15, 0.30825661490012535, 0.17198905127751632, 0.17125152602494623, 0.10305890770039564, 0.0006905806627892205, 0.20057548225918914, 0.1309458600300929, 0.20929957463290758, 0.0007064485455317829, 0.30101327594476246, 0.1569767441860465, 0.160145691342301, 0.14266256985256, 0.1326605607298322, 0.11575732499316503, 0.08076923076923076, 0.06382978723404255, 0.0006990231452055489, 0.0, 0.0009729865889710875, 0.06835443037974683, 0.07912087912087912, 0.17197468850178316, 0.0, 0.1525394633330353, 0.3080894487149732, 0.09857686483892272, 0.17930175797630762, 0.15259271686149592, 0.09999999999999999, 0.06966471547019094, 0.15164772915019814, 0.16593328279345043, 0.11980172652184094, 0.22951251144614304, 0.0009130514570387183, 0.0006577945385547044, 0.06951219512195123, 0.23048762870780187, 0.14246377428629098, 0.0015192914303054218, 0.21046856151108287, 0.19748162463433894, 0.16212440742650486, 0.19761844245382404, 0.15254786768395429, 0.0, 0.30074483358792803, 0.000730781861298603, 0.2145925607331954, 0.1291139240506329, 0.1201077390329939, 0.30805007464965234, 0.07260440555636719, 0.30066889767948246, 0.13846153846153847, 0.264553343807496, 0.1986829616197136, 0.16283264326382135, 0.0011373501550097937, 0.09907578664911376, 0.2508662786498254, 0.2521065167927103, 0.10786516853932583, 0.1810193323936329, 0.18764764279627816, 0.20046978516636474, 0.01948076112651616, 0.23979698488739476, 0.20073650652331632, 0.2402309758318837, 0.0009282224545340077, 0.22065325872460395, 0.20079746559366435, 0.2344043887147335, 0.22000579210545282, 0.13076923076923078, 0.0004880068249910126, 0.11325183311736943, 0.14505532032741242, 0.18064516129032257, 0.0005595695927093553, 0.06923076923076923, 0.048974275630023115, 0.19638587039386302, 0.057692307692307696, 0.12857142857142856, 0.15914501611877313, 0.11923076923076922, 0.24923834800236677, 0.19751258494664672, 0.20131574873487684, 0.0, 0.026803069238535142, 0.2299971045155878, 0.057692307692307696, 0.14562122912833417, 0.3006905806627892, 0.3011213741677359, 0.1809310934708654, 0.18846153846153846, 0.09775475694099922, 0.1814299255401293, 0.24321989771289126, 0.22992108392198427, 0.22354633474272498, 0.015384615384615384, 0.11772151898734176, 0.032926829268292684, 0.17472527472527474, 0.22507178636955857, 0.0013733373040405287, 0.3088794924200175, 0.2314592208373779, 0.11975612960029978, 0.12692307692307692, 0.1642608338621859, 0.06538461538461539, 0.11068519922401582, 0.0, 0.12401450105358862, 0.3011756896799155, 0.19353074275136986, 0.0007658004733326889, 0.10049928501668148, 0.3085851809317517, 0.13270836716780618, 0.08976622611652472, 0.06382978723404255, 0.2003926115190677, 0.0006293954872546943, 0.0846153846153846, 0.07215189873417721, 0.07215189873417721, 0.17164099338843822, 0.046289131676437084, 0.24891019653116778, 0.17289017971997253, 0.19105267840370974, 0.1652169159668467, 0.11982769858140659, 0.12977372368796952, 0.1519755813439575, 0.23962720587605757, 0.0007203988327530216, 0.1713386068320142, 0.3083630126304383, 0.10065753035757927, 0.08106855699060896, 0.08888888888888888, 0.3007754134163587, 0.060759493670886074, 0.12025200296824062, 0.22037000478092986, 0.5208866746884949, 0.0005155014821274001, 0.13846153846153847, 0.30037431590505065, 0.10384615384615384, 0.13163201055021553, 0.2562574854160543, 0.2400418818185037, 0.0, 0.30887333730404054, 0.014712476843409185, 0.08354430379746834, 0.00080233146976784, 0.20077256231276014, 0.11026355337384558, 0.0005691092239008677, 0.26870825228255524, 0.30083922007770575, 0.09025501587949951, 0.3005334856477465, 0.30078725078973423, 0.25916481718350776, 0.15616320889774643, 0.30138541019694226, 0.14634146341463414, 0.12906976744186047, 0.0006895327211316217, 0.20854010555816876, 0.09999999999999999, 0.10072221766061987, 0.0006131330489943499, 0.09157662118463664, 0.057692307692307696, 0.2653866099864556, 0.2458326144140881, 0.19775021245123542, 0.18846153846153846, 0.22067060950159104, 0.20092656010722884, 0.023076923076923078, 0.0, 0.0006148885333380919, 0.30122510301537736, 0.22813050906659388, 0.12069671213432114, 0.0006596065384037266, 0.001237160940520799, 0.3013506296927782, 0.08076923076923076, 0.04063980336633206, 0.08846153846153847, 0.14285974296508905, 0.09615384615384616, 0.09999999999999999, 0.0006266981519891468, 0.1423020473227284, 0.0, 0.6, 0.30049290178201354, 0.22843115051361504, 0.039907524718652984, 0.19234296886430063, 0.27719557340223805, 0.11826022392844492, 0.0915558024645967, 0.0008646519084537937, 0.3080717111154451, 0.0005617993974912951, 0.14087230852001534, 0.19399071385409883, 0.0007041099365806176, 0.17119726133706223, 0.11511627906976744, 0.0008279724261075728, 0.12307692307692307, 0.3006576433301687, 0.3006104793190763, 0.12440772993898375, 0.21434105846945953, 0.25825661490012536, 0.11298701298701298, 0.0, 0.11384697128976497, 0.21095241309367516, 0.16215576818452795, 0.16224882031247018, 0.09615384615384616, 0.08496823610155534, 0.30073937375781595, 0.007594936708860759, 0.3005413000256583, 0.22001839197315554, 0.23053072392050108, 0.0007872507897342179, 0.11547009943195573, 0.18104907896595124, 0.24307119758248436, 0.03846153846153846, 0.18128441527110828, 0.25088772005231186, 0.08856253118994632, 0.06923076923076923, 0.3004896785468758, 0.12692307692307692, 0.18126405187296493, 0.12296587351814389, 0.00035670850501847535, 0.18693335808812928, 0.30126314812316096, 0.1713215299597322, 0.1326200172447332, 0.30837760328838376, 0.08957876363295676, 0.1918453579797952, 0.2105088464984476, 0.2103401328981791, 0.21987793846665168, 0.3007481575431645, 0.1729363244374584, 0.1232540497529694, 0.3080717111154451, 0.3012704478580866, 0.00047647108886398205, 0.18461538461538463, 0.06938371024251132, 0.11153846153846154, 0.0989010989010989, 0.0, 0.12329217965281167, 0.22062419279234052, 0.0006429511987947641, 0.16393375354930093, 0.1066835255358902, 0.1141304347826087, 0.1133057220201548, 0.09813210530594074, 0.2506461429626583, 0.10129870129870129, 0.16187526604693747, 0.054838709677419356, 0.14615384615384613, 0.22317949161816086, 0.13695652173913042, 0.15384615384615383, 0.17870766983852132, 0.19760004877682, 0.19159361420316107, 0.06538461538461539, 0.0975, 0.2042370121774578, 0.3006104793190763, 0.18710734298950976, 0.0005704608973559947, 0.3008130517478245, 0.14273991581127488, 0.07692307692307691, 0.10786516853932583, 0.18129036609685872, 0.2172405754959996, 0.15213507088870715, 0.3013000024581023, 0.3010808382288018, 0.0, 0.0005833781628868226, 0.2872281445068634, 0.3006104793190763, 0.0009404415540006214, 0.017827040492385628, 0.25389198008614783, 0.17598572714894875, 0.23974372606355016, 0.2356291600402523, 0.17172786950658994, 0.0, 0.10120481927710842, 0.1817104587040098, 0.000752286510402544, 0.23961077744739753, 0.0006619963669931596, 0.2202397768786282, 0.0005145382955497242, 0.5429477637450001, 0.2238587798141761, 0.14197669384559553, 0.0015289225556643867, 0.17140153676757913, 0.17163225031937437, 0.12627249859418693, 0.11923076923076922, 0.001355970408818307, 0.0584664712236597, 0.18427136687026438, 0.2759190925985382, 0.07307692307692307, 0.2101342283989595, 0.1268346626454565, 0.09782608695652174, 0.10001238937298496, 0.11094508439558312, 0.3008130517478245, 0.1576923076923077, 0.2630375751585435, 0.0, 0.22422156596878381, 0.15384615384615383, 0.30078725078973423, 0.0, 0.2081461429626583, 0.20084306427547782, 0.21981437987216437, 0.3, 0.0, 0.21102345185565063, 0.23975913781425623, 0.20052722011467747, 0.1974845550977917, 0.25127151921840823, 0.15312528665090921, 0.14276078210750442, 0.03833798445038173, 0.1576923076923077, 0.0004922202407100699, 0.18166490593402299, 0.13350898260511762, 0.12374999999999999, 0.19203806504596993, 0.0005848547258742403, 0.06884910878163028, 0.10769230769230768, 0.24307082310584577, 0.30066889767948246, 0.30870387895706514, 0.19426002129493206, 0.16153846153846152, 0.002238135018732889, 0.18264934095385701, 0.20391138849263402, 0.13076923076923078, 0.000962109465039227, 0.11923076923076922, 0.0003301431461939817, 0.06951219512195123, 0.3011611879812029, 0.1623644894962454, 0.0, 0.162551218288376, 0.21481913982384057, 0.15198462939455074, 0.24226919951067197, 0.14657531496428533, 0.13191890385983734, 0.19827369957429125, 0.09383991376319356, 0.30101742396644593, 0.0007762534340478237, 0.15206579318796867, 0.15246199678739936, 0.20128969279535994, 0.24271784752811787, 0.0014695257215568617, 0.17320252941883713, 0.3011581872762641, 0.1425857592652049, 0.2506576433301687, 0.0, 0.2308485506122045, 0.17595234674441823, 0.172812776851909, 0.21868561687444477, 0.12662119488083004, 0.09615384615384616, 0.24024500674672053, 0.3008581115563526, 0.20112578713299428, 0.30808070680378297, 0.2197141796516367, 0.2197461156726923, 0.09230769230769231, 0.2245390954334438, 0.0, 0.2287662994468863, 0.3006217367424801, 0.13118144609547044, 0.2447523435273043, 0.10769230769230768, 0.25424276965915743, 0.14282458928279107, 0.30075661490012534, 0.1692307692307692, 0.28717456513715794, 0.1737405439172981, 0.2046963083271208, 0.14279507071814626, 0.030722891566265058, 0.0949367088607595, 0.13734939759036144, 0.12322354222225647, 0.02957746478873239, 0.20048733075754283, 0.1427367220931087, 0.06923076923076923, 0.25053846462504903, 0.1867295323126801]
Finish training and take 46m

Namespace(log_name='./RQ5/tfix_16_2/codet5p_770m_f.log', model_name='Salesforce/codet5p-770m', lang='javascript', output_dir='RQ5/tfix_16_2/codet5p_770m_f', data_dir='./data/RQ5/tfix_16_2', no_cuda=False, visible_gpu='0', add_task_prefix=False, add_lang_ids=False, num_train_epochs=10, num_test_epochs=10, train_batch_size=4, eval_batch_size=4, gradient_accumulation_steps=2, load_model_path=None, config_name='', tokenizer_name='', max_source_length=512, max_target_length=512, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, do_lower_case=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, max_steps=-1, eval_steps=-1, train_steps=-1, local_rank=-1, seed=42, early_stop_threshold=2)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, model_name: Salesforce/codet5p-770m
model created!
Total 16 training instances 
***** Running training *****
  Num examples = 16
  Batch size = 4
  Num epoch = 10

***** Running evaluation *****
  Num examples = 100
  Batch size = 4
  epoch = 0
  eval_ppl = 1.00842
  global_step = 5
  train_loss = 1.818
  ********************
Previous best ppl:inf
Achieve Best ppl:1.00842
  ********************
BLEU file: ./data/RQ5/tfix_16_2/validation.jsonl
Namespace(log_name='./RQ5/tfix_16_2/codet5p_770m_f.log', model_name='Salesforce/codet5p-770m', lang='javascript', output_dir='RQ5/tfix_16_2/codet5p_770m_f', data_dir='./data/RQ5/tfix_16_2', no_cuda=False, visible_gpu='0', add_task_prefix=False, add_lang_ids=False, num_train_epochs=10, num_test_epochs=10, train_batch_size=4, eval_batch_size=4, gradient_accumulation_steps=2, load_model_path=None, config_name='', tokenizer_name='', max_source_length=512, max_target_length=512, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, do_lower_case=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, max_steps=-1, eval_steps=-1, train_steps=-1, local_rank=-1, seed=42, early_stop_threshold=2)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, model_name: Salesforce/codet5p-770m
model created!
Total 16 training instances 
***** Running training *****
  Num examples = 16
  Batch size = 4
  Num epoch = 10

***** Running evaluation *****
  Num examples = 100
  Batch size = 4
  epoch = 0
  eval_ppl = 1.00842
  global_step = 5
  train_loss = 1.818
  ********************
Previous best ppl:inf
Achieve Best ppl:1.00842
  ********************
BLEU file: ./data/RQ5/tfix_16_2/validation.jsonl
  codebleu-4 = 25.37 	 Previous best codebleu 0
  ********************
 Achieve Best bleu:25.37
  ********************

***** Running evaluation *****
  Num examples = 100
  Batch size = 4
  epoch = 1
  eval_ppl = 1.00622
  global_step = 9
  train_loss = 0.7639
  ********************
Previous best ppl:1.00842
Achieve Best ppl:1.00622
  ********************
BLEU file: ./data/RQ5/tfix_16_2/validation.jsonl
  codebleu-4 = 25.37 	 Previous best codebleu 0
  ********************
 Achieve Best bleu:25.37
  ********************

***** Running evaluation *****
  Num examples = 100
  Batch size = 4
  epoch = 1
  eval_ppl = 1.00622
  global_step = 9
  train_loss = 0.7639
  ********************
Previous best ppl:1.00842
Achieve Best ppl:1.00622
  ********************
BLEU file: ./data/RQ5/tfix_16_2/validation.jsonl
  codebleu-4 = 45.88 	 Previous best codebleu 25.37
  ********************
 Achieve Best bleu:45.88
  ********************

***** Running evaluation *****
  Num examples = 100
  Batch size = 4
  epoch = 2
  eval_ppl = 1.00555
  global_step = 13
  train_loss = 0.3784
  ********************
Previous best ppl:1.00622
Achieve Best ppl:1.00555
  ********************
BLEU file: ./data/RQ5/tfix_16_2/validation.jsonl
  codebleu-4 = 46.06 	 Previous best codebleu 25.37
  ********************
 Achieve Best bleu:46.06
  ********************

***** Running evaluation *****
  Num examples = 100
  Batch size = 4
  epoch = 2
  eval_ppl = 1.00555
  global_step = 13
  train_loss = 0.3784
  ********************
Previous best ppl:1.00622
Achieve Best ppl:1.00555
  ********************
BLEU file: ./data/RQ5/tfix_16_2/validation.jsonl
  codebleu-4 = 53.84 	 Previous best codebleu 45.88
  ********************
 Achieve Best bleu:53.84
  ********************

***** Running evaluation *****
  Num examples = 100
  Batch size = 4
  epoch = 3
  eval_ppl = 1.0053
  global_step = 17
  train_loss = 0.1876
  ********************
Previous best ppl:1.00555
Achieve Best ppl:1.0053
  ********************
BLEU file: ./data/RQ5/tfix_16_2/validation.jsonl
  codebleu-4 = 53.83 	 Previous best codebleu 46.06
  ********************
 Achieve Best bleu:53.83
  ********************

***** Running evaluation *****
  Num examples = 100
  Batch size = 4
  epoch = 3
  eval_ppl = 1.0053
  global_step = 17
  train_loss = 0.1876
  ********************
Previous best ppl:1.00555
Achieve Best ppl:1.0053
  ********************
BLEU file: ./data/RQ5/tfix_16_2/validation.jsonl
  codebleu-4 = 56.48 	 Previous best codebleu 53.84
  ********************
 Achieve Best bleu:56.48
  ********************

***** Running evaluation *****
  Num examples = 100
  Batch size = 4
  epoch = 4
  eval_ppl = 1.00514
  global_step = 21
  train_loss = 0.1056
  ********************
Previous best ppl:1.0053
Achieve Best ppl:1.00514
  ********************
BLEU file: ./data/RQ5/tfix_16_2/validation.jsonl
  codebleu-4 = 56.41 	 Previous best codebleu 53.83
  ********************
 Achieve Best bleu:56.41
  ********************

***** Running evaluation *****
  Num examples = 100
  Batch size = 4
  epoch = 4
  eval_ppl = 1.00514
  global_step = 21
  train_loss = 0.1056
  ********************
Previous best ppl:1.0053
Achieve Best ppl:1.00514
  ********************
BLEU file: ./data/RQ5/tfix_16_2/validation.jsonl
  codebleu-4 = 57.59 	 Previous best codebleu 56.48
  ********************
 Achieve Best bleu:57.59
  ********************

***** Running evaluation *****
  Num examples = 100
  Batch size = 4
  epoch = 5
  eval_ppl = 1.00517
  global_step = 25
  train_loss = 0.0646
  ********************
Previous best ppl:1.00514
BLEU file: ./data/RQ5/tfix_16_2/validation.jsonl
  codebleu-4 = 57.55 	 Previous best codebleu 56.41
  ********************
 Achieve Best bleu:57.55
  ********************

***** Running evaluation *****
  Num examples = 100
  Batch size = 4
  epoch = 5
  eval_ppl = 1.00517
  global_step = 25
  train_loss = 0.0646
  ********************
Previous best ppl:1.00514
BLEU file: ./data/RQ5/tfix_16_2/validation.jsonl
  codebleu-4 = 56.29 	 Previous best codebleu 57.59
  ********************

***** Running evaluation *****
  Num examples = 100
  Batch size = 4
  epoch = 6
  eval_ppl = 1.00527
  global_step = 29
  train_loss = 0.0312
  ********************
Previous best ppl:1.00514
BLEU file: ./data/RQ5/tfix_16_2/validation.jsonl
  codebleu-4 = 56.25 	 Previous best codebleu 57.55
  ********************

***** Running evaluation *****
  Num examples = 100
  Batch size = 4
  epoch = 6
  eval_ppl = 1.00527
  global_step = 29
  train_loss = 0.0312
  ********************
Previous best ppl:1.00514
BLEU file: ./data/RQ5/tfix_16_2/validation.jsonl
  codebleu-4 = 55.94 	 Previous best codebleu 57.59
  ********************
reload model from RQ5/tfix_16_2/codet5p_770m_f/checkpoint-best-bleu
BLEU file: ./data/RQ5/tfix_16_2/test.jsonl
  codebleu-4 = 55.94 	 Previous best codebleu 57.55
  ********************
reload model from RQ5/tfix_16_2/codet5p_770m_f/checkpoint-best-bleu
BLEU file: ./data/RQ5/tfix_16_2/test.jsonl
  codebleu = 55.42 
  Total = 500 
  Exact Fixed = 21 
[25, 47, 52, 132, 173, 188, 201, 205, 238, 253, 263, 294, 303, 305, 330, 349, 367, 435, 439, 442, 457]
  Syntax Fixed = 3 
[22, 202, 270]
  Cleaned Fixed = 9 
[35, 126, 153, 166, 172, 193, 390, 417, 469]
  ********************
  Total = 500 
  Exact Fixed = 21 
[25, 47, 52, 132, 173, 188, 201, 205, 238, 253, 263, 294, 303, 305, 330, 349, 367, 435, 439, 442, 457]
  Syntax Fixed = 3 
[22, 202, 270]
  Cleaned Fixed = 9 
[35, 126, 153, 166, 172, 193, 390, 417, 469]
  codebleu = 55.42 
[0.5670445241047504, 0.5681547438307162, 0.6057190588618955, 0.31331096368700495, 0.9433946642877236, 0.8821894623768516, 0.0, 0.5632071341189149, 0.29875916069705455, 0.12, 0.5953079437151456, 0.5638063820069366, 0.15393576085345756, 0.7569706667451968, 0.6196949179201965, 0.811117687292167, 0.5007520143098162, 0.7099766481408452, 0.6885240359080308, 0.4478030608159431, 0.6716511056875383, 0.899706024803423, 0.25583464080738794, 0.30339981731348864, 0.7691886750930661, 0.006758238160278511, 0.9194711239895874, 0.26164945162585174, 0.679937506633708, 0.2855072113105671, 0.7059323615142865, 0.0, 0.4507183101653729, 0.9113854927948712, 0.8790355083665293, 0.5830833113292266, 0.0, 0.10556510016615601, 0.18344880468836688, 0.6398412446099295, 0.49915440082990403, 0.8230253102708935, 0.10202520055807765, 0.40366685053304824, 0.28896233275834576, 0.37367284349135044, 1.0, 0.1968349491302143, 0.7776251874771634, 0.27468411643929896, 0.350381564995214, 1.0, 0.5567052722262924, 0.9219902071957782, 0.1297947365831559, 0.7028480321005652, 0.3070782538395746, 0.5858036582643444, 0.9318213423140442, 0.6232902973738775, 0.9315380507550484, 0.714297617187952, 0.5348435312891645, 0.7698918124013976, 0.47573016560124975, 0.6197233100748608, 0.6877745357134093, 0.4706502402815602, 0.4562469010663871, 0.28269688894370654, 0.5708201517568863, 0.2039938551280689, 0.8508222909971193, 0.39452984161828986, 0.702664818575847, 0.23920961742833027, 0.15, 0.7870966762409493, 0.3762263314774751, 0.5808806063655805, 0.591516286342532, 0.3683458566180241, 0.36662249548760817, 0.816074986663424, 0.6359585563603126, 0.5451417837590342, 0.515412224928219, 0.9377106968911376, 0.8053935031810717, 0.44058280681232764, 0.5836243674583652, 0.7402739997668998, 0.44517512468103604, 0.2955414762032743, 0.17049656541364344, 0.7470738524243741, 0.8349004181959196, 0.8639557211113615, 0.8097407224050479, 0.5304913829730156, 0.7942011322130667, 0.7765712201237638, 0.7275723927836586, 0.6445931574752105, 0.811709194192274, 0.0, 0.4593867118293433, 0.8399114554115357, 0.8049637497745419, 0.05270446328111167, 0.2878852119582799, 0.7468446370144718, 0.39272004516267667, 0.3798418629627377, 0.509901499184051, 0.5592594653964404, 0.21178229269315577, 0.9778557135210861, 0.5143209096122012, 0.7231896021778675, 0.7302547136373172, 0.39344297891548086, 0.763761398744189, 0.0, 0.2176694832919011, 0.8186530227858186, 0.2011770485941022, 0.5600382105380115, 0.5246680028432865, 0.4976113387647193, 0.4588835399767188, 1.0, 0.08180217201052084, 0.39089314466834374, 0.6667528334695118, 0.4460952454685818, 0.8091441569283881, 0.523099034776898, 0.08830564087244708, 0.4136911179244788, 0.78685519109128, 0.23532606505914805, 0.22117487048232867, 0.47180509653022784, 0.3992286298565113, 0.5984992107820759, 0.3607039998273758, 0.3561219555899987, 0.5862322739141566, 0.26493187938965956, 0.4854183564853334, 0.6612091961731477, 0.6983535654700125, 0.8045937759301073, 0.40825339177238446, 0.64935519109128, 0.617517369093352, 0.49363804004496625, 0.22499999999999998, 0.22479075946263982, 0.39347209291868157, 0.20487603547840597, 0.29799571967581034, 0.7423029428997638, 0.45443627493082295, 0.671995337914775, 0.7006847188488577, 0.49215257204284135, 0.16593651328065362, 0.44556336675408204, 0.6868474083243508, 0.5336911179244788, 1.0, 0.9265860442169083, 0.40693291435805307, 0.6734232449967186, 0.41996134394226886, 0.0, 0.6278910313966588, 0.11453360085481801, 0.36686807121046905, 0.6780323751412478, 0.5164927712445991, 0.6046379048692274, 0.5186883738888508, 0.8372433448759671, 0.669924448317195, 0.7135428903906851, 0.19535576197454044, 0.7725146668513112, 0.7562262989907678, 0.8693381407515255, 0.41130178148606267, 0.602900674952493, 0.43648868589003154, 0.5758089748131177, 0.007044218708112843, 0.7960658705890922, 0.49007095902260256, 0.39722643810031, 1.0, 0.8958282740277042, 0.40485075092622447, 0.49891980404509845, 1.0, 0.6271806220068676, 0.4139240818757265, 0.6955980328281302, 0.4697300318922557, 0.6599223799332465, 0.19575085189665523, 0.9365276486140073, 0.39306633246252903, 0.3491439982146318, 0.9066789515243823, 0.174436274930823, 0.6129938455930134, 0.5536911179244788, 0.19822678924609494, 0.7755969629986152, 0.4580200993563527, 0.6340564047491466, 0.731117687292167, 0.15997084006767517, 0.4673851287829819, 0.7819216374730074, 0.7834452289722301, 0.8547211363207963, 0.9414428605659417, 0.1412553466955474, 0.48074569931823535, 0.8560223473586787, 0.005825242718446601, 0.5992413083109663, 0.15384948979556398, 0.6829859387503355, 0.33985271067894746, 1.0, 0.3683458566180241, 0.6729989975277095, 0.7471765364160405, 0.3711234393139395, 0.7471633983399641, 0.7263487966630597, 0.9056583090096291, 0.6127572978503959, 0.37487890958867326, 0.7225371723695806, 0.30192420478023085, 0.5333108614657077, 0.5073028085492076, 0.9663865109019152, 1.0, 0.6636363636363636, 0.22499999999999998, 0.7430779662080889, 0.2772943579237247, 0.836942030771336, 0.7100060129578126, 0.7299948711471688, 0.4239419814755695, 0.5585140118159326, 1.0, 0.7503305249945151, 0.36522840682175095, 0.6624678525854575, 0.330171834883827, 0.4501947080651152, 0.6876346520405138, 0.6737903830933105, 0.6848698374809952, 0.8307467892419347, 0.1516310084727187, 0.2912524882813255, 0.6, 0.5947952452977411, 0.4016534478992738, 0.8222267233801039, 0.7142845202249919, 0.5551668790236555, 0.5600468038501167, 0.4561779924571592, 0.377764931269415, 0.6877459225855624, 0.8470997505392659, 0.0, 0.5171258603602051, 0.8420812716756092, 0.37712632315543404, 0.7853515848748065, 0.030196845793754545, 0.22719082257468703, 0.6366015466501336, 1.0, 0.8232059780715621, 0.377190822574687, 0.8072615927227478, 0.4623128324531056, 0.7212489793637704, 0.2972747330570886, 0.8374634481857526, 0.4687131054697118, 1.0, 0.44245571892563784, 1.0, 0.5181498551143461, 0.14330282731482427, 0.8356658099532572, 0.8555090515828416, 0.8255980153481091, 0.3220998891127413, 0.1344057918034266, 0.22368441215365098, 0.6682556320550647, 0.5113616550848404, 0.6276136760976885, 0.714297617187952, 0.3502184077768308, 0.542766960135034, 0.06, 0.8378414230005442, 0.4847938771139478, 0.48461043931965503, 0.6240048954556174, 0.8034645362012123, 0.9617868617067262, 0.34600762214891934, 0.20728825518836927, 0.44065521764595156, 1.0, 0.6414656393063431, 0.6273488306532815, 0.6088652057858469, 0.7189894209825303, 0.656468030647374, 0.5928455941630664, 0.8050241598897441, 0.8455355915212772, 0.5015372100944879, 0.8033946307914341, 0.6981023533844464, 0.5183193633729429, 0.2790935725738941, 0.8521964460866425, 0.6287796716807859, 0.44507381648898203, 0.5398855599662549, 0.5038833860066276, 1.0, 0.6393949501703278, 0.8069007178395178, 0.9176675865658077, 0.4147896756607047, 0.5952887122558812, 0.12, 0.4890714508161259, 0.4129139077323539, 0.6745228788727515, 0.5964858645175034, 0.5780999494416426, 0.7191441569283882, 0.3057265995447144, 0.9265757127424608, 0.4614470406899055, 0.5027054768195429, 0.3445672601793484, 1.0, 0.7894978414909921, 0.004544895682429588, 0.8378414230005442, 0.444006594916457, 0.7536060548993002, 0.32898762131831805, 0.30525881868819754, 0.29707639090093896, 0.7625515340301889, 0.45101776545562844, 0.4129740706026147, 0.3053372331674803, 0.2592698712812866, 0.4621787547146431, 0.010004245075302343, 0.8184276974159628, 0.7730817392743747, 0.585862662719982, 0.5627243873293499, 0.7211277277287549, 0.7530301180787049, 0.8619254788161215, 0.6983535654700125, 0.5654473178899494, 0.760978313726013, 0.734763973349975, 0.1341979980200088, 0.4592493207167594, 0.7210821183929019, 0.6473041576762639, 0.09810652517147422, 0.5019774510104837, 0.31860139828537487, 0.5235173156441624, 0.7108049881272258, 0.7433503156010464, 0.25843467365925654, 0.3497971971294547, 0.5033554133637828, 0.6354739770278475, 0.8600057888291379, 0.5595581748828689, 0.0857142857142857, 0.0, 0.7553071103169158, 0.8655056700329364, 0.8, 0.709115943344826, 0.08230250743390528, 0.6585117129535003, 0.39753490965039084, 0.038139497655491794, 0.15013551186214386, 0.12720409506959984, 0.4749766675130823, 0.7054819616225767, 0.6049522285347575, 0.8761070565997585, 0.5187732888660772, 0.5786580151554076, 0.5092272948800609, 0.21410743157431567, 0.6183689771600134, 0.3121948805274514, 0.21151332797896238, 0.685303136808272, 0.7288312733021203, 1.0, 0.6829777303051304, 0.7511655122445988, 0.6275893856012176, 1.0, 0.08928571428571427, 0.40739727760582384, 0.7135428903906851, 0.7260484492137269, 0.8845572237610086, 0.8292906179772745, 0.636068568378893, 0.6615859752999135, 0.7148321218614053, 0.11682401107306362, 0.5471589663515812, 0.6592906179772744, 0.8379283989138028, 0.8917028689549173, 0.33594700943102185, 0.8648103351245982, 0.0828714707479615, 1.0, 0.8326781496971694, 0.17599507186211227, 0.7845578251721461, 0.6099380655621088, 0.7780387576883845, 0.5149441763089433, 0.4714698407062744, 0.8677459225855626, 0.4459094228551539, 0.3583507427572924, 0.8665707411224077, 0.6807990952074163, 0.6809070226208283, 0.7316423857228858, 0.6433443143526654, 0.5076755387868307, 0.7158229243802021, 0.7993157050834909, 0.3, 0.5345878440281425, 0.7392647227570666, 0.8038961967467184, 0.32868746441434177, 0.5220398231634966, 0.7586172059015853, 0.6924012535180504, 0.0570067559016835, 0.4592359915981675, 0.6456695739860672, 0.6901940524102714, 0.35616988639596414, 0.23868348617790436, 0.2745721808032954, 0.7135160729534664, 0.4695633649758072, 0.6157955965877151, 0.4282450921231242, 0.5562895166803407, 0.8632148025904984, 0.28515328647075866, 0.7856607594664533, 0.38457771185543144, 0.6101458438731493]
Finish training and take 50m
  codebleu = 55.38 
  Total = 500 
  Exact Fixed = 21 
[25, 47, 52, 132, 173, 188, 201, 205, 238, 253, 263, 294, 303, 305, 330, 349, 367, 435, 439, 442, 457]
  Syntax Fixed = 3 
[22, 202, 270]
  Cleaned Fixed = 9 
[35, 126, 153, 166, 172, 193, 390, 417, 469]
  ********************
  Total = 500 
  Exact Fixed = 21 
[25, 47, 52, 132, 173, 188, 201, 205, 238, 253, 263, 294, 303, 305, 330, 349, 367, 435, 439, 442, 457]
  Syntax Fixed = 3 
[22, 202, 270]
  Cleaned Fixed = 9 
[35, 126, 153, 166, 172, 193, 390, 417, 469]
  codebleu = 55.38 
[0.5670445241047504, 0.5681547438307162, 0.6057190588618955, 0.31331096368700495, 0.9433946642877236, 0.8821894623768516, 0.0, 0.5632071341189149, 0.29875916069705455, 0.12, 0.5953079437151456, 0.5638063820069366, 0.15393576085345756, 0.7569706667451968, 0.6196949179201965, 0.811117687292167, 0.5007520143098162, 0.7099766481408452, 0.6885240359080308, 0.4478030608159431, 0.7145082485446812, 0.899706024803423, 0.25583464080738794, 0.30339981731348864, 0.7691886750930661, 0.006758238160278511, 0.9194711239895874, 0.26164945162585174, 0.679937506633708, 0.2855072113105671, 0.7059323615142865, 0.0, 0.4507183101653729, 0.9113854927948712, 0.8790355083665293, 0.5830833113292266, 0.0, 0.10556510016615601, 0.18344880468836688, 0.6398412446099295, 0.49915440082990403, 0.8230253102708935, 0.10202520055807765, 0.40366685053304824, 0.28896233275834576, 0.37367284349135044, 1.0, 0.1968349491302143, 0.7776251874771634, 0.27468411643929896, 0.350381564995214, 1.0, 0.5567052722262924, 0.9219902071957782, 0.1297947365831559, 0.7028480321005652, 0.3070782538395746, 0.5858036582643444, 0.9318213423140442, 0.6232902973738775, 0.9315380507550484, 0.714297617187952, 0.5348435312891645, 0.7698918124013976, 0.47573016560124975, 0.6197233100748608, 0.6877745357134093, 0.4706502402815602, 0.4562469010663871, 0.28269688894370654, 0.5708201517568863, 0.2039938551280689, 0.8508222909971193, 0.39452984161828986, 0.702664818575847, 0.23920961742833027, 0.15, 0.7870966762409493, 0.3762263314774751, 0.5380234635084377, 0.591516286342532, 0.3683458566180241, 0.36662249548760817, 0.816074986663424, 0.6359585563603126, 0.5451417837590342, 0.515412224928219, 0.9377106968911376, 0.8053935031810717, 0.44058280681232764, 0.5836243674583652, 0.7402739997668998, 0.44517512468103604, 0.2955414762032743, 0.17049656541364344, 0.7470738524243741, 0.8349004181959196, 0.8639557211113615, 0.8097407224050479, 0.5304913829730156, 0.7942011322130667, 0.7765712201237638, 0.7275723927836586, 0.6445931574752105, 0.811709194192274, 0.0, 0.4593867118293433, 0.8399114554115357, 0.8049637497745419, 0.05270446328111167, 0.2878852119582799, 0.7468446370144718, 0.39272004516267667, 0.3798418629627377, 0.509901499184051, 0.5592594653964404, 0.21178229269315577, 0.9778557135210861, 0.5143209096122012, 0.7017610307492962, 0.7302547136373172, 0.39344297891548086, 0.763761398744189, 0.0, 0.2176694832919011, 0.8186530227858186, 0.2011770485941022, 0.5600382105380115, 0.5246680028432865, 0.4976113387647193, 0.41602639711957595, 1.0, 0.08180217201052084, 0.39089314466834374, 0.6667528334695118, 0.4460952454685818, 0.8091441569283881, 0.523099034776898, 0.08830564087244708, 0.4136911179244788, 0.6368551910912801, 0.23532606505914805, 0.22117487048232867, 0.47180509653022784, 0.3992286298565113, 0.5984992107820759, 0.3607039998273758, 0.3561219555899987, 0.5862322739141566, 0.26493187938965956, 0.4854183564853334, 0.6612091961731477, 0.6983535654700125, 0.8045937759301073, 0.40825339177238446, 0.64935519109128, 0.617517369093352, 0.49363804004496625, 0.22499999999999998, 0.22479075946263982, 0.39347209291868157, 0.20487603547840597, 0.29799571967581034, 0.7423029428997638, 0.45443627493082295, 0.671995337914775, 0.7006847188488577, 0.49215257204284135, 0.16593651328065362, 0.44556336675408204, 0.6868474083243508, 0.5336911179244788, 1.0, 0.9265860442169083, 0.40693291435805307, 0.6734232449967186, 0.41996134394226886, 0.0, 0.6278910313966588, 0.11453360085481801, 0.36686807121046905, 0.6780323751412478, 0.5164927712445991, 0.6046379048692274, 0.5186883738888508, 0.8372433448759671, 0.669924448317195, 0.7135428903906851, 0.19535576197454044, 0.7725146668513112, 0.7562262989907678, 0.8693381407515255, 0.41130178148606267, 0.602900674952493, 0.43648868589003154, 0.5758089748131177, 0.007044218708112843, 0.7960658705890922, 0.49007095902260256, 0.39722643810031, 1.0, 0.8958282740277042, 0.40485075092622447, 0.49891980404509845, 1.0, 0.6271806220068676, 0.4139240818757265, 0.6955980328281302, 0.4697300318922557, 0.6599223799332465, 0.19575085189665523, 0.9365276486140073, 0.39306633246252903, 0.3491439982146318, 0.9066789515243823, 0.174436274930823, 0.6129938455930134, 0.5536911179244788, 0.19822678924609494, 0.7755969629986152, 0.4580200993563527, 0.6340564047491466, 0.731117687292167, 0.15997084006767517, 0.4673851287829819, 0.7819216374730074, 0.7834452289722301, 0.8547211363207963, 0.9414428605659417, 0.1412553466955474, 0.48074569931823535, 0.8560223473586787, 0.005825242718446601, 0.5992413083109663, 0.15384948979556398, 0.6829859387503355, 0.33985271067894746, 1.0, 0.3683458566180241, 0.6729989975277095, 0.7471765364160405, 0.3711234393139395, 0.7304967316732975, 0.7263487966630597, 0.9056583090096291, 0.6127572978503959, 0.37487890958867326, 0.7225371723695806, 0.30192420478023085, 0.5333108614657077, 0.5073028085492076, 0.9663865109019152, 1.0, 0.6636363636363636, 0.22499999999999998, 0.7430779662080889, 0.2772943579237247, 0.836942030771336, 0.7100060129578126, 0.7299948711471688, 0.4239419814755695, 0.5585140118159326, 1.0, 0.7503305249945151, 0.36522840682175095, 0.6624678525854575, 0.330171834883827, 0.4501947080651152, 0.7209679853738471, 0.6737903830933105, 0.6848698374809952, 0.8307467892419347, 0.1516310084727187, 0.2912524882813255, 0.6, 0.5947952452977411, 0.4016534478992738, 0.8222267233801039, 0.7142845202249919, 0.5551668790236555, 0.5600468038501167, 0.4561779924571592, 0.377764931269415, 0.6877459225855624, 0.8470997505392659, 0.0, 0.5171258603602051, 0.8849384145327521, 0.37712632315543404, 0.7853515848748065, 0.030196845793754545, 0.22719082257468703, 0.6366015466501336, 1.0, 0.8232059780715621, 0.377190822574687, 0.8072615927227478, 0.4623128324531056, 0.7212489793637704, 0.2972747330570886, 0.8374634481857526, 0.4687131054697118, 1.0, 0.44245571892563784, 1.0, 0.5181498551143461, 0.14330282731482427, 0.8356658099532572, 0.8555090515828416, 0.8255980153481091, 0.3220998891127413, 0.1344057918034266, 0.22368441215365098, 0.6682556320550647, 0.5113616550848404, 0.6276136760976885, 0.714297617187952, 0.3502184077768308, 0.542766960135034, 0.06, 0.8378414230005442, 0.4847938771139478, 0.48461043931965503, 0.6240048954556174, 0.8034645362012123, 0.9617868617067262, 0.34600762214891934, 0.20728825518836927, 0.44065521764595156, 1.0, 0.6414656393063431, 0.6273488306532815, 0.6088652057858469, 0.7189894209825303, 0.656468030647374, 0.5928455941630664, 0.8050241598897441, 0.8455355915212772, 0.5015372100944879, 0.8033946307914341, 0.6981023533844464, 0.4849860300396096, 0.2790935725738941, 0.8521964460866425, 0.6287796716807859, 0.44507381648898203, 0.5398855599662549, 0.5038833860066276, 1.0, 0.6393949501703278, 0.8069007178395178, 0.9176675865658077, 0.4147896756607047, 0.5952887122558812, 0.12, 0.4890714508161259, 0.4129139077323539, 0.6745228788727515, 0.5964858645175034, 0.5780999494416426, 0.7191441569283882, 0.3057265995447144, 0.9265757127424608, 0.4614470406899055, 0.5027054768195429, 0.3445672601793484, 1.0, 0.7894978414909921, 0.004544895682429588, 0.8378414230005442, 0.444006594916457, 0.7536060548993002, 0.32898762131831805, 0.30525881868819754, 0.29707639090093896, 0.7625515340301889, 0.45101776545562844, 0.4129740706026147, 0.3053372331674803, 0.2592698712812866, 0.4621787547146431, 0.010004245075302343, 0.8184276974159628, 0.7730817392743747, 0.585862662719982, 0.5627243873293499, 0.7211277277287549, 0.7530301180787049, 0.8619254788161215, 0.6983535654700125, 0.5654473178899494, 0.760978313726013, 0.734763973349975, 0.1341979980200088, 0.4592493207167594, 0.7210821183929019, 0.6473041576762639, 0.09810652517147422, 0.5019774510104837, 0.31860139828537487, 0.5235173156441624, 0.7108049881272258, 0.7433503156010464, 0.25843467365925654, 0.3497971971294547, 0.5033554133637828, 0.6354739770278475, 0.8600057888291379, 0.5595581748828689, 0.0857142857142857, 0.0, 0.7553071103169158, 0.8655056700329364, 0.8, 0.709115943344826, 0.08230250743390528, 0.6585117129535003, 0.39753490965039084, 0.038139497655491794, 0.15013551186214386, 0.12720409506959984, 0.4749766675130823, 0.7054819616225767, 0.6049522285347575, 0.8761070565997585, 0.5187732888660772, 0.6453246818220744, 0.5092272948800609, 0.21410743157431567, 0.6183689771600134, 0.3121948805274514, 0.21151332797896238, 0.685303136808272, 0.7288312733021203, 1.0, 0.6829777303051304, 0.7511655122445988, 0.6275893856012176, 1.0, 0.08928571428571427, 0.40739727760582384, 0.7135428903906851, 0.7260484492137269, 0.8845572237610086, 0.8292906179772745, 0.636068568378893, 0.6615859752999135, 0.7148321218614053, 0.11682401107306362, 0.5471589663515812, 0.6592906179772744, 0.8379283989138028, 0.8917028689549173, 0.33594700943102185, 0.8648103351245982, 0.0828714707479615, 1.0, 0.8326781496971694, 0.17599507186211227, 0.7845578251721461, 0.6099380655621088, 0.7780387576883845, 0.5149441763089433, 0.4714698407062744, 0.8677459225855626, 0.4459094228551539, 0.3583507427572924, 0.8665707411224077, 0.6807990952074163, 0.6809070226208283, 0.7316423857228858, 0.6433443143526654, 0.5076755387868307, 0.7158229243802021, 0.7993157050834909, 0.3, 0.5345878440281425, 0.7392647227570666, 0.8038961967467184, 0.32868746441434177, 0.5220398231634966, 0.725283872568252, 0.6924012535180504, 0.0570067559016835, 0.4592359915981675, 0.6456695739860672, 0.6901940524102714, 0.35616988639596414, 0.23868348617790436, 0.2745721808032954, 0.7135160729534664, 0.4695633649758072, 0.6157955965877151, 0.4282450921231242, 0.5562895166803407, 0.8632148025904984, 0.28515328647075866, 0.7856607594664533, 0.38457771185543144, 0.6101458438731493]

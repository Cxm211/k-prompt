Namespace(log_name='./RQ5/javascript_1/f1_codet5p_220m.log', model_name='Salesforce/codet5p-220m', lang='javascript', output_dir='RQ5/javascript_1/f1_codet5p_220m', data_dir='./data/RQ5/javascript_1_1', no_cuda=False, visible_gpu='0', add_task_prefix=False, add_lang_ids=False, num_train_epochs=10, num_test_epochs=10, train_batch_size=8, eval_batch_size=4, gradient_accumulation_steps=2, load_model_path=None, config_name='', tokenizer_name='', max_source_length=128, max_target_length=128, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, do_lower_case=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, max_steps=-1, eval_steps=-1, train_steps=-1, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, model_name: Salesforce/codet5p-220m
model created!
Total 1 training instances 
***** Running training *****
  Num examples = 1
  Batch size = 8
  Num epoch = 10

***** Running evaluation *****
  Num examples = 500
  Batch size = 4
  epoch = 0
  eval_ppl = 1.01407
  global_step = 1
  train_loss = 2.4102
  ********************
Previous best ppl:inf
Achieve Best ppl:1.01407
  ********************
BLEU file: ./data/RQ5/javascript_1_1/validation.jsonl
  codebleu-4 = 9.21 	 Previous best codebleu 0
  ********************
 Achieve Best bleu:9.21
  ********************

***** Running evaluation *****
  Num examples = 500
  Batch size = 4
  epoch = 1
  eval_ppl = 1.01407
  global_step = 1
  train_loss = 2.6298
  ********************
Previous best ppl:1.01407
BLEU file: ./data/RQ5/javascript_1_1/validation.jsonl
  codebleu-4 = 9.21 	 Previous best codebleu 9.21
  ********************

***** Running evaluation *****
  Num examples = 500
  Batch size = 4
  epoch = 2
  eval_ppl = 1.01407
  global_step = 1
  train_loss = 3.5851
  ********************
Previous best ppl:1.01407
BLEU file: ./data/RQ5/javascript_1_1/validation.jsonl
  codebleu-4 = 9.21 	 Previous best codebleu 9.21
  ********************

***** Running evaluation *****
  Num examples = 500
  Batch size = 4
  epoch = 3
  eval_ppl = 1.01407
  global_step = 1
  train_loss = 2.9178
  ********************
Previous best ppl:1.01407
BLEU file: ./data/RQ5/javascript_1_1/validation.jsonl
  codebleu-4 = 9.21 	 Previous best codebleu 9.21
  ********************
reload model from RQ5/javascript_1/f1_codet5p_220m/checkpoint-best-bleu
BLEU file: ./data/RQ5/javascript_1_1/test.jsonl
  codebleu = 8.48 
  Total = 500 
  Exact Fixed = 0 
[]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  ********************
  Total = 500 
  Exact Fixed = 0 
[]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  codebleu = 8.48 
[0.45047156056251614, 0.24579192179436443, 0.008333333333333333, 0.15669029454182548, 0.009481316321921398, 0.16004748588076356, 0.08753315649867374, 0.049999999999999996, 0.30014029984034013, 0.04, 0.0, 0.2601327521582192, 0.0, 0.009411880786578609, 0.03214285714285714, 0.08529116191633593, 0.0, 0.01639610519234522, 0.0, 0.10122448979591836, 0.03157894736842105, 0.18333333333333335, 0.24973888587182452, 0.021428571428571425, 0.03259439134463542, 0.59765625, 0.024324324324324326, 0.0, 0.059186270357749364, 0.00027767524274151587, 0.1549032920664981, 0.020298859893786082, 0.0032590286912267826, 0.06, 0.0, 0.42908535209730614, 0.004026845637583892, 0.02023349611538818, 0.0, 0.0, 0.0, 0.0, 0.08145798593220896, 0.08, 0.05357142857142857, 0.0, 0.10714285714285714, 0.02077281398474711, 0.03222811671087533, 0.2619510268636369, 0.07204835780481528, 0.0, 0.10710947491031785, 0.015280133977024919, 0.0, 0.5977918533917194, 0.0, 0.03333333333333333, 0.22663853100317444, 0.6007146503716609, 0.08959142268990865, 0.13290929264071497, 0.09041265125752686, 0.07515625000000001, 0.05226945776816852, 0.02, 0.1103388994407456, 0.44737247839327404, 0.054878048780487805, 0.09166080980919142, 0.04285714285714285, 0.15041322290825043, 0.0, 0.0, 0.0, 0.16822429906542055, 0.13795918367346938, 0.0, 0.0916030534351145, 0.02608695652173913, 0.0, 0.123361325426494, 0.026925806756124396, 0.0, 0.0, 0.12895972322471594, 0.0, 0.15680953143925971, 0.0, 0.023495810054164942, 0.01764705882352941, 0.04, 0.05565920809187122, 0.41538461538461535, 0.00035479984220565145, 0.11286546632277683, 0.10232504983226257, 0.08340646098758585, 0.04, 0.18147096406222157, 0.298295529424338, 0.14666666666666667, 0.2971704056815701, 0.20519633021463665, 0.03, 0.00018451528627067118, 0.08122448979591837, 0.06454372263867464, 0.01111111111111111, 0.00014519948981001152, 0.0, 0.0001867651756656778, 0.0, 0.00022674222944181572, 0.24085397950110657, 0.13452003568521193, 0.029445427523815307, 0.13218351187017066, 0.0, 0.1401015228426396, 0.17055335968379445, 0.08285714285714285, 0.006629799336047015, 0.33985271067894746, 0.30029669910386825, 0.0, 0.197926292040859, 0.03157894736842105, 0.590739536365471, 0.028989408040563, 0.021428571428571425, 0.04285714285714285, 0.00019960223845056353, 0.13401004289201524, 0.3001668452145809, 0.0029411764705882353, 0.0, 0.09236579932431288, 0.10122448979591836, 0.0, 0.055714285714285716, 0.09021739130434782, 0.0002157913274053676, 0.0692156862745098, 0.2982456140350877, 0.08839925346362018, 0.0, 0.12362334554407789, 0.060545390529934795, 0.13357767827172148, 0.0, 0.00020855169345796278, 0.30027138042901624, 0.3, 0.6010732232385148, 0.07062496134571988, 0.03023351726651945, 0.15765348052117295, 0.057537456752361826, 0.020365441170697444, 0.1783783783783784, 0.045, 0.06428571428571428, 0.00022820273016375023, 0.02337321073415167, 0.2068157977122484, 0.0, 0.045, 0.26692488461715236, 0.0, 0.0, 0.0, 0.041379310344827586, 0.10410958904109588, 0.03214285714285714, 0.06080776640263081, 0.0002894720763631028, 0.02039554061585188, 0.028124999999999997, 0.0, 0.14750092837086687, 0.006149263878053831, 0.11829125020567038, 0.0, 0.09038414177841918, 0.03532611985302801, 0.20784511940032485, 0.31832955547612024, 0.12860897695234758, 0.33772828506017816, 0.01038370635050403, 0.04027767698646141, 0.02, 0.06695581600724952, 0.0523963133640553, 0.04, 0.0, 0.07543307086614173, 0.04, 0.0184831132805018, 0.06509450421021735, 0.07537161856016059, 0.04, 0.10726858187627543, 0.06, 0.02030263702651814, 0.0, 0.0523963133640553, 0.4781583336244614, 0.0, 0.075, 0.06, 0.10146437423597308, 0.0, 0.0, 0.3748978941296281, 0.0, 0.0, 0.03333333333333333, 0.12291434865311886, 0.04411894036549549, 0.17357648914383667, 0.0, 0.0922080770422607, 0.02, 0.397867909233351, 0.0, 0.043661689763966574, 0.0, 0.0001870100919406833, 0.09297817047817047, 0.04808467009525821, 0.08077117577942763, 0.19591836734693877, 0.33003095744382094, 0.00012517257485876736, 0.04859936147700543, 0.03529411764705882, 0.16465183282103707, 0.00857142857142857, 0.02, 0.02727272727272727, 0.0, 0.0009321194512898824, 0.00031486422716014913, 0.00018383927954475354, 0.003464155820155152, 0.0, 0.06363636363636363, 0.30037141633498726, 0.04, 0.0, 0.11836400697422791, 0.0893522609412382, 0.06627762655134391, 0.18, 0.05753424657534246, 0.0004902791884868981, 0.003081452430135006, 0.010482653348011425, 0.10553481845279611, 0.04, 0.10749999999999998, 0.0593746874886078, 0.043095420937879665, 0.010289152159831155, 0.07540631880139895, 0.0, 0.0, 0.0, 0.03157894736842105, 0.04, 0.03214285714285714, 0.09882926829268292, 0.537382749175379, 0.10602674431717368, 0.00040290010703913253, 0.0, 0.021633589895487394, 0.0, 0.0, 0.00023422139267328276, 0.00023349611538816682, 0.03, 0.0, 0.07749453219991567, 0.19999999999999998, 0.0, 0.02035869745951291, 0.040199517997906456, 0.0, 0.0, 0.16184675879898694, 0.021428571428571425, 0.0, 0.014634146341463414, 0.0, 0.6001258428652341, 0.0, 0.30218632643626797, 0.0402782540290236, 0.3, 0.02, 0.08, 0.00019822591134145175, 0.15362272855676534, 0.26797641025582875, 0.04244161212165373, 0.014394221717442174, 0.012162162162162163, 0.03333333333333333, 0.0, 0.0547112462006079, 0.07334045804634946, 0.03, 0.08, 0.3377287699302137, 0.19, 0.0, 0.04341441837887568, 0.3866005914369258, 0.0, 0.28253199695159065, 0.08035688688065158, 0.0002696812302301848, 0.13518858049092491, 0.09515625, 0.5862595419847327, 0.1228093553867836, 0.04426961942021854, 0.0, 0.0005192759410041587, 0.0, 0.0001950691347312675, 0.02, 0.004983858502903159, 0.0, 0.0, 0.157438989937186, 0.03339184175250268, 0.07515625000000001, 0.04, 0.0002837564986656055, 0.0005215158540955067, 0.02023349611538818, 0.03354145690803381, 0.0, 0.0003254905508545684, 0.04285714285714285, 0.17774741093071703, 0.37668161434977576, 0.1579591836734694, 0.0, 0.06804123711340206, 0.0, 0.2984566904217032, 0.28275189166846737, 0.2110352494244493, 0.0, 0.06, 0.021428571428571425, 0.04, 0.021734591091381535, 0.0, 0.09451737451737452, 0.18387498238757016, 0.0, 0.09150216678237977, 0.0001867651756656778, 0.16, 0.07619047619047618, 0.18, 0.003278688524590164, 0.0, 0.0802800180834927, 0.08183888218043817, 0.0, 0.0, 0.0, 0.06783974974333448, 0.01308738094720047, 0.17273037635126237, 0.07381854588666761, 0.03296996662958843, 0.03, 0.08848619154833898, 0.024489795918367346, 0.00024836842686128124, 0.03610426533612821, 0.062186511042840835, 0.041675597833970374, 0.041583525959921305, 0.12145811654300931, 0.0, 0.013239579259052388, 0.0703125, 0.29549421928960995, 0.0, 0.15066246273817807, 0.0, 0.0009036093193652479, 0.0, 0.24, 0.0, 0.0818851791334321, 0.019572567933919562, 0.10272397387777933, 0.0007432225816248341, 0.0003627913523621846, 0.09371412096618068, 0.0, 0.0, 0.0, 0.2988304785797531, 0.0, 0.06666666666666667, 0.0, 0.06836357506683996, 0.06188964135844799, 0.09999999999999999, 0.03, 0.0005118013152473384, 0.15381279883221546, 0.09515625, 0.07199230687600994, 0.11070971259022452, 0.11357647749045771, 0.04, 0.061386138613861385, 0.18702055095763911, 0.07524163430338587, 0.04, 0.42630106021995795, 0.08782208942339848, 0.0, 0.15039189568410832, 0.055842270096999144, 0.18570909651170167, 0.1070957095709571, 0.0007498060733716656, 0.24021236923176995, 0.06459677419354838, 0.01, 0.1169761273209549, 0.00022820282992979128, 0.00028207375116408946, 0.00028532709413154445, 0.07543123486708307, 0.0, 0.11813117441708759, 0.0, 0.0, 0.035489910307760004, 0.0001600644738435384, 0.014285714285714284, 0.1150807453416149, 0.15122448979591835, 0.00021261827626806938, 0.11673469387755102, 0.2230115163669691, 0.00028491806859603125, 0.0, 0.07276620136487058, 0.3378606000365917, 0.0, 0.18576717400246812, 0.01918508829624853, 0.026578848001547625, 0.4266988176464459, 0.0002930329375525539, 0.004852447888950517, 0.1626026947091686, 0.0, 0.004515410649001783, 0.07867840724684996, 0.03572235424994629, 0.29871222057718294, 0.14384831963368253, 0.11056713635755225, 0.04094778364737175, 0.2988423058089507, 0.0, 0.6019353477602658, 0.07376047578470112, 0.021428571428571425, 0.04, 0.012103787724135541, 0.07086614173228346, 0.09614358681384716, 0.0, 0.0, 0.00016698539951259545, 0.10678207048324895, 0.08, 0.12244897959183673, 0.0683599251806898, 0.0, 0.04028915215983116, 0.053745163089831655, 0.12268247717435057]
Finish training and take 1h26m

Namespace(log_name='./RQ5/java_1/f1_codet5p_770m.log', model_name='Salesforce/codet5p-770m', lang='java', output_dir='RQ5/java_1/f1_codet5p_770m', data_dir='./data/RQ5/java_1_3', no_cuda=False, visible_gpu='0', add_task_prefix=False, add_lang_ids=False, num_train_epochs=10, num_test_epochs=10, train_batch_size=8, eval_batch_size=4, gradient_accumulation_steps=2, load_model_path=None, config_name='', tokenizer_name='', max_source_length=128, max_target_length=128, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, do_lower_case=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, max_steps=-1, eval_steps=-1, train_steps=-1, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, model_name: Salesforce/codet5p-770m
model created!
Total 1 training instances 
***** Running training *****
  Num examples = 1
  Batch size = 8
  Num epoch = 10

***** Running evaluation *****
  Num examples = 100
  Batch size = 4
  epoch = 0
  eval_ppl = 1.00169
  global_step = 1
  train_loss = 0.7063
  ********************
Previous best ppl:inf
Achieve Best ppl:1.00169
  ********************
BLEU file: ./data/RQ5/java_1_3/validation.jsonl
  codebleu-4 = 22.78 	 Previous best codebleu 0
  ********************
 Achieve Best bleu:22.78
  ********************

***** Running evaluation *****
  Num examples = 100
  Batch size = 4
  epoch = 1
  eval_ppl = 1.00169
  global_step = 1
  train_loss = 0.5826
  ********************
Previous best ppl:1.00169
BLEU file: ./data/RQ5/java_1_3/validation.jsonl
  codebleu-4 = 22.78 	 Previous best codebleu 22.78
  ********************

***** Running evaluation *****
  Num examples = 100
  Batch size = 4
  epoch = 2
  eval_ppl = 1.00169
  global_step = 1
  train_loss = 0.6087
  ********************
Previous best ppl:1.00169
BLEU file: ./data/RQ5/java_1_3/validation.jsonl
  codebleu-4 = 22.78 	 Previous best codebleu 22.78
  ********************

***** Running evaluation *****
  Num examples = 100
  Batch size = 4
  epoch = 3
  eval_ppl = 1.00169
  global_step = 1
  train_loss = 0.5446
  ********************
Previous best ppl:1.00169
BLEU file: ./data/RQ5/java_1_3/validation.jsonl
  codebleu-4 = 22.78 	 Previous best codebleu 22.78
  ********************
reload model from RQ5/java_1/f1_codet5p_770m/checkpoint-best-bleu
BLEU file: ./data/RQ5/java_1_3/test.jsonl
  codebleu = 19.37 
  Total = 500 
  Exact Fixed = 0 
[]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  ********************
  Total = 500 
  Exact Fixed = 0 
[]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  codebleu = 19.37 
[0.016129032258064516, 0.26523897285176906, 0.2969316987780919, 0.12410492489125403, 0.03589407023366494, 0.3527924965979186, 0.16415392904500423, 0.03846153846153846, 0.31101968530473323, 0.03225806451612903, 0.36787242193873154, 0.2451877770329363, 0.2594809168155134, 0.3162805294453539, 0.3525851504629833, 0.3224230139314371, 0.29316987308900755, 0.04488146097447045, 0.36711856391583264, 0.2831323605149352, 0.013100475080851999, 0.24190821236341375, 0.16457750707336546, 0.05384615384615384, 0.237924040027988, 0.3144306445046021, 0.38269209166020535, 0.1502669074291631, 0.03375, 0.19577834341522304, 0.31971599590136707, 0.024999999999999998, 0.03994508189258428, 0.3122331057392717, 0.025178584736786726, 0.18565779196297563, 0.5357689599510256, 0.38499320820780236, 0.3144046814513586, 0.35031876401327267, 0.17433523582457477, 0.17126167501818088, 0.04285714285714285, 0.28461607282996837, 0.05018352442447491, 0.33407696631864425, 0.16779101332961016, 0.30711205986405254, 0.023684210526315787, 0.26853513167863285, 0.32557709588995215, 0.03277057917407565, 0.1479751425535235, 0.040298487882672214, 0.3241981738510966, 0.17508387235238537, 0.032473067751521, 0.3224413006424627, 0.16415392904500423, 0.297455624122433, 0.4088423322834489, 0.2688277771521381, 0.32913817743384044, 0.28550712416269064, 0.24597963472768886, 0.3772718169820788, 0.02621359223300971, 0.21263355575408785, 0.03673469387755102, 0.28185234470429327, 0.2560655456782139, 0.015584415584415584, 0.2438083034003801, 0.17126167501818088, 0.34744136414955595, 0.2863195499544832, 0.24576760106727302, 0.5960942096485482, 0.038709677419354833, 0.2396977217202917, 0.2875087764827252, 0.33542362223438255, 0.35808542036573543, 0.05420411474183056, 0.23540939710820372, 0.04285714285714285, 0.04661087686245902, 0.12547646421668116, 0.3281286597678559, 0.019736842105263157, 0.2843416339834175, 0.3244555579102347, 0.16225558647379743, 0.34074853112797, 0.035483870967741936, 0.012897414425898136, 0.31778357866027995, 0.5465480853783484, 0.26298368901470426, 0.02727272727272727, 0.3029314225439768, 0.18384300064183604, 0.04238266531563592, 0.36659185253848725, 0.03116883116883117, 0.1029000964430897, 0.25054900547558445, 0.29383538042381646, 0.022018348623853212, 0.05052631578947368, 0.16327416617001492, 0.25144684698866016, 0.2599090134103196, 0.005825242718446601, 0.29740869194278247, 0.20932533097437606, 0.09642857142857143, 0.02, 0.011538461538461539, 0.035526315789473684, 0.4301819872341954, 0.33106784722584565, 0.015, 0.31096795318959747, 0.2909023481329242, 0.19526221027186386, 0.04285714285714285, 0.2950251810659258, 0.0032143465180191613, 0.17154209505080056, 0.17026125695653727, 0.04591836734693878, 0.3158817642176165, 0.3484817934019728, 0.3063632154270763, 0.3080790475474848, 0.32716619331547425, 0.17268465611903877, 0.20302731867891746, 0.32462010751534653, 0.3018539001333569, 0.27212365348388723, 0.029329698812791346, 0.019148936170212762, 0.036143642959066906, 0.22681120999575957, 0.32621774078086063, 0.278722127664061, 0.4409373150093864, 0.25500032696981867, 0.6202520112195533, 0.3193984320610116, 0.3375178000009185, 0.3129356865761337, 0.17260600223247521, 0.3241981738510966, 0.6202520112195533, 0.2905348074544444, 0.02763157894736842, 0.279560834269795, 0.04285714285714285, 0.1708644233799338, 0.37357299006829714, 0.2952159917247462, 0.3184297676994156, 0.027947320688005484, 0.029126213592233007, 0.4506708743756156, 0.316264140692211, 0.04485402993416629, 0.038709677419354833, 0.04285714285714285, 0.29178377036115394, 0.304788480585707, 0.2365324663714808, 0.20529780564263322, 0.3734407639408129, 0.27641151884249077, 0.0, 0.026074872625563714, 0.1682276929413124, 0.17810295755836925, 0.4622808123522332, 0.2625338328854888, 0.29158096769899344, 0.1368053894749946, 0.0614792804739489, 0.1616549250202055, 0.3755244082278153, 0.018897946149002007, 0.2474464915989423, 0.27944188433796174, 0.32513989461725995, 0.3382855107185453, 0.32340953827464436, 0.5965482589805534, 0.237924040027988, 0.008737864077669903, 0.08674079313150579, 0.05060240963855421, 0.023376623376623374, 0.015584415584415584, 0.042355962623289764, 0.25057865745079566, 0.11449012811527298, 0.2928340540764932, 0.04257776578659765, 0.3501174159250316, 0.3152583553229909, 0.18673115168105595, 0.33820327292526514, 0.017499999999999998, 0.047368421052631574, 0.32032550649473, 0.19919112838866557, 0.3012385768815288, 0.015789473684210523, 0.3645137433027553, 0.1666493877099185, 0.011428571428571429, 0.09965151568212544, 0.1682276929413124, 0.11562874019291422, 0.32201630892757666, 0.3681743989280792, 0.1714319320674253, 0.05237212760488644, 0.18138358173280095, 0.31276945608015366, 0.16779101332961016, 0.3137530013663992, 0.04285714285714285, 0.33217043102594185, 0.038258119993139016, 0.2667719711005361, 0.047368421052631574, 0.17560822667733614, 0.035866480481147336, 0.3055274058334464, 0.028, 0.18565779196297563, 0.004553517295035531, 0.3089463642632105, 0.26090648913430325, 0.1986316421833785, 0.035483870967741936, 0.04054054054054054, 0.17026125695653727, 0.16501421796940463, 0.3051584314235175, 0.3571114332676238, 0.2807031589739921, 0.044785380740634394, 0.016359836667844647, 0.05590457495362949, 0.02, 0.0, 0.0, 0.2821628397578583, 0.03734729859962845, 0.12375441575649651, 0.370698183992132, 0.0375, 0.3532399988708018, 0.156640755291972, 0.2796538813666677, 0.17087994821205074, 0.03405715650698247, 0.3501464314705594, 0.17895472298358212, 0.2953334493490245, 0.3105442862012889, 0.18475396664680602, 0.2714919265764712, 0.023684210526315787, 0.02727272727272727, 0.23523581771222302, 0.19922109407897998, 0.010567762060210074, 0.11525088117054957, 0.26587942156374056, 0.0, 0.3940537257923464, 0.21376711293151784, 0.15869165931839535, 0.00021151902352513035, 0.022464114832535884, 0.3276096267786871, 0.027970289444417602, 0.26908587068508677, 0.19919112838866557, 0.02, 0.07388575843176723, 0.244062137318309, 0.030275229357798167, 0.5908569648271542, 0.23668187412041883, 0.011688311688311687, 0.012903225806451613, 0.023376623376623374, 0.05970791298958393, 0.0, 0.0064516129032258064, 0.32327273214706415, 0.029126213592233007, 0.5999577287544409, 0.035890142874097086, 0.1790504550641606, 0.3781573890807765, 0.5324926621170245, 0.45866273378018063, 0.26239684033922395, 0.11142391522877228, 0.14612286983843556, 0.1867185060235655, 0.3470210331074726, 0.0, 0.34661434747624664, 0.2624439972965403, 0.33629170121656027, 0.3398329539073416, 0.3092337049338043, 0.3321222610389871, 0.2786728744697542, 0.03216725187380051, 0.02542372881355932, 0.34134091081910367, 0.023708770245817714, 0.18253697138266703, 0.01062200956937799, 0.02722790799481469, 0.3480215499285323, 0.04201648169239484, 0.30248971611643016, 0.31268439260979686, 0.025179659290865422, 0.3173872276023094, 0.26412686887849957, 0.1980575840950728, 0.07923470742217217, 0.02692307692307692, 0.027499999999999997, 0.16710455991615358, 0.2871138872902549, 0.27187870318872104, 0.3298294096115237, 0.13205832573319415, 0.17026125695653727, 0.2549419036325214, 0.03189468910905811, 0.3906535944051172, 0.11400374443461703, 0.03636439145230408, 0.24644190658361245, 0.32789202568382175, 0.3685831132852607, 0.357565165454469, 0.2828777105998992, 0.025806451612903226, 0.10211072019276213, 0.03586800573888092, 0.280946021238787, 0.03651155359670512, 0.31797067263863393, 0.1479751425535235, 0.0325, 0.30474189472342134, 0.22972945339685696, 0.3257520401727422, 0.3158215722606528, 0.3571543702222129, 0.04074074074074074, 0.07693639078708148, 0.28208398104406984, 0.015384615384615384, 0.300701962753217, 0.1919249850272328, 0.01875, 0.32989141082681694, 0.03882706560120711, 0.3180958729139289, 0.3101389510447363, 0.07312697741279463, 0.039473684210526314, 0.05384615384615384, 0.310454032249235, 0.32285288990839134, 0.04444444444444444, 0.32410526273716056, 0.053800005631646775, 0.03225806451612903, 0.03506493506493506, 0.05034279245328826, 0.02939671070968976, 0.03, 0.2413748965031429, 0.2998902528710594, 0.3506849298873027, 0.3013841316944174, 0.3220362369236246, 0.10895449523019984, 0.039473684210526314, 0.3098695310008889, 0.060426234008119986, 0.3017937442988387, 0.3003101869373235, 0.40167778442958724, 0.2715181642444345, 0.31108272683123345, 0.32515132264242214, 0.052743268405923374, 0.2865125415014886, 0.007792207792207792, 0.02222222222222222, 0.3090988479145487, 0.2481187606341247, 0.02763157894736842, 0.012244897959183673, 0.3303464031214605, 0.36268472387399375, 0.08674079313150579, 0.2591424381031991, 0.3390959829963569, 0.037864077669902914, 0.23065680447167827, 0.3148009776488973, 0.2683446883006529, 0.0, 0.1523448075317397, 0.09909524575261429, 0.27614944630488564, 0.29672411716191527, 0.022018348623853212, 0.11377433816470409, 0.018897946149002007, 0.2117363738594092, 0.020388349514563104, 0.0379746835443038, 0.019354838709677417, 0.2687387994332012, 0.0225, 0.332650183984684, 0.31968253162884674, 0.0680355591514058, 0.049219049287630615, 0.03253063436157963, 0.2861783007340068, 0.04538331212830482, 0.27120080908403177, 0.3754636004158611, 0.5928411428440299, 0.012028879695409368, 0.20090089599991534, 0.31344560664705623, 0.03846153846153846, 0.2519041230487654, 0.31787739146318483, 0.17393060224060686, 0.5455268993378968, 0.23550966398579973, 0.3569202532826443, 0.2875609538225004, 0.2652821981690426, 0.2958774332057123, 0.029447204842719864, 0.3403171878119327, 0.03813559322033898, 0.023076923076923078, 0.022315165957716872, 0.05231085147908167, 0.3295911502100738, 0.03461538461538462, 0.13895177122036115, 0.027966101694915254, 0.18553691835339825, 0.026411483253588514, 0.2860228066419273, 0.005, 0.30345346635045806, 0.3710188194124737, 0.061916858058290815, 0.1781978349974921, 0.05789150688006059, 0.3137197866915396, 0.04285714285714285, 0.33675242857218723, 0.08289473684210527, 0.3040381040521424, 0.18475396664680602, 0.049999999999999996, 0.0, 0.297876322144381, 0.0303030303030303, 0.03614457831325301, 0.035526315789473684, 0.03932209928515763, 0.22424957109087662, 0.05467095579361856, 0.025806451612903226, 0.17026125695653727]
Finish training and take 54m

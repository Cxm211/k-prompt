Namespace(log_name='./RQ5/python_5/f1_codet5p_220m.log', model_name='Salesforce/codet5p-220m', lang='java', output_dir='RQ5/python_5/f1_codet5p_220m', data_dir='./data/RQ5/python_5_1', no_cuda=False, visible_gpu='0', add_task_prefix=False, add_lang_ids=False, num_train_epochs=10, num_test_epochs=10, train_batch_size=8, eval_batch_size=4, gradient_accumulation_steps=2, load_model_path=None, config_name='', tokenizer_name='', max_source_length=128, max_target_length=128, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, do_lower_case=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, max_steps=-1, eval_steps=-1, train_steps=-1, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, model_name: Salesforce/codet5p-220m
model created!
Total 5 training instances 
***** Running training *****
  Num examples = 5
  Batch size = 8
  Num epoch = 10

***** Running evaluation *****
  Num examples = 103
  Batch size = 4
  epoch = 0
  eval_ppl = 1.00267
  global_step = 2
  train_loss = 1.1056
  ********************
Previous best ppl:inf
Achieve Best ppl:1.00267
  ********************
BLEU file: ./data/RQ5/python_5_1/validation.jsonl
  codebleu-4 = 9.6 	 Previous best codebleu 0
  ********************
 Achieve Best bleu:9.6
  ********************

***** Running evaluation *****
  Num examples = 103
  Batch size = 4
  epoch = 1
  eval_ppl = 1.00221
  global_step = 3
  train_loss = 0.9481
  ********************
Previous best ppl:1.00267
Achieve Best ppl:1.00221
  ********************
BLEU file: ./data/RQ5/python_5_1/validation.jsonl
  codebleu-4 = 8.79 	 Previous best codebleu 9.6
  ********************

***** Running evaluation *****
  Num examples = 103
  Batch size = 4
  epoch = 2
  eval_ppl = 1.00205
  global_step = 4
  train_loss = 0.7655
  ********************
Previous best ppl:1.00221
Achieve Best ppl:1.00205
  ********************
BLEU file: ./data/RQ5/python_5_1/validation.jsonl
  codebleu-4 = 18.66 	 Previous best codebleu 9.6
  ********************
 Achieve Best bleu:18.66
  ********************

***** Running evaluation *****
  Num examples = 103
  Batch size = 4
  epoch = 3
  eval_ppl = 1.00196
  global_step = 5
  train_loss = 0.3939
  ********************
Previous best ppl:1.00205
Achieve Best ppl:1.00196
  ********************
BLEU file: ./data/RQ5/python_5_1/validation.jsonl
  codebleu-4 = 22.84 	 Previous best codebleu 18.66
  ********************
 Achieve Best bleu:22.84
  ********************

***** Running evaluation *****
  Num examples = 103
  Batch size = 4
  epoch = 4
  eval_ppl = 1.00192
  global_step = 6
  train_loss = 0.485
  ********************
Previous best ppl:1.00196
Achieve Best ppl:1.00192
  ********************
BLEU file: ./data/RQ5/python_5_1/validation.jsonl
  codebleu-4 = 31.84 	 Previous best codebleu 22.84
  ********************
 Achieve Best bleu:31.84
  ********************

***** Running evaluation *****
  Num examples = 103
  Batch size = 4
  epoch = 5
  eval_ppl = 1.0019
  global_step = 7
  train_loss = 0.2324
  ********************
Previous best ppl:1.00192
Achieve Best ppl:1.0019
  ********************
BLEU file: ./data/RQ5/python_5_1/validation.jsonl
  codebleu-4 = 33.91 	 Previous best codebleu 31.84
  ********************
 Achieve Best bleu:33.91
  ********************

***** Running evaluation *****
  Num examples = 103
  Batch size = 4
  epoch = 6
  eval_ppl = 1.00186
  global_step = 8
  train_loss = 0.3208
  ********************
Previous best ppl:1.0019
Achieve Best ppl:1.00186
  ********************
BLEU file: ./data/RQ5/python_5_1/validation.jsonl
  codebleu-4 = 35.15 	 Previous best codebleu 33.91
  ********************
 Achieve Best bleu:35.15
  ********************

***** Running evaluation *****
  Num examples = 103
  Batch size = 4
  epoch = 7
  eval_ppl = 1.00184
  global_step = 9
  train_loss = 0.3442
  ********************
Previous best ppl:1.00186
Achieve Best ppl:1.00184
  ********************
BLEU file: ./data/RQ5/python_5_1/validation.jsonl
  codebleu-4 = 41.4 	 Previous best codebleu 35.15
  ********************
 Achieve Best bleu:41.4
  ********************

***** Running evaluation *****
  Num examples = 103
  Batch size = 4
  epoch = 8
  eval_ppl = 1.00183
  global_step = 10
  train_loss = 0.2786
  ********************
Previous best ppl:1.00184
Achieve Best ppl:1.00183
  ********************
BLEU file: ./data/RQ5/python_5_1/validation.jsonl
  codebleu-4 = 42.98 	 Previous best codebleu 41.4
  ********************
 Achieve Best bleu:42.98
  ********************

***** Running evaluation *****
  Num examples = 103
  Batch size = 4
  epoch = 9
  eval_ppl = 1.00182
  global_step = 11
  train_loss = 0.1936
  ********************
Previous best ppl:1.00183
Achieve Best ppl:1.00182
  ********************
BLEU file: ./data/RQ5/python_5_1/validation.jsonl
  codebleu-4 = 43.79 	 Previous best codebleu 42.98
  ********************
 Achieve Best bleu:43.79
  ********************
reload model from RQ5/python_5/f1_codet5p_220m/checkpoint-best-bleu
BLEU file: ./data/RQ5/python_5_1/test.jsonl
  codebleu = 46.1 
  Total = 113 
  Exact Fixed = 0 
[]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  ********************
  Total = 113 
  Exact Fixed = 0 
[]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  codebleu = 46.1 
[0.6522256774960772, 0.8362793833462014, 0.3413082256129578, 0.55192711207797, 0.25499728916868175, 0.0593648785553158, 0.8546960927286607, 0.36145429575809385, 0.3747758627188692, 0.9097526997716585, 0.5469918077384597, 0.3048162353426246, 0.10243807061860341, 0.787419092526321, 0.6241043468225718, 0.22814487448762621, 0.5291227835568806, 0.13144490233849698, 0.31417863854170347, 0.8111357386966389, 0.08162546040109103, 0.7091715069289511, 0.8734757335097882, 0.40681117107915826, 0.23397353172656998, 0.7835962902891767, 0.2731171788933564, 0.23148123384936914, 0.13064511634004067, 0.28500496992960367, 0.05795077312340839, 0.86839194611479, 0.7353699168505481, 0.24836536265023107, 0.39323563371077447, 0.3171242951268993, 0.5945626053180312, 0.28350316129355385, 0.9142445273649933, 0.6821832079458738, 0.7077635080859459, 0.08013519046915335, 0.2829347502785373, 0.4098071860331237, 0.16517124435979352, 0.10831825704993286, 0.9112106089658587, 0.5333761527685988, 0.558670102717157, 0.2699084665733675, 0.3345936947346933, 0.6631089054737493, 0.28965720884750357, 0.36715617392249705, 0.18315660672020034, 0.6764585773631465, 0.22947835260387606, 0.2801388034047821, 0.6283358045907946, 0.8645054825240843, 0.5028707920892315, 0.17639744336831423, 0.2414798516626656, 0.15142943103353035, 0.7376821655242644, 0.6723128964817018, 0.3370917728510338, 0.827520741514125, 0.7813508298443214, 0.18547572201149107, 0.21191368764087837, 0.23686103931799313, 0.8118783298082308, 0.7810321610524646, 0.2648698806108579, 0.2029628709946939, 0.8036912296313905, 0.033935374538693476, 0.4706328396310464, 0.10339158199757663, 0.6245445910843439, 0.01717746051437937, 0.2558315361921705, 0.8091085204709254, 0.1640071739081536, 0.1188591896872372, 0.5106856388873968, 0.26074010517725554, 0.8459045563046029, 0.9173081320200047, 0.7741060622474224, 0.2793441829705805, 0.611932112211434, 0.07521481083589003, 0.3444685066552163, 0.16867270369898357, 0.7967424781098473, 0.7921312815681449, 0.23555424059936636, 0.28264582040330233, 0.8001014953161311, 0.802939186005293, 0.25651429367891415, 0.7485101376175234, 0.23470511130957553, 0.7643130284485444, 0.3008314314574208, 0.7469631735672339, 0.06640792747425649, 0.03930171134212569, 0.8136404633300387, 0.9552117847742996, 0.9175347987671937]
Finish training and take 42m
Namespace(log_name='./RQ5/python_5/f1_codet5p_220m.log', model_name='Salesforce/codet5p-220m', lang='python', output_dir='RQ5/python_5/f1_codet5p_220m', data_dir='./data/RQ5/python_5_1', no_cuda=False, visible_gpu='0', add_task_prefix=False, add_lang_ids=False, num_train_epochs=10, num_test_epochs=10, train_batch_size=8, eval_batch_size=4, gradient_accumulation_steps=2, load_model_path=None, config_name='', tokenizer_name='', max_source_length=128, max_target_length=128, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, do_lower_case=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, max_steps=-1, eval_steps=-1, train_steps=-1, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, model_name: Salesforce/codet5p-220m
model created!
Total 5 training instances 
***** Running training *****
  Num examples = 5
  Batch size = 8
  Num epoch = 10

***** Running evaluation *****
  Num examples = 103
  Batch size = 4
  epoch = 0
  eval_ppl = 1.00267
  global_step = 2
  train_loss = 1.1056
  ********************
Previous best ppl:inf
Achieve Best ppl:1.00267
  ********************
BLEU file: ./data/RQ5/python_5_1/validation.jsonl
Namespace(log_name='./RQ5/python_5/f1_codet5p_220m.log', model_name='Salesforce/codet5p-220m', lang='python', output_dir='RQ5/python_5/f1_codet5p_220m', data_dir='./data/RQ5/python_5_1', no_cuda=False, visible_gpu='0', add_task_prefix=False, add_lang_ids=False, num_train_epochs=10, num_test_epochs=10, train_batch_size=8, eval_batch_size=4, gradient_accumulation_steps=2, load_model_path=None, config_name='', tokenizer_name='', max_source_length=128, max_target_length=128, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, do_lower_case=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, max_steps=-1, eval_steps=-1, train_steps=-1, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, model_name: Salesforce/codet5p-220m
model created!
Total 5 training instances 
***** Running training *****
  Num examples = 5
  Batch size = 8
  Num epoch = 10

***** Running evaluation *****
  Num examples = 103
  Batch size = 4
  epoch = 0
  eval_ppl = 1.00267
  global_step = 2
  train_loss = 1.1056
  ********************
Previous best ppl:inf
Achieve Best ppl:1.00267
  ********************
BLEU file: ./data/RQ5/python_5_1/validation.jsonl
  codebleu-4 = 12.88 	 Previous best codebleu 0
  ********************
 Achieve Best bleu:12.88
  ********************

***** Running evaluation *****
  Num examples = 103
  Batch size = 4
  epoch = 1
  eval_ppl = 1.00221
  global_step = 3
  train_loss = 0.9481
  ********************
Previous best ppl:1.00267
Achieve Best ppl:1.00221
  ********************
BLEU file: ./data/RQ5/python_5_1/validation.jsonl
  codebleu-4 = 14.01 	 Previous best codebleu 12.88
  ********************
 Achieve Best bleu:14.01
  ********************

***** Running evaluation *****
  Num examples = 103
  Batch size = 4
  epoch = 2
  eval_ppl = 1.00205
  global_step = 4
  train_loss = 0.7655
  ********************
Previous best ppl:1.00221
Achieve Best ppl:1.00205
  ********************
BLEU file: ./data/RQ5/python_5_1/validation.jsonl
  codebleu-4 = 22.22 	 Previous best codebleu 14.01
  ********************
 Achieve Best bleu:22.22
  ********************

***** Running evaluation *****
  Num examples = 103
  Batch size = 4
  epoch = 3
  eval_ppl = 1.00196
  global_step = 5
  train_loss = 0.3939
  ********************
Previous best ppl:1.00205
Achieve Best ppl:1.00196
  ********************
BLEU file: ./data/RQ5/python_5_1/validation.jsonl
  codebleu-4 = 27.73 	 Previous best codebleu 22.22
  ********************
 Achieve Best bleu:27.73
  ********************

***** Running evaluation *****
  Num examples = 103
  Batch size = 4
  epoch = 4
  eval_ppl = 1.00192
  global_step = 6
  train_loss = 0.485
  ********************
Previous best ppl:1.00196
Achieve Best ppl:1.00192
  ********************
BLEU file: ./data/RQ5/python_5_1/validation.jsonl
  codebleu-4 = 35.27 	 Previous best codebleu 27.73
  ********************
 Achieve Best bleu:35.27
  ********************

***** Running evaluation *****
  Num examples = 103
  Batch size = 4
  epoch = 5
  eval_ppl = 1.0019
  global_step = 7
  train_loss = 0.2324
  ********************
Previous best ppl:1.00192
Achieve Best ppl:1.0019
  ********************
BLEU file: ./data/RQ5/python_5_1/validation.jsonl
  codebleu-4 = 36.82 	 Previous best codebleu 35.27
  ********************
 Achieve Best bleu:36.82
  ********************

***** Running evaluation *****
  Num examples = 103
  Batch size = 4
  epoch = 6
  eval_ppl = 1.00186
  global_step = 8
  train_loss = 0.3208
  ********************
Previous best ppl:1.0019
Achieve Best ppl:1.00186
  ********************
BLEU file: ./data/RQ5/python_5_1/validation.jsonl
  codebleu-4 = 39.56 	 Previous best codebleu 36.82
  ********************
 Achieve Best bleu:39.56
  ********************

***** Running evaluation *****
  Num examples = 103
  Batch size = 4
  epoch = 7
  eval_ppl = 1.00184
  global_step = 9
  train_loss = 0.3442
  ********************
Previous best ppl:1.00186
Achieve Best ppl:1.00184
  ********************
BLEU file: ./data/RQ5/python_5_1/validation.jsonl
  codebleu-4 = 45.17 	 Previous best codebleu 39.56
  ********************
 Achieve Best bleu:45.17
  ********************

***** Running evaluation *****
  Num examples = 103
  Batch size = 4
  epoch = 8
  eval_ppl = 1.00183
  global_step = 10
  train_loss = 0.2786
  ********************
Previous best ppl:1.00184
Achieve Best ppl:1.00183
  ********************
BLEU file: ./data/RQ5/python_5_1/validation.jsonl
  codebleu-4 = 46.22 	 Previous best codebleu 45.17
  ********************
 Achieve Best bleu:46.22
  ********************

***** Running evaluation *****
  Num examples = 103
  Batch size = 4
  epoch = 9
  eval_ppl = 1.00182
  global_step = 11
  train_loss = 0.1936
  ********************
Previous best ppl:1.00183
Achieve Best ppl:1.00182
  ********************
BLEU file: ./data/RQ5/python_5_1/validation.jsonl
  codebleu-4 = 46.8 	 Previous best codebleu 46.22
  ********************
 Achieve Best bleu:46.8
  ********************
reload model from RQ5/python_5/f1_codet5p_220m/checkpoint-best-bleu
BLEU file: ./data/RQ5/python_5_1/test.jsonl
  codebleu = 48.85 
  Total = 113 
  Exact Fixed = 0 
[]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  ********************
  Total = 113 
  Exact Fixed = 0 
[]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  codebleu = 48.85 
[0.6728230800934798, 0.7716304088583943, 0.31361203633687884, 0.47166395418323315, 0.21940872203752407, 0.32202230512360086, 0.8674433454759134, 0.3608020784634865, 0.5571314709024371, 0.7953587603777192, 0.7275487275290159, 0.3445680662891013, 0.23044535730009721, 0.7768711691119308, 0.5156627883810132, 0.2882251500222055, 0.23292013478000712, 0.24453297659505527, 0.2974211097554385, 0.8884573785188872, 0.29341625082188516, 0.7520456315632097, 0.8517652071939987, 0.3805222600182908, 0.24894381964133006, 0.6508693332230462, 0.11978004790233125, 0.25690146229577737, 0.2120110323888025, 0.23939658711734124, 0.36365780279749493, 0.8808919461147899, 0.7420541780659815, 0.2668661762533687, 0.2607171000360527, 0.22678638057105874, 0.6612058804381958, 0.3380735908639835, 0.9142445273649933, 0.7093853536262804, 0.712891713214151, 0.24104066267256702, 0.31046767709914114, 0.37307116057981976, 0.19129734492819347, 0.23330576187330554, 0.8077895563342797, 0.6323479512961402, 0.549916846856608, 0.44293770559624357, 0.3317471689296842, 0.7545477642400293, 0.3153980960950289, 0.515599849811825, 0.3064195216762281, 0.5117566728908322, 0.27522925740083354, 0.34350294718891033, 0.309032277714195, 0.860117164263619, 0.8202681121066357, 0.17195268779536874, 0.1650736998897046, 0.435794370343859, 0.8475332565755729, 0.6896725238481038, 0.37727661378691313, 0.7890278782295435, 0.6441425627537012, 0.17312084585050033, 0.1770620686043954, 0.2693202213444841, 0.8450968335293472, 0.676525822803221, 0.22784147108119296, 0.18059020018724048, 0.769112175007131, 0.2946844421877273, 0.7449734989717058, 0.5274862020215074, 0.8727790091136098, 0.16575677085920693, 0.23712232797053226, 0.8358395384567638, 0.2665178639329171, 0.32168002191289596, 0.44554278174453965, 0.20253794855155258, 0.8627606169106636, 0.9178662308912058, 0.8282346736174131, 0.24506112067272004, 0.5266112195874727, 0.29883831275374145, 0.37101563946155314, 0.7205804549974631, 0.6584716430730965, 0.7524846671788035, 0.2577352814023395, 0.34332172834015473, 0.7225931341121177, 0.7768277736984348, 0.298336356676029, 0.5060250431836375, 0.19658141841339466, 0.6376188828854137, 0.4346724524311052, 0.7372865825878999, 0.05289040548972139, 0.24645788849830286, 0.7340832194013065, 0.7669617847742995, 0.8444933588138556]
Finish training and take 43m

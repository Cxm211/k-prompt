Namespace(log_name='./RQ5/tfix_1_1/codet5p_220m_f.log', model_name='Salesforce/codet5p-220m', lang='javascript', output_dir='RQ5/tfix_1_1/codet5p_220m_f', data_dir='./data/RQ5/tfix_1_1', no_cuda=False, visible_gpu='0', add_task_prefix=False, add_lang_ids=False, num_train_epochs=10, num_test_epochs=10, train_batch_size=8, eval_batch_size=4, gradient_accumulation_steps=2, load_model_path=None, config_name='', tokenizer_name='', max_source_length=512, max_target_length=512, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, do_lower_case=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, max_steps=-1, eval_steps=-1, train_steps=-1, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, model_name: Salesforce/codet5p-220m
model created!
Total 1 training instances 
***** Running training *****
  Num examples = 1
  Batch size = 8
  Num epoch = 10

***** Running evaluation *****
  Num examples = 100
  Batch size = 4
  epoch = 0
  eval_ppl = 1.01652
  global_step = 1
  train_loss = 4.2198
  ********************
Previous best ppl:inf
Achieve Best ppl:1.01652
  ********************
BLEU file: ./data/RQ5/tfix_1_1/validation.jsonl
  codebleu-4 = 8.0 	 Previous best codebleu 0
  ********************
 Achieve Best bleu:8.0
  ********************

***** Running evaluation *****
  Num examples = 100
  Batch size = 4
  epoch = 1
  eval_ppl = 1.01652
  global_step = 1
  train_loss = 3.1294
  ********************
Previous best ppl:1.01652
BLEU file: ./data/RQ5/tfix_1_1/validation.jsonl
  codebleu-4 = 8.0 	 Previous best codebleu 8.0
  ********************

***** Running evaluation *****
  Num examples = 100
  Batch size = 4
  epoch = 2
  eval_ppl = 1.01652
  global_step = 1
  train_loss = 3.199
  ********************
Previous best ppl:1.01652
BLEU file: ./data/RQ5/tfix_1_1/validation.jsonl
  codebleu-4 = 8.0 	 Previous best codebleu 8.0
  ********************

***** Running evaluation *****
  Num examples = 100
  Batch size = 4
  epoch = 3
  eval_ppl = 1.01652
  global_step = 1
  train_loss = 3.7239
  ********************
Previous best ppl:1.01652
BLEU file: ./data/RQ5/tfix_1_1/validation.jsonl
  codebleu-4 = 8.0 	 Previous best codebleu 8.0
  ********************
reload model from RQ5/tfix_1_1/codet5p_220m_f/checkpoint-best-bleu
BLEU file: ./data/RQ5/tfix_1_1/test.jsonl
  codebleu = 8.9 
  Total = 500 
  Exact Fixed = 0 
[]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  ********************
  Total = 500 
  Exact Fixed = 0 
[]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  codebleu = 8.9 
[0.0, 0.02, 0.23805061789804505, 0.0, 0.0, 0.020231698433601536, 0.0, 0.06568420415775672, 0.016981132075471698, 0.04285714285714285, 0.02, 0.00034757863906829397, 0.03333333333333333, 0.0, 0.06, 0.026811483682793846, 0.021428571428571425, 0.0, 0.03, 0.09355322338830585, 0.047757378629445714, 0.0, 0.0, 0.15916295353775126, 0.33780037708830607, 0.22911616373042168, 0.22499999999999998, 0.075, 0.0, 0.06, 0.02, 0.08372454260803608, 0.08691781375924082, 0.03662831887037895, 0.0, 0.0, 0.04, 0.041379310344827586, 0.07815831952777592, 0.0, 0.012536688412309687, 0.0, 0.16629091767405862, 0.00035479984220565145, 0.09626139342678772, 0.0, 0.2015195833451859, 0.0, 0.0, 0.02727272727272727, 0.10760057285478816, 0.23661971830985912, 0.04527714885454336, 0.2601327521582192, 0.30037141633498726, 0.0, 0.007716974543857631, 0.0, 0.21675940492084103, 0.44799705737378326, 0.12272665483457824, 0.0, 0.15175079924670454, 0.03632955543007352, 0.07749453219991567, 0.20953404606697032, 0.0, 0.12784296824833571, 0.0002334961162260458, 0.040184646489905336, 0.09194426466759831, 0.0, 0.03639455782312925, 0.036, 0.14123931623931624, 0.00022059644370572292, 0.09145662847790507, 0.00839981694718259, 0.5963006740931145, 0.26477348071584134, 0.0, 0.0, 0.0, 0.2793103448275862, 0.1663070569241623, 0.0, 0.0067415730337078645, 0.00019960223845056353, 0.04, 0.060107418240230415, 0.0002776752417451163, 0.33302414895759214, 0.0591904122151614, 0.022499905069572963, 0.036628879222626885, 0.05787935737172772, 0.11708842965603142, 0.02222222222222222, 0.04313336590784968, 0.0, 0.0, 0.04, 0.03214285714285714, 0.3698586555468796, 0.16113673128524508, 0.0, 0.15694212111073935, 0.012103787724135541, 0.0, 0.04285714285714285, 0.38461538461538464, 0.06945696428475706, 0.0003047612813754688, 0.07519657612447127, 0.03260869565217391, 0.0184831132805018, 0.3106592105134916, 0.03214285714285714, 0.0002573308374538352, 0.03784675197180019, 0.08381215318883803, 0.0006477741618237837, 0.0, 0.06923076923076923, 0.15022912341949193, 0.03625733099190305, 0.004304196373687458, 0.19492358743768232, 0.1926112306071761, 0.0, 0.0, 0.0, 0.11057680518954137, 0.035642234788913464, 0.05559105431309904, 0.06666666666666667, 0.1113789457339341, 0.01629582832537571, 0.06306818181818181, 0.10023546620261521, 0.05357142857142857, 0.0, 0.02, 0.02222222222222222, 0.0, 0.0, 0.1817643269758196, 0.022455718337619463, 0.09502609231902673, 0.0, 0.04, 0.0, 0.1695843101912936, 0.10931157551277569, 0.0, 0.07555555555555556, 0.45047156056251614, 0.0, 0.19629080740794644, 0.0, 0.09774216694570677, 0.00028914876158781796, 0.08707947311622521, 0.1581063570686056, 0.29, 0.0, 0.0, 0.07325581395348836, 0.015280133977024919, 0.02608695652173913, 0.07515625000000001, 0.07894736842105263, 0.002243110661158092, 0.0, 0.0, 0.02, 0.5917605592680589, 0.05746227617858743, 0.2982053196798774, 0.02, 0.3003712053311756, 0.0, 0.04, 0.06, 0.0, 0.021428571428571425, 0.09999999999999999, 0.1530684384018517, 0.46956455944825376, 0.00857142857142857, 0.0, 0.0003688283273764759, 0.04285714285714285, 0.021428571428571425, 0.4775433352141639, 0.0, 0.0945578231292517, 0.10039950378535825, 0.00046952755994335483, 0.34417712939360523, 0.03194910810933169, 0.0, 0.17289610291128407, 0.0, 0.0525010272248546, 0.3377283753082555, 0.18772852896615871, 0.13197705392029108, 0.19, 0.0, 0.12213606232036155, 0.0, 0.0003451163064011043, 0.0, 0.014603455352296898, 0.12722399152222358, 0.06, 0.32002867916298966, 0.0001756352113293001, 0.1646876250955414, 0.0, 0.4465755063793754, 0.15, 0.0, 0.30022820272160156, 0.23100427108948116, 0.26797641025582875, 0.0, 0.5915481028795357, 0.00026832186254608953, 0.0, 0.049999999999999996, 0.09930305850606094, 0.07106682944955937, 0.060288790571006806, 0.12854128922266217, 0.06754023768295395, 0.00028034413651807546, 0.43606856837889296, 0.0, 0.06, 0.00011960841056168018, 0.4770163428336524, 0.2898876404494382, 0.05357142857142857, 0.0, 0.08742082525986877, 0.0, 0.02215651810904784, 0.03778217833180493, 0.0, 0.19, 0.0539086156508692, 0.0, 0.0, 0.0, 0.15774591919513703, 0.10852173913043477, 0.0, 0.29671413975357536, 0.07643867257451495, 0.17834066391769643, 0.04, 0.18274856999325872, 0.00029381519384894016, 0.1032169256220856, 0.0, 0.1161885253632598, 0.0, 0.08, 0.00013499558291079809, 0.06, 0.0, 0.04, 0.03630749150244325, 0.2401032953916197, 0.3084604578903368, 0.1503730470062547, 0.0, 0.020689655172413793, 0.15267586684382622, 0.4000962989374772, 0.0, 0.0, 0.0526558499796007, 0.05360230547550432, 0.08344671201814058, 0.00026310515656618045, 0.007320306043699406, 0.21575483182040928, 0.0854385461752231, 0.0002696472493531126, 0.00023303932035671624, 0.15164778230292306, 0.0, 0.00018398584786665618, 0.22530967159759097, 0.2074988960979138, 0.06017108930258991, 0.023184684885044257, 0.0, 0.0, 0.16302979468541973, 0.02727272727272727, 0.18488678139998915, 0.000238717422175849, 0.00019960223845056353, 0.02299503620696933, 0.0, 0.00022681847204221006, 0.00041743594210530134, 0.11516531220831963, 0.18773351726651943, 0.00029274209485586705, 0.0523963133640553, 0.0, 0.0, 0.200154589791152, 0.13846153846153847, 0.3, 0.16304347826086954, 0.006474256294885302, 0.06968637353427132, 0.0, 0.16531800534337612, 0.05421686746987952, 0.02, 0.12268247572812732, 0.18, 0.0, 0.0002770868652837186, 0.054707447472731804, 0.003881390441000099, 0.00035437757836472255, 0.05489710437312207, 0.06915632754342432, 0.02, 0.0, 0.0, 0.06688182065891832, 0.0, 0.024338666439275732, 0.00019955590325981357, 0.0, 0.04, 0.1984160156584473, 0.00018531562838786225, 0.07041718680957562, 0.07515625000000001, 0.004740678013130337, 0.0, 0.08035481614213923, 0.0, 0.0, 0.5959274429225132, 0.03214285714285714, 0.08372439486549133, 0.04285714285714285, 0.0, 0.09882926829268292, 0.0, 0.0, 0.17482432040224868, 0.33999999999999997, 0.0, 0.043825448946157, 0.0, 0.33111632039817634, 0.014012234001371448, 0.0, 0.0, 0.33194910810933165, 0.011448882192825556, 0.10666666666666667, 0.3029296132316057, 0.057142857142857134, 0.02168674632660286, 0.021428571428571425, 0.08372594557469415, 0.024999999999999998, 0.0, 0.11357647749045771, 0.17745955593541826, 0.0, 0.04019951778106755, 0.061538461538461535, 0.5866967742548903, 0.003223939064166333, 0.541061854541675, 0.12718054524020211, 0.1127777003948209, 0.16444444444444445, 0.22408202610025932, 0.3, 0.004769724286705766, 0.0978287407551812, 0.0, 0.06179579237591537, 0.13039666723668691, 0.00035479984220565145, 0.03333333333333333, 0.12279813772340233, 0.022511370986518564, 0.18, 0.10443046220880609, 0.0, 0.0, 0.0, 0.24, 0.5940936592614818, 0.29871222057718294, 0.18939704301792903, 0.5862960441982066, 0.0037735849056603774, 0.07364797888847682, 0.2986206992166982, 0.0, 0.03, 0.00015775246633903463, 0.00026770267239860005, 0.021428571428571425, 0.0, 0.0001905031636395449, 0.0, 0.00022690291873633293, 0.47703532534920245, 0.11597222222222223, 0.30363343961501144, 0.00035234718367973134, 0.0, 0.022499897737465215, 0.0, 0.0, 0.025591831016575632, 0.30022820347454077, 0.0, 0.09257821433862937, 0.036585365853658534, 0.12334059272501924, 0.00014371651532206318, 0.09721897375840428, 0.31262652294735693, 0.0003487956866342327, 0.07142857142857142, 0.24163603622690616, 0.08682596473294148, 0.04, 0.22568610096749345, 0.08135466195530595, 0.22180662147559094, 0.06, 0.0, 0.0, 0.0005318769969229302, 0.040354843678856556, 0.04, 0.258249662080247, 0.06230695812487068, 0.03214285714285714, 0.1575, 0.0, 0.0737028838704902, 0.02630942688626862, 0.07044642299970147, 0.10024702410889164, 0.02, 0.0, 0.0004639015567279213, 0.0, 0.5930232558139534, 0.005859852608202974, 0.0014074574942521865, 0.20030269956074828, 0.14290732140712145, 0.29377146256962644, 0.0001256012099242293, 0.1314016878503572, 0.0, 0.11676306707680564, 0.12842004228093837, 0.08931078735501795, 0.08322233806489132, 0.35019973768875595, 0.024514845447620708, 0.18, 0.06229040298961967, 0.00027767524274151587, 0.07582269398018188, 0.0, 0.0, 0.0, 0.06, 0.0, 0.0, 0.17109307222813683, 0.15, 0.0, 0.04, 0.07795183478024426, 0.23684005065496708]
Finish training and take 50m

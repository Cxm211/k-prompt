Namespace(log_name='./RQ5/xcodeeval_1_2/codet5p_770m_f.log', model_name='Salesforce/codet5p-770m', lang='c', output_dir='RQ5/xcodeeval_1_2/codet5p_770m_f', data_dir='./data/RQ5/xcodeeval_1_2', no_cuda=False, visible_gpu='0', add_task_prefix=False, add_lang_ids=False, num_train_epochs=10, num_test_epochs=10, train_batch_size=4, eval_batch_size=4, gradient_accumulation_steps=2, load_model_path=None, config_name='', tokenizer_name='', max_source_length=512, max_target_length=512, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, do_lower_case=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, max_steps=-1, eval_steps=-1, train_steps=-1, local_rank=-1, seed=42, early_stop_threshold=2)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, model_name: Salesforce/codet5p-770m
model created!
Total 1 training instances 
***** Running training *****
  Num examples = 1
  Batch size = 4
  Num epoch = 10

***** Running evaluation *****
  Num examples = 100
  Batch size = 4
  epoch = 0
  eval_ppl = 1.0005
  global_step = 1
  train_loss = 1.1144
  ********************
Previous best ppl:inf
Achieve Best ppl:1.0005
  ********************
BLEU file: ./data/RQ5/xcodeeval_1_2/validation.jsonl
  codebleu-4 = 5.6 	 Previous best codebleu 0
  ********************
 Achieve Best bleu:5.6
  ********************

***** Running evaluation *****
  Num examples = 100
  Batch size = 4
  epoch = 1
  eval_ppl = 1.0005
  global_step = 1
  train_loss = 1.1043
  ********************
Previous best ppl:1.0005
BLEU file: ./data/RQ5/xcodeeval_1_2/validation.jsonl
  codebleu-4 = 5.6 	 Previous best codebleu 5.6
  ********************

***** Running evaluation *****
  Num examples = 100
  Batch size = 4
  epoch = 2
  eval_ppl = 1.0005
  global_step = 1
  train_loss = 1.1289
  ********************
Previous best ppl:1.0005
BLEU file: ./data/RQ5/xcodeeval_1_2/validation.jsonl
  codebleu-4 = 5.6 	 Previous best codebleu 5.6
  ********************
reload model from RQ5/xcodeeval_1_2/codet5p_770m_f/checkpoint-best-bleu
BLEU file: ./data/RQ5/xcodeeval_1_2/test.jsonl
  codebleu = 6.03 
  Total = 500 
  Exact Fixed = 0 
[]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  ********************
  Total = 500 
  Exact Fixed = 0 
[]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  codebleu = 6.03 
[0.1879923603233944, 0.0, 0.04814814814814814, 0.06666666666666667, 0.0611111111111111, 0.029629629629629627, 0.037037037037037035, 0.0, 0.07361963190184048, 0.054878048780487805, 0.1111111111111111, 0.07407407407407407, 0.049999999999999996, 0.001354653007386662, 0.04259259259259259, 0.03248407643312102, 0.21385869513884243, 0.0, 0.05555555555555555, 0.014543430090047549, 0.05555555555555555, 0.04444444444444444, 0.04074074074074074, 0.0, 0.0577639751552795, 0.07407407407407407, 0.08703703703703704, 0.06296296296296296, 0.09259259259259259, 0.06102401104505143, 0.03888888888888888, 0.059259259259259255, 0.0, 0.005144869136292059, 0.18181592237723754, 0.025611027033367324, 0.049999999999999996, 0.07080745341614907, 0.0, 0.38408690742043405, 0.051533742331288344, 0.027777777777777776, 0.016770186335403725, 0.02407407407407407, 0.04814814814814814, 0.019961703777678537, 0.0, 0.025611027033367324, 0.024533099058134507, 0.025180214583527708, 0.046296296296296294, 0.04969325153374233, 0.04074074074074074, 0.059259259259259255, 0.266889650613249, 0.0574074074074074, 0.0, 0.03354037267080745, 0.075, 0.07592592592592592, 0.31481821405477567, 0.16717294733785687, 0.07592592592592592, 0.07407407407407407, 0.024913920730446487, 0.04074074074074074, 0.1783904990257879, 0.04285714285714285, 0.06481481481481481, 0.04785276073619631, 0.0, 0.014814814814814814, 0.06521739130434782, 0.0537037037037037, 0.02484639361108076, 0.03888888888888888, 0.026244279557747184, 0.0, 0.028662420382165606, 0.025710131022892057, 0.04390243902439024, 0.07222222222222222, 0.09444444444444444, 0.08333333333333333, 0.06375, 0.02795031055900621, 0.21709111388524982, 0.18010164327903905, 0.03354037267080745, 0.0685185185185185, 0.02307307307307307, 0.0574074074074074, 0.0, 0.10185185185185185, 0.049999999999999996, 0.031677018633540374, 0.06496815286624204, 0.03, 0.04233128834355828, 0.040993788819875775, 0.03865030674846626, 0.06296296296296296, 0.046875, 0.04444444444444444, 0.04259259259259259, 0.05185185185185185, 0.08012422360248447, 0.02795031055900621, 0.057055214723926384, 0.01111111111111111, 0.01111111111111111, 0.5237181107996504, 0.059259259259259255, 0.05555555555555555, 0.017019314637840285, 0.046296296296296294, 0.04259259259259259, 0.06666666666666667, 0.0901840490797546, 0.04259259259259259, 0.0611111111111111, 0.022259926747618446, 0.17966933200385773, 0.0, 0.04785276073619631, 0.22288584207808243, 0.07777777777777777, 0.027777777777777776, 0.02441374503258373, 0.03888888888888888, 0.04074074074074074, 0.037037037037037035, 0.012962962962962963, 0.0, 0.0, 0.0611111111111111, 0.02422360248447205, 0.00920245398773006, 0.07592592592592592, 0.06441717791411043, 0.08780487804878048, 0.03680981595092024, 0.059259259259259255, 0.05555555555555555, 0.04444444444444444, 0.046296296296296294, 0.0825, 0.04444444444444444, 0.037037037037037035, 0.0537037037037037, 0.0, 0.0537037037037037, 0.0, 0.03518518518518518, 0.037037037037037035, 0.22244957630932954, 0.037037037037037035, 0.04259259259259259, 0.025180214583527708, 0.037267080745341616, 0.04814814814814814, 0.016666666666666666, 0.0611111111111111, 0.024708313681900476, 0.07636363636363636, 0.03333333333333333, 0.025521637456597752, 0.0611111111111111, 0.07730061349693251, 0.06296296296296296, 0.04394904458598726, 0.03888888888888888, 0.024160524074624455, 0.02760736196319018, 0.07592592592592592, 0.07777777777777777, 0.04074074074074074, 0.049999999999999996, 0.012077218613638595, 0.04074074074074074, 0.06481481481481481, 0.022929936305732482, 0.049999999999999996, 0.06666666666666667, 0.025299288545086222, 0.03680981595092024, 0.0, 0.05590062111801242, 0.02236024844720497, 0.03148148148148148, 0.07962962962962963, 0.07080745341614907, 0.3305829921491822, 0.03354037267080745, 0.05337423312883435, 0.04074074074074074, 0.0968944099378882, 0.05555555555555555, 0.08333333333333333, 0.04074074074074074, 0.0, 0.04394904458598726, 0.05732484076433121, 0.06257990867579909, 0.09074074074074075, 0.05304878048780488, 0.0685185185185185, 0.059259259259259255, 0.03865030674846626, 0.027777777777777776, 0.45702039897900304, 0.08888888888888888, 0.04814814814814814, 0.05555555555555555, 0.017139753376712575, 0.0, 0.05185185185185185, 0.057055214723926384, 0.1066728452270621, 0.025925925925925925, 0.016666666666666666, 0.05031055900621118, 0.06296296296296296, 0.0611111111111111, 0.02422360248447205, 0.04573170731707317, 0.22230673245553045, 0.44355984910392676, 0.0574074074074074, 0.07818181818181819, 0.06296296296296296, 0.05590062111801242, 0.0, 0.08703703703703704, 0.027777777777777776, 0.0, 0.06481481481481481, 0.046583850931677016, 0.07407407407407407, 0.03888888888888888, 0.1793203862610398, 0.04074074074074074, 0.031875, 0.0, 0.04444444444444444, 0.01840490797546012, 0.0, 0.06335403726708075, 0.09754601226993866, 0.3146826016120066, 0.03312883435582822, 0.040993788819875775, 0.07222222222222222, 0.04394904458598726, 0.04259259259259259, 0.027777777777777776, 0.037037037037037035, 0.040993788819875775, 0.037037037037037035, 0.0574074074074074, 0.014906832298136644, 0.08518518518518518, 0.024375, 0.04785276073619631, 0.11042944785276072, 0.16836258338507132, 0.03354037267080745, 0.003726708074534161, 0.05555555555555555, 0.025710131022892057, 0.07643312101910828, 0.03888888888888888, 0.05217391304347826, 0.05185185185185185, 0.08148148148148147, 0.06702127659574468, 0.0574074074074074, 0.0537037037037037, 0.05403726708074534, 0.037037037037037035, 0.0, 0.09629629629629628, 0.0611111111111111, 0.0, 0.04785276073619631, 0.03333333333333333, 0.0037037037037037034, 0.06402439024390244, 0.03680981595092024, 0.0574468085106383, 0.02582062742929353, 0.0685185185185185, 0.031677018633540374, 0.047272727272727265, 0.031677018633540374, 0.016770186335403725, 0.03888888888888888, 0.0, 0.051592356687898085, 0.03333333333333333, 0.059259259259259255, 0.0, 0.0611111111111111, 0.0375, 0.6128156448385951, 0.02795031055900621, 0.08148148148148147, 0.08703703703703704, 0.028662420382165606, 0.0, 0.09259259259259259, 0.07592592592592592, 0.0484472049689441, 0.029629629629629627, 0.04394904458598726, 0.11666666666666667, 0.04259259259259259, 0.05185185185185185, 0.07037037037037036, 0.04074074074074074, 0.02499062264529472, 0.0, 0.025925925925925925, 0.10925925925925926, 0.029813664596273288, 0.3342684699970986, 0.02422360248447205, 0.018518518518518517, 0.09629629629629628, 0.06149068322981366, 0.04472049689440994, 0.06441717791411043, 0.03888888888888888, 0.07407407407407407, 0.0, 0.02642773182532989, 0.059259259259259255, 0.046583850931677016, 0.06402439024390244, 0.06305732484076433, 0.024308492450855503, 0.23134559405954602, 0.0685185185185185, 0.04074074074074074, 0.06305732484076433, 0.09259259259259259, 0.022553137108602333, 0.03333333333333333, 0.0268915674386065, 0.16700254483434795, 0.06257668711656442, 0.0, 0.059259259259259255, 0.06481481481481481, 0.046153846153846156, 0.0268915674386065, 0.0574074074074074, 0.060365853658536583, 0.05555555555555555, 0.049999999999999996, 0.040127388535031845, 0.059259259259259255, 0.0, 0.07865853658536585, 0.024372103677983988, 0.040993788819875775, 0.040993788819875775, 0.059259259259259255, 0.06402439024390244, 0.014814814814814814, 0.05555555555555555, 0.05889570552147239, 0.04259259259259259, 0.07962962962962963, 0.03518518518518518, 0.07080745341614907, 0.03333333333333333, 0.5799043621506073, 0.05889570552147239, 0.046296296296296294, 0.05185185185185185, 0.04259259259259259, 0.030573248407643312, 0.09259259259259259, 0.07592592592592592, 0.013043478260869565, 0.07592592592592592, 0.06481481481481481, 0.0537037037037037, 0.051592356687898085, 0.016666666666666666, 0.05031055900621118, 0.049999999999999996, 0.04444444444444444, 0.08333333333333333, 0.08888888888888888, 0.166927397971942, 0.04444444444444444, 0.20042910685167498, 0.032692307692307694, 0.025925925925925925, 0.06666666666666667, 0.07037037037037036, 0.073125, 0.03540372670807453, 0.04074074074074074, 0.024461735764356986, 0.046012269938650305, 0.08944099378881988, 0.0, 0.040490797546012265, 0.040490797546012265, 0.03333333333333333, 0.05555555555555555, 0.0, 0.0, 0.031875, 0.06666666666666667, 0.03518518518518518, 0.05185185185185185, 0.07070063694267516, 0.0577639751552795, 0.05555555555555555, 0.05555555555555555, 0.026751592356687896, 0.0, 0.06993865030674846, 0.07222222222222222, 0.035849056603773584, 0.07777777777777777, 0.025710131022892057, 0.05555555555555555, 0.0, 0.04444444444444444, 0.0, 0.02407407407407407, 0.07222222222222222, 0.029629629629629627, 0.040127388535031845, 0.07592592592592592, 0.0, 0.040127388535031845, 0.09629629629629628, 0.0388833850281773, 0.04233128834355828, 0.0, 0.07037037037037036, 0.0, 0.04777070063694267, 0.03630573248407643, 0.03148148148148148, 0.0611111111111111, 0.03865030674846626, 0.05590062111801242, 0.025180214583527708, 0.018518518518518517, 0.04573170731707317, 0.0484472049689441, 0.0, 0.11437499999999999, 0.02195121951219512, 0.07222222222222222, 0.05555555555555555, 0.0, 0.07317073170731707, 0.07177914110429448, 0.04074074074074074, 0.04444444444444444, 0.011750156476051038, 0.07636363636363636, 0.05185185185185185, 0.08703703703703704, 0.030000680935647023, 0.08333333333333333, 0.017666023649368503, 0.07037037037037036, 0.03333333333333333, 0.046296296296296294, 0.04472049689440994, 0.03128834355828221, 0.5005936064272865, 0.0611111111111111, 0.03540372670807453, 0.5014667343327925, 0.06481481481481481, 0.0, 0.40733078377100607, 0.013043478260869565, 0.07037037037037036, 0.0, 0.022929936305732482, 0.0, 0.0037037037037037034, 0.025180214583527708, 0.06625766871165643, 0.03148148148148148, 0.0, 0.0, 0.05217391304347826, 0.0475609756097561]
Finish training and take 1h2m

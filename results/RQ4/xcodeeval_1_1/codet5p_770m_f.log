Namespace(log_name='./RQ5/xcodeeval_1_1/codet5p_770m_f.log', model_name='Salesforce/codet5p-770m', lang='c', output_dir='RQ5/xcodeeval_1_1/codet5p_770m_f', data_dir='./data/RQ5/xcodeeval_1_1', no_cuda=False, visible_gpu='0', add_task_prefix=False, add_lang_ids=False, num_train_epochs=10, num_test_epochs=10, train_batch_size=4, eval_batch_size=4, gradient_accumulation_steps=2, load_model_path=None, config_name='', tokenizer_name='', max_source_length=512, max_target_length=512, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, do_lower_case=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, max_steps=-1, eval_steps=-1, train_steps=-1, local_rank=-1, seed=42, early_stop_threshold=2)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, model_name: Salesforce/codet5p-770m
model created!
Total 1 training instances 
***** Running training *****
  Num examples = 1
  Batch size = 4
  Num epoch = 10

***** Running evaluation *****
  Num examples = 100
  Batch size = 4
  epoch = 0
  eval_ppl = 1.00043
  global_step = 1
  train_loss = 0.5883
  ********************
Previous best ppl:inf
Achieve Best ppl:1.00043
  ********************
BLEU file: ./data/RQ5/xcodeeval_1_1/validation.jsonl
  codebleu-4 = 5.42 	 Previous best codebleu 0
  ********************
 Achieve Best bleu:5.42
  ********************

***** Running evaluation *****
  Num examples = 100
  Batch size = 4
  epoch = 1
  eval_ppl = 1.00043
  global_step = 1
  train_loss = 0.6775
  ********************
Previous best ppl:1.00043
BLEU file: ./data/RQ5/xcodeeval_1_1/validation.jsonl
  codebleu-4 = 5.42 	 Previous best codebleu 5.42
  ********************

***** Running evaluation *****
  Num examples = 100
  Batch size = 4
  epoch = 2
  eval_ppl = 1.00043
  global_step = 1
  train_loss = 0.4795
  ********************
Previous best ppl:1.00043
BLEU file: ./data/RQ5/xcodeeval_1_1/validation.jsonl
  codebleu-4 = 5.42 	 Previous best codebleu 5.42
  ********************
reload model from RQ5/xcodeeval_1_1/codet5p_770m_f/checkpoint-best-bleu
BLEU file: ./data/RQ5/xcodeeval_1_1/test.jsonl
  codebleu = 5.41 
  Total = 500 
  Exact Fixed = 0 
[]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  ********************
  Total = 500 
  Exact Fixed = 0 
[]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  codebleu = 5.41 
[0.025033019490301376, 0.04444444444444444, 0.0537037037037037, 0.027777777777777776, 0.0611111111111111, 0.015286624203821656, 0.0574074074074074, 0.05217391304347826, 0.04074074074074074, 0.171138858050697, 0.045859872611464965, 0.04259259259259259, 0.0, 0.03888888888888888, 0.07639751552795031, 0.024127791222889945, 0.02466263985945276, 0.05555555555555555, 0.040127388535031845, 0.018518518518518517, 0.193782192352044, 0.024999999999999998, 0.06257668711656442, 0.0611111111111111, 0.059259259259259255, 0.018518518518518517, 0.0, 0.03461538461538462, 0.0, 0.0, 0.07222222222222222, 0.05555555555555555, 0.025521637456597752, 0.07962962962962963, 0.07962962962962963, 0.0537037037037037, 0.08518518518518518, 0.07962962962962963, 0.0, 0.0, 0.05031055900621118, 0.0611111111111111, 0.04074074074074074, 0.025925925925925925, 0.0537037037037037, 0.06481481481481481, 0.0611111111111111, 0.0, 0.059259259259259255, 0.025611027033367324, 0.05555555555555555, 0.05192307692307692, 0.04233128834355828, 0.03248407643312102, 0.0, 0.02795031055900621, 0.024708313681900476, 0.09074074074074075, 0.03888888888888888, 0.04814814814814814, 0.0, 0.0, 0.029629629629629627, 0.03333333333333333, 0.08148148148148147, 0.0825, 0.0, 0.0685185185185185, 0.07865319865319866, 0.04394904458598726, 0.03312883435582822, 0.0475609756097561, 0.06666666666666667, 0.0673076923076923, 0.029629629629629627, 0.018633540372670808, 0.07125, 0.0, 0.05590062111801242, 0.0537037037037037, 0.059259259259259255, 0.0, 0.0, 0.0, 0.0685185185185185, 0.0, 0.04074074074074074, 0.059259259259259255, 0.051592356687898085, 0.018518518518518517, 0.0, 0.0, 0.029629629629629627, 0.0, 0.059259259259259255, 0.06481481481481481, 0.03333333333333333, 0.035625, 0.0, 0.08148148148148147, 0.029629629629629627, 0.05185185185185185, 0.06296296296296296, 0.06296296296296296, 0.025299288545086222, 0.049999999999999996, 0.03518518518518518, 0.0, 0.08231707317073171, 0.07865853658536585, 0.02608695652173913, 0.02037037037037037, 0.03788788788788788, 0.09074074074074075, 0.01883956508396191, 0.0685185185185185, 0.037037037037037035, 0.0, 0.024281623942330813, 0.025033019490301376, 0.0, 0.04074074074074074, 0.05555555555555555, 0.04444444444444444, 0.024220570955335106, 0.0574074074074074, 0.05217391304347826, 0.08518518518518518, 0.07407407407407407, 0.01983962585569246, 0.025908878923410435, 0.0, 0.062195121951219505, 0.03913043478260869, 0.03518518518518518, 0.027777777777777776, 0.04259259259259259, 0.04074074074074074, 0.04074074074074074, 0.04074074074074074, 0.0, 0.07134146341463414, 0.19181907524864522, 0.03148148148148148, 0.050625, 0.05031055900621118, 0.04207317073170732, 0.191429402560078, 0.04444444444444444, 0.06335403726708075, 0.017728787471457553, 0.07592592592592592, 0.025521637456597752, 0.03821656050955414, 0.024372103677983988, 0.06441717791411043, 0.0268915674386065, 0.029629629629629627, 0.05185185185185185, 0.0, 0.02407407407407407, 0.08703703703703704, 0.08518518518518518, 0.04444444444444444, 0.03333333333333333, 0.07777777777777777, 0.07962962962962963, 0.07361963190184048, 0.02608469902403444, 0.04074074074074074, 0.07037037037037036, 0.06666666666666667, 0.03148148148148148, 0.037267080745341616, 0.027777777777777776, 0.037267080745341616, 0.022929936305732482, 0.0, 0.026351351351351353, 0.046012269938650305, 0.020042910836692292, 0.3742587337221238, 0.03333333333333333, 0.018633540372670808, 0.02608695652173913, 0.08703703703703704, 0.02795031055900621, 0.030573248407643312, 0.0, 0.1222222222222222, 0.08888888888888888, 0.4687943023854715, 0.029813664596273288, 0.07962962962962963, 0.06481481481481481, 0.025521637456597752, 0.04259259259259259, 0.07777777777777777, 0.05185185185185185, 0.037037037037037035, 0.013043478260869565, 0.03018867924528302, 0.0, 0.0, 0.0574074074074074, 0.049999999999999996, 0.09444444444444444, 0.03888888888888888, 0.025440598832248352, 0.07037037037037036, 0.027777777777777776, 0.02236024844720497, 0.0475609756097561, 0.0484472049689441, 0.04233128834355828, 0.024436859277734865, 0.07361963190184048, 0.03680981595092024, 0.07037037037037036, 0.45420730641452634, 0.06296296296296296, 0.0685185185185185, 0.02407407407407407, 0.01910828025477707, 0.05555555555555555, 0.21385869513884243, 0.17862653885711116, 0.5531277706777963, 0.04074074074074074, 0.02392669117897722, 0.051219512195121955, 0.0, 0.029629629629629627, 0.009554140127388535, 0.03518518518518518, 0.05889570552147239, 0.016770186335403725, 0.19535814445368388, 0.04259259259259259, 0.0, 0.07307692307692307, 0.03333333333333333, 0.0, 0.03148148148148148, 0.009146341463414634, 0.05590062111801242, 0.016666666666666666, 0.05889570552147239, 0.0537037037037037, 0.17894243026455775, 0.08385093167701863, 0.05555555555555555, 0.037037037037037035, 0.07962962962962963, 0.06296296296296296, 0.059259259259259255, 0.059627329192546576, 0.03518518518518518, 0.014814814814814814, 0.0, 0.02222222222222222, 0.03913043478260869, 0.09999999999999999, 0.0, 0.024913920730446487, 0.0, 0.027439024390243903, 0.049999999999999996, 0.02236024844720497, 0.04444444444444444, 0.09814814814814815, 0.024353282790360774, 0.04444444444444444, 0.07962962962962963, 0.046583850931677016, 0.06481481481481481, 0.0574074074074074, 0.08385093167701863, 0.029813664596273288, 0.6809066093546878, 0.09, 0.027777777777777776, 0.02307307307307307, 0.0, 0.03888888888888888, 0.03148148148148148, 0.049999999999999996, 0.0, 0.06149068322981366, 0.059259259259259255, 0.029813664596273288, 0.05961538461538461, 0.43357032366164383, 0.0, 0.0, 0.07222222222222222, 0.12132581743888302, 0.075, 0.040837001359595615, 0.07777777777777777, 0.0, 0.08333333333333333, 0.0, 0.0, 0.024402791240845614, 0.028662420382165606, 0.016666666666666666, 0.09636363636363636, 0.08703703703703704, 0.0, 0.10925925925925926, 0.09074074074074075, 0.0, 0.04074074074074074, 0.00375, 0.05590062111801242, 0.02760736196319018, 0.0, 0.0, 0.03333333333333333, 0.07222222222222222, 0.06666666666666667, 0.0, 0.07407407407407407, 0.08148148148148147, 0.04074074074074074, 0.025925925925925925, 0.03333333333333333, 0.0, 0.059259259259259255, 0.03913043478260869, 0.057055214723926384, 0.037037037037037035, 0.11524390243902438, 0.06257668711656442, 0.046987951807228916, 0.018964852147349227, 0.025925925925925925, 0.02236024844720497, 0.0036585365853658534, 0.09629629629629628, 0.059259259259259255, 0.06878980891719745, 0.1037037037037037, 0.06296296296296296, 0.0, 0.05590062111801242, 0.0, 0.018518518518518517, 0.07777777777777777, 0.07407407407407407, 0.05031055900621118, 0.025611027033367324, 0.06666666666666667, 0.05555555555555555, 0.1595323671321502, 0.046296296296296294, 0.06296296296296296, 0.049999999999999996, 0.049999999999999996, 0.05555555555555555, 0.05031055900621118, 0.0007348347041672731, 0.03540372670807453, 0.03888888888888888, 0.0, 0.037267080745341616, 0.03461538461538462, 0.025925925925925925, 0.1575, 0.08518518518518518, 0.02037037037037037, 0.027777777777777776, 0.22288584207808243, 0.037037037037037035, 0.06402439024390244, 0.007407407407407407, 0.0611111111111111, 0.028124999999999997, 0.07592592592592592, 0.04814814814814814, 0.059259259259259255, 0.011320754716981131, 0.06257668711656442, 0.04444444444444444, 0.02642773182532989, 0.04074074074074074, 0.045859872611464965, 0.016714385385570425, 0.05521472392638036, 0.020213339037811265, 0.01097560975609756, 0.025925925925925925, 0.08148148148148147, 0.07037037037037036, 0.0, 0.06666666666666667, 0.012883435582822086, 0.029629629629629627, 0.10925925925925926, 0.10843373493975904, 0.0475609756097561, 0.0, 0.04207317073170732, 0.037267080745341616, 0.03333333333333333, 0.02484076433121019, 0.04259259259259259, 0.05403726708074534, 0.044171779141104296, 0.08703703703703704, 0.051533742331288344, 0.08518518518518518, 0.029813664596273288, 0.025180214583527708, 0.02759158729908745, 0.03333333333333333, 0.049999999999999996, 0.04259259259259259, 0.0, 0.02407407407407407, 0.08062499999999999, 0.0, 0.0, 0.04259259259259259, 0.06666666666666667, 0.04939024390243903, 0.03148148148148148, 0.059259259259259255, 0.08944099378881988, 0.03865030674846626, 0.04444444444444444, 0.03841463414634146, 0.0, 0.037267080745341616, 0.02582062742929353, 0.07407407407407407, 0.2237166632141648, 0.6236007743899898, 0.04390243902439024, 0.0611111111111111, 0.03518518518518518, 0.046296296296296294, 0.0, 0.06296296296296296, 0.03841463414634146, 0.016875, 0.016666666666666666, 0.07361963190184048, 0.0, 0.04444444444444444, 0.05555555555555555, 0.0, 0.0, 0.07639751552795031, 0.02037037037037037, 0.04074074074074074, 0.02422360248447205, 0.045859872611464965, 0.07826086956521738, 0.05555555555555555, 0.17355589028416954, 0.18090069138478332, 0.007407407407407407, 0.04285714285714285, 0.049999999999999996, 0.02608695652173913, 0.03518518518518518, 0.17955266110806617, 0.0685185185185185, 0.04814814814814814, 0.08888888888888888, 0.0, 0.0574074074074074, 0.04074074074074074, 0.0537037037037037, 0.0, 0.034394904458598725, 0.09074074074074075, 0.014260958306150423, 0.05555555555555555, 0.7215758906666333, 0.10925925925925926, 0.0037037037037037034, 0.07875, 0.018633540372670808, 0.046583850931677016, 0.04394904458598726, 0.0, 0.037267080745341616, 0.024392212146662384, 0.049999999999999996, 0.10803008497968733, 0.037037037037037035, 0.0, 0.024951011736122134, 0.03148148148148148, 0.08888888888888888, 0.08, 0.046583850931677016]
Finish training and take 56m

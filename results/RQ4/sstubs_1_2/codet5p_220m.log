Namespace(log_name='./RQ5/sstubs_1_2/codet5p_220m.log', model_name='Salesforce/codet5p-220m', lang='java', output_dir='RQ5/sstubs_1_2/codet5p_220m', data_dir='./data/RQ5/sstubs_1_2', choice=0, no_cuda=False, visible_gpu='0', num_train_epochs=10, num_test_epochs=1, train_batch_size=8, eval_batch_size=4, gradient_accumulation_steps=1, load_model_path=None, config_name='', tokenizer_name='', max_source_length=512, max_target_length=512, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, freeze=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
Model created!!
[[{'text': '*     * @return The closed DataStream    */  public DataStream<OUT> writeAsText(String path, int batchSize) {    return writeAsText(this, path, new WriteFormatAsText<OUT>(), batchSize, null);   }', 'loss_ids': 0, 'shortenable_ids': 1}, {'text': '<mask>', 'loss_ids': 1, 'shortenable_ids': 0}, {'text': 'is the fixed version', 'loss_ids': 0, 'shortenable_ids': 0}], {'guid': 0, 'tgt_text': '*     * @return The closed DataStream    */  public DataStreamSink<OUT> writeAsText(String path, int batchSize) {    return writeAsText(this, path, new WriteFormatAsText<OUT>(), batchSize, null);   }'}]
***** Running training *****
  Num examples = 1
  Batch size = 8
  Num epoch = 10

***** Running evaluation *****
  Num examples = 100
  Batch size = 4
  epoch = 0
  eval_ppl = 6.150234611041912e+300
  global_step = 2
  train_loss = 53.9315
  ********************
Previous best ppl:inf
Achieve Best ppl:6.150234611041912e+300
  ********************
BLEU file: ./data/RQ5/sstubs_1_2/validation.jsonl
  codebleu-4 = 16.54 	 Previous best codebleu 0
  ********************
 Achieve Best bleu:16.54
  ********************

***** Running evaluation *****
  Num examples = 100
  Batch size = 4
  epoch = 1
  eval_ppl = 1.2419678680540383e+295
  global_step = 3
  train_loss = 56.8077
  ********************
Previous best ppl:6.150234611041912e+300
Achieve Best ppl:1.2419678680540383e+295
  ********************
BLEU file: ./data/RQ5/sstubs_1_2/validation.jsonl
  codebleu-4 = 21.72 	 Previous best codebleu 16.54
  ********************
 Achieve Best bleu:21.72
  ********************

***** Running evaluation *****
  Num examples = 100
  Batch size = 4
  epoch = 2
  eval_ppl = 3.7551397869825413e+288
  global_step = 4
  train_loss = 24.4085
  ********************
Previous best ppl:1.2419678680540383e+295
Achieve Best ppl:3.7551397869825413e+288
  ********************
BLEU file: ./data/RQ5/sstubs_1_2/validation.jsonl
  codebleu-4 = 20.43 	 Previous best codebleu 21.72
  ********************

***** Running evaluation *****
  Num examples = 100
  Batch size = 4
  epoch = 3
  eval_ppl = 7.97247858981606e+283
  global_step = 5
  train_loss = 14.1073
  ********************
Previous best ppl:3.7551397869825413e+288
Achieve Best ppl:7.97247858981606e+283
  ********************
BLEU file: ./data/RQ5/sstubs_1_2/validation.jsonl
  codebleu-4 = 22.02 	 Previous best codebleu 21.72
  ********************
 Achieve Best bleu:22.02
  ********************

***** Running evaluation *****
  Num examples = 100
  Batch size = 4
  epoch = 4
  eval_ppl = 8.351906652311119e+281
  global_step = 6
  train_loss = 9.3818
  ********************
Previous best ppl:7.97247858981606e+283
Achieve Best ppl:8.351906652311119e+281
  ********************
BLEU file: ./data/RQ5/sstubs_1_2/validation.jsonl
  codebleu-4 = 22.78 	 Previous best codebleu 22.02
  ********************
 Achieve Best bleu:22.78
  ********************

***** Running evaluation *****
  Num examples = 100
  Batch size = 4
  epoch = 5
  eval_ppl = 3.9487769203518334e+282
  global_step = 7
  train_loss = 9.2977
  ********************
Previous best ppl:8.351906652311119e+281
BLEU file: ./data/RQ5/sstubs_1_2/validation.jsonl
  codebleu-4 = 23.29 	 Previous best codebleu 22.78
  ********************
 Achieve Best bleu:23.29
  ********************

***** Running evaluation *****
  Num examples = 100
  Batch size = 4
  epoch = 6
  eval_ppl = 4.0036047045384225e+284
  global_step = 8
  train_loss = 2.8997
  ********************
Previous best ppl:8.351906652311119e+281
BLEU file: ./data/RQ5/sstubs_1_2/validation.jsonl
  codebleu-4 = 25.6 	 Previous best codebleu 23.29
  ********************
 Achieve Best bleu:25.6
  ********************

***** Running evaluation *****
  Num examples = 100
  Batch size = 4
  epoch = 7
  eval_ppl = 1.0939439925814148e+287
  global_step = 9
  train_loss = 3.8133
  ********************
Previous best ppl:8.351906652311119e+281
BLEU file: ./data/RQ5/sstubs_1_2/validation.jsonl
  codebleu-4 = 27.36 	 Previous best codebleu 25.6
  ********************
 Achieve Best bleu:27.36
  ********************

***** Running evaluation *****
  Num examples = 100
  Batch size = 4
  epoch = 8
  eval_ppl = 2.4065473431684117e+289
  global_step = 10
  train_loss = 2.4917
  ********************
Previous best ppl:8.351906652311119e+281
BLEU file: ./data/RQ5/sstubs_1_2/validation.jsonl
  codebleu-4 = 29.47 	 Previous best codebleu 27.36
  ********************
 Achieve Best bleu:29.47
  ********************

***** Running evaluation *****
  Num examples = 100
  Batch size = 4
  epoch = 9
  eval_ppl = 3.141216486892717e+290
  global_step = 11
  train_loss = 3.1227
  ********************
Previous best ppl:8.351906652311119e+281
BLEU file: ./data/RQ5/sstubs_1_2/validation.jsonl
  codebleu-4 = 28.95 	 Previous best codebleu 29.47
  ********************
reload model from RQ5/sstubs_1_2/codet5p_220m/checkpoint-best-bleu
BLEU file: ./data/RQ5/sstubs_1_2/test.jsonl
  codebleu = 27.16 
  Total = 500 
  Exact Fixed = 5 
[111, 297, 307, 398, 489]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  ********************
  Total = 500 
  Exact Fixed = 5 
[111, 297, 307, 398, 489]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  codebleu = 27.16 
[0.25598723587536354, 0.7922489711082565, 0.3085731703104531, 0.3, 0.3, 0.3, 0.9598988001907718, 0.3, 0.0, 0.3, 0.20452162336296625, 0.0, 0.3, 0.3, 0.0, 0.30016788909290804, 0.3, 0.0, 0.0, 0.356629799010115, 0.0, 0.3881316695443784, 0.21023308734332533, 0.5782336484727829, 0.3, 0.9327629036246103, 0.0, 0.16621686900543461, 0.30016788909290804, 0.0, 0.024200149662472165, 0.0, 0.3, 0.7343262700910256, 0.6990948397529049, 0.38766042599505257, 0.8655641924881594, 0.3085731703104531, 0.18694453239264971, 0.0, 0.0, 0.3, 0.3, 0.0, 0.0, 0.0, 0.0, 0.3, 0.3, 0.3, 0.3, 0.0, 0.0, 0.0, 0.3, 0.3, 0.3, 0.0, 0.19043467392192354, 0.0, 0.3, 0.3, 0.30018543884267135, 0.33908096156313605, 0.2713169576198315, 0.1869213233122067, 0.3, 0.3000831759150374, 0.9222373349754207, 0.0, 0.29705304518664044, 0.0, 0.3443114057810051, 0.1869213233122067, 0.3, 0.3, 0.0, 0.3, 0.3, 0.01967193118990121, 0.0, 0.0, 0.0, 0.0, 0.7393346709407568, 0.3, 0.0, 0.8908661890024412, 0.0, 0.1869213233122067, 0.5782336484727829, 0.3, 0.1876803572131687, 0.0, 0.0, 0.0, 0.902844616635692, 0.07995815500723608, 0.7641377785853717, 0.3, 0.3, 0.0, 0.0, 0.3, 0.3, 0.3, 0.8560265325904475, 0.3321280225603612, 0.3, 0.0, 1.0, 0.3, 0.0, 0.3, 0.0, 0.9042730084194632, 0.0, 0.3, 0.3, 0.28256173040525717, 0.3, 0.9439975336408695, 0.859671486657912, 0.3, 0.0, 0.3, 0.3, 0.0, 0.0, 0.0, 0.3, 0.3, 0.3, 0.9222373349754207, 0.3, 0.0, 0.3, 0.9077335309839862, 0.0, 0.0, 0.3881316695443784, 0.3, 0.9295451446225973, 0.8476194302350164, 0.5782336484727829, 0.3, 0.5415551889188216, 0.0, 0.3, 0.30254785981247184, 0.16621686900543461, 0.43636363636363634, 0.3, 0.0, 0.0, 0.3, 0.3, 0.0, 0.9477454832552463, 0.7565565502046814, 0.0, 0.0, 0.0, 0.35433524973001396, 0.0, 0.3, 0.6435056005553412, 0.3, 0.30254785981247184, 0.0, 0.300167480271109, 0.3, 0.3, 0.3, 0.3, 0.9301837642961475, 0.3, 0.0, 0.0, 0.3, 0.22918413577244676, 0.7922489711082565, 0.05958898565170259, 0.0, 0.0, 0.22144107047877473, 0.3, 0.3, 0.7572106995596821, 0.6920593814462994, 0.9493239030379825, 0.0, 0.0, 0.9444765972568354, 0.0, 0.0, 0.3, 0.3, 0.3000920493125394, 0.0, 0.3, 0.0, 0.3, 0.0, 0.3, 0.0, 0.882260496528867, 0.9583676774082095, 0.18694453239264971, 0.0, 0.3, 0.3, 0.7755472074860542, 0.4545743631700999, 0.0, 0.0, 0.0, 0.2849172694217106, 0.30014032599309304, 0.3, 0.851473618503158, 0.031330932944210604, 0.7845575199568887, 0.3, 0.3, 0.0, 0.0, 0.0, 0.30008317591498496, 0.0, 0.9477454832552463, 0.0, 0.0, 0.3, 0.0, 0.33495424495894816, 0.3, 0.3, 0.3, 0.9431571237072573, 0.0, 0.3, 0.21434327384918922, 0.0, 0.0, 0.0, 0.3, 0.3, 0.3, 0.0, 0.3, 0.3, 0.3, 0.3, 0.30254785981247184, 0.3, 0.3, 0.3, 0.3, 0.3, 0.0, 0.3, 0.0, 0.0, 0.8281886038360344, 0.5782336484727829, 0.6727422639687641, 0.0, 0.18694453239264971, 0.20437257453730726, 0.0, 0.0, 0.30658832317270357, 0.0, 0.3, 0.0, 0.9096059691496151, 0.0, 0.0, 0.0, 0.2713169576198315, 0.9608514269956967, 0.3, 0.3, 0.3, 0.0, 0.851473618503158, 0.3, 0.0, 0.0, 0.0, 0.8562557657119574, 0.0, 0.0, 0.0, 0.3, 1.0, 0.0, 0.3, 0.3, 0.0, 0.20360092672434532, 0.915038704727656, 0.3, 0.25948870059908397, 0.0, 1.0, 0.3, 0.0, 0.0, 0.3, 0.3, 0.8281886038360344, 0.0, 0.9270405384522935, 0.0, 0.1869213233122067, 0.21136040311390805, 0.0, 0.0, 0.0, 0.20360092672434532, 0.3, 0.3, 0.3, 0.9295451446225973, 0.0, 0.18694453239264971, 0.9231335375314982, 0.00719768835745738, 0.23221833558559743, 0.5280902805261166, 0.3, 0.7565565502046814, 0.3, 0.3, 0.0, 0.0, 0.43893127193854264, 0.0, 0.8536687375662593, 0.3, 6.99477269695116e-05, 0.0, 0.3, 0.3, 0.0, 0.18694453239264971, 0.3, 0.3, 0.3, 0.0, 0.0, 0.3, 0.18694453239264971, 0.3, 0.0, 0.46007194602208706, 0.3, 0.3, 0.0, 0.1869213233122067, 0.0, 0.3, 0.0, 0.18694453239264971, 0.3, 0.49821459386845796, 0.18694453239264971, 0.9493239030379825, 0.3, 0.3, 0.0, 0.3, 0.0, 0.0, 0.2913998106011243, 0.936752055107628, 0.3, 0.300167480271109, 0.3, 0.3, 0.25147602485980064, 0.0, 0.3, 0.3, 0.3, 0.0, 0.3, 0.3, 0.18476127851262833, 0.0, 0.0, 0.3389468531479279, 0.20452162336296625, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.9417126558697961, 0.3, 0.3, 0.35642173170062713, 0.0, 0.0, 0.3, 0.3, 0.20478681307637792, 0.0, 0.3, 0.30029227207977927, 0.3, 0.9439975336408695, 0.0, 0.21023308734332533, 0.3, 0.25147602485980064, 0.3, 0.0, 0.16211254811276943, 0.9257116180592027, 0.3, 0.0, 0.0, 0.3, 0.9698138929646263, 0.3292502745500607, 0.34863750024235235, 0.0, 0.0, 0.0, 0.0, 0.3287572605618104, 0.3, 0.0, 0.9231335375314982, 0.0, 0.3909562105884453, 0.33495424495894816, 0.3, 0.0, 0.1869213233122067, 0.8472367293037075, 0.3, 0.0, 0.0, 0.0, 0.3, 0.3, 0.7565565502046814, 0.3, 0.3, 0.3, 0.7687677218420086, 0.3, 0.0, 0.3, 0.9637364956234171, 0.30254785981247184, 0.2685485602426402, 0.3, 0.0, 0.3, 0.9424689312858054, 0.20452162336296625, 0.0, 0.5566741554006543, 0.3, 0.300167480271109, 0.0, 0.0, 0.3, 0.0, 0.3, 0.8819747967863025, 0.1869213233122067, 0.3, 0.0, 0.3, 0.3, 0.3, 0.0, 0.3, 0.3, 0.3, 1.0, 0.0, 0.0, 0.0, 0.12872699849853825, 0.3, 0.4456337998724833, 0.18915814572765516, 0.0, 0.0, 0.3, 0.0]
Finish training and take 56m

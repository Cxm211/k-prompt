Namespace(log_name='./RQ5/sstubs_1_2/codet5p_220m_f.log', model_name='Salesforce/codet5p-220m', lang='java', output_dir='RQ5/sstubs_1_2/codet5p_220m_f', data_dir='./data/RQ5/sstubs_1_2', no_cuda=False, visible_gpu='0', add_task_prefix=False, add_lang_ids=False, num_train_epochs=10, num_test_epochs=10, train_batch_size=8, eval_batch_size=4, gradient_accumulation_steps=2, load_model_path=None, config_name='', tokenizer_name='', max_source_length=512, max_target_length=512, warm_up_ratio=0.1, do_train=True, do_eval=True, do_test=True, do_lower_case=False, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, max_steps=-1, eval_steps=-1, train_steps=-1, local_rank=-1, seed=42, early_stop_threshold=3)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, model_name: Salesforce/codet5p-220m
model created!
Total 1 training instances 
***** Running training *****
  Num examples = 1
  Batch size = 8
  Num epoch = 10

***** Running evaluation *****
  Num examples = 100
  Batch size = 4
  epoch = 0
  eval_ppl = 1.00357
  global_step = 1
  train_loss = 1.2083
  ********************
Previous best ppl:inf
Achieve Best ppl:1.00357
  ********************
BLEU file: ./data/RQ5/sstubs_1_2/validation.jsonl
  codebleu-4 = 6.71 	 Previous best codebleu 0
  ********************
 Achieve Best bleu:6.71
  ********************

***** Running evaluation *****
  Num examples = 100
  Batch size = 4
  epoch = 1
  eval_ppl = 1.00357
  global_step = 1
  train_loss = 1.0534
  ********************
Previous best ppl:1.00357
BLEU file: ./data/RQ5/sstubs_1_2/validation.jsonl
  codebleu-4 = 6.71 	 Previous best codebleu 6.71
  ********************

***** Running evaluation *****
  Num examples = 100
  Batch size = 4
  epoch = 2
  eval_ppl = 1.00357
  global_step = 1
  train_loss = 1.9639
  ********************
Previous best ppl:1.00357
BLEU file: ./data/RQ5/sstubs_1_2/validation.jsonl
  codebleu-4 = 6.71 	 Previous best codebleu 6.71
  ********************

***** Running evaluation *****
  Num examples = 100
  Batch size = 4
  epoch = 3
  eval_ppl = 1.00357
  global_step = 1
  train_loss = 1.0617
  ********************
Previous best ppl:1.00357
BLEU file: ./data/RQ5/sstubs_1_2/validation.jsonl
  codebleu-4 = 6.71 	 Previous best codebleu 6.71
  ********************
reload model from RQ5/sstubs_1_2/codet5p_220m_f/checkpoint-best-bleu
BLEU file: ./data/RQ5/sstubs_1_2/test.jsonl
  codebleu = 6.09 
  Total = 500 
  Exact Fixed = 0 
[]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  ********************
  Total = 500 
  Exact Fixed = 0 
[]
  Syntax Fixed = 0 
[]
  Cleaned Fixed = 0 
[]
  codebleu = 6.09 
[0.042158030313929715, 0.03850336716308983, 0.42821810620430634, 0.05555555555555555, 0.029268292682926828, 0.03846153846153846, 0.02637994368537977, 0.029268292682926828, 0.07930171756483195, 0.02413793103448276, 0.029268292682926828, 0.08084795302236233, 0.01923076923076923, 0.029268292682926828, 0.02444842716137509, 0.030008946881712194, 0.029268292682926828, 0.0525, 0.0, 0.03693213997827833, 0.02045454545454545, 0.10145562909676539, 0.015472680770206578, 0.008594114001468643, 0.038565336183577624, 0.037928865810863306, 0.029268292682926828, 0.22557650573686017, 0.030008946881712194, 0.017502512689975186, 0.025609756097560978, 0.011538461538461539, 0.03214285714285714, 0.2538781142694698, 0.025609756097560978, 0.05795454545454545, 0.0004915506694683193, 0.42821810620430634, 0.029268292682926828, 0.029268292682926828, 0.029268292682926828, 0.22246268846739337, 0.00019962295338697976, 0.05898010587541716, 0.015584415584415584, 0.03103448275862069, 0.03214285714285714, 0.030379746835443037, 0.029268292682926828, 0.0001736961455145884, 0.057692307692307696, 0.07555021901096573, 0.021804538558328743, 0.027586206896551724, 0.029268292682926828, 0.007317073170731707, 0.0, 0.01810344827586207, 0.029268292682926828, 0.011671758667053717, 0.02386062103392467, 0.00017720199070206258, 0.027872973289042428, 0.07533599663187068, 0.04090824158255012, 0.029268292682926828, 0.029268292682926828, 0.0387047542439348, 0.01606708236751034, 0.007434767132975863, 0.0, 0.030769230769230767, 0.24401701470670467, 0.029268292682926828, 0.0, 0.029268292682926828, 0.017451604930786388, 0.029268292682926828, 0.2448566758089149, 0.027777777777777776, 0.0, 0.11905370843989768, 0.049999999999999996, 0.03103448275862069, 0.01875, 0.2834945973317957, 0.18587826446813205, 0.0005207067228498577, 0.012499999999999999, 0.029268292682926828, 0.008594114001468643, 0.030769230769230767, 0.029268292682926828, 0.007594936708860759, 0.0, 0.027586206896551724, 0.0008283313594340638, 0.00024209037944225868, 0.02669411216520866, 0.029268292682926828, 0.2837403939181237, 0.30279858879675936, 0.3130107567422864, 0.029268292682926828, 0.029268292682926828, 0.03476793916680015, 0.0423076923076923, 0.04024390243902439, 0.014634146341463414, 0.2534308804687, 0.022469387178553648, 0.014285714285714284, 0.0, 0.011200912664544791, 0.02222222222222222, 0.00023457024054606413, 0.02045454545454545, 0.00020276794409418948, 0.007692307692307692, 0.04792994961367194, 0.0, 0.00023457024054606413, 0.03484474949817896, 0.029268292682926828, 0.2036975612423323, 0.015584415584415584, 0.007523684798783523, 0.046153846153846156, 0.024999999999999998, 0.02608695652173913, 0.017045454545454544, 0.029268292682926828, 0.0002065322644756516, 0.008179686050387446, 0.029268292682926828, 0.03214285714285714, 0.029268292682926828, 0.01562719208739518, 0.03686102953984871, 0.03214285714285714, 0.10145562909676539, 0.1953774980186161, 0.008028739281982047, 0.09886363636363636, 0.008594114001468643, 0.3285321824598165, 0.0, 0.0, 0.029268292682926828, 0.03732863815533257, 0.22557650573686017, 0.088549243028389, 0.26873754872181765, 0.02968609289038069, 0.05397323212980425, 0.029268292682926828, 0.029268292682926828, 0.28975825872178573, 0.04275686430330017, 0.046788970266111195, 0.3130107567422864, 0.02967032967032967, 0.011671758667053717, 0.07682926829268293, 0.029268292682926828, 0.029268292682926828, 0.030637390150243894, 0.24103392163665965, 0.03732863815533257, 0.0002331337495966263, 0.03195127741443901, 0.0341991341991342, 0.029268292682926828, 0.029268292682926828, 0.2082513844410077, 0.013186813186813187, 0.26873754872181765, 0.0, 0.02441860465116279, 0.05217391304347826, 0.2318033616122117, 0.03850336716308983, 0.10619863953787051, 0.02222222222222222, 0.043623521068170495, 0.05730337078651685, 0.01396830998940639, 0.0, 0.03494892479073041, 0.13881629384970715, 0.0005928039101636814, 0.36562832741422785, 0.019480519480519477, 0.30638294669331145, 0.045, 0.0, 0.02195121951219512, 0.029268292682926828, 0.02731629933608068, 0.02386363636363636, 0.029268292682926828, 0.051219512195121955, 0.02553191489361702, 0.27906677472626434, 0.0, 0.058019586946148866, 0.0003245456506265216, 0.000241420243847319, 0.029268292682926828, 0.04827586206896552, 0.029268292682926828, 0.05056179775280899, 0.051219512195121955, 0.0002462270069433976, 0.06538461538461539, 0.049999999999999996, 0.0, 0.007792958429651773, 0.024616431462050812, 0.02195121951219512, 0.0004990567491135724, 0.026673156282816635, 0.046197126368457284, 0.00019889286503836388, 0.020689655172413793, 0.013793103448275862, 0.0, 0.10689287779976084, 0.026791617712942736, 0.04482758620689655, 0.037928865810863306, 0.0, 0.030769230769230767, 0.019291762059430215, 0.005454545454545454, 0.0737634575951237, 0.03176470588235294, 0.045864604887731926, 0.029268292682926828, 0.007006594960252806, 0.27680427875029023, 0.029268292682926828, 0.030769230769230767, 0.049999999999999996, 0.014634146341463414, 0.04074074074074074, 0.03846153846153846, 0.0, 0.029268292682926828, 0.05398093585170844, 0.029268292682926828, 0.029268292682926828, 0.029268292682926828, 0.019291762059430215, 0.03732863815533257, 0.029268292682926828, 0.2082513844410077, 0.029268292682926828, 0.31399201700462975, 0.017857142857142856, 0.08157630998376403, 0.04647118087067515, 0.04772727272727272, 0.3199918762519601, 0.04169142104541396, 0.008594114001468643, 0.020864630889107665, 0.025806451612903226, 0.029268292682926828, 0.024999999999999998, 0.05185185185185185, 0.044211115418698675, 0.0074727677459738625, 0.0, 0.277331680522859, 0.029268292682926828, 0.0007482966283516011, 0.0, 0.02631578947368421, 0.029268292682926828, 0.04090824158255012, 0.16968165728731865, 0.025454746275679962, 0.029268292682926828, 0.018918918918918916, 0.006382978723404255, 0.0004990567491135724, 0.029268292682926828, 0.03506493506493506, 0.04125, 0.2656964071257352, 0.018292682926829267, 0.054878048780487805, 0.043623521068170495, 0.07838408175189529, 0.0, 0.014233724572109151, 0.02454353363581084, 0.2834945973317957, 0.029268292682926828, 0.04468085106382978, 0.029268292682926828, 0.008377329157259845, 0.05052631578947368, 0.04390243902439024, 0.02891566265060241, 0.022469387178553648, 0.029268292682926828, 0.027027027027027025, 0.049999999999999996, 0.014634146341463414, 0.029268292682926828, 0.04169142104541396, 0.018855327295662656, 0.011317722739162926, 0.18198084586327765, 0.029268292682926828, 0.09822128277079814, 0.07097901618899076, 0.030769230769230767, 0.04100750240896937, 0.029268292682926828, 0.2082513844410077, 0.029268292682926828, 0.029268292682926828, 0.008028739281982047, 0.0, 0.029268292682926828, 0.007057803610471459, 0.03571428571428571, 0.008020359258136605, 0.49114844535802243, 0.14457818639419667, 0.046788970266111195, 0.051219512195121955, 0.09385763622185966, 0.3015719218758112, 0.18459549284031987, 0.0, 0.0, 0.1763656734769676, 0.05384615384615384, 0.06916623760819912, 0.0, 0.029268292682926828, 0.029268292682926828, 0.049999999999999996, 0.029268292682926828, 0.0, 0.029268292682926828, 0.26873754872181765, 0.029268292682926828, 0.10913318873149663, 0.029268292682926828, 0.029268292682926828, 0.017618553132571824, 0.01843386568432228, 0.03814965652757861, 0.025609756097560978, 0.011009174311926606, 0.075, 0.029268292682926828, 0.29958781528253675, 0.034822436022861974, 0.047368421052631574, 0.029268292682926828, 0.029268292682926828, 0.0004017077398723221, 0.029268292682926828, 0.0005928039101636814, 0.029268292682926828, 0.007317073170731707, 0.0189873417721519, 0.029268292682926828, 0.29722245197854574, 0.04588235294117647, 0.02731616954642096, 0.00023363150786421475, 0.029268292682926828, 0.03195127741443901, 0.028235294117647056, 0.029268292682926828, 0.029986765685888237, 0.025609756097560978, 0.22246268846739337, 0.029268292682926828, 0.029268292682926828, 0.14662441193824194, 0.029268292682926828, 0.05217391304347826, 0.12163517033371818, 0.2534308804687, 0.018292682926829267, 0.07741429900783918, 0.029268292682926828, 0.051364841939823505, 0.018292682926829267, 0.022469387178553648, 0.05398093585170844, 0.015789473684210523, 0.013793103448275862, 0.025839773318570076, 0.01154365433812873, 0.23065001336658894, 0.005263157894736842, 0.3709071815478525, 0.029268292682926828, 0.264959682277854, 0.029268292682926828, 0.01081081081081081, 0.029268292682926828, 0.0, 0.029268292682926828, 0.00756110007727065, 0.5567010309278351, 0.00023457024054606413, 0.031153337727935496, 0.015472680770206578, 0.0077070140854276796, 0.029986765685888237, 0.029268292682926828, 0.3100971260512867, 0.30897618472573485, 0.007769194828452498, 0.31027258667291957, 0.053901483039974586, 0.0963083380989976, 0.029268292682926828, 0.0498292482520133, 0.005645200478855432, 0.020937231069512396, 0.0688964080282791, 0.0, 0.025292664144017835, 0.32364778472764055, 0.31900688508572106, 0.2082513844410077, 0.02608695652173913, 0.007057803610471459, 0.039285714285714285, 0.054024586848597546, 0.07643358776673119, 0.361120703317427, 0.025806451612903226, 0.029268292682926828, 0.037676726877281456, 0.029268292682926828, 0.28813666192073767, 0.029268292682926828, 0.05398093585170844, 0.029268292682926828, 0.038774869781167655, 0.046788970266111195, 0.2082513844410077, 0.029268292682926828, 0.029268292682926828, 0.007317073170731707, 0.029268292682926828, 0.029268292682926828, 0.029268292682926828, 0.000693744597268347, 0.03732863815533257, 0.007142857142857142, 0.029268292682926828, 0.015957446808510637, 0.029268292682926828, 0.0004469614785577372, 0.029268292682926828, 0.026373626373626374, 0.007451342250567231, 0.00018802300570350695, 0.03195127741443901, 0.006896551724137931, 0.02980460261290444, 0.029268292682926828, 0.010227272727272725, 0.009677419354838708, 0.01081081081081081, 0.029268292682926828, 0.023376623376623374, 0.051219512195121955, 0.030769230769230767, 0.2837403939181237, 0.03416259273085338, 0.02608695652173913, 0.30400008357477093, 0.036585365853658534, 0.029268292682926828, 0.022469387178553648, 0.07591447242597495, 0.029268292682926828, 0.029629629629629627, 0.02625, 0.014574887547443833, 0.17156325045420134, 0.015192447628498574, 0.09066200001154977, 0.17648180554518345, 0.034482758620689655, 0.0]
Finish training and take 47m

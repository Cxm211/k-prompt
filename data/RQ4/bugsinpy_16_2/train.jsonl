{"id": "matplotlib_1", "problem": " def _get_renderer(figure, print_method=None, *, draw_disabled=False):\n         except Done as exc:\n             renderer, = figure._cachedRenderer, = exc.args\n    if draw_disabled:\n        for meth_name in dir(RendererBase):\n            if (meth_name.startswith(\"draw_\")\n                    or meth_name in [\"open_group\", \"close_group\"]):\n                setattr(renderer, meth_name, lambda *args, **kwargs: None)\n     return renderer", "fixed": " def _get_renderer(figure, print_method=None, *, draw_disabled=False):\n         except Done as exc:\n             renderer, = figure._cachedRenderer, = exc.args\n     return renderer"}
{"id": "spacy_10", "problem": " class Errors(object):\n     E168 = (\"Unknown field: {field}\")\n     E169 = (\"Can't find module: {module}\")\n     E170 = (\"Cannot apply transition {name}: invalid for the current state.\")\n @add_codes", "fixed": " class Errors(object):\n     E168 = (\"Unknown field: {field}\")\n     E169 = (\"Can't find module: {module}\")\n     E170 = (\"Cannot apply transition {name}: invalid for the current state.\")\n    E171 = (\"Matcher.add received invalid on_match callback argument: expected \"\n            \"callable or None, but got: {arg_type}\")\n @add_codes"}
{"id": "fastapi_14", "problem": " class Schema(SchemaBase):\nnot_: Optional[List[SchemaBase]] = PSchema(None, alias=\"not\")\n     items: Optional[SchemaBase] = None\n     properties: Optional[Dict[str, SchemaBase]] = None\n    additionalProperties: Optional[Union[bool, SchemaBase]] = None\n class Example(BaseModel):", "fixed": " class Schema(SchemaBase):\nnot_: Optional[List[SchemaBase]] = PSchema(None, alias=\"not\")\n     items: Optional[SchemaBase] = None\n     properties: Optional[Dict[str, SchemaBase]] = None\n    additionalProperties: Optional[Union[SchemaBase, bool]] = None\n class Example(BaseModel):"}
{"id": "pandas_65", "problem": " def get_handle(\n         from io import TextIOWrapper\n         g = TextIOWrapper(f, encoding=encoding, newline=\"\")\n        if not isinstance(f, BufferedIOBase):\n             handles.append(g)\n         f = g", "fixed": " def get_handle(\n         from io import TextIOWrapper\n         g = TextIOWrapper(f, encoding=encoding, newline=\"\")\n        if not isinstance(f, (BufferedIOBase, RawIOBase)):\n             handles.append(g)\n         f = g"}
{"id": "pandas_110", "problem": " class CategoricalIndex(Index, accessor.PandasDelegate):\n     take_nd = take\n     def map(self, mapper):\n         Map values using input correspondence (a dict, Series, or function).", "fixed": " class CategoricalIndex(Index, accessor.PandasDelegate):\n     take_nd = take\n    @Appender(_index_shared_docs[\"_maybe_cast_slice_bound\"])\n    def _maybe_cast_slice_bound(self, label, side, kind):\n        if kind == \"loc\":\n            return label\n        return super()._maybe_cast_slice_bound(label, side, kind)\n     def map(self, mapper):\n         Map values using input correspondence (a dict, Series, or function)."}
{"id": "thefuck_22", "problem": " class SortedCorrectedCommandsSequence(object):\n     def _realise(self):\n        commands = self._remove_duplicates(self._commands)\n        self._cached = [self._cached[0]] + sorted(\n            commands, key=lambda corrected_command: corrected_command.priority)\n         self._realised = True\n         debug('SortedCommandsSequence was realised with: {}, after: {}'.format(\n             self._cached, '\\n'.join(format_stack())), self._settings)", "fixed": " class SortedCorrectedCommandsSequence(object):\n     def _realise(self):\n        if self._cached:\n            commands = self._remove_duplicates(self._commands)\n            self._cached = [self._cached[0]] + sorted(\n                commands, key=lambda corrected_command: corrected_command.priority)\n         self._realised = True\n         debug('SortedCommandsSequence was realised with: {}, after: {}'.format(\n             self._cached, '\\n'.join(format_stack())), self._settings)"}
{"id": "pandas_141", "problem": " class RangeIndex(Int64Index):\n         if self.step > 0:\n             start, stop, step = self.start, self.stop, self.step\n         else:\n            start, stop, step = (self.stop - self.step, self.start + 1, -self.step)\n         target_array = np.asarray(target)\n         if not (is_integer_dtype(target_array) and target_array.ndim == 1):", "fixed": " class RangeIndex(Int64Index):\n         if self.step > 0:\n             start, stop, step = self.start, self.stop, self.step\n         else:\n            reverse = self._range[::-1]\n            start, stop, step = reverse.start, reverse.stop, reverse.step\n         target_array = np.asarray(target)\n         if not (is_integer_dtype(target_array) and target_array.ndim == 1):"}
{"id": "fastapi_1", "problem": " def jsonable_encoder(\n                 exclude=exclude,\n                 by_alias=by_alias,\n                 exclude_unset=bool(exclude_unset or skip_defaults),\n             )\nelse:\n             obj_dict = obj.dict(\n                 include=include,\n                 exclude=exclude,", "fixed": " def jsonable_encoder(\n                 exclude=exclude,\n                 by_alias=by_alias,\n                 exclude_unset=bool(exclude_unset or skip_defaults),\n                exclude_none=exclude_none,\n                exclude_defaults=exclude_defaults,\n             )\nelse:\n            if exclude_defaults:\n                raise ValueError(\"Cannot use exclude_defaults\")\n             obj_dict = obj.dict(\n                 include=include,\n                 exclude=exclude,"}
{"id": "pandas_34", "problem": " class TimeGrouper(Grouper):\n         binner = labels = date_range(\n             freq=self.freq,\n             start=first,\n             end=last,\n             tz=ax.tz,\n             name=ax.name,\n            ambiguous=\"infer\",\n             nonexistent=\"shift_forward\",\n         )", "fixed": " class TimeGrouper(Grouper):\n         binner = labels = date_range(\n             freq=self.freq,\n             start=first,\n             end=last,\n             tz=ax.tz,\n             name=ax.name,\n            ambiguous=True,\n             nonexistent=\"shift_forward\",\n         )"}
{"id": "pandas_37", "problem": " class StringArray(PandasArray):\n             if copy:\n                 return self.copy()\n             return self\n         return super().astype(dtype, copy)\n     def _reduce(self, name, skipna=True, **kwargs):", "fixed": " class StringArray(PandasArray):\n             if copy:\n                 return self.copy()\n             return self\n        elif isinstance(dtype, _IntegerDtype):\n            arr = self._ndarray.copy()\n            mask = self.isna()\n            arr[mask] = 0\n            values = arr.astype(dtype.numpy_dtype)\n            return IntegerArray(values, mask, copy=False)\n         return super().astype(dtype, copy)\n     def _reduce(self, name, skipna=True, **kwargs):"}
{"id": "scrapy_40", "problem": " class PythonItemExporter(BaseItemExporter):\n             return dict(self._serialize_dict(value))\n         if is_listlike(value):\n             return [self._serialize_value(v) for v in value]\n        if self.binary:\n            return to_bytes(value, encoding=self.encoding)\n        else:\n            return to_unicode(value, encoding=self.encoding)\n     def _serialize_dict(self, value):\n         for key, val in six.iteritems(value):", "fixed": " class PythonItemExporter(BaseItemExporter):\n             return dict(self._serialize_dict(value))\n         if is_listlike(value):\n             return [self._serialize_value(v) for v in value]\n        encode_func = to_bytes if self.binary else to_unicode\n        if isinstance(value, (six.text_type, bytes)):\n            return encode_func(value, encoding=self.encoding)\n        return value\n     def _serialize_dict(self, value):\n         for key, val in six.iteritems(value):"}
{"id": "pandas_3", "problem": " Name: Max Speed, dtype: float64\n         if copy:\n             new_values = new_values.copy()\n        assert isinstance(self.index, DatetimeIndex)\nnew_index = self.index.to_period(freq=freq)\n         return self._constructor(new_values, index=new_index).__finalize__(\n             self, method=\"to_period\"", "fixed": " Name: Max Speed, dtype: float64\n         if copy:\n             new_values = new_values.copy()\n        if not isinstance(self.index, DatetimeIndex):\n            raise TypeError(f\"unsupported Type {type(self.index).__name__}\")\nnew_index = self.index.to_period(freq=freq)\n         return self._constructor(new_values, index=new_index).__finalize__(\n             self, method=\"to_period\""}
{"id": "fastapi_1", "problem": " class APIRoute(routing.Route):\n         response_model_exclude: Union[SetIntStr, DictIntStrAny] = set(),\n         response_model_by_alias: bool = True,\n         response_model_exclude_unset: bool = False,\n         include_in_schema: bool = True,\n         response_class: Optional[Type[Response]] = None,\n         dependency_overrides_provider: Any = None,", "fixed": " class APIRoute(routing.Route):\n         response_model_exclude: Union[SetIntStr, DictIntStrAny] = set(),\n         response_model_by_alias: bool = True,\n         response_model_exclude_unset: bool = False,\n        response_model_exclude_defaults: bool = False,\n        response_model_exclude_none: bool = False,\n         include_in_schema: bool = True,\n         response_class: Optional[Type[Response]] = None,\n         dependency_overrides_provider: Any = None,"}
{"id": "pandas_136", "problem": " class _AsOfMerge(_OrderedMerge):\n                 if self.tolerance < Timedelta(0):\n                     raise MergeError(\"tolerance must be positive\")\n            elif is_int64_dtype(lt):\n                 if not is_integer(self.tolerance):\n                     raise MergeError(msg)\n                 if self.tolerance < 0:", "fixed": " class _AsOfMerge(_OrderedMerge):\n                 if self.tolerance < Timedelta(0):\n                     raise MergeError(\"tolerance must be positive\")\n            elif is_integer_dtype(lt):\n                 if not is_integer(self.tolerance):\n                     raise MergeError(msg)\n                 if self.tolerance < 0:"}
{"id": "ansible_13", "problem": " class GalaxyCLI(CLI):\n             else:\n                 requirements = []\n                 for collection_input in collections:\n                    name, dummy, requirement = collection_input.partition(':')\n                     requirements.append((name, requirement or '*', None))\n             output_path = GalaxyCLI._resolve_path(output_path)", "fixed": " class GalaxyCLI(CLI):\n             else:\n                 requirements = []\n                 for collection_input in collections:\n                    requirement = None\n                    if os.path.isfile(to_bytes(collection_input, errors='surrogate_or_strict')) or \\\n                            urlparse(collection_input).scheme.lower() in ['http', 'https']:\n                        name = collection_input\n                    else:\n                        name, dummy, requirement = collection_input.partition(':')\n                     requirements.append((name, requirement or '*', None))\n             output_path = GalaxyCLI._resolve_path(output_path)"}
{"id": "pandas_129", "problem": " class DatetimeLikeArrayMixin(ExtensionOpsMixin, AttributesMixin, ExtensionArray)\n         if is_datetime64_any_dtype(other) and is_timedelta64_dtype(self.dtype):\n             if not isinstance(other, DatetimeLikeArrayMixin):\n                 from pandas.core.arrays import DatetimeArray", "fixed": " class DatetimeLikeArrayMixin(ExtensionOpsMixin, AttributesMixin, ExtensionArray)\n         if is_datetime64_any_dtype(other) and is_timedelta64_dtype(self.dtype):\n            if lib.is_scalar(other):\n                return Timestamp(other) - self\n             if not isinstance(other, DatetimeLikeArrayMixin):\n                 from pandas.core.arrays import DatetimeArray"}

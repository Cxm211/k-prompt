{"id": "pandas_54", "problem": " class CategoricalDtype(PandasExtensionDtype, ExtensionDtype):\n                 raise ValueError(\n                     \"Cannot specify `categories` or `ordered` together with `dtype`.\"\n                 )\n         elif is_categorical(values):", "fixed": " class CategoricalDtype(PandasExtensionDtype, ExtensionDtype):\n                 raise ValueError(\n                     \"Cannot specify `categories` or `ordered` together with `dtype`.\"\n                 )\n            elif not isinstance(dtype, CategoricalDtype):\n                raise ValueError(f\"Cannot not construct CategoricalDtype from {dtype}\")\n         elif is_categorical(values):"}
{"id": "pandas_17", "problem": " class TestPartialSetting:\n         df = orig.copy()\n        msg = \"cannot insert DatetimeIndex with incompatible label\"\n         with pytest.raises(TypeError, match=msg):\n             df.loc[100.0, :] = df.iloc[0]", "fixed": " class TestPartialSetting:\n         df = orig.copy()\n        msg = \"cannot insert DatetimeArray with incompatible label\"\n         with pytest.raises(TypeError, match=msg):\n             df.loc[100.0, :] = df.iloc[0]"}
{"id": "black_22", "problem": " def delimiter_split(line: Line, py36: bool = False) -> Iterator[Line]:\n             trailing_comma_safe = trailing_comma_safe and py36\n         leaf_priority = delimiters.get(id(leaf))\n         if leaf_priority == delimiter_priority:\n            normalize_prefix(current_line.leaves[0], inside_brackets=True)\n             yield current_line\n             current_line = Line(depth=line.depth, inside_brackets=line.inside_brackets)", "fixed": " def delimiter_split(line: Line, py36: bool = False) -> Iterator[Line]:\n             trailing_comma_safe = trailing_comma_safe and py36\n         leaf_priority = delimiters.get(id(leaf))\n         if leaf_priority == delimiter_priority:\n             yield current_line\n             current_line = Line(depth=line.depth, inside_brackets=line.inside_brackets)"}
{"id": "pandas_112", "problem": " import re\n import numpy as np\n import pytest\nfrom pandas import Interval, IntervalIndex, Timedelta, date_range, timedelta_range\n from pandas.core.indexes.base import InvalidIndexError\n import pandas.util.testing as tm", "fixed": " import re\n import numpy as np\n import pytest\nfrom pandas import (\n    CategoricalIndex,\n    Interval,\n    IntervalIndex,\n    Timedelta,\n    date_range,\n    timedelta_range,\n)\n from pandas.core.indexes.base import InvalidIndexError\n import pandas.util.testing as tm"}
{"id": "tornado_6", "problem": " class BaseAsyncIOLoop(IOLoop):\n         self.readers = set()\n         self.writers = set()\n         self.closing = False\n         IOLoop._ioloop_for_asyncio[asyncio_loop] = self\n         super(BaseAsyncIOLoop, self).initialize(**kwargs)", "fixed": " class BaseAsyncIOLoop(IOLoop):\n         self.readers = set()\n         self.writers = set()\n         self.closing = False\n        for loop in list(IOLoop._ioloop_for_asyncio):\n            if loop.is_closed():\n                del IOLoop._ioloop_for_asyncio[loop]\n         IOLoop._ioloop_for_asyncio[asyncio_loop] = self\n         super(BaseAsyncIOLoop, self).initialize(**kwargs)"}
{"id": "pandas_36", "problem": " def _use_inf_as_na(key):\n def _isna_ndarraylike(obj):\n    is_extension = is_extension_array_dtype(obj)\n    if not is_extension:\n        values = getattr(obj, \"_values\", obj)\n    else:\n        values = obj\n     dtype = values.dtype\n     if is_extension:\n        if isinstance(obj, (ABCIndexClass, ABCSeries)):\n            values = obj._values\n        else:\n            values = obj\n         result = values.isna()\n    elif isinstance(obj, ABCDatetimeArray):\n        return obj.isna()\n     elif is_string_dtype(dtype):\n        shape = values.shape\n        if is_string_like_dtype(dtype):\n            result = np.zeros(values.shape, dtype=bool)\n        else:\n            result = np.empty(shape, dtype=bool)\n            vec = libmissing.isnaobj(values.ravel())\n            result[...] = vec.reshape(shape)\n     elif needs_i8_conversion(dtype):", "fixed": " def _use_inf_as_na(key):\n def _isna_ndarraylike(obj):\n    is_extension = is_extension_array_dtype(obj.dtype)\n    values = getattr(obj, \"_values\", obj)\n     dtype = values.dtype\n     if is_extension:\n         result = values.isna()\n     elif is_string_dtype(dtype):\n        result = _isna_string_dtype(values, dtype, old=False)\n     elif needs_i8_conversion(dtype):"}
{"id": "keras_41", "problem": " import sys\n import tarfile\n import threading\n import time\n import zipfile\n from abc import abstractmethod\n from multiprocessing.pool import ThreadPool", "fixed": " import sys\n import tarfile\n import threading\n import time\nimport traceback\n import zipfile\n from abc import abstractmethod\n from multiprocessing.pool import ThreadPool"}
{"id": "youtube-dl_42", "problem": " class MetacriticIE(InfoExtractor):\n         webpage = self._download_webpage(url, video_id)\ninfo = self._download_xml('http:\n            video_id, 'Downloading info xml', transform_source=fix_xml_all_ampersand)\n         clip = next(c for c in info.findall('playList/clip') if c.find('id').text == video_id)\n         formats = []", "fixed": " class MetacriticIE(InfoExtractor):\n         webpage = self._download_webpage(url, video_id)\ninfo = self._download_xml('http:\n            video_id, 'Downloading info xml', transform_source=fix_xml_ampersands)\n         clip = next(c for c in info.findall('playList/clip') if c.find('id').text == video_id)\n         formats = []"}
{"id": "black_23", "problem": " def func_no_args():\n         print(i)\n         continue\n     return None\nasync def coroutine(arg):\n     \"Single-line docstring. Multiline is harder to reformat.\"\n     async with some_connection() as conn:\n         await conn.do_what_i_mean('SELECT bobby, tables FROM xkcd', timeout=2)", "fixed": " def func_no_args():\n         print(i)\n         continue\n    exec(\"new-style exec\", {}, {})\n     return None\nasync def coroutine(arg, exec=False):\n     \"Single-line docstring. Multiline is harder to reformat.\"\n     async with some_connection() as conn:\n         await conn.do_what_i_mean('SELECT bobby, tables FROM xkcd', timeout=2)"}
{"id": "pandas_42", "problem": " def assert_series_equal(\n             check_dtype=check_dtype,\n             obj=str(obj),\n         )\n    elif is_extension_array_dtype(left.dtype) or is_extension_array_dtype(right.dtype):\n         assert_extension_array_equal(left._values, right._values)\n     elif needs_i8_conversion(left.dtype) or needs_i8_conversion(right.dtype):", "fixed": " def assert_series_equal(\n             check_dtype=check_dtype,\n             obj=str(obj),\n         )\n    elif is_extension_array_dtype(left.dtype) and is_extension_array_dtype(right.dtype):\n         assert_extension_array_equal(left._values, right._values)\n     elif needs_i8_conversion(left.dtype) or needs_i8_conversion(right.dtype):"}
{"id": "fastapi_1", "problem": " class APIRouter(routing.Router):\n         response_model_by_alias: bool = True,\n         response_model_skip_defaults: bool = None,\n         response_model_exclude_unset: bool = False,\n         include_in_schema: bool = True,\n         response_class: Type[Response] = None,\n         name: str = None,", "fixed": " class APIRouter(routing.Router):\n         response_model_by_alias: bool = True,\n         response_model_skip_defaults: bool = None,\n         response_model_exclude_unset: bool = False,\n        response_model_exclude_defaults: bool = False,\n        response_model_exclude_none: bool = False,\n         include_in_schema: bool = True,\n         response_class: Type[Response] = None,\n         name: str = None,"}
{"id": "spacy_10", "problem": " class Errors(object):\n     E168 = (\"Unknown field: {field}\")\n     E169 = (\"Can't find module: {module}\")\n     E170 = (\"Cannot apply transition {name}: invalid for the current state.\")\n @add_codes", "fixed": " class Errors(object):\n     E168 = (\"Unknown field: {field}\")\n     E169 = (\"Can't find module: {module}\")\n     E170 = (\"Cannot apply transition {name}: invalid for the current state.\")\n    E171 = (\"Matcher.add received invalid on_match callback argument: expected \"\n            \"callable or None, but got: {arg_type}\")\n @add_codes"}
{"id": "ansible_11", "problem": " def map_obj_to_commands(updates, module):\n def map_config_to_obj(module):\n    rc, out, err = exec_command(module, 'show banner %s' % module.params['banner'])\n    if rc == 0:\n        output = out\n    else:\n        rc, out, err = exec_command(module,\n                                    'show running-config | begin banner %s'\n                                    % module.params['banner'])\n        if out:\n            output = re.search(r'\\^C(.*?)\\^C', out, re.S).group(1).strip()\n         else:\n             output = None\n     obj = {'banner': module.params['banner'], 'state': 'absent'}\n     if output:\n         obj['text'] = output", "fixed": " def map_obj_to_commands(updates, module):\n def map_config_to_obj(module):\n    out = get_config(module, flags='| begin banner %s' % module.params['banner'])\n    if out:\n        regex = 'banner ' + module.params['banner'] + ' ^C\\n'\n        if search('banner ' + module.params['banner'], out, M):\n            output = str((out.split(regex))[1].split(\"^C\\n\")[0])\n         else:\n             output = None\n    else:\n        output = None\n     obj = {'banner': module.params['banner'], 'state': 'absent'}\n     if output:\n         obj['text'] = output"}
{"id": "black_18", "problem": " def format_stdin_to_stdout(\n     finally:\n         if write_back == WriteBack.YES:\n            sys.stdout.write(dst)\n         elif write_back == WriteBack.DIFF:\n             src_name = \"<stdin>  (original)\"\n             dst_name = \"<stdin>  (formatted)\"\n            sys.stdout.write(diff(src, dst, src_name, dst_name))\n def format_file_contents(", "fixed": " def format_stdin_to_stdout(\n     finally:\n         if write_back == WriteBack.YES:\n            f = io.TextIOWrapper(\n                sys.stdout.buffer,\n                encoding=encoding,\n                newline=newline,\n                write_through=True,\n            )\n            f.write(dst)\n            f.detach()\n         elif write_back == WriteBack.DIFF:\n             src_name = \"<stdin>  (original)\"\n             dst_name = \"<stdin>  (formatted)\"\n            f = io.TextIOWrapper(\n                sys.stdout.buffer,\n                encoding=encoding,\n                newline=newline,\n                write_through=True,\n            )\n            f.write(diff(src, dst, src_name, dst_name))\n            f.detach()\n def format_file_contents("}
{"id": "fastapi_15", "problem": " class APIRouter(routing.Router):\n                     include_in_schema=route.include_in_schema,\n                     name=route.name,\n                 )\n     def get(\n         self,", "fixed": " class APIRouter(routing.Router):\n                     include_in_schema=route.include_in_schema,\n                     name=route.name,\n                 )\n            elif isinstance(route, routing.WebSocketRoute):\n                self.add_websocket_route(\n                    prefix + route.path, route.endpoint, name=route.name\n                )\n     def get(\n         self,"}
{"id": "sanic_3", "problem": " class Sanic:\n         netloc = kwargs.pop(\"_server\", None)\n         if netloc is None and external:\n            netloc = self.config.get(\"SERVER_NAME\", \"\")\n         if external:\n             if not scheme:", "fixed": " class Sanic:\n         netloc = kwargs.pop(\"_server\", None)\n         if netloc is None and external:\n            netloc = host or self.config.get(\"SERVER_NAME\", \"\")\n         if external:\n             if not scheme:"}
{"id": "pandas_97", "problem": " class TimedeltaIndex(\n         if self[0] <= other[0]:\n             left, right = self, other\n         else:\n             left, right = other, self", "fixed": " class TimedeltaIndex(\n         if self[0] <= other[0]:\n             left, right = self, other\n        elif sort is False:\n            left, right = self, other\n            left_start = left[0]\n            loc = right.searchsorted(left_start, side=\"left\")\n            right_chunk = right.values[:loc]\n            dates = concat_compat((left.values, right_chunk))\n            return self._shallow_copy(dates)\n         else:\n             left, right = other, self"}
{"id": "pandas_112", "problem": " class IntervalIndex(IntervalMixin, Index):\n             left_indexer = self.left.get_indexer(target_as_index.left)\n             right_indexer = self.right.get_indexer(target_as_index.right)\n             indexer = np.where(left_indexer == right_indexer, left_indexer, -1)\n         elif not is_object_dtype(target_as_index):\n             target_as_index = self._maybe_convert_i8(target_as_index)", "fixed": " class IntervalIndex(IntervalMixin, Index):\n             left_indexer = self.left.get_indexer(target_as_index.left)\n             right_indexer = self.right.get_indexer(target_as_index.right)\n             indexer = np.where(left_indexer == right_indexer, left_indexer, -1)\n        elif is_categorical(target_as_index):\n            categories_indexer = self.get_indexer(target_as_index.categories)\n            indexer = take_1d(categories_indexer, target_as_index.codes, fill_value=-1)\n         elif not is_object_dtype(target_as_index):\n             target_as_index = self._maybe_convert_i8(target_as_index)"}
{"id": "keras_18", "problem": " class Function(object):\n                         'supported with sparse inputs.')\n                 return self._legacy_call(inputs)\n             return self._call(inputs)\n         else:\n             if py_any(is_tensor(x) for x in inputs):", "fixed": " class Function(object):\n                         'supported with sparse inputs.')\n                 return self._legacy_call(inputs)\n            if (self.run_metadata and\n                    StrictVersion(tf.__version__.split('-')[0]) < StrictVersion('1.10.0')):\n                if py_any(is_tensor(x) for x in inputs):\n                    raise ValueError(\n                        'In order to feed symbolic tensors to a Keras model and set '\n                        '`run_metadata`, you need tensorflow 1.10 or higher.')\n                return self._legacy_call(inputs)\n             return self._call(inputs)\n         else:\n             if py_any(is_tensor(x) for x in inputs):"}
{"id": "pandas_167", "problem": " def convert_to_index_sliceable(obj, key):\n        if idx.is_all_dates:\n             try:\n                 return idx._get_string_slice(key)\n             except (KeyError, ValueError, NotImplementedError):", "fixed": " def convert_to_index_sliceable(obj, key):\n        if idx._supports_partial_string_indexing:\n             try:\n                 return idx._get_string_slice(key)\n             except (KeyError, ValueError, NotImplementedError):"}
{"id": "youtube-dl_35", "problem": " def unified_strdate(date_str):\n         '%d/%m/%Y',\n         '%d/%m/%y',\n         '%Y/%m/%d %H:%M:%S',\n         '%Y-%m-%d %H:%M:%S',\n         '%d.%m.%Y %H:%M',\n         '%d.%m.%Y %H.%M',", "fixed": " def unified_strdate(date_str):\n         '%d/%m/%Y',\n         '%d/%m/%y',\n         '%Y/%m/%d %H:%M:%S',\n        '%d/%m/%Y %H:%M:%S',\n         '%Y-%m-%d %H:%M:%S',\n         '%d.%m.%Y %H:%M',\n         '%d.%m.%Y %H.%M',"}
{"id": "ansible_7", "problem": " def generate_commands(vlan_id, to_set, to_remove):\n     if \"vlan_id\" in to_remove:\n         return [\"no vlan {0}\".format(vlan_id)]\n     for key, value in to_set.items():\n         if key == \"vlan_id\" or value is None:\n             continue\n         commands.append(\"{0} {1}\".format(key, value))\n    for key in to_remove:\n        commands.append(\"no {0}\".format(key))\n     if commands:\n         commands.insert(0, \"vlan {0}\".format(vlan_id))\n     return commands", "fixed": " def generate_commands(vlan_id, to_set, to_remove):\n     if \"vlan_id\" in to_remove:\n         return [\"no vlan {0}\".format(vlan_id)]\n    for key in to_remove:\n        if key in to_set.keys():\n            continue\n        commands.append(\"no {0}\".format(key))\n     for key, value in to_set.items():\n         if key == \"vlan_id\" or value is None:\n             continue\n         commands.append(\"{0} {1}\".format(key, value))\n     if commands:\n         commands.insert(0, \"vlan {0}\".format(vlan_id))\n     return commands"}
{"id": "pandas_42", "problem": " def assert_series_equal(\n                 f\"is not equal to {right._values}.\"\n             )\n             raise AssertionError(msg)\n    elif is_interval_dtype(left.dtype) or is_interval_dtype(right.dtype):\n         assert_interval_array_equal(left.array, right.array)\n     elif is_categorical_dtype(left.dtype) or is_categorical_dtype(right.dtype):\n         _testing.assert_almost_equal(", "fixed": " def assert_series_equal(\n                 f\"is not equal to {right._values}.\"\n             )\n             raise AssertionError(msg)\n    elif is_interval_dtype(left.dtype) and is_interval_dtype(right.dtype):\n         assert_interval_array_equal(left.array, right.array)\n     elif is_categorical_dtype(left.dtype) or is_categorical_dtype(right.dtype):\n         _testing.assert_almost_equal("}
{"id": "pandas_16", "problem": " def _make_wrapped_arith_op_with_freq(opname: str):\n         if result is NotImplemented:\n             return NotImplemented\n        new_freq = self._get_addsub_freq(other)\n         result._freq = new_freq\n         return result", "fixed": " def _make_wrapped_arith_op_with_freq(opname: str):\n         if result is NotImplemented:\n             return NotImplemented\n        new_freq = self._get_addsub_freq(other, result)\n         result._freq = new_freq\n         return result"}
{"id": "matplotlib_29", "problem": " class XAxis(Axis):\n     def get_minpos(self):\n         return self.axes.dataLim.minposx\n     def set_default_intervals(self):\n         xmin, xmax = 0., 1.", "fixed": " class XAxis(Axis):\n     def get_minpos(self):\n         return self.axes.dataLim.minposx\n    def set_inverted(self, inverted):\n        a, b = self.get_view_interval()\n        self.axes.set_xlim(sorted((a, b), reverse=inverted), auto=None)\n     def set_default_intervals(self):\n         xmin, xmax = 0., 1."}
{"id": "keras_42", "problem": " class Sequential(Model):\n                 or (inputs, targets, sample_weights)\n             steps: Total number of steps (batches of samples)\n                 to yield from `generator` before stopping.\n             max_queue_size: maximum size for the generator queue\n             workers: maximum number of processes to spin up\n             use_multiprocessing: if True, use process based threading.", "fixed": " class Sequential(Model):\n                 or (inputs, targets, sample_weights)\n             steps: Total number of steps (batches of samples)\n                 to yield from `generator` before stopping.\n                Optional for `Sequence`: if unspecified, will use\n                the `len(generator)` as a number of steps.\n             max_queue_size: maximum size for the generator queue\n             workers: maximum number of processes to spin up\n             use_multiprocessing: if True, use process based threading."}
{"id": "thefuck_6", "problem": " from thefuck.utils import eager\n @git_support\n def match(command):\n     return (\"fatal: A branch named '\" in command.output\n            and \" already exists.\" in command.output)\n @git_support\n @eager\n def get_new_command(command):\n     branch_name = re.findall(\n        r\"fatal: A branch named '([^']*)' already exists.\", command.output)[0]\n     new_command_templates = [['git branch -d {0}', 'git branch {0}'],\n                              ['git branch -d {0}', 'git checkout -b {0}'],\n                              ['git branch -D {0}', 'git branch {0}'],", "fixed": " from thefuck.utils import eager\n @git_support\n def match(command):\n     return (\"fatal: A branch named '\" in command.output\n            and \"' already exists.\" in command.output)\n @git_support\n @eager\n def get_new_command(command):\n     branch_name = re.findall(\n        r\"fatal: A branch named '(.+)' already exists.\", command.output)[0]\n    branch_name = branch_name.replace(\"'\", r\"\\'\")\n     new_command_templates = [['git branch -d {0}', 'git branch {0}'],\n                              ['git branch -d {0}', 'git checkout -b {0}'],\n                              ['git branch -D {0}', 'git branch {0}'],"}
{"id": "youtube-dl_5", "problem": " def unified_timestamp(date_str, day_first=True):\n     for expression in date_formats(day_first):\n         try:\n            dt = datetime.datetime.strptime(date_str, expression) - timezone + pm_delta\n             return calendar.timegm(dt.timetuple())\n         except ValueError:\n             pass\n     timetuple = email.utils.parsedate_tz(date_str)\n     if timetuple:\n        return calendar.timegm(timetuple.timetuple())\n def determine_ext(url, default_ext='unknown_video'):", "fixed": " def unified_timestamp(date_str, day_first=True):\n     for expression in date_formats(day_first):\n         try:\n            dt = datetime.datetime.strptime(date_str, expression) - timezone + datetime.timedelta(hours=pm_delta)\n             return calendar.timegm(dt.timetuple())\n         except ValueError:\n             pass\n     timetuple = email.utils.parsedate_tz(date_str)\n     if timetuple:\n        return calendar.timegm(timetuple) + pm_delta * 3600\n def determine_ext(url, default_ext='unknown_video'):"}
{"id": "black_18", "problem": " def format_file_in_place(\n         if lock:\n             lock.acquire()\n         try:\n            sys.stdout.write(diff_contents)\n         finally:\n             if lock:\n                 lock.release()", "fixed": " def format_file_in_place(\n         if lock:\n             lock.acquire()\n         try:\n            f = io.TextIOWrapper(\n                sys.stdout.buffer,\n                encoding=encoding,\n                newline=newline,\n                write_through=True,\n            )\n            f.write(diff_contents)\n            f.detach()\n         finally:\n             if lock:\n                 lock.release()"}
{"id": "pandas_87", "problem": " def crosstab(\n         kwargs = {\"aggfunc\": aggfunc}\n     table = df.pivot_table(\n        \"__dummy__\",\n         index=rownames,\n         columns=colnames,\n         margins=margins,", "fixed": " def crosstab(\n         kwargs = {\"aggfunc\": aggfunc}\n     table = df.pivot_table(\n        [\"__dummy__\"],\n         index=rownames,\n         columns=colnames,\n         margins=margins,"}
{"id": "pandas_46", "problem": " def cartesian_product(X):\n         b = np.zeros_like(cumprodX)\n    return [\n        np.tile(\n            np.repeat(np.asarray(com.values_from_object(x)), b[i]), np.product(a[i])\n        )\n        for i, x in enumerate(X)\n    ]", "fixed": " def cartesian_product(X):\n         b = np.zeros_like(cumprodX)\n    return [_tile_compat(np.repeat(x, b[i]), np.product(a[i])) for i, x in enumerate(X)]\ndef _tile_compat(arr, num: int):\n    if isinstance(arr, np.ndarray):\n        return np.tile(arr, num)\n    taker = np.tile(np.arange(len(arr)), num)\n    return arr.take(taker)"}
{"id": "PySnooper_2", "problem": " import functools\n import inspect\n import opcode\n import sys\n import re\n import collections", "fixed": " import functools\n import inspect\n import opcode\nimport os\n import sys\n import re\n import collections"}
